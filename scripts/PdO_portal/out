[2024-05-06 16:31:51,257][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:31:51,258][__main__][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:32:17,055][__main__][INFO] - Instantiating model <src.models.bnn.NN>
[2024-05-06 16:32:17,067][__main__][INFO] - Instantiating callbacks...
[2024-05-06 16:32:17,068][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:32:17,075][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>
[2024-05-06 16:32:17,077][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:32:17,078][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:32:17,080][__main__][INFO] - Instantiating loggers...
[2024-05-06 16:32:17,080][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:32:17,093][__main__][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:32:17,264][__main__][INFO] - Logging hyperparameters!
[2024-05-06 16:32:17,439][__main__][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/4  ━━━━━━━━━━━━━━━━━━━ 123/123 0:00:00 • 0:00:00 131.26it/s v_num: 0.000
[2024-05-06 16:32:23,823][__main__][INFO] - Starting testing!
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         mse/test          │    0.08347218483686447    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15/15 0:00:00 • 0:00:00 257.94it/s 
[2024-05-06 16:32:23,901][__main__][INFO] - Best ckpt path: /home/g15farris/bin/bayesaenet/src/logs/pretrain/runs/2024-05-06_16-31-51/checkpoints/epoch_4-step_615.ckpt
[2024-05-06 16:32:23,903][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:32:23,904][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/pretrain/runs/2024-05-06_16-31-51
[2024-05-06 16:34:37,765][__main__][INFO] - Instantiating study <optuna.create_study>
{'_target_': 'optuna.create_study', 'direction': 'minimize', 'study_name': 'bnn_lrt', 'sampler': {'_target_': 'optuna.samplers.TPESampler', 'seed': 1234, 'n_startup_trials': 10}, 'pruner': {'_target_': 'optuna.pruners.PatientPruner', 'wrapped_pruner': {'_target_': 'optuna.pruners.MedianPruner'}, 'patience': 2}, 'storage': '???', 'load_if_exists': True}
[2024-05-06 16:34:37,974][__main__][INFO] - Instantiating objective <src.tasks.hpsearch.objective_bnn>
[2024-05-06 16:34:37,994][__main__][INFO] - Starting hyperparameter search ...
[2024-05-06 16:34:38,033][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:34:38,052][src.tasks.hpsearch][INFO] - 7.50681093606854e-05, lr
[2024-05-06 16:34:38,069][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:34:38,088][src.tasks.hpsearch][INFO] - 0.029048697214318013 prior_scale
[2024-05-06 16:34:38,106][src.tasks.hpsearch][INFO] - 0.0003572140318996377 q_scale
[2024-05-06 16:34:38,123][src.tasks.hpsearch][INFO] - 1.1047391773518673 obs_scale
[2024-05-06 16:34:38,141][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 16:34:38,141][src.tasks.hpsearch][INFO] - _________________ Starting trial 000 __________________
[2024-05-06 16:34:38,141][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:34:38,141][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:35:04,579][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:35:04,588][train][INFO] - Instantiating callbacks...
[2024-05-06 16:35:04,588][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:35:04,590][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:35:04,591][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:35:04,592][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:35:04,594][train][INFO] - Instantiating loggers...
[2024-05-06 16:35:04,594][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:35:04,603][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:35:04,777][train][INFO] - Logging hyperparameters!
[2024-05-06 16:35:05,858][train][INFO] - Starting training!
[2024-05-06 16:35:05,861][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
[2024-05-06 16:37:24,302][__main__][INFO] - Instantiating study <optuna.create_study>
{'_target_': 'optuna.create_study', 'direction': 'minimize', 'study_name': 'bnn_rad', 'sampler': {'_target_': 'optuna.samplers.TPESampler', 'seed': 1234, 'n_startup_trials': 10}, 'pruner': {'_target_': 'optuna.pruners.PatientPruner', 'wrapped_pruner': {'_target_': 'optuna.pruners.MedianPruner'}, 'patience': 2}, 'storage': '???', 'load_if_exists': True}
[2024-05-06 16:37:24,556][__main__][INFO] - Instantiating objective <src.tasks.hpsearch.objective_bnn>
[2024-05-06 16:37:24,562][__main__][INFO] - Starting hyperparameter search ...
[2024-05-06 16:37:24,602][__main__][INFO] - Instantiating study <optuna.create_study>
{'_target_': 'optuna.create_study', 'direction': 'minimize', 'study_name': 'bnn_fo', 'sampler': {'_target_': 'optuna.samplers.TPESampler', 'seed': 1234, 'n_startup_trials': 10}, 'pruner': {'_target_': 'optuna.pruners.PatientPruner', 'wrapped_pruner': {'_target_': 'optuna.pruners.MedianPruner'}, 'patience': 2}, 'storage': '???', 'load_if_exists': True}
[2024-05-06 16:37:24,621][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:37:24,653][src.tasks.hpsearch][INFO] - 7.50681093606854e-05, lr
[2024-05-06 16:37:24,678][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:37:24,732][src.tasks.hpsearch][INFO] - 0.029048697214318013 prior_scale
[2024-05-06 16:37:24,784][src.tasks.hpsearch][INFO] - 0.0003572140318996377 q_scale
[2024-05-06 16:37:24,814][src.tasks.hpsearch][INFO] - 1.1047391773518673 obs_scale
[2024-05-06 16:37:24,854][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 16:37:24,855][src.tasks.hpsearch][INFO] - _________________ Starting trial 000 __________________
[2024-05-06 16:37:24,855][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:37:24,856][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
[2024-05-06 16:37:24,919][__main__][INFO] - Instantiating objective <src.tasks.hpsearch.objective_bnn>
[2024-05-06 16:37:24,928][__main__][INFO] - Starting hyperparameter search ...
[2024-05-06 16:37:25,008][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:37:25,047][src.tasks.hpsearch][INFO] - 7.50681093606854e-05, lr
[2024-05-06 16:37:25,073][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:37:25,107][src.tasks.hpsearch][INFO] - 0.029048697214318013 prior_scale
[2024-05-06 16:37:25,127][src.tasks.hpsearch][INFO] - 0.0003572140318996377 q_scale
[2024-05-06 16:37:25,151][src.tasks.hpsearch][INFO] - 1.1047391773518673 obs_scale
[2024-05-06 16:37:25,176][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 16:37:25,176][src.tasks.hpsearch][INFO] - _________________ Starting trial 000 __________________
[2024-05-06 16:37:25,177][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:37:25,177][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:37:59,768][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:37:59,781][train][INFO] - Instantiating callbacks...
[2024-05-06 16:37:59,782][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:37:59,786][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:37:59,788][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:37:59,788][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:37:59,802][train][INFO] - Instantiating loggers...
[2024-05-06 16:37:59,803][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:37:59,817][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:38:00,004][train][INFO] - Logging hyperparameters!
[2024-05-06 16:38:00,251][train][INFO] - Starting training!
[2024-05-06 16:38:00,257][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:38:03,656][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:38:03,665][train][INFO] - Instantiating callbacks...
[2024-05-06 16:38:03,665][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:38:03,668][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:38:03,668][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:38:03,669][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:38:03,670][train][INFO] - Instantiating loggers...
[2024-05-06 16:38:03,670][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:38:03,677][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:38:03,819][train][INFO] - Logging hyperparameters!
[2024-05-06 16:38:03,902][train][INFO] - Starting training!
[2024-05-06 16:38:03,905][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.39it/s v_num: 0.000
[2024-05-06 16:41:54,843][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:41:54,845][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/000
[2024-05-06 16:41:54,951][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:41:54,972][src.tasks.hpsearch][INFO] - 0.0001325538578998538, lr
[2024-05-06 16:41:54,993][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:41:55,014][src.tasks.hpsearch][INFO] - 0.20559343783957656 prior_scale
[2024-05-06 16:41:55,036][src.tasks.hpsearch][INFO] - 0.0058248182837850404 q_scale
[2024-05-06 16:41:55,056][src.tasks.hpsearch][INFO] - 0.29835107709343195 obs_scale
[2024-05-06 16:41:55,083][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:41:55,084][src.tasks.hpsearch][INFO] - _________________ Starting trial 001 __________________
[2024-05-06 16:41:55,084][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:41:55,084][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:42:27,314][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:42:27,321][train][INFO] - Instantiating callbacks...
[2024-05-06 16:42:27,322][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:42:27,325][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:42:27,326][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:42:27,326][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:42:27,327][train][INFO] - Instantiating loggers...
[2024-05-06 16:42:27,327][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:42:27,328][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:42:27,369][train][INFO] - Logging hyperparameters!
[2024-05-06 16:42:27,376][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 32.18it/s v_num: 0.000
[2024-05-06 16:43:08,816][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:43:08,817][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/000
[2024-05-06 16:43:08,910][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:43:08,928][src.tasks.hpsearch][INFO] - 0.0001325538578998538, lr
[2024-05-06 16:43:08,946][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:43:08,964][src.tasks.hpsearch][INFO] - 0.20559343783957656 prior_scale
[2024-05-06 16:43:08,983][src.tasks.hpsearch][INFO] - 0.0058248182837850404 q_scale
[2024-05-06 16:43:09,004][src.tasks.hpsearch][INFO] - 0.29835107709343195 obs_scale
[2024-05-06 16:43:09,022][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:43:09,023][src.tasks.hpsearch][INFO] - _________________ Starting trial 001 __________________
[2024-05-06 16:43:09,023][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:43:09,023][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:43:36,692][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:43:36,699][train][INFO] - Instantiating callbacks...
[2024-05-06 16:43:36,699][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:43:36,702][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:43:36,703][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:43:36,703][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:43:36,704][train][INFO] - Instantiating loggers...
[2024-05-06 16:43:36,704][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:43:36,706][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:43:36,744][train][INFO] - Logging hyperparameters!
[2024-05-06 16:43:36,752][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.81it/s v_num: 0.000
[2024-05-06 16:43:58,087][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:43:58,088][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/000
[2024-05-06 16:43:58,165][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:43:58,198][src.tasks.hpsearch][INFO] - 0.0001325538578998538, lr
[2024-05-06 16:43:58,214][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:43:58,231][src.tasks.hpsearch][INFO] - 0.20559343783957656 prior_scale
[2024-05-06 16:43:58,247][src.tasks.hpsearch][INFO] - 0.0058248182837850404 q_scale
[2024-05-06 16:43:58,264][src.tasks.hpsearch][INFO] - 0.29835107709343195 obs_scale
[2024-05-06 16:43:58,281][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:43:58,281][src.tasks.hpsearch][INFO] - _________________ Starting trial 001 __________________
[2024-05-06 16:43:58,281][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:43:58,282][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.79it/s v_num: 0.000
[2024-05-06 16:44:11,562][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:44:11,564][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/001
[2024-05-06 16:44:11,666][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:44:11,696][src.tasks.hpsearch][INFO] - 4.3020182095898586e-05, lr
[2024-05-06 16:44:11,727][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:44:11,754][src.tasks.hpsearch][INFO] - 0.05508654872763757 prior_scale
[2024-05-06 16:44:11,780][src.tasks.hpsearch][INFO] - 0.004020640881061957 q_scale
[2024-05-06 16:44:11,803][src.tasks.hpsearch][INFO] - 0.1538313853200085 obs_scale
[2024-05-06 16:44:11,826][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:44:11,827][src.tasks.hpsearch][INFO] - _________________ Starting trial 002 __________________
[2024-05-06 16:44:11,827][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:44:11,828][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 21.99it/s v_num: 0.000
[2024-05-06 16:44:56,086][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:44:56,087][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/001
[2024-05-06 16:44:56,175][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:44:56,194][src.tasks.hpsearch][INFO] - 4.3020182095898586e-05, lr
[2024-05-06 16:44:56,212][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:44:56,231][src.tasks.hpsearch][INFO] - 0.05508654872763757 prior_scale
[2024-05-06 16:44:56,249][src.tasks.hpsearch][INFO] - 0.004020640881061957 q_scale
[2024-05-06 16:44:56,267][src.tasks.hpsearch][INFO] - 0.1538313853200085 obs_scale
[2024-05-06 16:44:56,285][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:44:56,285][src.tasks.hpsearch][INFO] - _________________ Starting trial 002 __________________
[2024-05-06 16:44:56,286][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:44:56,286][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:45:23,080][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:45:23,087][train][INFO] - Instantiating callbacks...
[2024-05-06 16:45:23,087][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:45:23,090][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:45:23,090][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:45:23,091][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:45:23,092][train][INFO] - Instantiating loggers...
[2024-05-06 16:45:23,092][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:45:23,093][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:45:23,121][train][INFO] - Logging hyperparameters!
[2024-05-06 16:45:23,129][train][INFO] - Starting training!
[2024-05-06 16:45:23,132][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.20it/s v_num: 0.000
[2024-05-06 16:47:00,473][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:47:00,475][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/001
[2024-05-06 16:47:01,424][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:47:01,447][src.tasks.hpsearch][INFO] - 4.3020182095898586e-05, lr
[2024-05-06 16:47:01,469][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:47:01,490][src.tasks.hpsearch][INFO] - 0.05508654872763757 prior_scale
[2024-05-06 16:47:01,512][src.tasks.hpsearch][INFO] - 0.004020640881061957 q_scale
[2024-05-06 16:47:01,533][src.tasks.hpsearch][INFO] - 0.1538313853200085 obs_scale
[2024-05-06 16:47:01,555][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 16:47:01,556][src.tasks.hpsearch][INFO] - _________________ Starting trial 002 __________________
[2024-05-06 16:47:01,556][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:47:01,557][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 12.82it/s v_num: 0.000
[2024-05-06 16:47:15,113][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:47:15,114][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/002
[2024-05-06 16:47:15,198][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:47:15,219][src.tasks.hpsearch][INFO] - 2.336545096950015e-05, lr
[2024-05-06 16:47:15,240][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:47:15,260][src.tasks.hpsearch][INFO] - 0.1023881426733586 prior_scale
[2024-05-06 16:47:15,280][src.tasks.hpsearch][INFO] - 0.001165790000863127 q_scale
[2024-05-06 16:47:15,301][src.tasks.hpsearch][INFO] - 0.11385861721302043 obs_scale
[2024-05-06 16:47:15,320][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 16:47:15,321][src.tasks.hpsearch][INFO] - _________________ Starting trial 003 __________________
[2024-05-06 16:47:15,321][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:47:15,322][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:47:27,552][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:47:27,558][train][INFO] - Instantiating callbacks...
[2024-05-06 16:47:27,559][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:47:27,561][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:47:27,561][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:47:27,562][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:47:27,563][train][INFO] - Instantiating loggers...
[2024-05-06 16:47:27,563][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:47:27,564][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:47:27,608][train][INFO] - Logging hyperparameters!
[2024-05-06 16:47:27,618][train][INFO] - Starting training!
[2024-05-06 16:47:27,621][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:47:44,411][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:47:44,418][train][INFO] - Instantiating callbacks...
[2024-05-06 16:47:44,419][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:47:44,421][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:47:44,421][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:47:44,422][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:47:44,423][train][INFO] - Instantiating loggers...
[2024-05-06 16:47:44,423][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:47:44,424][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:47:44,452][train][INFO] - Logging hyperparameters!
[2024-05-06 16:47:44,463][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:12 • 0:00:00 3.79it/s v_num: 0.000
[2024-05-06 16:49:01,877][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:49:01,879][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/002
[2024-05-06 16:49:02,064][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:49:02,100][src.tasks.hpsearch][INFO] - 2.336545096950015e-05, lr
[2024-05-06 16:49:02,139][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:49:02,171][src.tasks.hpsearch][INFO] - 0.1023881426733586 prior_scale
[2024-05-06 16:49:02,199][src.tasks.hpsearch][INFO] - 0.001165790000863127 q_scale
[2024-05-06 16:49:02,232][src.tasks.hpsearch][INFO] - 0.11385861721302043 obs_scale
[2024-05-06 16:49:02,261][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 16:49:02,261][src.tasks.hpsearch][INFO] - _________________ Starting trial 003 __________________
[2024-05-06 16:49:02,262][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:49:02,262][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-05-06 16:49:49,516][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:49:49,525][train][INFO] - Instantiating callbacks...
[2024-05-06 16:49:49,526][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:49:49,531][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:49:49,533][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:49:49,534][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:49:49,535][train][INFO] - Instantiating loggers...
[2024-05-06 16:49:49,536][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:49:49,539][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:49:49,604][train][INFO] - Logging hyperparameters!
[2024-05-06 16:49:49,618][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:10 • 0:00:00 4.77it/s v_num: 0.000
[2024-05-06 16:51:13,158][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:51:13,160][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/002
[2024-05-06 16:51:13,262][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:51:13,283][src.tasks.hpsearch][INFO] - 2.336545096950015e-05, lr
[2024-05-06 16:51:13,304][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:51:13,322][src.tasks.hpsearch][INFO] - 0.1023881426733586 prior_scale
[2024-05-06 16:51:13,338][src.tasks.hpsearch][INFO] - 0.001165790000863127 q_scale
[2024-05-06 16:51:13,355][src.tasks.hpsearch][INFO] - 0.11385861721302043 obs_scale
[2024-05-06 16:51:13,371][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 16:51:13,372][src.tasks.hpsearch][INFO] - _________________ Starting trial 003 __________________
[2024-05-06 16:51:13,372][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:51:13,372][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:51:47,292][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:51:47,300][train][INFO] - Instantiating callbacks...
[2024-05-06 16:51:47,300][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:51:47,303][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:51:47,304][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:51:47,305][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:51:47,306][train][INFO] - Instantiating loggers...
[2024-05-06 16:51:47,306][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:51:47,307][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:51:47,346][train][INFO] - Logging hyperparameters!
[2024-05-06 16:51:47,361][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 30.85it/s v_num: 0.000
[2024-05-06 16:52:31,279][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:52:31,280][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/004
[2024-05-06 16:52:31,353][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:52:31,370][src.tasks.hpsearch][INFO] - 0.0009204696704635324, lr
[2024-05-06 16:52:31,388][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:52:31,405][src.tasks.hpsearch][INFO] - 0.17977467814503606 prior_scale
[2024-05-06 16:52:31,423][src.tasks.hpsearch][INFO] - 0.0014948832198169292 q_scale
[2024-05-06 16:52:31,440][src.tasks.hpsearch][INFO] - 0.4107788493789703 obs_scale
[2024-05-06 16:52:31,457][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 16:52:31,457][src.tasks.hpsearch][INFO] - _________________ Starting trial 005 __________________
[2024-05-06 16:52:31,458][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:52:31,458][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:52:56,200][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:52:56,207][train][INFO] - Instantiating callbacks...
[2024-05-06 16:52:56,207][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:52:56,209][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:52:56,210][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:52:56,210][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:52:56,211][train][INFO] - Instantiating loggers...
[2024-05-06 16:52:56,211][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:52:56,212][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:52:56,237][train][INFO] - Logging hyperparameters!
[2024-05-06 16:52:56,243][train][INFO] - Starting training!
[2024-05-06 16:52:56,245][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:08 • 0:00:00 2.86it/s v_num: 0.000
[2024-05-06 16:53:27,878][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:53:27,882][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/003
[2024-05-06 16:53:28,021][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:53:28,054][src.tasks.hpsearch][INFO] - 0.00017174472922154303, lr
[2024-05-06 16:53:28,081][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:53:28,111][src.tasks.hpsearch][INFO] - 0.48474869983391317 prior_scale
[2024-05-06 16:53:28,132][src.tasks.hpsearch][INFO] - 0.008271866644681318 q_scale
[2024-05-06 16:53:28,162][src.tasks.hpsearch][INFO] - 1.0724303485094406 obs_scale
[2024-05-06 16:53:28,189][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 16:53:28,190][src.tasks.hpsearch][INFO] - _________________ Starting trial 004 __________________
[2024-05-06 16:53:28,190][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:53:28,191][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:54:01,472][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:54:01,486][train][INFO] - Instantiating callbacks...
[2024-05-06 16:54:01,487][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:54:01,492][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:54:01,493][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:54:01,494][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:54:01,495][train][INFO] - Instantiating loggers...
[2024-05-06 16:54:01,495][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:54:01,496][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:54:01,549][train][INFO] - Logging hyperparameters!
[2024-05-06 16:54:01,558][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 27.40it/s v_num: 0.000
[2024-05-06 16:54:44,239][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:54:44,241][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/005
[2024-05-06 16:54:44,324][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:54:44,342][src.tasks.hpsearch][INFO] - 7.478015213333154e-05, lr
[2024-05-06 16:54:44,361][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 16:54:44,379][src.tasks.hpsearch][INFO] - 0.1156399334005538 prior_scale
[2024-05-06 16:54:44,397][src.tasks.hpsearch][INFO] - 0.002582231235363856 q_scale
[2024-05-06 16:54:44,414][src.tasks.hpsearch][INFO] - 0.15665279892931577 obs_scale
[2024-05-06 16:54:44,432][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 16:54:44,433][src.tasks.hpsearch][INFO] - _________________ Starting trial 006 __________________
[2024-05-06 16:54:44,433][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:54:44,433][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:06 • 0:00:00 3.51it/s v_num: 0.000
[2024-05-06 16:54:53,783][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:54:53,784][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/003
[2024-05-06 16:54:53,859][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 16:54:53,875][src.tasks.hpsearch][INFO] - 0.00017174472922154303, lr
[2024-05-06 16:54:53,891][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:54:53,907][src.tasks.hpsearch][INFO] - 0.48474869983391317 prior_scale
[2024-05-06 16:54:53,923][src.tasks.hpsearch][INFO] - 0.008271866644681318 q_scale
[2024-05-06 16:54:53,939][src.tasks.hpsearch][INFO] - 1.0724303485094406 obs_scale
[2024-05-06 16:54:53,955][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 16:54:53,956][src.tasks.hpsearch][INFO] - _________________ Starting trial 004 __________________
[2024-05-06 16:54:53,956][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:54:53,956][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:55:14,381][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:55:14,389][train][INFO] - Instantiating callbacks...
[2024-05-06 16:55:14,389][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:55:14,392][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:55:14,394][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:55:14,394][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:55:14,396][train][INFO] - Instantiating loggers...
[2024-05-06 16:55:14,396][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:55:14,397][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:55:14,458][train][INFO] - Logging hyperparameters!
[2024-05-06 16:55:14,467][train][INFO] - Starting training!
[2024-05-06 16:55:14,470][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:55:25,092][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:55:25,099][train][INFO] - Instantiating callbacks...
[2024-05-06 16:55:25,100][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:55:25,102][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:55:25,102][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:55:25,103][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:55:25,104][train][INFO] - Instantiating loggers...
[2024-05-06 16:55:25,104][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:55:25,105][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:55:25,131][train][INFO] - Logging hyperparameters!
[2024-05-06 16:55:25,137][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 22.09it/s v_num: 0.000
[2024-05-06 16:59:00,272][utils.utils][INFO] - Closing loggers...
[2024-05-06 16:59:00,273][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/004
[2024-05-06 16:59:00,344][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 16:59:00,359][src.tasks.hpsearch][INFO] - 0.0009204696704635324, lr
[2024-05-06 16:59:00,374][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 16:59:00,390][src.tasks.hpsearch][INFO] - 0.17977467814503606 prior_scale
[2024-05-06 16:59:00,405][src.tasks.hpsearch][INFO] - 0.0014948832198169292 q_scale
[2024-05-06 16:59:00,420][src.tasks.hpsearch][INFO] - 0.4107788493789703 obs_scale
[2024-05-06 16:59:00,436][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 16:59:00,436][src.tasks.hpsearch][INFO] - _________________ Starting trial 005 __________________
[2024-05-06 16:59:00,437][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 16:59:00,437][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1

0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:59:04,252][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:59:04,259][train][INFO] - Instantiating callbacks...
[2024-05-06 16:59:04,260][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:59:04,262][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:59:04,262][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:59:04,263][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:59:04,264][train][INFO] - Instantiating loggers...
[2024-05-06 16:59:04,264][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:59:04,265][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:59:04,306][train][INFO] - Logging hyperparameters!
[2024-05-06 16:59:04,315][train][INFO] - Starting training!
[2024-05-06 16:59:04,317][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 16:59:26,039][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 16:59:26,046][train][INFO] - Instantiating callbacks...
[2024-05-06 16:59:26,047][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 16:59:26,049][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 16:59:26,050][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 16:59:26,050][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 16:59:26,051][train][INFO] - Instantiating loggers...
[2024-05-06 16:59:26,051][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 16:59:26,052][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 16:59:26,087][train][INFO] - Logging hyperparameters!
[2024-05-06 16:59:26,096][train][INFO] - Starting training!
[2024-05-06 16:59:26,098][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:11 • 0:00:00 16.72it/s v_num: 0.000
[2024-05-06 17:00:09,133][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:00:09,135][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/006
[2024-05-06 17:00:09,230][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:00:09,250][src.tasks.hpsearch][INFO] - 0.0007995719083844353, lr
[2024-05-06 17:00:09,272][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 17:00:09,291][src.tasks.hpsearch][INFO] - 0.0816845546830656 prior_scale
[2024-05-06 17:00:09,313][src.tasks.hpsearch][INFO] - 0.004349147472454846 q_scale
[2024-05-06 17:00:09,335][src.tasks.hpsearch][INFO] - 0.11866131541331688 obs_scale
[2024-05-06 17:00:09,355][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 17:00:09,355][src.tasks.hpsearch][INFO] - _________________ Starting trial 007 __________________
[2024-05-06 17:00:09,355][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:00:09,355][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:00:37,009][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:00:37,015][train][INFO] - Instantiating callbacks...
[2024-05-06 17:00:37,016][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:00:37,018][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:00:37,019][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:00:37,020][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:00:37,021][train][INFO] - Instantiating loggers...
[2024-05-06 17:00:37,021][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:00:37,022][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:00:37,058][train][INFO] - Logging hyperparameters!
[2024-05-06 17:00:37,091][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 15.59it/s v_num: 0.000
[2024-05-06 17:02:01,124][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:02:01,126][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/005
[2024-05-06 17:02:01,219][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 17:02:01,239][src.tasks.hpsearch][INFO] - 7.478015213333154e-05, lr
[2024-05-06 17:02:01,259][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 17:02:01,278][src.tasks.hpsearch][INFO] - 0.1156399334005538 prior_scale
[2024-05-06 17:02:01,298][src.tasks.hpsearch][INFO] - 0.002582231235363856 q_scale
[2024-05-06 17:02:01,318][src.tasks.hpsearch][INFO] - 0.15665279892931577 obs_scale
[2024-05-06 17:02:01,337][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:02:01,338][src.tasks.hpsearch][INFO] - _________________ Starting trial 006 __________________
[2024-05-06 17:02:01,338][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:02:01,338][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1

0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:01:58,188][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:01:58,195][train][INFO] - Instantiating callbacks...
[2024-05-06 17:01:58,196][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:01:58,199][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:01:58,200][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:01:58,201][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:01:58,202][train][INFO] - Instantiating loggers...
[2024-05-06 17:01:58,202][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:01:58,203][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:01:58,250][train][INFO] - Logging hyperparameters!
[2024-05-06 17:01:58,261][train][INFO] - Starting training!
[2024-05-06 17:01:58,263][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 12.66it/s v_num: 0.000
[2024-05-06 17:02:26,747][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:02:26,749][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/007
[2024-05-06 17:02:26,833][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:02:26,850][src.tasks.hpsearch][INFO] - 1.1462886732717548e-05, lr
[2024-05-06 17:02:26,866][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:02:26,880][src.tasks.hpsearch][INFO] - 0.4124747947662307 prior_scale
[2024-05-06 17:02:26,895][src.tasks.hpsearch][INFO] - 0.00044814115470497614 q_scale
[2024-05-06 17:02:26,909][src.tasks.hpsearch][INFO] - 0.17860915820030454 obs_scale
[2024-05-06 17:02:26,924][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:02:26,924][src.tasks.hpsearch][INFO] - _________________ Starting trial 008 __________________
[2024-05-06 17:02:26,924][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:02:26,925][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
[2024-05-06 17:02:27,173][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:02:27,184][train][INFO] - Instantiating callbacks...
[2024-05-06 17:02:27,184][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:02:27,187][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:02:27,188][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:02:27,189][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:02:27,190][train][INFO] - Instantiating loggers...
[2024-05-06 17:02:27,190][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:02:27,191][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:02:27,237][train][INFO] - Logging hyperparameters!
[2024-05-06 17:02:27,246][train][INFO] - Starting training!
[2024-05-06 17:02:27,248][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:02:52,569][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:02:52,581][train][INFO] - Instantiating callbacks...
[2024-05-06 17:02:52,582][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:02:52,586][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:02:52,587][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:02:52,588][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:02:52,589][train][INFO] - Instantiating loggers...
[2024-05-06 17:02:52,590][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:02:52,591][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:02:52,633][train][INFO] - Logging hyperparameters!
[2024-05-06 17:02:52,646][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 28.60it/s v_num: 0.000
[2024-05-06 17:05:55,730][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:05:55,732][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/008
[2024-05-06 17:05:55,811][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 17:05:55,826][src.tasks.hpsearch][INFO] - 0.0002588548618299899, lr
[2024-05-06 17:05:55,842][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 17:05:55,857][src.tasks.hpsearch][INFO] - 0.21075404848706095 prior_scale
[2024-05-06 17:05:55,873][src.tasks.hpsearch][INFO] - 0.0015787361777166986 q_scale
[2024-05-06 17:05:55,890][src.tasks.hpsearch][INFO] - 0.23920082660450653 obs_scale
[2024-05-06 17:05:55,906][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 17:05:55,906][src.tasks.hpsearch][INFO] - _________________ Starting trial 009 __________________
[2024-05-06 17:05:55,907][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:05:55,907][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:06:22,631][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:06:22,638][train][INFO] - Instantiating callbacks...
[2024-05-06 17:06:22,639][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:06:22,641][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:06:22,642][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:06:22,642][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:06:22,643][train][INFO] - Instantiating loggers...
[2024-05-06 17:06:22,643][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:06:22,644][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:06:22,679][train][INFO] - Logging hyperparameters!
[2024-05-06 17:06:30,984][train][INFO] - Starting training!
[2024-05-06 17:06:30,988][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━━━━━ 192/192 0:00:24 • 0:00:00 7.78it/s v_num: 0.000
[2024-05-06 17:08:37,721][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 13.
[2024-05-06 17:08:37,758][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:08:37,843][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:08:37,873][src.tasks.hpsearch][INFO] - 0.0007995719083844353, lr
[2024-05-06 17:08:37,900][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 17:08:37,930][src.tasks.hpsearch][INFO] - 0.0816845546830656 prior_scale
[2024-05-06 17:08:37,963][src.tasks.hpsearch][INFO] - 0.004349147472454846 q_scale
[2024-05-06 17:08:38,010][src.tasks.hpsearch][INFO] - 0.11866131541331688 obs_scale
[2024-05-06 17:08:38,076][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 17:08:38,077][src.tasks.hpsearch][INFO] - _________________ Starting trial 007 __________________
[2024-05-06 17:08:38,078][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:08:38,079][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:08:45,587][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:08:45,594][train][INFO] - Instantiating callbacks...
[2024-05-06 17:08:45,595][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:08:45,598][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:08:45,598][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:08:45,599][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:08:45,600][train][INFO] - Instantiating loggers...
[2024-05-06 17:08:45,600][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:08:45,601][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:08:45,640][train][INFO] - Logging hyperparameters!
[2024-05-06 17:08:45,647][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:09:12,294][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:09:12,304][train][INFO] - Instantiating callbacks...
[2024-05-06 17:09:12,305][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:09:12,311][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:09:12,313][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:09:12,315][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:09:12,317][train][INFO] - Instantiating loggers...
[2024-05-06 17:09:12,318][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:09:12,320][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:09:12,385][train][INFO] - Logging hyperparameters!
[2024-05-06 17:09:12,398][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:10 • 0:00:00 9.52it/s v_num: 0.000
[2024-05-06 17:09:42,435][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:09:42,437][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/009
[2024-05-06 17:09:42,556][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:09:42,582][src.tasks.hpsearch][INFO] - 0.0002821061536892603, lr
[2024-05-06 17:09:42,604][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:09:42,627][src.tasks.hpsearch][INFO] - 0.011399374124093259 prior_scale
[2024-05-06 17:09:42,651][src.tasks.hpsearch][INFO] - 0.0001303181116735239 q_scale
[2024-05-06 17:09:42,674][src.tasks.hpsearch][INFO] - 1.71097163704802 obs_scale
[2024-05-06 17:09:42,697][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:09:42,697][src.tasks.hpsearch][INFO] - _________________ Starting trial 010 __________________
[2024-05-06 17:09:42,698][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:09:42,698][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:10:14,518][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:10:14,530][train][INFO] - Instantiating callbacks...
[2024-05-06 17:10:14,531][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:10:14,535][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:10:14,536][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:10:14,538][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:10:14,539][train][INFO] - Instantiating loggers...
[2024-05-06 17:10:14,540][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:10:14,541][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:10:14,582][train][INFO] - Logging hyperparameters!
[2024-05-06 17:10:14,593][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:12 • 0:00:00 3.93it/s v_num: 0.000
[2024-05-06 17:12:13,018][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:12:13,021][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/007
[2024-05-06 17:12:13,113][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:12:13,132][src.tasks.hpsearch][INFO] - 1.1462886732717548e-05, lr
[2024-05-06 17:12:13,151][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:12:13,171][src.tasks.hpsearch][INFO] - 0.4124747947662307 prior_scale
[2024-05-06 17:12:13,193][src.tasks.hpsearch][INFO] - 0.00044814115470497614 q_scale
[2024-05-06 17:12:13,213][src.tasks.hpsearch][INFO] - 0.17860915820030454 obs_scale
[2024-05-06 17:12:13,234][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:12:13,234][src.tasks.hpsearch][INFO] - _________________ Starting trial 008 __________________
[2024-05-06 17:12:13,235][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:12:13,235][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:12:39,755][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:12:39,765][train][INFO] - Instantiating callbacks...
[2024-05-06 17:12:39,766][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:12:39,769][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:12:39,770][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:12:39,770][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:12:39,772][train][INFO] - Instantiating loggers...
[2024-05-06 17:12:39,772][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:12:39,773][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:12:39,815][train][INFO] - Logging hyperparameters!
[2024-05-06 17:12:39,821][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:11 • 0:00:00 16.84it/s v_num: 0.000
[2024-05-06 17:13:42,876][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:13:42,878][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/010
[2024-05-06 17:13:42,973][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:13:42,993][src.tasks.hpsearch][INFO] - 0.00023494228630274776, lr
[2024-05-06 17:13:43,013][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:13:43,034][src.tasks.hpsearch][INFO] - 0.011706067857616107 prior_scale
[2024-05-06 17:13:43,056][src.tasks.hpsearch][INFO] - 0.00011539328391897615 q_scale
[2024-05-06 17:13:43,077][src.tasks.hpsearch][INFO] - 1.9746524398983545 obs_scale
[2024-05-06 17:13:43,098][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:13:43,098][src.tasks.hpsearch][INFO] - _________________ Starting trial 011 __________________
[2024-05-06 17:13:43,098][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:13:43,099][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:07 • 0:00:00 6.03it/s v_num: 0.000
[2024-05-06 17:13:45,845][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:13:45,847][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/007
[2024-05-06 17:13:45,975][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:13:46,000][src.tasks.hpsearch][INFO] - 1.1462886732717548e-05, lr
[2024-05-06 17:13:46,028][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:13:46,049][src.tasks.hpsearch][INFO] - 0.4124747947662307 prior_scale
[2024-05-06 17:13:46,079][src.tasks.hpsearch][INFO] - 0.00044814115470497614 q_scale
[2024-05-06 17:13:46,109][src.tasks.hpsearch][INFO] - 0.17860915820030454 obs_scale
[2024-05-06 17:13:46,136][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:13:46,136][src.tasks.hpsearch][INFO] - _________________ Starting trial 008 __________________
[2024-05-06 17:13:46,137][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:13:46,137][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:14:26,807][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:14:26,817][train][INFO] - Instantiating callbacks...
[2024-05-06 17:14:26,817][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:14:26,821][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:14:26,825][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:14:26,829][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:14:26,832][train][INFO] - Instantiating loggers...
[2024-05-06 17:14:26,833][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:14:26,834][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:14:26,909][train][INFO] - Logging hyperparameters!
[2024-05-06 17:14:26,918][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 19.49it/s v_num: 0.000
[2024-05-06 17:16:47,617][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:16:47,619][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/008
[2024-05-06 17:16:47,697][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 17:16:47,713][src.tasks.hpsearch][INFO] - 0.0002588548618299899, lr
[2024-05-06 17:16:47,731][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 17:16:47,750][src.tasks.hpsearch][INFO] - 0.21075404848706095 prior_scale
[2024-05-06 17:16:47,770][src.tasks.hpsearch][INFO] - 0.0015787361777166986 q_scale
[2024-05-06 17:16:47,791][src.tasks.hpsearch][INFO] - 0.23920082660450653 obs_scale
[2024-05-06 17:16:47,813][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 17:16:47,814][src.tasks.hpsearch][INFO] - _________________ Starting trial 009 __________________
[2024-05-06 17:16:47,814][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:16:47,814][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 28.16it/s v_num: 0.000
[2024-05-06 17:17:13,261][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:17:13,263][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/011
[2024-05-06 17:17:13,355][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:17:13,376][src.tasks.hpsearch][INFO] - 0.00035680140452935133, lr
[2024-05-06 17:17:13,396][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:17:13,416][src.tasks.hpsearch][INFO] - 0.016283693256007512 prior_scale
[2024-05-06 17:17:13,437][src.tasks.hpsearch][INFO] - 0.009783947466441957 q_scale
[2024-05-06 17:17:13,457][src.tasks.hpsearch][INFO] - 0.8975518465396408 obs_scale
[2024-05-06 17:17:13,478][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:17:13,478][src.tasks.hpsearch][INFO] - _________________ Starting trial 012 __________________
[2024-05-06 17:17:13,479][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:17:13,479][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
[2024-05-06 17:17:14,828][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:17:14,836][train][INFO] - Instantiating callbacks...
[2024-05-06 17:17:14,837][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:17:14,839][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:17:14,840][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:17:14,841][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:17:14,842][train][INFO] - Instantiating loggers...
[2024-05-06 17:17:14,842][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:17:14,843][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:17:14,880][train][INFO] - Logging hyperparameters!
[2024-05-06 17:17:14,888][train][INFO] - Starting training!
[2024-05-06 17:17:14,890][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:17:38,978][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:17:38,986][train][INFO] - Instantiating callbacks...
[2024-05-06 17:17:38,987][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:17:38,990][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:17:38,990][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:17:38,991][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:17:38,992][train][INFO] - Instantiating loggers...
[2024-05-06 17:17:38,992][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:17:38,993][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:17:39,020][train][INFO] - Logging hyperparameters!
[2024-05-06 17:17:39,028][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 31.28it/s v_num: 0.000
[2024-05-06 17:20:37,134][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:20:37,136][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/012
[2024-05-06 17:20:37,233][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:20:37,276][src.tasks.hpsearch][INFO] - 0.0004187758560483171, lr
[2024-05-06 17:20:37,304][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:20:37,333][src.tasks.hpsearch][INFO] - 0.029998790133936127 prior_scale
[2024-05-06 17:20:37,360][src.tasks.hpsearch][INFO] - 0.009940889714004643 q_scale
[2024-05-06 17:20:37,387][src.tasks.hpsearch][INFO] - 0.7555075323585013 obs_scale
[2024-05-06 17:20:37,405][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:20:37,406][src.tasks.hpsesearch][INFO] - _________________ Starting trial 009 __________________
[2024-05-06 17:20:12,800][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:20:12,800][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:20:55,318][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:20:55,325][train][INFO] - Instantiating callbacks...
[2024-05-06 17:20:55,326][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:20:55,329][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:20:55,330][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:20:55,330][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:20:55,331][train][INFO] - Instantiating loggers...
[2024-05-06 17:20:55,331][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:20:55,332][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:20:55,390][train][INFO] - Logging hyperparameters!
[2024-05-06 17:20:55,401][train][INFO] - Starting training!
[2024-05-06 17:20:55,403][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:21:25,242][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:21:25,250][train][INFO] - Instantiating callbacks...
[2024-05-06 17:21:25,251][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:21:25,254][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:21:25,255][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:21:25,256][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:21:25,257][train][INFO] - Instantiating loggers...
[2024-05-06 17:21:25,257][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:21:25,258][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:21:25,299][train][INFO] - Logging hyperparameters!
[2024-05-06 17:21:25,309][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:11 • 0:00:00 8.61it/s v_num: 0.000
[2024-05-06 17:22:58,270][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:22:58,271][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/009
[2024-05-06 17:22:58,346][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:22:58,363][src.tasks.hpsearch][INFO] - 0.0002821061536892603, lr
[2024-05-06 17:22:58,378][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:22:58,394][src.tasks.hpsearch][INFO] - 0.011399374124093259 prior_scale
[2024-05-06 17:22:58,412][src.tasks.hpsearch][INFO] - 0.0001303181116735239 q_scale
[2024-05-06 17:22:58,430][src.tasks.hpsearch][INFO] - 1.71097163704802 obs_scale
[2024-05-06 17:22:58,447][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:22:58,447][src.tasks.hpsearch][INFO] - _________________ Starting trial 010 __________________
[2024-05-06 17:22:58,447][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:22:58,448][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:23:23,865][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:23:23,872][train][INFO] - Instantiating callbacks...
[2024-05-06 17:23:23,873][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:23:23,876][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:23:23,876][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:23:23,877][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:23:23,878][train][INFO] - Instantiating loggers...
[2024-05-06 17:23:23,878][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:23:23,879][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:23:23,914][train][INFO] - Logging hyperparameters!
[2024-05-06 17:23:23,922][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 28.51it/s v_num: 0.000
[2024-05-06 17:25:20,475][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:25:20,477][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/013
[2024-05-06 17:25:20,577][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:25:20,599][src.tasks.hpsearch][INFO] - 0.00047099056233148326, lr
[2024-05-06 17:25:20,621][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:25:20,643][src.tasks.hpsearch][INFO] - 0.027265739595470306 prior_scale
[2024-05-06 17:25:20,665][src.tasks.hpsearch][INFO] - 0.008086747435543941 q_scale
[2024-05-06 17:25:20,686][src.tasks.hpsearch][INFO] - 0.7168746872185715 obs_scale
[2024-05-06 17:25:20,706][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 17:25:20,707][src.tasks.hpsearch][INFO] - _________________ Starting trial 014 __________________
[2024-05-06 17:25:20,707][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:25:20,707][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:25:49,935][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:25:49,942][train][INFO] - Instantiating callbacks...
[2024-05-06 17:25:49,943][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:25:49,946][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:25:49,947][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:25:49,947][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:25:49,948][train][INFO] - Instantiating loggers...
[2024-05-06 17:25:49,949][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:25:49,950][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:25:49,989][train][INFO] - Logging hyperparameters!
[2024-05-06 17:25:49,996][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 15.50it/s v_num: 0.000
[2024-05-06 17:26:40,498][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:26:40,500][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/014
[2024-05-06 17:26:40,580][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:26:40,602][src.tasks.hpsearch][INFO] - 0.000471933226301514, lr
[2024-05-06 17:26:40,621][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:26:40,643][src.tasks.hpsearch][INFO] - 0.02201666456969733 prior_scale
[2024-05-06 17:26:40,666][src.tasks.hpsearch][INFO] - 0.0025463997550914342 q_scale
[2024-05-06 17:26:40,688][src.tasks.hpsearch][INFO] - 0.6299642046168044 obs_scale
[2024-05-06 17:26:40,709][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:26:40,710][src.tasks.hpsearch][INFO] - _________________ Starting trial 015 __________________
[2024-05-06 17:26:40,710][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:26:40,711][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.79it/s v_num: 0.000
[2024-05-06 17:27:05,455][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:27:05,456][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/010
[2024-05-06 17:27:05,538][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:27:05,571][src.tasks.hpsearch][INFO] - 0.00023494228630274776, lr
[2024-05-06 17:27:05,590][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:27:05,608][src.tasks.hpsearch][INFO] - 0.011706067857616107 prior_scale
[2024-05-06 17:27:05,627][src.tasks.hpsearch][INFO] - 0.00011539328391897615 q_scale
[2024-05-06 17:27:05,647][src.tasks.hpsearch][INFO] - 1.9746524398983545 obs_scale
[2024-05-06 17:27:05,665][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:27:05,666][src.tasks.hpsearch][INFO] - _________________ Starting trial 011 __________________
[2024-05-06 17:27:05,666][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:27:05,666][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:13 • 0:00:00 7.31it/s v_num: 0.000
[2024-05-06 17:27:18,455][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:27:18,457][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/009
[2024-05-06 17:27:18,585][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:27:18,616][src.tasks.hpsearch][INFO] - 0.0002821061536892603, lr
[2024-05-06 17:27:18,654][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:27:18,685][src.tasks.hpsearch][INFO] - 0.011399374124093259 prior_scale
[2024-05-06 17:27:18,722][src.tasks.hpsearch][INFO] - 0.0001303181116735239 q_scale
[2024-05-06 17:27:18,756][src.tasks.hpsearch][INFO] - 1.71097163704802 obs_scale
[2024-05-06 17:27:18,789][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:27:18,790][src.tasks.hpsearch][INFO] - _________________ Starting trial 010 __________________
[2024-05-06 17:27:18,790][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:27:18,790][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:27:30,281][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:27:30,288][train][INFO] - Instantiating callbacks...
[2024-05-06 17:27:30,289][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:27:30,291][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:27:30,291][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:27:30,292][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:27:30,293][train][INFO] - Instantiating loggers...
[2024-05-06 17:27:30,293][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:27:30,294][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:27:30,320][train][INFO] - Logging hyperparameters!
[2024-05-06 17:27:30,328][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 19.88it/s v_num: 0.000
[2024-05-06 17:31:53,760][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:31:53,762][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/011
[2024-05-06 17:31:53,859][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:31:53,882][src.tasks.hpsearch][INFO] - 0.00035680140452935133, lr
[2024-05-06 17:31:53,903][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:31:53,924][src.tasks.hpsearch][INFO] - 0.016283693256007512 prior_scale
[2024-05-06 17:31:53,946][src.tasks.hpsearch][INFO] - 0.009783947466441957 q_scale
[2024-05-06 17:31:53,967][src.tasks.hpsearch][INFO] - 0.8975518465396408 obs_scale
[2024-05-06 17:31:53,988][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:31:53,988][src.tasks.hpsearch][INFO] - _________________ Starting trial 012 __________________
[2024-05-06 17:31:53,989][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:31:53,989][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:32:19,982][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:32:19,990][train][INFO] - Instantiating callbacks...
[2024-05-06 17:32:19,990][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:32:19,993][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:32:19,994][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:32:19,995][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:32:19,996][train][INFO] - Instantiating loggers...
[2024-05-06 17:32:19,996][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:32:19,997][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:32:20,035][train][INFO] - Logging hyperparameters!
[2024-05-06 17:32:20,043][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 33.15it/s v_num: 0.000
[2024-05-06 17:32:41,126][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:32:41,127][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/015
[2024-05-06 17:32:41,198][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:32:41,214][src.tasks.hpsearch][INFO] - 0.000547121976155858, lr
[2024-05-06 17:32:41,229][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:32:41,244][src.tasks.hpsearch][INFO] - 0.04133742496369643 prior_scale
[2024-05-06 17:32:41,260][src.tasks.hpsearch][INFO] - 0.0025555101989354345 q_scale
[2024-05-06 17:32:41,277][src.tasks.hpsearch][INFO] - 0.5485259914682614 obs_scale
[2024-05-06 17:32:41,293][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:32:41,293][src.tasks.hpsearch][INFO] - _________________ Starting trial 016 __________________
[2024-05-06 17:32:41,293][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:32:41,294][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:33:06,358][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:33:06,366][train][INFO] - Instantiating callbacks...
[2024-05-06 17:33:06,366][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:33:06,369][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:33:06,369][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:33:06,370][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:33:06,371][train][INFO] - Instantiating loggers...
[2024-05-06 17:33:06,371][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:33:06,372][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:33:06,398][train][INFO] - Logging hyperparameters!
[2024-05-06 17:33:06,408][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.81it/s v_num: 0.000
[2024-05-06 17:33:57,372][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:33:57,374][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/010
[2024-05-06 17:33:57,468][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:33:57,495][src.tasks.hpsearch][INFO] - 0.00023494228630274776, lr
[2024-05-06 17:33:57,530][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:33:57,553][src.tasks.hpsearch][INFO] - 0.011706067857616107 prior_scale
[2024-05-06 17:33:57,592][src.tasks.hpsearch][INFO] - 0.00011539328391897615 q_scale
[2024-05-06 17:33:57,618][src.tasks.hpsearch][INFO] - 1.9746524398983545 obs_scale
[2024-05-06 17:33:57,652][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:33:57,652][src.tasks.hpsearch][INFO] - _________________ Starting trial 011 __________________
[2024-05-06 17:33:57,652][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:33:57,653][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:34:30,658][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:34:30,667][train][INFO] - Instantiating callbacks...
[2024-05-06 17:34:30,668][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:34:30,671][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:34:30,672][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:34:30,673][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:34:30,675][train][INFO] - Instantiating loggers...
[2024-05-06 17:34:30,675][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:34:30,677][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:34:30,728][train][INFO] - Logging hyperparameters!
[2024-05-06 17:34:30,741][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.71it/s v_num: 0.000
[2024-05-06 17:36:25,389][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:36:25,391][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/012
[2024-05-06 17:36:25,460][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:36:25,475][src.tasks.hpsearch][INFO] - 0.0004187758560483171, lr
[2024-05-06 17:36:25,490][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:36:25,506][src.tasks.hpsearch][INFO] - 0.029998790133936127 prior_scale
[2024-05-06 17:36:25,524][src.tasks.hpsearch][INFO] - 0.009940889714004643 q_scale
[2024-05-06 17:36:25,542][src.tasks.hpsearch][INFO] - 0.7555075323585013 obs_scale
[2024-05-06 17:36:25,559][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:36:25,559][src.tasks.hpsearch][INFO] - _________________ Starting trial 013 __________________
[2024-05-06 17:36:25,560][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:36:25,560][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:36:49,677][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:36:49,683][train][INFO] - Instantiating callbacks...
[2024-05-06 17:36:49,683][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:36:49,686][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:36:49,687][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:36:49,687][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:36:49,688][train][INFO] - Instantiating loggers...
[2024-05-06 17:36:49,688][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:36:49,689][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:36:49,726][train][INFO] - Logging hyperparameters!
[2024-05-06 17:36:49,733][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:18 • 0:00:00 20.98it/s v_num: 0.000
[2024-05-06 17:38:54,673][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:38:54,675][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/016
[2024-05-06 17:38:54,799][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:38:54,826][src.tasks.hpsearch][INFO] - 0.0006911809612075885, lr
[2024-05-06 17:38:54,854][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:38:54,915][src.tasks.hpsearch][INFO] - 0.04931702773628011 prior_scale
[2024-05-06 17:38:54,977][src.tasks.hpsearch][INFO] - 0.0006396905880911574 q_scale
[2024-05-06 17:38:55,039][src.tasks.hpsearch][INFO] - 0.49326200224837785 obs_scale
[2024-05-06 17:38:55,096][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:38:55,098][src.tasks.hpsearch][INFO] - _________________ Starting trial 017 __________________
[2024-05-06 17:38:55,099][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:38:55,100][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:39:20,181][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:39:20,188][train][INFO] - Instantiating callbacks...
[2024-05-06 17:39:20,189][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:39:20,191][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:39:20,191][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:39:20,192][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:39:20,193][train][INFO] - Instantiating loggers...
[2024-05-06 17:39:20,193][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:39:20,194][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:39:20,232][train][INFO] - Logging hyperparameters!
[2024-05-06 17:39:20,240][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:10 • 0:00:00 17.49it/s v_num: 0.000
[2024-05-06 17:39:27,463][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:39:27,465][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/011
[2024-05-06 17:39:27,626][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:39:27,660][src.tasks.hpsearch][INFO] - 0.00035680140452935133, lr
[2024-05-06 17:39:27,696][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:39:27,730][src.tasks.hpsearch][INFO] - 0.016283693256007512 prior_scale
[2024-05-06 17:39:27,756][src.tasks.hpsearch][INFO] - 0.009783947466441957 q_scale
[2024-05-06 17:39:27,784][src.tasks.hpsearch][INFO] - 0.8975518465396408 obs_scale
[2024-05-06 17:39:27,810][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:39:27,811][src.tasks.hpsearch][INFO] - _________________ Starting trial 012 __________________
[2024-05-06 17:39:27,811][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:39:27,811][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:39:55,064][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:39:55,071][train][INFO] - Instantiating callbacks...
[2024-05-06 17:39:55,072][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:39:55,076][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:39:55,077][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:39:55,078][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:39:55,079][train][INFO] - Instantiating loggers...
[2024-05-06 17:39:55,079][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:39:55,080][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:39:55,119][train][INFO] - Logging hyperparameters!
[2024-05-06 17:39:55,128][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 20.02it/s v_num: 0.000
[2024-05-06 17:41:03,867][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:41:03,869][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/013
[2024-05-06 17:41:03,951][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:41:03,969][src.tasks.hpsearch][INFO] - 0.00047099056233148326, lr
[2024-05-06 17:41:03,986][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:41:04,004][src.tasks.hpsearch][INFO] - 0.027265739595470306 prior_scale
[2024-05-06 17:41:04,021][src.tasks.hpsearch][INFO] - 0.008086747435543941 q_scale
[2024-05-06 17:41:04,041][src.tasks.hpsearch][INFO] - 0.7168746872185715 obs_scale
[2024-05-06 17:41:04,058][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 17:41:04,059][src.tasks.hpsearch][INFO] - _________________ Starting trial 014 __________________
[2024-05-06 17:41:04,059][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:41:04,059][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:41:34,325][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:41:34,333][train][INFO] - Instantiating callbacks...
[2024-05-06 17:41:34,333][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:41:34,337][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:41:34,337][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:41:34,338][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:41:34,339][train][INFO] - Instantiating loggers...
[2024-05-06 17:41:34,339][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:41:34,340][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:41:34,379][train][INFO] - Logging hyperparameters!
[2024-05-06 17:41:34,387][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 23.73it/s v_num: 0.000
[2024-05-06 17:43:25,233][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:43:25,234][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/012
[2024-05-06 17:43:25,334][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:43:25,356][src.tasks.hpsearch][INFO] - 0.0004187758560483171, lr
[2024-05-06 17:43:25,376][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:43:25,399][src.tasks.hpsearch][INFO] - 0.029998790133936127 prior_scale
[2024-05-06 17:43:25,420][src.tasks.hpsearch][INFO] - 0.009940889714004643 q_scale
[2024-05-06 17:43:25,441][src.tasks.hpsearch][INFO] - 0.7555075323585013 obs_scale
[2024-05-06 17:43:25,462][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 17:43:25,463][src.tasks.hpsearch][INFO] - _________________ Starting trial 013 __________________
[2024-05-06 17:43:25,463][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:43:25,463][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:43:50,568][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:43:50,578][train][INFO] - Instantiating callbacks...
[2024-05-06 17:43:50,578][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:43:50,581][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:43:50,582][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:43:50,582][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:43:50,976][train][INFO] - Instantiating loggers...
[2024-05-06 17:43:50,976][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:43:50,978][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:43:51,016][train][INFO] - Logging hyperparameters!
[2024-05-06 17:43:51,027][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
   
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.12it/s v_num: 0.000
[2024-05-06 17:45:19,092][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:45:19,094][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/017
[2024-05-06 17:45:19,206][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:45:19,231][src.tasks.hpsearch][INFO] - 0.0007263091335083298, lr
[2024-05-06 17:45:19,254][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:45:19,278][src.tasks.hpsearch][INFO] - 0.049890828546736744 prior_scale
[2024-05-06 17:45:19,302][src.tasks.hpsearch][INFO] - 0.0006414587910215425 q_scale
[2024-05-06 17:45:19,326][src.tasks.hpsearch][INFO] - 0.4841366687300466 obs_scale
[2024-05-06 17:45:19,350][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:45:19,351][src.tasks.hpsearch][INFO] - _________________ Starting trial 018 __________________
[2024-05-06 17:45:19,351][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:45:19,351][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:45:45,444][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:45:45,452][train][INFO] - Instantiating callbacks...
[2024-05-06 17:45:45,452][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:45:45,456][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:45:45,456][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:45:45,457][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:45:45,458][train][INFO] - Instantiating loggers...
[2024-05-06 17:45:45,458][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:45:45,459][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:45:45,494][train][INFO] - Logging hyperparameters!
[2024-05-06 17:45:45,501][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 20.70it/s v_num: 0.000
[2024-05-06 17:47:24,432][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:47:24,434][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/013
[2024-05-06 17:47:24,535][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:47:24,558][src.tasks.hpsearch][INFO] - 0.00047099056233148326, lr
[2024-05-06 17:47:24,579][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:47:24,601][src.tasks.hpsearch][INFO] - 0.027265739595470306 prior_scale
[2024-05-06 17:47:24,623][src.tasks.hpsearch][INFO] - 0.008086747435543941 q_scale
[2024-05-06 17:47:24,645][src.tasks.hpsearch][INFO] - 0.7168746872185715 obs_scale
[2024-05-06 17:47:24,668][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 17:47:24,668][src.tasks.hpsearch][INFO] - _________________ Starting trial 014 __________________
[2024-05-06 17:47:24,669][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:47:24,669][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:47:57,697][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:47:57,704][train][INFO] - Instantiating callbacks...
[2024-05-06 17:47:57,705][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:47:57,709][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:47:57,710][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:47:57,711][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:47:57,712][train][INFO] - Instantiating loggers...
[2024-05-06 17:47:57,712][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:47:57,713][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:47:57,754][train][INFO] - Logging hyperparameters!
[2024-05-06 17:47:57,765][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.04it/s v_num: 0.000
[2024-05-06 17:49:23,093][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:49:23,095][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/014
[2024-05-06 17:49:23,202][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:49:23,224][src.tasks.hpsearch][INFO] - 0.000471933226301514, lr
[2024-05-06 17:49:23,246][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:49:23,270][src.tasks.hpsearch][INFO] - 0.02201666456969733 prior_scale
[2024-05-06 17:49:23,293][src.tasks.hpsearch][INFO] - 0.0025463997550914342 q_scale
[2024-05-06 17:49:23,317][src.tasks.hpsearch][INFO] - 0.6299642046168044 obs_scale
[2024-05-06 17:49:23,340][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:49:23,341][src.tasks.hpsearch][INFO] - _________________ Starting trial 015 __________________
[2024-05-06 17:49:23,341][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:49:23,341][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:49:51,392][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:49:51,400][train][INFO] - Instantiating callbacks...
[2024-05-06 17:49:51,400][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:49:51,404][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:49:51,405][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:49:51,405][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:49:51,406][train][INFO] - Instantiating loggers...
[2024-05-06 17:49:51,407][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:49:51,408][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:49:51,452][train][INFO] - Logging hyperparameters!
[2024-05-06 17:49:51,464][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:18 • 0:00:00 21.07it/s v_num: 0.000
[2024-05-06 17:50:55,779][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:50:55,781][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/015
[2024-05-06 17:50:55,894][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:50:55,920][src.tasks.hpsearch][INFO] - 0.000547121976155858, lr
[2024-05-06 17:50:55,944][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:50:55,969][src.tasks.hpsearch][INFO] - 0.04133742496369643 prior_scale
[2024-05-06 17:50:55,994][src.tasks.hpsearch][INFO] - 0.0025555101989354345 q_scale
[2024-05-06 17:50:56,020][src.tasks.hpsearch][INFO] - 0.5485259914682614 obs_scale
[2024-05-06 17:50:56,044][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:50:56,044][src.tasks.hpsearch][INFO] - _________________ Starting trial 016 __________________
[2024-05-06 17:50:56,044][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:50:56,045][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:51:29,848][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:51:29,859][train][INFO] - Instantiating callbacks...
[2024-05-06 17:51:29,860][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:51:29,866][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:51:29,867][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:51:29,868][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:51:29,869][train][INFO] - Instantiating loggers...
[2024-05-06 17:51:29,869][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:51:29,871][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:51:29,918][train][INFO] - Logging hyperparameters!
[2024-05-06 17:51:29,932][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 32.44it/s v_num: 0.000
[2024-05-06 17:51:44,038][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:51:44,040][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/018
[2024-05-06 17:51:44,143][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:51:44,167][src.tasks.hpsearch][INFO] - 0.0007595257909698891, lr
[2024-05-06 17:51:44,187][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:51:44,208][src.tasks.hpsearch][INFO] - 0.0553052327399875 prior_scale
[2024-05-06 17:51:44,229][src.tasks.hpsearch][INFO] - 0.0006518197309155569 q_scale
[2024-05-06 17:51:44,250][src.tasks.hpsearch][INFO] - 0.3966824074922798 obs_scale
[2024-05-06 17:51:44,270][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:51:44,271][src.tasks.hpsearch][INFO] - _________________ Starting trial 019 __________________
[2024-05-06 17:51:44,271][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:51:44,272][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:52:17,016][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:52:17,027][train][INFO] - Instantiating callbacks...
[2024-05-06 17:52:17,027][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:52:17,031][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:52:17,032][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:52:17,033][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:52:17,034][train][INFO] - Instantiating loggers...
[2024-05-06 17:52:17,035][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:52:17,036][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:52:17,072][train][INFO] - Logging hyperparameters!
[2024-05-06 17:52:17,083][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.17it/s v_num: 0.000
[2024-05-06 17:56:59,069][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:56:59,070][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/015
[2024-05-06 17:56:59,175][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:56:59,200][src.tasks.hpsearch][INFO] - 0.000547121976155858, lr
[2024-05-06 17:56:59,224][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:56:59,248][src.tasks.hpsearch][INFO] - 0.04133742496369643 prior_scale
[2024-05-06 17:56:59,271][src.tasks.hpsearch][INFO] - 0.0025555101989354345 q_scale
[2024-05-06 17:56:59,295][src.tasks.hpsearch][INFO] - 0.5485259914682614 obs_scale
[2024-05-06 17:56:59,320][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:56:59,320][src.tasks.hpsearch][INFO] - _________________ Starting trial 016 __________________
[2024-05-06 17:56:59,320][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:56:59,320][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:57:25,861][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:57:25,869][train][INFO] - Instantiating callbacks...
[2024-05-06 17:57:25,869][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:57:25,873][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:57:25,873][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:57:25,874][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:57:25,874][train][INFO] - Instantiating loggers...
[2024-05-06 17:57:25,875][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:57:25,875][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:57:25,966][train][INFO] - Logging hyperparameters!
[2024-05-06 17:57:25,990][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 34.48it/s v_num: 0.000
[2024-05-06 17:58:04,137][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:58:04,139][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/019
[2024-05-06 17:58:04,215][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:58:04,232][src.tasks.hpsearch][INFO] - 0.0009410248956021665, lr
[2024-05-06 17:58:04,248][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:58:04,265][src.tasks.hpsearch][INFO] - 0.06343664261871752 prior_scale
[2024-05-06 17:58:04,282][src.tasks.hpsearch][INFO] - 0.00020116582693680395 q_scale
[2024-05-06 17:58:04,299][src.tasks.hpsearch][INFO] - 0.3555713872117341 obs_scale
[2024-05-06 17:58:04,316][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:58:04,316][src.tasks.hpsearch][INFO] - _________________ Starting trial 020 __________________
[2024-05-06 17:58:04,316][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:58:04,316][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:58:29,057][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:58:29,064][train][INFO] - Instantiating callbacks...
[2024-05-06 17:58:29,064][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:58:29,066][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:58:29,067][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:58:29,067][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:58:29,068][train][INFO] - Instantiating loggers...
[2024-05-06 17:58:29,068][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:58:29,069][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:58:29,119][train][INFO] - Logging hyperparameters!
[2024-05-06 17:58:29,132][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.84it/s v_num: 0.000
[2024-05-06 17:58:54,793][utils.utils][INFO] - Closing loggers...
[2024-05-06 17:58:54,795][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/016
[2024-05-06 17:58:54,884][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 17:58:54,902][src.tasks.hpsearch][INFO] - 0.0006911809612075885, lr
[2024-05-06 17:58:54,919][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 17:58:54,939][src.tasks.hpsearch][INFO] - 0.04931702773628011 prior_scale
[2024-05-06 17:58:54,961][src.tasks.hpsearch][INFO] - 0.0006396905880911574 q_scale
[2024-05-06 17:58:54,981][src.tasks.hpsearch][INFO] - 0.49326200224837785 obs_scale
[2024-05-06 17:58:54,999][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 17:58:54,999][src.tasks.hpsearch][INFO] - _________________ Starting trial 017 __________________
[2024-05-06 17:58:54,999][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 17:58:54,999][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 17:59:19,707][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 17:59:19,713][train][INFO] - Instantiating callbacks...
[2024-05-06 17:59:19,714][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 17:59:19,716][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 17:59:19,717][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 17:59:19,717][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 17:59:19,718][train][INFO] - Instantiating loggers...
[2024-05-06 17:59:19,718][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 17:59:19,719][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 17:59:19,746][train][INFO] - Logging hyperparameters!
[2024-05-06 17:59:19,755][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.86it/s v_num: 0.000
[2024-05-06 18:04:04,645][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:04:04,654][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/016
[2024-05-06 18:04:04,758][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:04:04,781][src.tasks.hpsearch][INFO] - 0.0006911809612075885, lr
[2024-05-06 18:04:04,804][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:04:04,832][src.tasks.hpsearch][INFO] - 0.04931702773628011 prior_scale
[2024-05-06 18:04:04,860][src.tasks.hpsearch][INFO] - 0.0006396905880911574 q_scale
[2024-05-06 18:04:04,890][src.tasks.hpsearch][INFO] - 0.49326200224837785 obs_scale
[2024-05-06 18:04:04,916][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:04:04,917][src.tasks.hpsearch][INFO] - _________________ Starting trial 017 __________________
[2024-05-06 18:04:04,917][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:04:04,917][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:04:33,102][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:04:33,117][train][INFO] - Instantiating callbacks...
[2024-05-06 18:04:33,118][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:04:33,124][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:04:33,125][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:04:33,126][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:04:33,127][train][INFO] - Instantiating loggers...
[2024-05-06 18:04:33,127][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:04:33,129][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:04:33,208][train][INFO] - Logging hyperparameters!
[2024-05-06 18:04:33,220][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:04:55,650][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:04:55,665][train][INFO] - Instantiating callbacks...
[2024-05-06 18:04:55,667][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:04:55,674][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:04:55,677][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:04:55,679][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:04:55,681][train][INFO] - Instantiating loggers...
[2024-05-06 18:04:55,682][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:04:55,685][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:04:55,767][train][INFO] - Logging hyperparameters!
[2024-05-06 18:04:55,782][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.00it/s v_num: 0.000
[2024-05-06 18:07:17,308][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:07:17,310][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/017
[2024-05-06 18:07:17,432][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:07:17,459][src.tasks.hpsearch][INFO] - 0.0007263091335083298, lr
[2024-05-06 18:07:17,485][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:07:17,513][src.tasks.hpsearch][INFO] - 0.049890828546736744 prior_scale
[2024-05-06 18:07:17,540][src.tasks.hpsearch][INFO] - 0.0006414587910215425 q_scale
[2024-05-06 18:07:17,567][src.tasks.hpsearch][INFO] - 0.4841366687300466 obs_scale
[2024-05-06 18:07:17,594][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:07:17,594][src.tasks.hpsearch][INFO] - _________________ Starting trial 018 __________________
[2024-05-06 18:07:17,595][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:07:17,595][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:07:47,231][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:07:47,243][train][INFO] - Instantiating callbacks...
[2024-05-06 18:07:47,244][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:07:47,247][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:07:47,248][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:07:47,249][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:07:47,250][train][INFO] - Instantiating loggers...
[2024-05-06 18:07:47,250][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:07:47,252][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:07:47,301][train][INFO] - Logging hyperparameters!
[2024-05-06 18:07:47,314][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.50it/s v_num: 0.000
[2024-05-06 18:11:46,880][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:11:46,882][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/017
[2024-05-06 18:11:47,006][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:11:47,027][src.tasks.hpsearch][INFO] - 0.0007263091335083298, lr
[2024-05-06 18:11:47,045][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:11:47,066][src.tasks.hpsearch][INFO] - 0.049890828546736744 prior_scale
[2024-05-06 18:11:47,086][src.tasks.hpsearch][INFO] - 0.0006414587910215425 q_scale
[2024-05-06 18:11:47,108][src.tasks.hpsearch][INFO] - 0.4841366687300466 obs_scale
[2024-05-06 18:11:47,125][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:11:47,125][src.tasks.hpsearch][INFO] - _________________ Starting trial 018 __________________
[2024-05-06 18:11:47,125][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:11:47,126][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:12:12,066][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:12:12,074][train][INFO] - Instantiating callbacks...
[2024-05-06 18:12:12,074][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:12:12,078][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:12:12,078][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:12:12,079][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:12:12,080][train][INFO] - Instantiating loggers...
[2024-05-06 18:12:12,080][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:12:12,081][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:12:12,119][train][INFO] - Logging hyperparameters!
[2024-05-06 18:12:12,132][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.66it/s v_num: 0.000
[2024-05-06 18:15:38,728][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:15:38,730][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/018
[2024-05-06 18:15:38,844][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:15:38,869][src.tasks.hpsearch][INFO] - 0.0005257884343407167, lr
[2024-05-06 18:15:38,891][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:15:38,914][src.tasks.hpsearch][INFO] - 0.047783962721991306 prior_scale
[2024-05-06 18:15:38,936][src.tasks.hpsearch][INFO] - 0.0006503261522490175 q_scale
[2024-05-06 18:15:38,959][src.tasks.hpsearch][INFO] - 0.390052085961861 obs_scale
[2024-05-06 18:15:38,981][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:15:38,981][src.tasks.hpsearch][INFO] - _________________ Starting trial 019 __________________
[2024-05-06 18:15:38,982][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:15:38,982][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:16:10,117][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:16:10,128][train][INFO] - Instantiating callbacks...
[2024-05-06 18:16:10,129][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:16:10,132][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:16:10,133][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:16:10,133][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:16:10,135][train][INFO] - Instantiating loggers...
[2024-05-06 18:16:10,135][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:16:10,137][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:16:10,183][train][INFO] - Logging hyperparameters!
[2024-05-06 18:16:10,194][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.11it/s v_num: 0.000
[2024-05-06 18:18:00,516][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:18:00,517][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/022
[2024-05-06 18:18:00,619][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:18:00,642][src.tasks.hpsearch][INFO] - 0.0005520705419775921, lr
[2024-05-06 18:18:00,662][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:18:00,681][src.tasks.hpsearch][INFO] - 0.10613466247626048 prior_scale
[2024-05-06 18:18:00,701][src.tasks.hpsearch][INFO] - 0.00024345544575973658 q_scale
[2024-05-06 18:18:00,719][src.tasks.hpsearch][INFO] - 0.276678439213977 obs_scale
[2024-05-06 18:18:00,737][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:18:00,737][src.tasks.hpsearch][INFO] - _________________ Starting trial 023 __________________
[2024-05-06 18:18:00,738][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:18:00,738][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:18:25,134][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:18:25,141][train][INFO] - Instantiating callbacks...
[2024-05-06 18:18:25,141][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:18:25,143][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:18:25,144][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:18:25,144][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:18:25,145][train][INFO] - Instantiating loggers...
[2024-05-06 18:18:25,145][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:18:25,146][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:18:25,182][train][INFO] - Logging hyperparameters!
[2024-05-06 18:18:25,206][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.30it/s v_num: 0.000
[2024-05-06 18:19:27,610][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:19:27,612][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/018
[2024-05-06 18:19:27,742][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:19:27,766][src.tasks.hpsearch][INFO] - 0.0007595257909698891, lr
[2024-05-06 18:19:27,793][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:19:27,817][src.tasks.hpsearch][INFO] - 0.0553052327399875 prior_scale
[2024-05-06 18:19:27,835][src.tasks.hpsearch][INFO] - 0.0006518197309155569 q_scale
[2024-05-06 18:19:27,853][src.tasks.hpsearch][INFO] - 0.3966824074922798 obs_scale
[2024-05-06 18:19:27,875][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:19:27,875][src.tasks.hpsearch][INFO] - _________________ Starting trial 019 __________________
[2024-05-06 18:19:27,876][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:19:27,876][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:19:56,734][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:19:56,741][train][INFO] - Instantiating callbacks...
[2024-05-06 18:19:56,742][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:19:56,744][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:19:56,745][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:19:56,745][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:19:56,746][train][INFO] - Instantiating loggers...
[2024-05-06 18:19:56,746][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:19:56,747][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:19:56,786][train][INFO] - Logging hyperparameters!
[2024-05-06 18:19:56,821][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 10/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:20 • 0:00:00 18.99it/s v_num: 0.000
[2024-05-06 18:21:32,406][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 10.
[2024-05-06 18:21:32,558][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:21:32,630][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:21:32,661][src.tasks.hpsearch][INFO] - 0.00018191293917234794, lr
[2024-05-06 18:21:32,690][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:21:32,722][src.tasks.hpsearch][INFO] - 0.07276046906957684 prior_scale
[2024-05-06 18:21:32,753][src.tasks.hpsearch][INFO] - 0.0004960791867825049 q_scale
[2024-05-06 18:21:32,784][src.tasks.hpsearch][INFO] - 0.23646204862668888 obs_scale
[2024-05-06 18:21:32,813][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:21:32,814][src.tasks.hpsearch][INFO] - _________________ Starting trial 024 __________________
[2024-05-06 18:21:32,815][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:21:32,815][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:22:04,197][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:22:04,205][train][INFO] - Instantiating callbacks...
[2024-05-06 18:22:04,206][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:22:04,208][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:22:04,210][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:22:04,210][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:22:04,211][train][INFO] - Instantiating loggers...
[2024-05-06 18:22:04,211][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:22:04,213][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:22:04,252][train][INFO] - Logging hyperparameters!
[2024-05-06 18:22:04,265][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 23.98it/s v_num: 0.000
[2024-05-06 18:23:22,517][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:23:22,519][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/019
[2024-05-06 18:23:22,595][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:23:22,613][src.tasks.hpsearch][INFO] - 0.00016341722830749965, lr
[2024-05-06 18:23:22,630][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:23:22,647][src.tasks.hpsearch][INFO] - 0.06859744142139726 prior_scale
[2024-05-06 18:23:22,664][src.tasks.hpsearch][INFO] - 0.00020089389141657362 q_scale
[2024-05-06 18:23:22,681][src.tasks.hpsearch][INFO] - 0.3555713872117341 obs_scale
[2024-05-06 18:23:22,698][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:23:22,699][src.tasks.hpsearch][INFO] - _________________ Starting trial 020 __________________
[2024-05-06 18:23:22,699][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:23:22,699][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:23:47,700][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:23:47,707][train][INFO] - Instantiating callbacks...
[2024-05-06 18:23:47,707][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:23:47,712][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:23:47,713][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:23:47,713][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:23:47,714][train][INFO] - Instantiating loggers...
[2024-05-06 18:23:47,714][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:23:47,715][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:23:47,752][train][INFO] - Logging hyperparameters!
[2024-05-06 18:23:47,762][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 32.26it/s v_num: 0.000
[2024-05-06 18:26:52,663][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[2024-05-06 18:26:52,668][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:26:52,705][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:26:52,721][src.tasks.hpsearch][INFO] - 0.0006748438578408092, lr
[2024-05-06 18:26:52,736][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:26:52,751][src.tasks.hpsearch][INFO] - 0.1346970964250231 prior_scale
[2024-05-06 18:26:52,768][src.tasks.hpsearch][INFO] - 0.00020581642968448062 q_scale
[2024-05-06 18:26:52,786][src.tasks.hpsearch][INFO] - 0.4659110368290333 obs_scale
[2024-05-06 18:26:52,802][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:26:52,803][src.tasks.hpsearch][INFO] - _________________ Starting trial 025 __________________
[2024-05-06 18:26:52,803][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:26:52,803][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 27.59it/s v_num: 0.000
[2024-05-06 18:27:02,283][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:27:02,284][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/019
[2024-05-06 18:27:02,379][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:27:02,399][src.tasks.hpsearch][INFO] - 0.0009410248956021665, lr
[2024-05-06 18:27:02,418][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:27:02,441][src.tasks.hpsearch][INFO] - 0.06343664261871752 prior_scale
[2024-05-06 18:27:02,460][src.tasks.hpsearch][INFO] - 0.00020116582693680395 q_scale
[2024-05-06 18:27:02,485][src.tasks.hpsearch][INFO] - 0.3555713872117341 obs_scale
[2024-05-06 18:27:02,504][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:27:02,505][src.tasks.hpsearch][INFO] - _________________ Starting trial 020 __________________
[2024-05-06 18:27:02,505][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:27:02,505][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:27:27,317][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:27:27,324][train][INFO] - Instantiating callbacks...
[2024-05-06 18:27:27,324][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:27:27,328][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:27:27,329][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:27:27,329][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:27:27,330][train][INFO] - Instantiating loggers...
[2024-05-06 18:27:27,330][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:27:27,331][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:27:27,368][train][INFO] - Logging hyperparameters!
[2024-05-06 18:27:27,379][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.35it/s v_num: 0.000
[2024-05-06 18:30:19,523][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[2024-05-06 18:30:19,529][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:30:19,591][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:30:19,611][src.tasks.hpsearch][INFO] - 0.0006027416098410279, lr
[2024-05-06 18:30:19,634][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:30:19,654][src.tasks.hpsearch][INFO] - 0.044525246619667135 prior_scale
[2024-05-06 18:30:19,676][src.tasks.hpsearch][INFO] - 0.0007910538045185004 q_scale
[2024-05-06 18:30:19,699][src.tasks.hpsearch][INFO] - 0.4833704138798672 obs_scale
[2024-05-06 18:30:19,720][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:30:19,720][src.tasks.hpsearch][INFO] - _________________ Starting trial 021 __________________
[2024-05-06 18:30:19,720][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:30:19,720][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:30:47,569][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:30:47,576][train][INFO] - Instantiating callbacks...
[2024-05-06 18:30:47,576][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:30:47,579][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:30:47,579][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:30:47,580][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:30:47,580][train][INFO] - Instantiating loggers...
[2024-05-06 18:30:47,581][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:30:47,582][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:30:47,619][train][INFO] - Logging hyperparameters!
[2024-05-06 18:30:47,628][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 33.36it/s v_num: 0.000
[2024-05-06 18:32:38,032][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:32:38,033][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/025
[2024-05-06 18:32:38,115][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 18:32:38,130][src.tasks.hpsearch][INFO] - 0.0003309168926504286, lr
[2024-05-06 18:32:38,144][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 18:32:38,159][src.tasks.hpsearch][INFO] - 0.1600343999023588 prior_scale
[2024-05-06 18:32:38,174][src.tasks.hpsearch][INFO] - 0.00018157955174446106 q_scale
[2024-05-06 18:32:38,189][src.tasks.hpsearch][INFO] - 0.21141877978280718 obs_scale
[2024-05-06 18:32:38,203][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:32:38,204][src.tasks.hpsearch][INFO] - _________________ Starting trial 026 __________________
[2024-05-06 18:32:38,204][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:32:38,204][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:33:02,908][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:33:02,915][train][INFO] - Instantiating callbacks...
[2024-05-06 18:33:02,916][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:33:02,918][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:33:02,919][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:33:02,919][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:33:02,920][train][INFO] - Instantiating loggers...
[2024-05-06 18:33:02,920][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:33:02,921][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:33:02,957][train][INFO] - Logging hyperparameters!
[2024-05-06 18:33:02,965][train][INFO] - Starting training!
[2024-05-06 18:33:02,987][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.28it/s v_num: 0.000
[2024-05-06 18:34:05,832][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:34:05,834][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/020
[2024-05-06 18:34:05,924][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:34:05,945][src.tasks.hpsearch][INFO] - 0.000862223487183857, lr
[2024-05-06 18:34:05,966][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:34:05,986][src.tasks.hpsearch][INFO] - 0.06740901007980599 prior_scale
[2024-05-06 18:34:06,006][src.tasks.hpsearch][INFO] - 0.00022427661372579052 q_scale
[2024-05-06 18:34:06,026][src.tasks.hpsearch][INFO] - 0.33748187909036215 obs_scale
[2024-05-06 18:34:06,045][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:34:06,046][src.tasks.hpsearch][INFO] - _________________ Starting trial 021 __________________
[2024-05-06 18:34:06,046][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:34:06,046][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:34:33,010][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:34:33,021][train][INFO] - Instantiating callbacks...
[2024-05-06 18:34:33,023][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:34:33,036][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:34:33,038][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:34:33,039][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:34:33,040][train][INFO] - Instantiating loggers...
[2024-05-06 18:34:33,041][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:34:33,042][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:34:33,105][train][INFO] - Logging hyperparameters!
[2024-05-06 18:34:33,118][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 27.35it/s v_num: 0.000
[2024-05-06 18:37:39,688][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:37:39,690][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/021
[2024-05-06 18:37:40,966][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:37:40,985][src.tasks.hpsearch][INFO] - 0.0009759889358631576, lr
[2024-05-06 18:37:41,003][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:37:41,025][src.tasks.hpsearch][INFO] - 0.040160659459739026 prior_scale
[2024-05-06 18:37:41,043][src.tasks.hpsearch][INFO] - 0.0006801449341523255 q_scale
[2024-05-06 18:37:41,063][src.tasks.hpsearch][INFO] - 0.26776859501954126 obs_scale
[2024-05-06 18:37:41,080][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:37:41,080][src.tasks.hpsearch][INFO] - _________________ Starting trial 022 __________________
[2024-05-06 18:37:41,080][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:37:41,081][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:38:05,610][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:38:05,619][train][INFO] - Instantiating callbacks...
[2024-05-06 18:38:05,620][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:38:05,623][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:38:05,624][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:38:05,624][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:38:05,625][train][INFO] - Instantiating loggers...
[2024-05-06 18:38:05,626][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:38:05,627][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:38:05,677][train][INFO] - Logging hyperparameters!
[2024-05-06 18:38:05,696][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 27.31it/s v_num: 0.000
[2024-05-06 18:41:33,781][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:41:33,784][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/021
[2024-05-06 18:41:33,903][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:41:33,926][src.tasks.hpsearch][INFO] - 0.0009897517703610693, lr
[2024-05-06 18:41:33,948][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:41:33,972][src.tasks.hpsearch][INFO] - 0.07940156934878415 prior_scale
[2024-05-06 18:41:33,996][src.tasks.hpsearch][INFO] - 0.00021507479225071316 q_scale
[2024-05-06 18:41:34,020][src.tasks.hpsearch][INFO] - 0.3421209737180682 obs_scale
[2024-05-06 18:41:34,044][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:41:34,044][src.tasks.hpsearch][INFO] - _________________ Starting trial 022 __________________
[2024-05-06 18:41:34,045][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:41:34,045][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:41:58,375][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:41:58,382][train][INFO] - Instantiating callbacks...
[2024-05-06 18:41:58,383][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:41:58,387][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:41:58,388][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:41:58,389][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:41:58,391][train][INFO] - Instantiating loggers...
[2024-05-06 18:41:58,391][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:41:58,393][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:41:58,442][train][INFO] - Logging hyperparameters!
[2024-05-06 18:41:58,450][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:24 • 0:00:00 15.58it/s v_num: 0.000
[2024-05-06 18:42:28,219][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:42:28,222][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/026
[2024-05-06 18:42:28,333][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:42:28,359][src.tasks.hpsearch][INFO] - 0.0006167782848423004, lr
[2024-05-06 18:42:28,385][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:42:28,425][src.tasks.hpsearch][INFO] - 0.2763705310792612 prior_scale
[2024-05-06 18:42:28,460][src.tasks.hpsearch][INFO] - 0.0002904082597194098 q_scale
[2024-05-06 18:42:28,483][src.tasks.hpsearch][INFO] - 0.3746859534867915 obs_scale
[2024-05-06 18:42:28,505][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:42:28,505][src.tasks.hpsearch][INFO] - _________________ Starting trial 027 __________________
[2024-05-06 18:42:28,506][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:42:28,506][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:42:53,303][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:42:53,312][train][INFO] - Instantiating callbacks...
[2024-05-06 18:42:53,313][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:42:53,315][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:42:53,315][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:42:53,316][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:42:53,317][train][INFO] - Instantiating loggers...
[2024-05-06 18:42:53,317][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:42:53,318][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:42:53,353][train][INFO] - Logging hyperparameters!
[2024-05-06 18:42:53,360][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.79it/s v_num: 0.000
[2024-05-06 18:45:23,269][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:45:23,271][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/022
[2024-05-06 18:45:23,374][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:45:23,395][src.tasks.hpsearch][INFO] - 0.0006227221732994113, lr
[2024-05-06 18:45:23,415][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:45:23,434][src.tasks.hpsearch][INFO] - 0.06689413583604736 prior_scale
[2024-05-06 18:45:23,452][src.tasks.hpsearch][INFO] - 0.0003126425480395599 q_scale
[2024-05-06 18:45:23,471][src.tasks.hpsearch][INFO] - 0.4151409793914801 obs_scale
[2024-05-06 18:45:23,490][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:45:23,490][src.tasks.hpsearch][INFO] - _________________ Starting trial 023 __________________
[2024-05-06 18:45:23,490][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:45:23,491][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:45:48,739][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:45:48,746][train][INFO] - Instantiating callbacks...
[2024-05-06 18:45:48,747][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:45:48,751][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:45:48,752][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:45:48,753][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:45:48,753][train][INFO] - Instantiating loggers...
[2024-05-06 18:45:48,754][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:45:48,755][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:45:48,799][train][INFO] - Logging hyperparameters!
[2024-05-06 18:45:49,321][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.13it/s v_num: 0.000
[2024-05-06 18:48:38,861][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:48:38,863][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/022
[2024-05-06 18:48:38,954][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:48:38,978][src.tasks.hpsearch][INFO] - 0.0005971919166727717, lr
[2024-05-06 18:48:38,999][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:48:39,022][src.tasks.hpsearch][INFO] - 0.1178811267910555 prior_scale
[2024-05-06 18:48:39,045][src.tasks.hpsearch][INFO] - 0.00027425246065001445 q_scale
[2024-05-06 18:48:39,068][src.tasks.hpsearch][INFO] - 0.23001124617088653 obs_scale
[2024-05-06 18:48:39,089][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:48:39,090][src.tasks.hpsearch][INFO] - _________________ Starting trial 023 __________________
[2024-05-06 18:48:39,090][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:48:39,090][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:49:04,751][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:49:04,758][train][INFO] - Instantiating callbacks...
[2024-05-06 18:49:04,758][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:49:04,762][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:49:04,763][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:49:04,763][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:49:04,764][train][INFO] - Instantiating loggers...
[2024-05-06 18:49:04,764][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:49:04,766][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:49:04,807][train][INFO] - Logging hyperparameters!
[2024-05-06 18:49:04,815][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:49:27,040][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:49:27,047][train][INFO] - Instantiating callbacks...
[2024-05-06 18:49:27,048][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:49:27,051][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:49:27,051][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:49:27,051][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:49:27,052][train][INFO] - Instantiating loggers...
[2024-05-06 18:49:27,052][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:49:27,053][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:49:27,095][train][INFO] - Logging hyperparameters!
[2024-05-06 18:49:27,154][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 14.68it/s v_num: 0.000
[2024-05-06 18:50:17,558][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:50:17,559][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/028
[2024-05-06 18:50:17,649][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 18:50:17,668][src.tasks.hpsearch][INFO] - 8.702364224005333e-05, lr
[2024-05-06 18:50:17,690][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:50:17,711][src.tasks.hpsearch][INFO] - 0.13720478443334652 prior_scale
[2024-05-06 18:50:17,733][src.tasks.hpsearch][INFO] - 0.000383518181805017 q_scale
[2024-05-06 18:50:17,756][src.tasks.hpsearch][INFO] - 0.5748625129590912 obs_scale
[2024-05-06 18:50:17,777][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 18:50:17,778][src.tasks.hpsearch][INFO] - _________________ Starting trial 029 __________________
[2024-05-06 18:50:17,778][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:50:17,778][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:50:44,008][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:50:44,016][train][INFO] - Instantiating callbacks...
[2024-05-06 18:50:44,016][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:50:44,020][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:50:44,021][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:50:44,021][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:50:44,022][train][INFO] - Instantiating loggers...
[2024-05-06 18:50:44,022][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:50:44,023][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:50:44,051][train][INFO] - Logging hyperparameters!
[2024-05-06 18:50:44,114][train][INFO] - Starting training!
[2024-05-06 18:50:44,168][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 26.22it/s v_num: 0.000
[2024-05-06 18:52:31,311][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:52:31,313][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/029
[2024-05-06 18:52:31,395][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:52:31,416][src.tasks.hpsearch][INFO] - 0.00038396701131185356, lr
[2024-05-06 18:52:31,439][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:52:31,462][src.tasks.hpsearch][INFO] - 0.0861232110600651 prior_scale
[2024-05-06 18:52:31,486][src.tasks.hpsearch][INFO] - 0.0002912461426991157 q_scale
[2024-05-06 18:52:31,510][src.tasks.hpsearch][INFO] - 0.43700985105941337 obs_scale
[2024-05-06 18:52:31,533][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:52:31,533][src.tasks.hpsearch][INFO] - _________________ Starting trial 030 __________________
[2024-05-06 18:52:31,534][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:52:31,534][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:53:05,464][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:53:05,471][train][INFO] - Instantiating callbacks...
[2024-05-06 18:53:05,472][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:53:05,475][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:53:05,477][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:53:05,477][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:53:05,479][train][INFO] - Instantiating loggers...
[2024-05-06 18:53:05,479][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:53:05,481][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:53:05,527][train][INFO] - Logging hyperparameters!
[2024-05-06 18:53:05,580][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.34it/s v_num: 0.000
[2024-05-06 18:53:37,541][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:53:37,543][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/023
[2024-05-06 18:53:37,651][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:53:37,673][src.tasks.hpsearch][INFO] - 0.0006681762479256583, lr
[2024-05-06 18:53:37,694][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:53:37,716][src.tasks.hpsearch][INFO] - 0.08554798474183561 prior_scale
[2024-05-06 18:53:37,737][src.tasks.hpsearch][INFO] - 0.00033011851205550126 q_scale
[2024-05-06 18:53:37,758][src.tasks.hpsearch][INFO] - 0.5105715736300653 obs_scale
[2024-05-06 18:53:37,778][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:53:37,779][src.tasks.hpsearch][INFO] - _________________ Starting trial 024 __________________
[2024-05-06 18:53:37,779][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:53:37,779][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:54:03,659][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:54:03,667][train][INFO] - Instantiating callbacks...
[2024-05-06 18:54:03,667][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:54:03,671][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:54:03,672][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:54:03,672][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:54:03,673][train][INFO] - Instantiating loggers...
[2024-05-06 18:54:03,673][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:54:03,675][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:54:03,702][train][INFO] - Logging hyperparameters!
[2024-05-06 18:54:03,711][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.01it/s v_num: 0.000
[2024-05-06 18:55:10,745][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:55:10,748][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/023
[2024-05-06 18:55:10,904][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:55:10,936][src.tasks.hpsearch][INFO] - 0.00018191293917234794, lr
[2024-05-06 18:55:10,969][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:55:11,005][src.tasks.hpsearch][INFO] - 0.06428450868917908 prior_scale
[2024-05-06 18:55:11,036][src.tasks.hpsearch][INFO] - 0.00018013891144046316 q_scale
[2024-05-06 18:55:11,067][src.tasks.hpsearch][INFO] - 0.3630931498618861 obs_scale
[2024-05-06 18:55:11,100][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:55:11,100][src.tasks.hpsearch][INFO] - _________________ Starting trial 024 __________________
[2024-05-06 18:55:11,101][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:55:11,101][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:55:37,328][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:55:37,335][train][INFO] - Instantiating callbacks...
[2024-05-06 18:55:37,336][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:55:37,338][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:55:37,338][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:55:37,339][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:55:37,340][train][INFO] - Instantiating loggers...
[2024-05-06 18:55:37,340][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:55:37,341][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:55:37,377][train][INFO] - Logging hyperparameters!
[2024-05-06 18:55:38,759][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 32.69it/s v_num: 0.000
[2024-05-06 18:58:51,990][utils.utils][INFO] - Closing loggers...
[2024-05-06 18:58:51,992][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/030
[2024-05-06 18:58:52,123][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 18:58:52,145][src.tasks.hpsearch][INFO] - 0.0006680368066976181, lr
[2024-05-06 18:58:52,167][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 18:58:52,189][src.tasks.hpsearch][INFO] - 0.05579858997767185 prior_scale
[2024-05-06 18:58:52,212][src.tasks.hpsearch][INFO] - 0.0007242189305787746 q_scale
[2024-05-06 18:58:52,234][src.tasks.hpsearch][INFO] - 0.4786387433445234 obs_scale
[2024-05-06 18:58:52,256][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 18:58:52,256][src.tasks.hpsearch][INFO] - _________________ Starting trial 031 __________________
[2024-05-06 18:58:52,256][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 18:58:52,257][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 18:59:20,296][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 18:59:20,308][train][INFO] - Instantiating callbacks...
[2024-05-06 18:59:20,309][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 18:59:20,312][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 18:59:20,313][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 18:59:20,314][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 18:59:20,315][train][INFO] - Instantiating loggers...
[2024-05-06 18:59:20,316][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 18:59:20,318][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 18:59:20,366][train][INFO] - Logging hyperparameters!
[2024-05-06 18:59:20,408][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.62it/s v_num: 0.000
[2024-05-06 19:00:55,144][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:00:55,146][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/024
[2024-05-06 19:00:55,237][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:00:55,256][src.tasks.hpsearch][INFO] - 0.0003394050757930824, lr
[2024-05-06 19:00:55,277][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:00:55,300][src.tasks.hpsearch][INFO] - 0.1346970964250231 prior_scale
[2024-05-06 19:00:55,322][src.tasks.hpsearch][INFO] - 0.00029198439611751305 q_scale
[2024-05-06 19:00:55,345][src.tasks.hpsearch][INFO] - 0.3257267477229445 obs_scale
[2024-05-06 19:00:55,366][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:00:55,366][src.tasks.hpsearch][INFO] - _________________ Starting trial 025 __________________
[2024-05-06 19:00:55,367][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:00:55,367][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[2024-05-06 19:00:23,671][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:00:23,723][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:00:23,746][src.tasks.hpsearch][INFO] - 0.0009893755800209887, lr
[2024-05-06 19:00:23,769][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:00:23,791][src.tasks.hpsearch][INFO] - 0.03421979332545158 prior_scale
[2024-05-06 19:00:23,814][src.tasks.hpsearch][INFO] - 0.0006427159858661901 q_scale
[2024-05-06 19:00:23,836][src.tasks.hpsearch][INFO] - 0.2620362868752413 obs_scale
[2024-05-06 19:00:23,857][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:00:23,858][src.tasks.hpsearch][INFO] - _________________ Starting trial 025 __________________
[2024-05-06 19:00:23,858][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:00:23,858][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:00:49,095][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:00:49,102][train][INFO] - Instantiating callbacks...
[2024-05-06 19:00:49,103][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:00:49,106][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:00:49,107][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:00:49,107][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:00:49,108][train][INFO] - Instantiating loggers...
[2024-05-06 19:00:49,108][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:00:49,109][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:00:49,144][train][INFO] - Logging hyperparameters!
[2024-05-06 19:00:49,152][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:01:19,994][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:01:20,001][train][INFO] - Instantiating callbacks...
[2024-05-06 19:01:20,001][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:01:20,004][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:01:20,004][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:01:20,005][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:01:20,006][train][INFO] - Instantiating loggers...
[2024-05-06 19:01:20,006][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:01:20,007][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:01:20,038][train][INFO] - Logging hyperparameters!
[2024-05-06 19:01:20,045][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:20 • 0:00:00 18.80it/s v_num: 0.000
[2024-05-06 19:05:29,471][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:05:29,473][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/031
[2024-05-06 19:05:29,590][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:05:29,616][src.tasks.hpsearch][INFO] - 0.0006182721622361477, lr
[2024-05-06 19:05:29,640][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:05:29,665][src.tasks.hpsearch][INFO] - 0.0650746397020037 prior_scale
[2024-05-06 19:05:30,870][src.tasks.hpsearch][INFO] - 0.0007985508727179825 q_scale
[2024-05-06 19:05:30,897][src.tasks.hpsearch][INFO] - 0.6680718428263864 obs_scale
[2024-05-06 19:05:30,920][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:05:30,920][src.tasks.hpsearch][INFO] - _________________ Starting trial 032 __________________
[2024-05-06 19:05:30,921][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:05:30,921][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:06:04,875][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:06:04,883][train][INFO] - Instantiating callbacks...
[2024-05-06 19:06:04,884][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:06:04,887][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:06:04,888][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:06:04,888][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:06:04,889][train][INFO] - Instantiating loggers...
[2024-05-06 19:06:04,890][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:06:04,891][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:06:04,936][train][INFO] - Logging hyperparameters!
[2024-05-06 19:06:04,962][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 27.52it/s v_num: 0.000
[2024-05-06 19:06:35,598][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:06:35,614][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/025
[2024-05-06 19:06:35,698][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 19:06:35,717][src.tasks.hpsearch][INFO] - 0.0003628689069010046, lr
[2024-05-06 19:06:35,736][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 19:06:35,755][src.tasks.hpsearch][INFO] - 0.15479700679466404 prior_scale
[2024-05-06 19:06:35,775][src.tasks.hpsearch][INFO] - 0.00018157955174446106 q_scale
[2024-05-06 19:06:35,798][src.tasks.hpsearch][INFO] - 0.3987880946462157 obs_scale
[2024-05-06 19:06:35,820][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:06:35,821][src.tasks.hpsearch][INFO] - _________________ Starting trial 026 __________________
[2024-05-06 19:06:35,821][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:06:35,821][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:07:00,927][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:07:00,935][train][INFO] - Instantiating callbacks...
[2024-05-06 19:07:00,936][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:07:00,938][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:07:00,939][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:07:00,939][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:07:00,940][train][INFO] - Instantiating loggers...
[2024-05-06 19:07:00,941][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:07:00,942][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:07:00,984][train][INFO] - Logging hyperparameters!
[2024-05-06 19:07:02,366][train][INFO] - Starting training!
[2024-05-06 19:07:02,368][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.60it/s v_num: 0.000
[2024-05-06 19:08:19,789][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:08:19,791][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/025
[2024-05-06 19:08:19,927][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 19:08:19,954][src.tasks.hpsearch][INFO] - 0.0002178416264960444, lr
[2024-05-06 19:08:19,979][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 19:08:20,005][src.tasks.hpsearch][INFO] - 0.07455230132082015 prior_scale
[2024-05-06 19:08:20,032][src.tasks.hpsearch][INFO] - 0.00023274249435730555 q_scale
[2024-05-06 19:08:20,060][src.tasks.hpsearch][INFO] - 0.2299898013343447 obs_scale
[2024-05-06 19:08:20,087][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:08:20,088][src.tasks.hpsearch][INFO] - _________________ Starting trial 026 __________________
[2024-05-06 19:08:20,088][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:08:20,088][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:08:50,040][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:08:50,048][train][INFO] - Instantiating callbacks...
[2024-05-06 19:08:50,049][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:08:50,052][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:08:50,053][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:08:50,053][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:08:50,054][train][INFO] - Instantiating loggers...
[2024-05-06 19:08:50,054][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:08:50,056][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:08:50,097][train][INFO] - Logging hyperparameters!
[2024-05-06 19:08:50,104][train][INFO] - Starting training!
[2024-05-06 19:08:50,107][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 36.52it/s v_num: 0.000
[2024-05-06 19:12:12,501][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:12:12,503][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/032
[2024-05-06 19:12:12,623][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:12:12,648][src.tasks.hpsearch][INFO] - 0.0007266156417882253, lr
[2024-05-06 19:12:12,677][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:12:12,705][src.tasks.hpsearch][INFO] - 0.03681654956590566 prior_scale
[2024-05-06 19:12:12,731][src.tasks.hpsearch][INFO] - 0.00018067715999785242 q_scale
[2024-05-06 19:12:12,759][src.tasks.hpsearch][INFO] - 0.34141996198473645 obs_scale
[2024-05-06 19:12:12,784][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:12:12,784][src.tasks.hpsearch][INFO] - _________________ Starting trial 033 __________________
[2024-05-06 19:12:12,785][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:12:12,785][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:12:40,174][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:12:40,180][train][INFO] - Instantiating callbacks...
[2024-05-06 19:12:40,181][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:12:40,183][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:12:40,184][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:12:40,184][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:12:40,185][train][INFO] - Instantiating loggers...
[2024-05-06 19:12:40,185][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:12:40,186][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:12:40,226][train][INFO] - Logging hyperparameters!
[2024-05-06 19:12:40,246][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.46it/s v_num: 0.000
[2024-05-06 19:18:26,435][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:18:26,437][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/033
[2024-05-06 19:18:26,549][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:18:26,569][src.tasks.hpsearch][INFO] - 5.7136632515214274e-05, lr
[2024-05-06 19:18:26,589][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:18:26,611][src.tasks.hpsearch][INFO] - 0.059480207834859085 prior_scale
[2024-05-06 19:18:26,631][src.tasks.hpsearch][INFO] - 0.0011170018507351868 q_scale
[2024-05-06 19:18:26,652][src.tasks.hpsearch][INFO] - 0.27342775354008625 obs_scale
[2024-05-06 19:18:26,673][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 19:18:26,673][src.tasks.hpsearch][INFO] - _________________ Starting trial 034 __________________
[2024-05-06 19:18:26,674][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:18:26,674][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:18:56,868][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:18:56,876][train][INFO] - Instantiating callbacks...
[2024-05-06 19:18:56,876][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:18:56,880][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:18:56,881][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:18:56,881][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:18:56,882][train][INFO] - Instantiating loggers...
[2024-05-06 19:18:56,882][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:18:56,883][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:18:57,241][train][INFO] - Logging hyperparameters!
[2024-05-06 19:18:57,251][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 383/383 0:00:38 • 0:00:00 9.90it/s v_num: 0.000
[2024-05-06 19:20:15,203][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:20:15,206][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/026
[2024-05-06 19:20:15,345][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:20:15,372][src.tasks.hpsearch][INFO] - 0.0006167782848423004, lr
[2024-05-06 19:20:15,404][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:20:15,436][src.tasks.hpsearch][INFO] - 0.07078082608673836 prior_scale
[2024-05-06 19:20:15,467][src.tasks.hpsearch][INFO] - 0.0004018287278718421 q_scale
[2024-05-06 19:20:15,507][src.tasks.hpsearch][INFO] - 0.1980958002490439 obs_scale
[2024-05-06 19:20:15,540][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:20:15,541][src.tasks.hpsearch][INFO] - _________________ Starting trial 027 __________________
[2024-05-06 19:20:15,542][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:20:15,542][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:20:44,411][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:20:44,421][train][INFO] - Instantiating callbacks...
[2024-05-06 19:20:44,422][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:20:44,430][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:20:44,431][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:20:44,432][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:20:44,433][train][INFO] - Instantiating loggers...
[2024-05-06 19:20:44,433][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:20:44,435][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:20:44,481][train][INFO] - Logging hyperparameters!
[2024-05-06 19:20:44,659][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
  
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:31 • 0:00:00 12.27it/s v_num: 0.000
[2024-05-06 19:21:40,181][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:21:40,183][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/026
[2024-05-06 19:21:42,284][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:21:43,019][src.tasks.hpsearch][INFO] - 0.0006746258891313132, lr
[2024-05-06 19:21:43,044][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:21:43,069][src.tasks.hpsearch][INFO] - 0.14732222903843123 prior_scale
[2024-05-06 19:21:43,091][src.tasks.hpsearch][INFO] - 0.0004018287278718421 q_scale
[2024-05-06 19:21:43,115][src.tasks.hpsearch][INFO] - 0.5895199043485568 obs_scale
[2024-05-06 19:21:43,138][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:21:43,139][src.tasks.hpsearch][INFO] - _________________ Starting trial 027 __________________
[2024-05-06 19:21:43,139][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:21:43,140][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:22:18,826][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:22:18,833][train][INFO] - Instantiating callbacks...
[2024-05-06 19:22:18,834][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:22:18,884][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:22:18,885][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:22:18,886][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:22:18,887][train][INFO] - Instantiating loggers...
[2024-05-06 19:22:18,887][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:22:18,888][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:22:18,941][train][INFO] - Logging hyperparameters!
[2024-05-06 19:22:19,021][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.50it/s v_num: 0.000
[2024-05-06 19:29:41,208][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:29:41,233][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/027
[2024-05-06 19:29:41,369][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:29:41,391][src.tasks.hpsearch][INFO] - 4.0174518409972304e-05, lr
[2024-05-06 19:29:41,418][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:29:41,443][src.tasks.hpsearch][INFO] - 0.30186663651042894 prior_scale
[2024-05-06 19:29:41,467][src.tasks.hpsearch][INFO] - 0.0003025192277530568 q_scale
[2024-05-06 19:29:41,493][src.tasks.hpsearch][INFO] - 0.30651744591097546 obs_scale
[2024-05-06 19:29:41,519][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 19:29:41,520][src.tasks.hpsearch][INFO] - _________________ Starting trial 028 __________________
[2024-05-06 19:29:41,520][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:29:41,520][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:30:19,306][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:30:19,314][train][INFO] - Instantiating callbacks...
[2024-05-06 19:30:19,315][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:30:19,318][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:30:19,319][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:30:19,319][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:30:19,320][train][INFO] - Instantiating loggers...
[2024-05-06 19:30:19,321][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:30:19,322][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:30:19,381][train][INFO] - Logging hyperparameters!
[2024-05-06 19:30:19,513][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 6.27it/s v_num: 0.000
[2024-05-06 19:32:08,227][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:32:08,229][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/028
[2024-05-06 19:32:08,360][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 19:32:08,386][src.tasks.hpsearch][INFO] - 9.921553289851589e-05, lr
[2024-05-06 19:32:08,408][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:32:08,435][src.tasks.hpsearch][INFO] - 0.0394137062039809 prior_scale
[2024-05-06 19:32:08,463][src.tasks.hpsearch][INFO] - 0.0008515088472132865 q_scale
[2024-05-06 19:32:08,486][src.tasks.hpsearch][INFO] - 0.5822297899801435 obs_scale
[2024-05-06 19:32:08,515][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 19:32:08,516][src.tasks.hpsearch][INFO] - _________________ Starting trial 029 __________________
[2024-05-06 19:32:08,517][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:32:08,517][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:32:39,329][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:32:39,336][train][INFO] - Instantiating callbacks...
[2024-05-06 19:32:39,337][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:32:39,340][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:32:39,340][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:32:39,341][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:32:39,342][train][INFO] - Instantiating loggers...
[2024-05-06 19:32:39,342][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:32:39,343][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:32:39,390][train][INFO] - Logging hyperparameters!
[2024-05-06 19:32:39,503][train][INFO] - Starting training!
[2024-05-06 19:32:39,506][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:32:52,989][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:32:53,001][train][INFO] - Instantiating callbacks...
[2024-05-06 19:32:53,002][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:32:53,006][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:32:53,007][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:32:53,008][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:32:53,009][train][INFO] - Instantiating loggers...
[2024-05-06 19:32:53,010][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:32:53,011][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:32:53,047][train][INFO] - Logging hyperparameters!
[2024-05-06 19:32:53,092][train][INFO] - Starting training!
[2024-05-06 19:32:53,094][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 13.77it/s v_num: 0.000
[2024-05-06 19:35:39,484][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:35:39,486][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/029
[2024-05-06 19:35:39,575][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:35:39,596][src.tasks.hpsearch][INFO] - 0.00033887516581264203, lr
[2024-05-06 19:35:39,616][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:35:39,639][src.tasks.hpsearch][INFO] - 0.022689658887318578 prior_scale
[2024-05-06 19:35:39,662][src.tasks.hpsearch][INFO] - 0.00047528042867711856 q_scale
[2024-05-06 19:35:39,690][src.tasks.hpsearch][INFO] - 0.43700985105941337 obs_scale
[2024-05-06 19:35:39,716][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:35:39,717][src.tasks.hpsearch][INFO] - _________________ Starting trial 030 __________________
[2024-05-06 19:35:39,717][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:35:39,718][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:35:58,732][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:35:58,739][train][INFO] - Instantiating callbacks...
[2024-05-06 19:35:58,739][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:35:58,742][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:35:58,742][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:35:58,743][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:35:58,744][train][INFO] - Instantiating loggers...
[2024-05-06 19:35:58,744][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:35:58,745][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:35:58,787][train][INFO] - Logging hyperparameters!
[2024-05-06 19:35:58,866][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:36:07,375][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:36:07,384][train][INFO] - Instantiating callbacks...
[2024-05-06 19:36:07,385][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:36:07,390][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:36:07,391][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:36:07,391][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:36:07,392][train][INFO] - Instantiating loggers...
[2024-05-06 19:36:07,393][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:36:07,394][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:36:07,458][train][INFO] - Logging hyperparameters!
[2024-05-06 19:36:08,346][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 34.10it/s v_num: 0.000
[2024-05-06 19:38:16,812][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:38:16,814][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/036
[2024-05-06 19:38:16,902][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:38:16,924][src.tasks.hpsearch][INFO] - 0.000213940624590804, lr
[2024-05-06 19:38:16,943][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:38:16,968][src.tasks.hpsearch][INFO] - 0.031948325415545646 prior_scale
[2024-05-06 19:38:16,995][src.tasks.hpsearch][INFO] - 0.0016035412310709187 q_scale
[2024-05-06 19:38:17,020][src.tasks.hpsearch][INFO] - 0.5659522595670611 obs_scale
[2024-05-06 19:38:17,045][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 19:38:17,045][src.tasks.hpsearch][INFO] - _________________ Starting trial 037 __________________
[2024-05-06 19:38:17,046][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:38:17,046][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:38:45,770][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:38:45,777][train][INFO] - Instantiating callbacks...
[2024-05-06 19:38:45,777][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:38:45,779][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:38:45,780][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:38:45,780][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:38:45,781][train][INFO] - Instantiating loggers...
[2024-05-06 19:38:45,781][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:38:45,782][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:38:45,826][train][INFO] - Logging hyperparameters!
[2024-05-06 19:38:45,905][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 8.65it/s v_num: 0.000
[2024-05-06 19:39:45,392][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:39:45,394][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/037
[2024-05-06 19:39:45,521][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:39:45,551][src.tasks.hpsearch][INFO] - 0.0004966402699781978, lr
[2024-05-06 19:39:45,579][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 19:39:45,608][src.tasks.hpsearch][INFO] - 0.02307798890182512 prior_scale
[2024-05-06 19:39:45,637][src.tasks.hpsearch][INFO] - 0.0008677919586673049 q_scale
[2024-05-06 19:39:45,667][src.tasks.hpsearch][INFO] - 1.3422976092490297 obs_scale
[2024-05-06 19:39:45,695][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 19:39:45,695][src.tasks.hpsearch][INFO] - _________________ Starting trial 038 __________________
[2024-05-06 19:39:45,696][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:39:45,696][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:40:14,885][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:40:14,892][train][INFO] - Instantiating callbacks...
[2024-05-06 19:40:14,892][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:40:14,895][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:40:14,896][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:40:14,896][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:40:14,897][train][INFO] - Instantiating loggers...
[2024-05-06 19:40:14,897][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:40:14,898][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:40:14,947][train][INFO] - Logging hyperparameters!
[2024-05-06 19:40:14,957][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.42it/s v_num: 0.000
[2024-05-06 19:42:05,856][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:42:05,858][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/038
[2024-05-06 19:42:05,948][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 19:42:05,967][src.tasks.hpsearch][INFO] - 0.00013788557993523403, lr
[2024-05-06 19:42:05,985][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:42:06,004][src.tasks.hpsearch][INFO] - 0.046750137490587707 prior_scale
[2024-05-06 19:42:06,023][src.tasks.hpsearch][INFO] - 0.00014573544217320089 q_scale
[2024-05-06 19:42:06,042][src.tasks.hpsearch][INFO] - 0.387230310427509 obs_scale
[2024-05-06 19:42:06,059][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 19:42:06,060][src.tasks.hpsearch][INFO] - _________________ Starting trial 039 __________________
[2024-05-06 19:42:06,060][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:42:06,060][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:42:31,956][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:42:31,964][train][INFO] - Instantiating callbacks...
[2024-05-06 19:42:31,964][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:42:31,967][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:42:31,968][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:42:31,969][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:42:31,969][train][INFO] - Instantiating loggers...
[2024-05-06 19:42:31,970][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:42:31,971][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:42:32,007][train][INFO] - Logging hyperparameters!
[2024-05-06 19:42:32,030][train][INFO] - Starting training!
[2024-05-06 19:42:32,032][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.47it/s v_num: 0.000
[2024-05-06 19:42:39,168][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:42:39,169][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/030
[2024-05-06 19:42:39,260][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:42:39,276][src.tasks.hpsearch][INFO] - 0.0006557811813299671, lr
[2024-05-06 19:42:39,292][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:42:39,312][src.tasks.hpsearch][INFO] - 0.09461871011449606 prior_scale
[2024-05-06 19:42:39,327][src.tasks.hpsearch][INFO] - 0.0002478737992476807 q_scale
[2024-05-06 19:42:39,344][src.tasks.hpsearch][INFO] - 0.46632986902004947 obs_scale
[2024-05-06 19:42:39,363][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:42:39,363][src.tasks.hpsearch][INFO] - _________________ Starting trial 031 __________________
[2024-05-06 19:42:39,363][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:42:39,364][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:43:04,549][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:43:04,556][train][INFO] - Instantiating callbacks...
[2024-05-06 19:43:04,556][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:43:04,560][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:43:04,560][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:43:04,561][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:43:04,562][train][INFO] - Instantiating loggers...
[2024-05-06 19:43:04,562][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:43:04,563][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:43:04,591][train][INFO] - Logging hyperparameters!
[2024-05-06 19:43:04,599][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:18 • 0:00:00 20.16it/s v_num: 0.000
[2024-05-06 19:44:26,281][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:44:26,283][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/030
[2024-05-06 19:44:26,444][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:44:26,468][src.tasks.hpsearch][INFO] - 0.0007178839930599398, lr
[2024-05-06 19:44:26,493][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:44:26,515][src.tasks.hpsearch][INFO] - 0.04902796638075533 prior_scale
[2024-05-06 19:44:26,538][src.tasks.hpsearch][INFO] - 0.0006305977822506084 q_scale
[2024-05-06 19:44:26,563][src.tasks.hpsearch][INFO] - 0.4458370805228282 obs_scale
[2024-05-06 19:44:26,592][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:44:26,593][src.tasks.hpsearch][INFO] - _________________ Starting trial 031 __________________
[2024-05-06 19:44:26,593][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:44:26,593][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1

0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:44:43,089][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:44:43,098][train][INFO] - Instantiating callbacks...
[2024-05-06 19:44:43,098][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:44:43,102][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:44:43,102][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:44:43,103][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:44:43,104][train][INFO] - Instantiating loggers...
[2024-05-06 19:44:43,104][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:44:43,105][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:44:43,141][train][INFO] - Logging hyperparameters!
[2024-05-06 19:44:43,386][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:44:54,839][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:44:54,846][train][INFO] - Instantiating callbacks...
[2024-05-06 19:44:54,846][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:44:54,850][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:44:54,851][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:44:54,851][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:44:54,852][train][INFO] - Instantiating loggers...
[2024-05-06 19:44:54,852][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:44:54,853][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:44:54,902][train][INFO] - Logging hyperparameters!
[2024-05-06 19:44:54,949][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.90it/s v_num: 0.000
[2024-05-06 19:50:20,662][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:50:20,664][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/031
[2024-05-06 19:50:20,757][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:50:20,782][src.tasks.hpsearch][INFO] - 0.0003567555044956278, lr
[2024-05-06 19:50:20,807][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:50:20,832][src.tasks.hpsearch][INFO] - 0.05815104077663118 prior_scale
[2024-05-06 19:50:20,857][src.tasks.hpsearch][INFO] - 0.0002694232980195212 q_scale
[2024-05-06 19:50:20,880][src.tasks.hpsearch][INFO] - 0.3967240791658831 obs_scale
[2024-05-06 19:50:20,900][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:50:20,901][src.tasks.hpsearch][INFO] - _________________ Starting trial 032 __________________
[2024-05-06 19:50:20,901][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:50:20,901][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:50:54,206][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:50:54,217][train][INFO] - Instantiating callbacks...
[2024-05-06 19:50:54,217][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:50:54,222][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:50:54,223][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:50:54,223][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:50:54,225][train][INFO] - Instantiating loggers...
[2024-05-06 19:50:54,225][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:50:54,226][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:50:54,278][train][INFO] - Logging hyperparameters!
[2024-05-06 19:50:56,444][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:19 • 0:00:00 19.72it/s v_num: 0.000
[2024-05-06 19:53:23,241][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:53:23,243][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/031
[2024-05-06 19:53:23,393][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:53:23,437][src.tasks.hpsearch][INFO] - 0.000729074396149963, lr
[2024-05-06 19:53:23,472][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:53:23,510][src.tasks.hpsearch][INFO] - 0.09817041163299439 prior_scale
[2024-05-06 19:53:23,540][src.tasks.hpsearch][INFO] - 0.00026318471896278 q_scale
[2024-05-06 19:53:23,578][src.tasks.hpsearch][INFO] - 0.3199717779340769 obs_scale
[2024-05-06 19:53:23,617][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:53:23,618][src.tasks.hpsearch][INFO] - _________________ Starting trial 032 __________________
[2024-05-06 19:53:23,619][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:53:23,619][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:53:52,032][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:53:52,043][train][INFO] - Instantiating callbacks...
[2024-05-06 19:53:52,044][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:53:52,048][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:53:52,049][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:53:52,050][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:53:52,050][train][INFO] - Instantiating loggers...
[2024-05-06 19:53:52,051][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:53:52,052][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:53:52,091][train][INFO] - Logging hyperparameters!
[2024-05-06 19:53:52,300][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.70it/s v_num: 0.000
[2024-05-06 19:54:37,559][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:54:37,562][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/040
[2024-05-06 19:54:37,731][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:54:37,768][src.tasks.hpsearch][INFO] - 0.0007387085317501385, lr
[2024-05-06 19:54:37,804][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:54:37,840][src.tasks.hpsearch][INFO] - 0.05505225727543 prior_scale
[2024-05-06 19:54:37,877][src.tasks.hpsearch][INFO] - 0.000597938933323071 q_scale
[2024-05-06 19:54:37,913][src.tasks.hpsearch][INFO] - 0.505773582106805 obs_scale
[2024-05-06 19:54:37,951][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:54:37,951][src.tasks.hpsearch][INFO] - _________________ Starting trial 041 __________________
[2024-05-06 19:54:37,952][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:54:37,952][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:55:12,231][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:55:12,238][train][INFO] - Instantiating callbacks...
[2024-05-06 19:55:12,238][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:55:12,255][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:55:12,257][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:55:12,257][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:55:12,258][train][INFO] - Instantiating loggers...
[2024-05-06 19:55:12,258][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:55:12,259][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:55:12,305][train][INFO] - Logging hyperparameters!
[2024-05-06 19:55:12,342][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.68it/s v_num: 0.000
[2024-05-06 19:57:40,350][utils.utils][INFO] - Closing loggers...
[2024-05-06 19:57:40,352][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/032
[2024-05-06 19:57:40,483][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 19:57:40,506][src.tasks.hpsearch][INFO] - 0.0006432693407615532, lr
[2024-05-06 19:57:40,531][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 19:57:40,559][src.tasks.hpsearch][INFO] - 0.10207232513038603 prior_scale
[2024-05-06 19:57:40,588][src.tasks.hpsearch][INFO] - 0.0005500044262222238 q_scale
[2024-05-06 19:57:40,616][src.tasks.hpsearch][INFO] - 0.3036501581420814 obs_scale
[2024-05-06 19:57:40,641][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 19:57:40,642][src.tasks.hpsearch][INFO] - _________________ Starting trial 033 __________________
[2024-05-06 19:57:40,642][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 19:57:40,642][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 19:58:25,329][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 19:58:25,339][train][INFO] - Instantiating callbacks...
[2024-05-06 19:58:25,340][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 19:58:25,345][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 19:58:25,347][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 19:58:25,348][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 19:58:25,349][train][INFO] - Instantiating loggers...
[2024-05-06 19:58:25,349][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 19:58:25,351][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 19:58:25,412][train][INFO] - Logging hyperparameters!
[2024-05-06 19:58:25,548][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 27.89it/s v_num: 0.000
[2024-05-06 20:01:34,841][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:01:34,843][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/041
[2024-05-06 20:01:34,950][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:01:34,975][src.tasks.hpsearch][INFO] - 0.0007810047860749132, lr
[2024-05-06 20:01:34,999][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:01:35,024][src.tasks.hpsearch][INFO] - 0.04977734063670971 prior_scale
[2024-05-06 20:01:35,048][src.tasks.hpsearch][INFO] - 0.0009870864144858303 q_scale
[2024-05-06 20:01:35,073][src.tasks.hpsearch][INFO] - 0.44001273653437667 obs_scale
[2024-05-06 20:01:35,097][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:01:35,097][src.tasks.hpsearch][INFO] - _________________ Starting trial 042 __________________
[2024-05-06 20:01:35,097][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:01:35,098][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:01:40,842][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:01:40,848][train][INFO] - Instantiating callbacks...
[2024-05-06 20:01:40,849][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:01:40,851][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:01:40,852][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:01:40,852][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:01:40,853][train][INFO] - Instantiating loggers...
[2024-05-06 20:01:40,853][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:01:40,854][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:01:40,901][train][INFO] - Logging hyperparameters!
[2024-05-06 20:01:42,818][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:02:02,461][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:02:02,468][train][INFO] - Instantiating callbacks...
[2024-05-06 20:02:02,469][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:02:02,472][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:02:02,473][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:02:02,473][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:02:02,474][train][INFO] - Instantiating loggers...
[2024-05-06 20:02:02,474][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:02:02,475][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:02:02,521][train][INFO] - Logging hyperparameters!
[2024-05-06 20:02:02,766][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.92it/s v_num: 0.000
[2024-05-06 20:05:41,332][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:05:41,334][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/033
[2024-05-06 20:05:41,410][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:05:41,426][src.tasks.hpsearch][INFO] - 0.0007349925665405394, lr
[2024-05-06 20:05:41,443][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:05:41,461][src.tasks.hpsearch][INFO] - 0.17721944094520412 prior_scale
[2024-05-06 20:05:41,478][src.tasks.hpsearch][INFO] - 0.00015856821017201222 q_scale
[2024-05-06 20:05:41,495][src.tasks.hpsearch][INFO] - 0.6293638887691919 obs_scale
[2024-05-06 20:05:41,511][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 20:05:41,512][src.tasks.hpsearch][INFO] - _________________ Starting trial 034 __________________
[2024-05-06 20:05:41,512][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:05:41,512][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:06:08,639][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:06:08,646][train][INFO] - Instantiating callbacks...
[2024-05-06 20:06:08,647][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:06:08,651][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:06:08,652][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:06:08,652][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:06:08,653][train][INFO] - Instantiating loggers...
[2024-05-06 20:06:08,653][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:06:08,654][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:06:08,695][train][INFO] - Logging hyperparameters!
[2024-05-06 20:06:08,702][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.99it/s v_num: 0.000
[2024-05-06 20:07:22,496][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:07:22,499][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/033
[2024-05-06 20:07:22,585][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:07:22,609][src.tasks.hpsearch][INFO] - 0.0007076858351289794, lr
[2024-05-06 20:07:22,631][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:07:22,654][src.tasks.hpsearch][INFO] - 0.13606465675662016 prior_scale
[2024-05-06 20:07:22,676][src.tasks.hpsearch][INFO] - 0.0008187195374374731 q_scale
[2024-05-06 20:07:22,699][src.tasks.hpsearch][INFO] - 0.27342775354008625 obs_scale
[2024-05-06 20:07:22,723][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 20:07:22,724][src.tasks.hpsearch][INFO] - _________________ Starting trial 034 __________________
[2024-05-06 20:07:22,724][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:07:22,725][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:07:48,260][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:07:48,267][train][INFO] - Instantiating callbacks...
[2024-05-06 20:07:48,268][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:07:48,271][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:07:48,272][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:07:48,272][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:07:48,273][train][INFO] - Instantiating loggers...
[2024-05-06 20:07:48,273][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:07:48,274][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:07:48,311][train][INFO] - Logging hyperparameters!
[2024-05-06 20:07:48,320][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 10.15it/s v_num: 0.000
[2024-05-06 20:08:03,815][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:08:03,853][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/034
[2024-05-06 20:08:03,966][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:08:03,988][src.tasks.hpsearch][INFO] - 2.7722032902337684e-05, lr
[2024-05-06 20:08:04,009][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:08:04,030][src.tasks.hpsearch][INFO] - 0.06440353872516402 prior_scale
[2024-05-06 20:08:04,052][src.tasks.hpsearch][INFO] - 0.0009456229874537464 q_scale
[2024-05-06 20:08:04,073][src.tasks.hpsearch][INFO] - 1.097667916535935 obs_scale
[2024-05-06 20:08:04,095][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:08:04,095][src.tasks.hpsearch][INFO] - _________________ Starting trial 035 __________________
[2024-05-06 20:08:04,096][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:08:04,096][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:08:28,761][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:08:28,768][train][INFO] - Instantiating callbacks...
[2024-05-06 20:08:28,768][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:08:28,772][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:08:28,773][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:08:28,774][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:08:28,774][train][INFO] - Instantiating loggers...
[2024-05-06 20:08:28,775][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:08:28,776][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:08:28,802][train][INFO] - Logging hyperparameters!
[2024-05-06 20:08:28,846][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 15/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 15.40it/s v_num: 0.000
[2024-05-06 20:08:54,873][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[2024-05-06 20:08:55,114][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:08:55,167][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:08:55,188][src.tasks.hpsearch][INFO] - 0.00021171134279289951, lr
[2024-05-06 20:08:55,208][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:08:55,230][src.tasks.hpsearch][INFO] - 0.051783450179937934 prior_scale
[2024-05-06 20:08:55,253][src.tasks.hpsearch][INFO] - 0.00014643302226281866 q_scale
[2024-05-06 20:08:55,274][src.tasks.hpsearch][INFO] - 0.20296499173499513 obs_scale
[2024-05-06 20:08:55,295][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:08:55,296][src.tasks.hpsearch][INFO] - _________________ Starting trial 035 __________________
[2024-05-06 20:08:55,296][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:08:55,296][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:09:18,978][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:09:18,984][train][INFO] - Instantiating callbacks...
[2024-05-06 20:09:18,984][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:09:18,986][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:09:18,987][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:09:18,987][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:09:18,988][train][INFO] - Instantiating loggers...
[2024-05-06 20:09:18,988][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:09:18,989][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:09:19,034][train][INFO] - Logging hyperparameters!
[2024-05-06 20:09:19,044][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 35.24it/s v_num: 0.000
[2024-05-06 20:12:48,091][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:12:48,092][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/043
[2024-05-06 20:12:48,173][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:12:48,191][src.tasks.hpsearch][INFO] - 0.0006332625350956344, lr
[2024-05-06 20:12:48,209][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:12:48,227][src.tasks.hpsearch][INFO] - 0.059462115420992424 prior_scale
[2024-05-06 20:12:48,246][src.tasks.hpsearch][INFO] - 0.00010174879441412075 q_scale
[2024-05-06 20:12:48,265][src.tasks.hpsearch][INFO] - 0.4300640990720911 obs_scale
[2024-05-06 20:12:48,284][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:12:48,284][src.tasks.hpsearch][INFO] - _________________ Starting trial 044 __________________
[2024-05-06 20:12:48,284][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:12:48,284][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:13:13,079][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:13:13,090][train][INFO] - Instantiating callbacks...
[2024-05-06 20:13:13,091][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:13:13,093][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:13:13,094][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:13:13,095][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:13:13,096][train][INFO] - Instantiating loggers...
[2024-05-06 20:13:13,097][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:13:13,098][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:13:13,150][train][INFO] - Logging hyperparameters!
[2024-05-06 20:13:13,171][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:25 • 0:00:00 14.93it/s v_num: 0.000
[2024-05-06 20:17:04,401][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[2024-05-06 20:17:04,476][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:17:04,525][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 20:17:04,544][src.tasks.hpsearch][INFO] - 0.00012365570583686662, lr
[2024-05-06 20:17:04,561][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:17:04,579][src.tasks.hpsearch][INFO] - 0.09258552177020675 prior_scale
[2024-05-06 20:17:04,598][src.tasks.hpsearch][INFO] - 0.00107759808629228 q_scale
[2024-05-06 20:17:04,615][src.tasks.hpsearch][INFO] - 0.41318109010210613 obs_scale
[2024-05-06 20:17:04,632][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:17:04,632][src.tasks.hpsearch][INFO] - _________________ Starting trial 036 __________________
[2024-05-06 20:17:04,633][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:17:04,633][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:17:30,769][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:17:30,776][train][INFO] - Instantiating callbacks...
[2024-05-06 20:17:30,777][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:17:30,780][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:17:30,781][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:17:30,781][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:17:30,782][train][INFO] - Instantiating loggers...
[2024-05-06 20:17:30,782][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:17:30,783][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:17:30,819][train][INFO] - Logging hyperparameters!
[2024-05-06 20:17:30,827][train][INFO] - Starting training!
[2024-05-06 20:17:30,828][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.27it/s v_num: 0.000
[2024-05-06 20:18:48,062][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:18:48,064][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/044
[2024-05-06 20:18:48,160][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:18:48,178][src.tasks.hpsearch][INFO] - 0.0004253763151291993, lr
[2024-05-06 20:18:48,196][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:18:48,215][src.tasks.hpsearch][INFO] - 0.09855865418199694 prior_scale
[2024-05-06 20:18:48,233][src.tasks.hpsearch][INFO] - 0.00010158363528356515 q_scale
[2024-05-06 20:18:48,252][src.tasks.hpsearch][INFO] - 0.2743425869975343 obs_scale
[2024-05-06 20:18:48,270][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 20:18:48,270][src.tasks.hpsearch][INFO] - _________________ Starting trial 045 __________________
[2024-05-06 20:18:48,270][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:18:48,270][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:19:14,873][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:19:14,881][train][INFO] - Instantiating callbacks...
[2024-05-06 20:19:14,882][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:19:14,884][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:19:14,885][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:19:14,885][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:19:14,886][train][INFO] - Instantiating loggers...
[2024-05-06 20:19:14,886][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:19:14,888][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:19:14,939][train][INFO] - Logging hyperparameters!
[2024-05-06 20:19:14,961][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 17.74it/s v_num: 0.000
[2024-05-06 20:20:32,139][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:20:32,141][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/045
[2024-05-06 20:20:32,248][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:20:32,273][src.tasks.hpsearch][INFO] - 0.0009979307832409482, lr
[2024-05-06 20:20:32,296][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:20:32,321][src.tasks.hpsearch][INFO] - 0.060833387752002394 prior_scale
[2024-05-06 20:20:32,346][src.tasks.hpsearch][INFO] - 0.00021041204788870645 q_scale
[2024-05-06 20:20:32,371][src.tasks.hpsearch][INFO] - 0.42852216689824124 obs_scale
[2024-05-06 20:20:32,394][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:20:32,395][src.tasks.hpsearch][INFO] - _________________ Starting trial 046 __________________
[2024-05-06 20:20:32,395][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:20:32,396][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.71it/s v_num: 0.000
[2024-05-06 20:20:40,079][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:20:40,081][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/035
[2024-05-06 20:20:40,174][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 20:20:40,196][src.tasks.hpsearch][INFO] - 0.0004054309347254919, lr
[2024-05-06 20:20:40,216][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:20:40,237][src.tasks.hpsearch][INFO] - 0.0321829215948626 prior_scale
[2024-05-06 20:20:40,258][src.tasks.hpsearch][INFO] - 0.0002452656236328838 q_scale
[2024-05-06 20:20:40,283][src.tasks.hpsearch][INFO] - 0.44360034519482866 obs_scale
[2024-05-06 20:20:40,308][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:20:40,309][src.tasks.hpsearch][INFO] - _________________ Starting trial 036 __________________
[2024-05-06 20:20:40,309][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:20:40,309][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:20:57,272][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:20:57,279][train][INFO] - Instantiating callbacks...
[2024-05-06 20:20:57,279][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:20:57,281][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:20:57,282][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:20:57,282][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:20:57,283][train][INFO] - Instantiating loggers...
[2024-05-06 20:20:57,283][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:20:57,284][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:20:57,321][train][INFO] - Logging hyperparameters!
[2024-05-06 20:20:57,353][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:21:15,381][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:21:15,402][train][INFO] - Instantiating callbacks...
[2024-05-06 20:21:15,402][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:21:15,404][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:21:15,405][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:21:15,405][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:21:15,406][train][INFO] - Instantiating loggers...
[2024-05-06 20:21:15,406][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:21:15,407][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:21:15,437][train][INFO] - Logging hyperparameters!
[2024-05-06 20:21:15,501][train][INFO] - Starting training!
[2024-05-06 20:21:15,503][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:31 • 0:00:00 12.14it/s v_num: 0.000
[2024-05-06 20:24:26,344][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:24:26,346][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/036
[2024-05-06 20:24:26,438][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:24:26,458][src.tasks.hpsearch][INFO] - 5.1808411700953774e-05, lr
[2024-05-06 20:24:26,476][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:24:26,493][src.tasks.hpsearch][INFO] - 0.06061037395940922 prior_scale
[2024-05-06 20:24:26,512][src.tasks.hpsearch][INFO] - 0.0004969930137889889 q_scale
[2024-05-06 20:24:26,531][src.tasks.hpsearch][INFO] - 0.5064516163789642 obs_scale
[2024-05-06 20:24:26,552][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 20:24:26,552][src.tasks.hpsearch][INFO] - _________________ Starting trial 037 __________________
[2024-05-06 20:24:26,552][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:24:26,553][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:24:54,922][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:24:54,929][train][INFO] - Instantiating callbacks...
[2024-05-06 20:24:54,930][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:24:54,932][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:24:54,933][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:24:54,933][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:24:54,934][train][INFO] - Instantiating loggers...
[2024-05-06 20:24:54,934][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:24:54,935][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:24:54,971][train][INFO] - Logging hyperparameters!
[2024-05-06 20:24:54,982][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 3/19 ━━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 8.77it/s v_num: 0.000
[2024-05-06 20:25:09,775][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 3.
[2024-05-06 20:25:09,779][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:25:09,833][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:25:09,859][src.tasks.hpsearch][INFO] - 0.00044206432115025064, lr
[2024-05-06 20:25:09,883][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:25:09,909][src.tasks.hpsearch][INFO] - 0.03550002544853654 prior_scale
[2024-05-06 20:25:09,932][src.tasks.hpsearch][INFO] - 0.0017704988662195682 q_scale
[2024-05-06 20:25:09,954][src.tasks.hpsearch][INFO] - 0.6484039653175199 obs_scale
[2024-05-06 20:25:09,976][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 20:25:09,976][src.tasks.hpsearch][INFO] - _________________ Starting trial 038 __________________
[2024-05-06 20:25:09,977][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:25:09,977][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:25:43,318][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:25:43,328][train][INFO] - Instantiating callbacks...
[2024-05-06 20:25:43,329][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:25:43,333][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:25:43,336][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:25:43,337][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:25:43,338][train][INFO] - Instantiating loggers...
[2024-05-06 20:25:43,338][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:25:43,339][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:25:43,357][train][INFO] - Logging hyperparameters!
[2024-05-06 20:25:43,367][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 34.51it/s v_num: 0.000
[2024-05-06 20:26:04,066][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:26:04,067][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/046
[2024-05-06 20:26:04,166][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 20:26:04,192][src.tasks.hpsearch][INFO] - 0.0006000414195743824, lr
[2024-05-06 20:26:04,216][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:26:04,241][src.tasks.hpsearch][INFO] - 0.035258651824255645 prior_scale
[2024-05-06 20:26:04,267][src.tasks.hpsearch][INFO] - 0.00011985097304494221 q_scale
[2024-05-06 20:26:04,292][src.tasks.hpsearch][INFO] - 0.608179281616167 obs_scale
[2024-05-06 20:26:04,317][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 20:26:04,317][src.tasks.hpsearch][INFO] - _________________ Starting trial 047 __________________
[2024-05-06 20:26:04,318][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:26:04,318][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:26:28,770][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:26:28,776][train][INFO] - Instantiating callbacks...
[2024-05-06 20:26:28,777][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:26:28,779][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:26:28,779][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:26:28,780][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:26:28,781][train][INFO] - Instantiating loggers...
[2024-05-06 20:26:28,781][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:26:28,782][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:26:28,826][train][INFO] - Logging hyperparameters!
[2024-05-06 20:26:28,836][train][INFO] - Starting training!
[2024-05-06 20:26:28,839][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.11it/s v_num: 0.000
[2024-05-06 20:27:24,801][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:27:24,802][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/036
[2024-05-06 20:27:24,902][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:27:24,924][src.tasks.hpsearch][INFO] - 0.00014913593738818511, lr
[2024-05-06 20:27:24,943][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:27:24,965][src.tasks.hpsearch][INFO] - 0.09120439297552835 prior_scale
[2024-05-06 20:27:24,987][src.tasks.hpsearch][INFO] - 0.00038203459962374503 q_scale
[2024-05-06 20:27:25,006][src.tasks.hpsearch][INFO] - 0.5634114663218532 obs_scale
[2024-05-06 20:27:25,024][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 20:27:25,025][src.tasks.hpsearch][INFO] - _________________ Starting trial 037 __________________
[2024-05-06 20:27:25,025][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:27:25,025][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
Epoch 15/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 27.60it/s v_num: 0.000
[2024-05-06 20:27:48,216][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[2024-05-06 20:27:48,243][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:27:48,284][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:27:48,301][src.tasks.hpsearch][INFO] - 1.0125058472109015e-05, lr
[2024-05-06 20:27:48,317][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:27:48,333][src.tasks.hpsearch][INFO] - 0.20075418565349604 prior_scale
[2024-05-06 20:27:48,349][src.tasks.hpsearch][INFO] - 0.00014861953629173865 q_scale
[2024-05-06 20:27:48,365][src.tasks.hpsearch][INFO] - 0.13470210895997695 obs_scale
[2024-05-06 20:27:48,381][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 20:27:48,381][src.tasks.hpsearch][INFO] - _________________ Starting trial 048 __________________
[2024-05-06 20:27:48,381][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:27:48,381][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
[2024-05-06 20:27:52,294][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:27:52,317][train][INFO] - Instantiating callbacks...
[2024-05-06 20:27:52,317][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:27:52,320][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:27:52,321][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:27:52,321][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:27:52,322][train][INFO] - Instantiating loggers...
[2024-05-06 20:27:52,322][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:27:52,323][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:27:52,366][train][INFO] - Logging hyperparameters!
[2024-05-06 20:27:52,381][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:28:16,820][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:28:16,827][train][INFO] - Instantiating callbacks...
[2024-05-06 20:28:16,828][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:28:16,831][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:28:16,832][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:28:16,832][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:28:16,833][train][INFO] - Instantiating loggers...
[2024-05-06 20:28:16,833][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:28:16,834][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:28:16,863][train][INFO] - Logging hyperparameters!
[2024-05-06 20:28:16,873][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 3/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 14.51it/s v_num: 0.000
[2024-05-06 20:28:28,074][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 3.
[2024-05-06 20:28:28,078][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:28:28,129][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:28:28,156][src.tasks.hpsearch][INFO] - 0.000397903957099914, lr
[2024-05-06 20:28:28,180][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:28:28,201][src.tasks.hpsearch][INFO] - 0.08101161562963576 prior_scale
[2024-05-06 20:28:28,222][src.tasks.hpsearch][INFO] - 0.00032262214400778806 q_scale
[2024-05-06 20:28:28,244][src.tasks.hpsearch][INFO] - 0.8285181121952916 obs_scale
[2024-05-06 20:28:28,264][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:28:28,264][src.tasks.hpsearch][INFO] - _________________ Starting trial 049 __________________
[2024-05-06 20:28:28,264][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:28:28,265][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:10 • 0:00:00 4.39it/s v_num: 0.000
[2024-05-06 20:28:41,402][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:28:41,403][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/038
[2024-05-06 20:28:41,497][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 20:28:41,520][src.tasks.hpsearch][INFO] - 1.779960128170813e-05, lr
[2024-05-06 20:28:41,543][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:28:41,566][src.tasks.hpsearch][INFO] - 0.04258309931113822 prior_scale
[2024-05-06 20:28:41,596][src.tasks.hpsearch][INFO] - 0.00024697338723663815 q_scale
[2024-05-06 20:28:41,618][src.tasks.hpsearch][INFO] - 1.289015369175394 obs_scale
[2024-05-06 20:28:41,640][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 20:28:41,640][src.tasks.hpsearch][INFO] - _________________ Starting trial 039 __________________
[2024-05-06 20:28:41,641][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:28:41,641][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:29:10,038][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:29:10,045][train][INFO] - Instantiating callbacks...
[2024-05-06 20:29:10,045][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:29:10,049][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:29:10,049][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:29:10,050][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:29:10,050][train][INFO] - Instantiating loggers...
[2024-05-06 20:29:10,051][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:29:10,051][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:29:10,090][train][INFO] - Logging hyperparameters!
[2024-05-06 20:29:10,102][train][INFO] - Starting training!
[2024-05-06 20:29:10,104][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 6.90it/s v_num: 0.000
[2024-05-06 20:29:17,474][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:29:17,475][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/037
[2024-05-06 20:29:17,571][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:29:17,593][src.tasks.hpsearch][INFO] - 0.00029728400990432127, lr
[2024-05-06 20:29:17,614][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:29:17,634][src.tasks.hpsearch][INFO] - 0.14271947763354037 prior_scale
[2024-05-06 20:29:17,653][src.tasks.hpsearch][INFO] - 0.0011046943371972233 q_scale
[2024-05-06 20:29:17,673][src.tasks.hpsearch][INFO] - 0.7681695633728917 obs_scale
[2024-05-06 20:29:17,691][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 20:29:17,692][src.tasks.hpsearch][INFO] - _________________ Starting trial 038 __________________
[2024-05-06 20:29:17,692][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:29:17,692][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:29:43,206][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:29:43,212][train][INFO] - Instantiating callbacks...
[2024-05-06 20:29:43,213][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:29:43,215][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:29:43,215][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:29:43,216][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:29:43,217][train][INFO] - Instantiating loggers...
[2024-05-06 20:29:43,217][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:29:43,218][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:29:43,245][train][INFO] - Logging hyperparameters!
[2024-05-06 20:29:43,267][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 18.12it/s v_num: 0.000
[2024-05-06 20:31:29,229][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:31:29,231][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/039
[2024-05-06 20:31:29,317][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:31:29,336][src.tasks.hpsearch][INFO] - 0.00032287340305940605, lr
[2024-05-06 20:31:29,354][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:31:29,373][src.tasks.hpsearch][INFO] - 0.1152109815590333 prior_scale
[2024-05-06 20:31:29,392][src.tasks.hpsearch][INFO] - 0.00037533680472094904 q_scale
[2024-05-06 20:31:29,411][src.tasks.hpsearch][INFO] - 0.13869097760116636 obs_scale
[2024-05-06 20:31:29,429][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:31:29,429][src.tasks.hpsearch][INFO] - _________________ Starting trial 040 __________________
[2024-05-06 20:31:29,430][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:31:29,430][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:31:56,390][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:31:56,397][train][INFO] - Instantiating callbacks...
[2024-05-06 20:31:56,398][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:31:56,400][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:31:56,401][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:31:56,402][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:31:56,403][train][INFO] - Instantiating loggers...
[2024-05-06 20:31:56,403][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:31:56,404][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:31:56,440][train][INFO] - Logging hyperparameters!
[2024-05-06 20:31:56,447][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:08 • 0:00:00 5.93it/s v_num: 0.000
[2024-05-06 20:32:46,523][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:32:46,524][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/038
[2024-05-06 20:32:46,606][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 20:32:46,629][src.tasks.hpsearch][INFO] - 0.0008037234347984708, lr
[2024-05-06 20:32:46,651][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:32:46,674][src.tasks.hpsearch][INFO] - 0.12015069252918967 prior_scale
[2024-05-06 20:32:46,698][src.tasks.hpsearch][INFO] - 0.0005018583527468872 q_scale
[2024-05-06 20:32:46,721][src.tasks.hpsearch][INFO] - 0.20329334720403028 obs_scale
[2024-05-06 20:32:46,737][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 20:32:46,738][src.tasks.hpsearch][INFO] - _________________ Starting trial 039 __________________
[2024-05-06 20:32:46,738][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:32:46,738][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:33:11,460][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:33:11,467][train][INFO] - Instantiating callbacks...
[2024-05-06 20:33:11,467][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:33:11,470][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:33:11,470][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:33:11,471][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:33:11,471][train][INFO] - Instantiating loggers...
[2024-05-06 20:33:11,472][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:33:11,473][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:33:11,505][train][INFO] - Logging hyperparameters!
[2024-05-06 20:33:11,511][train][INFO] - Starting training!
[2024-05-06 20:33:11,513][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 17.47it/s v_num: 0.000
[2024-05-06 20:34:55,038][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[2024-05-06 20:34:55,061][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:34:55,107][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:34:55,129][src.tasks.hpsearch][INFO] - 9.156900205817904e-05, lr
[2024-05-06 20:34:55,154][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 20:34:55,179][src.tasks.hpsearch][INFO] - 0.17083483372328487 prior_scale
[2024-05-06 20:34:55,201][src.tasks.hpsearch][INFO] - 0.00034775158827545486 q_scale
[2024-05-06 20:34:55,220][src.tasks.hpsearch][INFO] - 0.33681574877144815 obs_scale
[2024-05-06 20:34:55,239][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:34:55,239][src.tasks.hpsearch][INFO] - _________________ Starting trial 040 __________________
[2024-05-06 20:34:55,240][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:34:55,240][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:35:19,464][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:35:19,470][train][INFO] - Instantiating callbacks...
[2024-05-06 20:35:19,471][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:35:19,474][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:35:19,475][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:35:19,475][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:35:19,476][train][INFO] - Instantiating loggers...
[2024-05-06 20:35:19,476][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:35:19,477][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:35:19,514][train][INFO] - Logging hyperparameters!
[2024-05-06 20:35:19,521][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:19 • 0:00:00 19.33it/s v_num: 0.000
[2024-05-06 20:37:10,543][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:37:10,545][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/049
[2024-05-06 20:37:10,635][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:37:10,656][src.tasks.hpsearch][INFO] - 0.00051392763232244, lr
[2024-05-06 20:37:10,676][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:37:10,696][src.tasks.hpsearch][INFO] - 0.1113720320629017 prior_scale
[2024-05-06 20:37:10,716][src.tasks.hpsearch][INFO] - 0.0036267701624537667 q_scale
[2024-05-06 20:37:10,736][src.tasks.hpsearch][INFO] - 1.0145434612062147 obs_scale
[2024-05-06 20:37:10,755][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:37:10,756][src.tasks.hpsearch][INFO] - _________________ Starting trial 050 __________________
[2024-05-06 20:37:10,756][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:37:10,756][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:37:34,543][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:37:34,550][train][INFO] - Instantiating callbacks...
[2024-05-06 20:37:34,551][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:37:34,553][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:37:34,553][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:37:34,554][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:37:34,555][train][INFO] - Instantiating loggers...
[2024-05-06 20:37:34,555][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:37:34,556][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:37:34,595][train][INFO] - Logging hyperparameters!
[2024-05-06 20:37:34,602][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 37.01it/s v_num: 0.000
[2024-05-06 20:42:32,278][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:42:32,279][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/050
[2024-05-06 20:42:32,366][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:42:32,389][src.tasks.hpsearch][INFO] - 0.0007834564129333778, lr
[2024-05-06 20:42:32,410][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:42:32,429][src.tasks.hpsearch][INFO] - 0.04784075629852245 prior_scale
[2024-05-06 20:42:32,452][src.tasks.hpsearch][INFO] - 0.00142397504288141 q_scale
[2024-05-06 20:42:32,475][src.tasks.hpsearch][INFO] - 0.49683402466956833 obs_scale
[2024-05-06 20:42:32,497][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:42:32,497][src.tasks.hpsearch][INFO] - _________________ Starting trial 051 __________________
[2024-05-06 20:42:32,498][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:42:32,498][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:42:56,497][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:42:56,503][train][INFO] - Instantiating callbacks...
[2024-05-06 20:42:56,504][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:42:56,506][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:42:56,507][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:42:56,507][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:42:56,508][train][INFO] - Instantiating loggers...
[2024-05-06 20:42:56,508][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:42:56,509][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:42:56,547][train][INFO] - Logging hyperparameters!
[2024-05-06 20:42:56,566][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:28 • 0:00:00 13.40it/s v_num: 0.000
[2024-05-06 20:43:14,666][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 19.
[2024-05-06 20:43:14,682][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:43:14,722][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:43:14,739][src.tasks.hpsearch][INFO] - 0.0007810047684009159, lr
[2024-05-06 20:43:14,756][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:43:14,773][src.tasks.hpsearch][INFO] - 0.07460398630428068 prior_scale
[2024-05-06 20:43:14,792][src.tasks.hpsearch][INFO] - 0.00021009633065040994 q_scale
[2024-05-06 20:43:14,814][src.tasks.hpsearch][INFO] - 0.3074253737063702 obs_scale
[2024-05-06 20:43:14,834][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:43:14,834][src.tasks.hpsearch][INFO] - _________________ Starting trial 041 __________________
[2024-05-06 20:43:14,834][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:43:14,835][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:43:39,232][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:43:39,239][train][INFO] - Instantiating callbacks...
[2024-05-06 20:43:39,240][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:43:39,242][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:43:39,245][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:43:39,245][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:43:39,246][train][INFO] - Instantiating loggers...
[2024-05-06 20:43:39,246][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:43:39,247][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:43:39,283][train][INFO] - Logging hyperparameters!
[2024-05-06 20:43:39,289][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:28 • 0:00:00 13.52it/s v_num: 0.000
[2024-05-06 20:45:52,709][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:45:52,711][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/040
[2024-05-06 20:45:52,811][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:45:52,833][src.tasks.hpsearch][INFO] - 0.000631737331581124, lr
[2024-05-06 20:45:52,854][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:45:52,877][src.tasks.hpsearch][INFO] - 0.09461612618755087 prior_scale
[2024-05-06 20:45:52,900][src.tasks.hpsearch][INFO] - 0.0002973573624642535 q_scale
[2024-05-06 20:45:52,925][src.tasks.hpsearch][INFO] - 0.5200950570914035 obs_scale
[2024-05-06 20:45:52,948][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:45:52,949][src.tasks.hpsearch][INFO] - _________________ Starting trial 041 __________________
[2024-05-06 20:45:52,949][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:45:52,950][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:46:18,589][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:46:18,596][train][INFO] - Instantiating callbacks...
[2024-05-06 20:46:18,596][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:46:18,598][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:46:18,598][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:46:18,599][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:46:18,600][train][INFO] - Instantiating loggers...
[2024-05-06 20:46:18,600][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:46:18,601][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:46:18,659][train][INFO] - Logging hyperparameters!
[2024-05-06 20:46:18,681][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 35.87it/s v_num: 0.000
[2024-05-06 20:47:52,042][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:47:52,044][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/051
[2024-05-06 20:47:52,207][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:47:52,233][src.tasks.hpsearch][INFO] - 0.0006552714893977419, lr
[2024-05-06 20:47:52,259][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:47:52,284][src.tasks.hpsearch][INFO] - 0.04210916466264082 prior_scale
[2024-05-06 20:47:52,309][src.tasks.hpsearch][INFO] - 0.000661531658818666 q_scale
[2024-05-06 20:47:52,334][src.tasks.hpsearch][INFO] - 0.3789156150142302 obs_scale
[2024-05-06 20:47:52,358][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:47:52,359][src.tasks.hpsearch][INFO] - _________________ Starting trial 052 __________________
[2024-05-06 20:47:52,359][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:47:52,360][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:48:16,340][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:48:16,346][train][INFO] - Instantiating callbacks...
[2024-05-06 20:48:16,347][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:48:16,349][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:48:16,350][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:48:16,350][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:48:16,351][train][INFO] - Instantiating loggers...
[2024-05-06 20:48:16,351][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:48:16,352][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:48:16,387][train][INFO] - Logging hyperparameters!
[2024-05-06 20:48:16,393][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.90it/s v_num: 0.000
[2024-05-06 20:50:02,455][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:50:02,457][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/041
[2024-05-06 20:50:02,544][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:50:02,564][src.tasks.hpsearch][INFO] - 0.0008338237384061257, lr
[2024-05-06 20:50:02,583][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:50:02,607][src.tasks.hpsearch][INFO] - 0.05936172622629898 prior_scale
[2024-05-06 20:50:02,627][src.tasks.hpsearch][INFO] - 0.00015915366241471443 q_scale
[2024-05-06 20:50:02,647][src.tasks.hpsearch][INFO] - 0.3313858318021943 obs_scale
[2024-05-06 20:50:02,668][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:50:02,668][src.tasks.hpsearch][INFO] - _________________ Starting trial 042 __________________
[2024-05-06 20:50:02,669][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:50:02,669][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:50:27,369][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:50:27,376][train][INFO] - Instantiating callbacks...
[2024-05-06 20:50:27,377][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:50:27,380][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:50:27,380][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:50:27,381][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:50:27,381][train][INFO] - Instantiating loggers...
[2024-05-06 20:50:27,382][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:50:27,382][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:50:27,418][train][INFO] - Logging hyperparameters!
[2024-05-06 20:50:27,427][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.60it/s v_num: 0.000
[2024-05-06 20:52:47,594][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:52:47,596][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/041
[2024-05-06 20:52:47,694][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:52:47,716][src.tasks.hpsearch][INFO] - 0.0005752880938533469, lr
[2024-05-06 20:52:47,738][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:52:47,760][src.tasks.hpsearch][INFO] - 0.09932446036472457 prior_scale
[2024-05-06 20:52:47,782][src.tasks.hpsearch][INFO] - 0.00019597689702210863 q_scale
[2024-05-06 20:52:47,804][src.tasks.hpsearch][INFO] - 0.4404073995649562 obs_scale
[2024-05-06 20:52:47,827][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:52:47,827][src.tasks.hpsearch][INFO] - _________________ Starting trial 042 __________________
[2024-05-06 20:52:47,827][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:52:47,828][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 33.27it/s v_num: 0.000
[2024-05-06 20:53:10,087][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:53:10,089][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/052
[2024-05-06 20:53:10,178][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:53:10,198][src.tasks.hpsearch][INFO] - 0.0006568117881031401, lr
[2024-05-06 20:53:10,217][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:53:10,237][src.tasks.hpsearch][INFO] - 0.04213674639680718 prior_scale
[2024-05-06 20:53:10,257][src.tasks.hpsearch][INFO] - 0.00026096594583978355 q_scale
[2024-05-06 20:53:10,276][src.tasks.hpsearch][INFO] - 0.3816046867756409 obs_scale
[2024-05-06 20:53:10,296][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:53:10,296][src.tasks.hpsearch][INFO] - _________________ Starting trial 053 __________________
[2024-05-06 20:53:10,296][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:53:10,297][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:53:12,509][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:53:12,517][train][INFO] - Instantiating callbacks...
[2024-05-06 20:53:12,517][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:53:12,520][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:53:12,521][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:53:12,521][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:53:12,522][train][INFO] - Instantiating loggers...
[2024-05-06 20:53:12,522][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:53:12,523][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:53:12,560][train][INFO] - Logging hyperparameters!
[2024-05-06 20:53:12,568][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:53:34,088][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:53:34,095][train][INFO] - Instantiating callbacks...
[2024-05-06 20:53:34,095][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:53:34,097][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:53:34,098][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:53:34,098][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:53:34,099][train][INFO] - Instantiating loggers...
[2024-05-06 20:53:34,099][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:53:34,100][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:53:34,127][train][INFO] - Logging hyperparameters!
[2024-05-06 20:53:34,134][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:19 • 0:00:00 19.25it/s v_num: 0.000
[2024-05-06 20:57:03,000][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:57:03,002][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/042
[2024-05-06 20:57:03,094][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:57:03,120][src.tasks.hpsearch][INFO] - 0.0008056697292903494, lr
[2024-05-06 20:57:03,146][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:57:03,168][src.tasks.hpsearch][INFO] - 0.05667581375668681 prior_scale
[2024-05-06 20:57:03,189][src.tasks.hpsearch][INFO] - 0.00010713881154318892 q_scale
[2024-05-06 20:57:03,212][src.tasks.hpsearch][INFO] - 0.40364776332904556 obs_scale
[2024-05-06 20:57:03,233][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:57:03,233][src.tasks.hpsearch][INFO] - _________________ Starting trial 043 __________________
[2024-05-06 20:57:03,234][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:57:03,234][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:57:27,814][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:57:27,822][train][INFO] - Instantiating callbacks...
[2024-05-06 20:57:27,822][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:57:27,825][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:57:27,825][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:57:27,826][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:57:27,827][train][INFO] - Instantiating loggers...
[2024-05-06 20:57:27,827][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:57:27,828][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:57:27,861][train][INFO] - Logging hyperparameters!
[2024-05-06 20:57:27,869][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:09 • 0:00:00 39.10it/s v_num: 0.000
[2024-05-06 20:58:32,622][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:58:32,624][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/053
[2024-05-06 20:58:32,727][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:58:32,752][src.tasks.hpsearch][INFO] - 0.0008405087462915266, lr
[2024-05-06 20:58:32,775][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:58:32,797][src.tasks.hpsearch][INFO] - 0.025823816505289553 prior_scale
[2024-05-06 20:58:32,820][src.tasks.hpsearch][INFO] - 0.0002568817698408126 q_scale
[2024-05-06 20:58:32,844][src.tasks.hpsearch][INFO] - 0.3628072411901558 obs_scale
[2024-05-06 20:58:32,867][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:58:32,868][src.tasks.hpsearch][INFO] - _________________ Starting trial 054 __________________
[2024-05-06 20:58:32,868][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:58:32,869][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:58:56,462][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:58:56,469][train][INFO] - Instantiating callbacks...
[2024-05-06 20:58:56,469][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:58:56,473][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:58:56,474][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:58:56,474][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:58:56,475][train][INFO] - Instantiating loggers...
[2024-05-06 20:58:56,475][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:58:56,476][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:58:56,512][train][INFO] - Logging hyperparameters!
[2024-05-06 20:58:56,519][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.62it/s v_num: 0.000
[2024-05-06 20:59:27,468][utils.utils][INFO] - Closing loggers...
[2024-05-06 20:59:27,469][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/042
[2024-05-06 20:59:27,561][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 20:59:27,580][src.tasks.hpsearch][INFO] - 0.0004893506537327236, lr
[2024-05-06 20:59:27,602][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 20:59:27,624][src.tasks.hpsearch][INFO] - 0.10190403880637242 prior_scale
[2024-05-06 20:59:27,646][src.tasks.hpsearch][INFO] - 0.00016050009896061184 q_scale
[2024-05-06 20:59:27,668][src.tasks.hpsearch][INFO] - 0.432203932266647 obs_scale
[2024-05-06 20:59:27,689][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 20:59:27,689][src.tasks.hpsearch][INFO] - _________________ Starting trial 043 __________________
[2024-05-06 20:59:27,690][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 20:59:27,690][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 20:59:51,554][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 20:59:51,560][train][INFO] - Instantiating callbacks...
[2024-05-06 20:59:51,560][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 20:59:51,563][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 20:59:51,564][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 20:59:51,564][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 20:59:51,565][train][INFO] - Instantiating loggers...
[2024-05-06 20:59:51,565][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 20:59:51,566][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 20:59:51,599][train][INFO] - Logging hyperparameters!
[2024-05-06 20:59:51,610][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.47it/s v_num: 0.000
[2024-05-06 21:04:03,839][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:04:03,841][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/043
[2024-05-06 21:04:03,947][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:04:03,969][src.tasks.hpsearch][INFO] - 0.0005441983505767138, lr
[2024-05-06 21:04:03,991][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:04:04,020][src.tasks.hpsearch][INFO] - 0.08864713317680804 prior_scale
[2024-05-06 21:04:04,046][src.tasks.hpsearch][INFO] - 0.0001452635275060882 q_scale
[2024-05-06 21:04:04,072][src.tasks.hpsearch][INFO] - 0.35064533938700676 obs_scale
[2024-05-06 21:04:04,097][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:04:04,097][src.tasks.hpsearch][INFO] - _________________ Starting trial 044 __________________
[2024-05-06 21:04:04,098][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:04:04,098][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1

0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:04:01,289][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:04:01,296][train][INFO] - Instantiating callbacks...
[2024-05-06 21:04:01,296][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:04:01,299][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:04:01,299][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:04:01,300][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:04:01,300][train][INFO] - Instantiating loggers...
[2024-05-06 21:04:01,301][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:04:01,301][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:04:01,340][train][INFO] - Logging hyperparameters!
[2024-05-06 21:04:01,347][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:04:29,359][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:04:29,367][train][INFO] - Instantiating callbacks...
[2024-05-06 21:04:29,367][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:04:29,369][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:04:29,370][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:04:29,370][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:04:29,371][train][INFO] - Instantiating loggers...
[2024-05-06 21:04:29,371][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:04:29,372][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:04:29,409][train][INFO] - Logging hyperparameters!
[2024-05-06 21:04:29,416][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 29.70it/s v_num: 0.000
[2024-05-06 21:05:23,585][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:05:23,587][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/043
[2024-05-06 21:05:23,661][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:05:23,678][src.tasks.hpsearch][INFO] - 1.1818092032455107e-05, lr
[2024-05-06 21:05:23,693][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:05:23,709][src.tasks.hpsearch][INFO] - 0.059462115420992424 prior_scale
[2024-05-06 21:05:23,725][src.tasks.hpsearch][INFO] - 0.00010407011758375458 q_scale
[2024-05-06 21:05:23,741][src.tasks.hpsearch][INFO] - 0.3666043592179569 obs_scale
[2024-05-06 21:05:23,757][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:05:23,757][src.tasks.hpsearch][INFO] - _________________ Starting trial 044 __________________
[2024-05-06 21:05:23,758][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:05:23,758][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:05:47,224][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:05:47,230][train][INFO] - Instantiating callbacks...
[2024-05-06 21:05:47,230][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:05:47,232][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:05:47,233][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:05:47,233][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:05:47,234][train][INFO] - Instantiating loggers...
[2024-05-06 21:05:47,234][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:05:47,235][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:05:47,272][train][INFO] - Logging hyperparameters!
[2024-05-06 21:05:47,281][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:05 • 0:00:00 36.22it/s v_num: 0.000
[2024-05-06 21:06:29,817][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:06:29,819][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/055
[2024-05-06 21:06:29,894][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:06:29,910][src.tasks.hpsearch][INFO] - 0.0005683201359350748, lr
[2024-05-06 21:06:29,930][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:06:29,947][src.tasks.hpsearch][INFO] - 0.039812173617282585 prior_scale
[2024-05-06 21:06:29,963][src.tasks.hpsearch][INFO] - 0.0004498881918430304 q_scale
[2024-05-06 21:06:29,980][src.tasks.hpsearch][INFO] - 0.3000366761205296 obs_scale
[2024-05-06 21:06:29,997][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:06:29,997][src.tasks.hpsearch][INFO] - _________________ Starting trial 056 __________________
[2024-05-06 21:06:29,997][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:06:29,998][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:06:53,874][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:06:53,880][train][INFO] - Instantiating callbacks...
[2024-05-06 21:06:53,881][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:06:53,884][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:06:53,884][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:06:53,885][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:06:53,885][train][INFO] - Instantiating loggers...
[2024-05-06 21:06:53,885][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:06:53,886][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:06:53,912][train][INFO] - Logging hyperparameters!
[2024-05-06 21:06:53,919][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 3/19 ━━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.28it/s v_num: 0.000
[2024-05-06 21:06:55,876][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 3.
[2024-05-06 21:06:55,915][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:06:55,971][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:06:55,994][src.tasks.hpsearch][INFO] - 0.0007852634527765138, lr
[2024-05-06 21:06:56,017][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:06:56,042][src.tasks.hpsearch][INFO] - 0.07574169818571772 prior_scale
[2024-05-06 21:06:56,068][src.tasks.hpsearch][INFO] - 0.0002060177287612192 q_scale
[2024-05-06 21:06:56,091][src.tasks.hpsearch][INFO] - 0.29802886348401114 obs_scale
[2024-05-06 21:06:56,114][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 21:06:56,114][src.tasks.hpsearch][INFO] - _________________ Starting trial 045 __________________
[2024-05-06 21:06:56,115][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:06:56,115][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:07:23,657][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:07:23,663][train][INFO] - Instantiating callbacks...
[2024-05-06 21:07:23,664][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:07:23,667][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:07:23,668][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:07:23,668][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:07:23,669][train][INFO] - Instantiating loggers...
[2024-05-06 21:07:23,670][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:07:23,671][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:07:23,702][train][INFO] - Logging hyperparameters!
[2024-05-06 21:07:23,710][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 12.67it/s v_num: 0.000
[2024-05-06 21:09:01,782][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[2024-05-06 21:09:01,787][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:09:01,829][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:09:01,847][src.tasks.hpsearch][INFO] - 0.00020097100557417953, lr
[2024-05-06 21:09:01,864][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:09:01,881][src.tasks.hpsearch][INFO] - 0.0925596039981866 prior_scale
[2024-05-06 21:09:01,898][src.tasks.hpsearch][INFO] - 0.0003116856578104833 q_scale
[2024-05-06 21:09:01,915][src.tasks.hpsearch][INFO] - 0.43880498015587355 obs_scale
[2024-05-06 21:09:01,932][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:09:01,932][src.tasks.hpsearch][INFO] - _________________ Starting trial 046 __________________
[2024-05-06 21:09:01,932][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:09:01,933][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:09:25,231][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:09:25,237][train][INFO] - Instantiating callbacks...
[2024-05-06 21:09:25,238][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:09:25,239][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:09:25,240][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:09:25,240][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:09:25,241][train][INFO] - Instantiating loggers...
[2024-05-06 21:09:25,241][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:09:25,242][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:09:25,289][train][INFO] - Logging hyperparameters!
[2024-05-06 21:09:25,299][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.27it/s v_num: 0.000
[2024-05-06 21:10:58,711][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:10:58,713][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/044
[2024-05-06 21:10:58,796][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:10:58,816][src.tasks.hpsearch][INFO] - 0.0009667551493626546, lr
[2024-05-06 21:10:58,833][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:10:58,853][src.tasks.hpsearch][INFO] - 0.2357626494360721 prior_scale
[2024-05-06 21:10:58,875][src.tasks.hpsearch][INFO] - 0.00015870411810596594 q_scale
[2024-05-06 21:10:58,899][src.tasks.hpsearch][INFO] - 0.2284740192713978 obs_scale
[2024-05-06 21:10:58,923][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 21:10:58,923][src.tasks.hpsearch][INFO] - _________________ Starting trial 045 __________________
[2024-05-06 21:10:58,924][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:10:58,924][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:11:24,578][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:11:24,584][train][INFO] - Instantiating callbacks...
[2024-05-06 21:11:24,585][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:11:24,587][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:11:24,588][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:11:24,588][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:11:24,589][train][INFO] - Instantiating loggers...
[2024-05-06 21:11:24,590][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:11:24,591][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:11:24,631][train][INFO] - Logging hyperparameters!
[2024-05-06 21:11:24,712][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:09 • 0:00:00 39.19it/s v_num: 0.000
[2024-05-06 21:11:31,325][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:11:31,327][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_rad/runs/2024-05-06_16-37-24/056
[2024-05-06 21:11:31,410][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:11:31,429][src.tasks.hpsearch][INFO] - 0.0002623861528802146, lr
[2024-05-06 21:11:31,447][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:11:31,465][src.tasks.hpsearch][INFO] - 0.04328590310669614 prior_scale
[2024-05-06 21:11:31,482][src.tasks.hpsearch][INFO] - 0.0002083790625223039 q_scale
[2024-05-06 21:11:31,501][src.tasks.hpsearch][INFO] - 0.23533756673077186 obs_scale
[2024-05-06 21:11:31,517][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:11:31,517][src.tasks.hpsearch][INFO] - _________________ Starting trial 057 __________________
[2024-05-06 21:11:31,518][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:11:31,518][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:11:55,023][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:11:55,030][train][INFO] - Instantiating callbacks...
[2024-05-06 21:11:55,030][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:11:55,032][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:11:55,033][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:11:55,033][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:11:55,034][train][INFO] - Instantiating loggers...
[2024-05-06 21:11:55,034][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:11:55,035][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:11:55,072][train][INFO] - Logging hyperparameters!
[2024-05-06 21:11:55,093][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 14.13it/s v_num: 0.000
[2024-05-06 21:12:50,701][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:12:50,703][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/045
[2024-05-06 21:12:50,796][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:12:50,821][src.tasks.hpsearch][INFO] - 0.0006652190222180234, lr
[2024-05-06 21:12:50,843][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:12:50,867][src.tasks.hpsearch][INFO] - 0.04418451526407311 prior_scale
[2024-05-06 21:12:50,886][src.tasks.hpsearch][INFO] - 0.00034283844133024317 q_scale
[2024-05-06 21:12:50,904][src.tasks.hpsearch][INFO] - 0.46609545318674406 obs_scale
[2024-05-06 21:12:50,922][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:12:50,923][src.tasks.hpsearch][INFO] - _________________ Starting trial 046 __________________
[2024-05-06 21:12:50,923][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:12:50,923][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:13:15,308][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:13:15,315][train][INFO] - Instantiating callbacks...
[2024-05-06 21:13:15,316][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:13:15,321][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:13:15,322][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:13:15,322][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:13:15,323][train][INFO] - Instantiating loggers...
[2024-05-06 21:13:15,323][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:13:15,324][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:13:15,360][train][INFO] - Logging hyperparameters!
[2024-05-06 21:13:15,381][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.00it/s v_num: 0.000
[2024-05-06 21:15:12,680][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:15:12,682][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/046
[2024-05-06 21:15:12,792][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 21:15:12,818][src.tasks.hpsearch][INFO] - 0.0004082199577692091, lr
[2024-05-06 21:15:12,843][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:15:12,868][src.tasks.hpsearch][INFO] - 0.037169078384831473 prior_scale
[2024-05-06 21:15:12,894][src.tasks.hpsearch][INFO] - 0.000137494878558567 q_scale
[2024-05-06 21:15:12,919][src.tasks.hpsearch][INFO] - 0.6975201192592543 obs_scale
[2024-05-06 21:15:12,944][src.tasks.hpsearch][INFO] - 128 batch_size
[2024-05-06 21:15:12,944][src.tasks.hpsearch][INFO] - _________________ Starting trial 047 __________________
[2024-05-06 21:15:12,945][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:15:12,945][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:15:37,384][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:15:37,391][train][INFO] - Instantiating callbacks...
[2024-05-06 21:15:37,391][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:15:37,394][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:15:37,394][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:15:37,395][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:15:37,396][train][INFO] - Instantiating loggers...
[2024-05-06 21:15:37,396][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:15:37,397][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:15:37,432][train][INFO] - Logging hyperparameters!
[2024-05-06 21:15:37,439][train][INFO] - Starting training!
[2024-05-06 21:15:37,440][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:09 • 0:00:00 38.91it/s v_num: 0.000
[2024-05-06 21:16:32,022][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 19.
[2024-05-06 21:16:32,026][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:16:32,068][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:16:32,086][src.tasks.hpsearch][INFO] - 0.00035329799697589136, lr
[2024-05-06 21:16:32,105][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:16:32,123][src.tasks.hpsearch][INFO] - 0.032428970570311355 prior_scale
[2024-05-06 21:16:32,141][src.tasks.hpsearch][INFO] - 0.00018374432732042855 q_scale
[2024-05-06 21:16:32,160][src.tasks.hpsearch][INFO] - 0.3585568247400323 obs_scale
[2024-05-06 21:16:32,178][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:16:32,179][src.tasks.hpsearch][INFO] - _________________ Starting trial 058 __________________
[2024-05-06 21:16:32,180][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:16:32,180][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:16:55,627][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:16:55,634][train][INFO] - Instantiating callbacks...
[2024-05-06 21:16:55,634][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:16:55,636][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:16:55,636][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:16:55,637][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:16:55,638][train][INFO] - Instantiating loggers...
[2024-05-06 21:16:55,638][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:16:55,639][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:16:55,672][train][INFO] - Logging hyperparameters!
[2024-05-06 21:16:55,919][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 17.91it/s v_num: 0.000
[2024-05-06 21:17:59,754][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:17:59,755][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/047
[2024-05-06 21:17:59,828][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:17:59,844][src.tasks.hpsearch][INFO] - 0.000557106195883259, lr
[2024-05-06 21:17:59,859][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:17:59,880][src.tasks.hpsearch][INFO] - 0.11369743725583471 prior_scale
[2024-05-06 21:17:59,899][src.tasks.hpsearch][INFO] - 0.00021692437473279705 q_scale
[2024-05-06 21:17:59,913][src.tasks.hpsearch][INFO] - 0.5148631572775435 obs_scale
[2024-05-06 21:17:59,928][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 21:17:59,928][src.tasks.hpsearch][INFO] - _________________ Starting trial 048 __________________
[2024-05-06 21:17:59,928][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:17:59,929][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:18:27,967][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:18:27,974][train][INFO] - Instantiating callbacks...
[2024-05-06 21:18:27,974][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:18:27,976][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:18:27,977][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:18:27,977][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:18:27,978][train][INFO] - Instantiating loggers...
[2024-05-06 21:18:27,978][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:18:27,979][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:18:28,156][train][INFO] - Logging hyperparameters!
[2024-05-06 21:18:28,250][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.27it/s v_num: 0.000
[2024-05-06 21:19:50,700][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:19:50,702][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/048
[2024-05-06 21:19:50,779][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:19:50,798][src.tasks.hpsearch][INFO] - 0.0002987667572326055, lr
[2024-05-06 21:19:50,815][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 21:19:50,832][src.tasks.hpsearch][INFO] - 0.21305216672969624 prior_scale
[2024-05-06 21:19:50,848][src.tasks.hpsearch][INFO] - 0.00018609609268027566 q_scale
[2024-05-06 21:19:50,864][src.tasks.hpsearch][INFO] - 0.8994594276110933 obs_scale
[2024-05-06 21:19:50,881][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:19:50,881][src.tasks.hpsearch][INFO] - _________________ Starting trial 049 __________________
[2024-05-06 21:19:50,881][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:19:50,881][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:19:49,082][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:19:49,089][train][INFO] - Instantiating callbacks...
[2024-05-06 21:19:49,090][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:19:49,092][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:19:49,092][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:19:49,093][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:19:49,094][train][INFO] - Instantiating loggers...
[2024-05-06 21:19:49,094][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:19:49,095][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:19:49,132][train][INFO] - Logging hyperparameters!
[2024-05-06 21:19:49,141][train][INFO] - Starting training!
[2024-05-06 21:19:49,143][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:20:14,407][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:20:14,414][train][INFO] - Instantiating callbacks...
[2024-05-06 21:20:14,414][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:20:14,416][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:20:14,416][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:20:14,417][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:20:14,418][train][INFO] - Instantiating loggers...
[2024-05-06 21:20:14,418][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:20:14,419][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:20:14,454][train][INFO] - Logging hyperparameters!
[2024-05-06 21:20:14,461][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 36.31it/s v_num: 0.000
[2024-05-06 21:21:23,998][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[2024-05-06 21:21:24,004][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:21:24,054][src.tasks.hpsearch][INFO] - 5 pretrain_epochs
[2024-05-06 21:21:24,077][src.tasks.hpsearch][INFO] - 0.000883647434773169, lr
[2024-05-06 21:21:24,095][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:21:24,114][src.tasks.hpsearch][INFO] - 0.06987808840349537 prior_scale
[2024-05-06 21:21:24,134][src.tasks.hpsearch][INFO] - 0.0001281002446001283 q_scale
[2024-05-06 21:21:24,157][src.tasks.hpsearch][INFO] - 0.2614789338988419 obs_scale
[2024-05-06 21:21:24,177][src.tasks.hpsearch][INFO] - 256 batch_size
[2024-05-06 21:21:24,177][src.tasks.hpsearch][INFO] - _________________ Starting trial 059 __________________
[2024-05-06 21:21:24,178][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:21:24,178][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:21:50,205][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:21:50,212][train][INFO] - Instantiating callbacks...
[2024-05-06 21:21:50,213][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:21:50,216][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:21:50,217][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:21:50,217][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:21:50,218][train][INFO] - Instantiating loggers...
[2024-05-06 21:21:50,218][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:21:50,219][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:21:50,254][train][INFO] - Logging hyperparameters!
[2024-05-06 21:21:50,262][train][INFO] - Starting training!
[2024-05-06 21:21:50,264][train][INFO] - Restoring pretrained net from: /home/g15farris/bin/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 15.43it/s v_num: 0.000
[2024-05-06 21:22:02,235][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:22:02,237][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/047
[2024-05-06 21:22:02,363][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:22:02,391][src.tasks.hpsearch][INFO] - 0.00028230392745546906, lr
[2024-05-06 21:22:02,419][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:22:02,451][src.tasks.hpsearch][INFO] - 0.041490269688819956 prior_scale
[2024-05-06 21:22:02,481][src.tasks.hpsearch][INFO] - 0.0012648184594538834 q_scale
[2024-05-06 21:22:02,508][src.tasks.hpsearch][INFO] - 0.46141397715447324 obs_scale
[2024-05-06 21:22:02,534][src.tasks.hpsearch][INFO] - 512 batch_size
[2024-05-06 21:22:02,535][src.tasks.hpsearch][INFO] - _________________ Starting trial 048 __________________
[2024-05-06 21:22:02,536][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:22:02,536][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:22:37,445][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:22:37,453][train][INFO] - Instantiating callbacks...
[2024-05-06 21:22:37,454][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:22:37,458][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:22:37,460][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:22:37,461][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:22:37,461][train][INFO] - Instantiating loggers...
[2024-05-06 21:22:37,462][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:22:37,463][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:22:37,503][train][INFO] - Logging hyperparameters!
[2024-05-06 21:22:37,512][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 6.24it/s v_num: 0.000
[2024-05-06 21:24:13,883][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:24:13,885][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/048
[2024-05-06 21:24:13,995][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:24:14,022][src.tasks.hpsearch][INFO] - 0.0006466897260547845, lr
[2024-05-06 21:24:14,044][src.tasks.hpsearch][INFO] - 2 mc_samples_train
[2024-05-06 21:24:14,069][src.tasks.hpsearch][INFO] - 0.01894128845243052 prior_scale
[2024-05-06 21:24:14,091][src.tasks.hpsearch][INFO] - 0.0008421853275663288 q_scale
[2024-05-06 21:24:14,130][src.tasks.hpsearch][INFO] - 0.5420580472110063 obs_scale
[2024-05-06 21:24:14,165][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:24:14,166][src.tasks.hpsearch][INFO] - _________________ Starting trial 049 __________________
[2024-05-06 21:24:14,167][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:24:14,167][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:24:41,763][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:24:41,770][train][INFO] - Instantiating callbacks...
[2024-05-06 21:24:41,771][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:24:41,775][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:24:41,775][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:24:41,776][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:24:41,777][train][INFO] - Instantiating loggers...
[2024-05-06 21:24:41,777][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:24:41,778][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:24:41,818][train][INFO] - Logging hyperparameters!
[2024-05-06 21:24:41,830][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:23 • 0:00:00 16.11it/s v_num: 0.000
[2024-05-06 21:30:00,380][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:30:00,382][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/049
[2024-05-06 21:30:00,458][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:30:00,475][src.tasks.hpsearch][INFO] - 0.000902467356034076, lr
[2024-05-06 21:30:00,490][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:30:00,507][src.tasks.hpsearch][INFO] - 0.05444743108973497 prior_scale
[2024-05-06 21:30:00,523][src.tasks.hpsearch][INFO] - 0.0016463811168018138 q_scale
[2024-05-06 21:30:00,537][src.tasks.hpsearch][INFO] - 0.2641259170431867 obs_scale
[2024-05-06 21:30:00,553][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:30:00,553][src.tasks.hpsearch][INFO] - _________________ Starting trial 050 __________________
[2024-05-06 21:30:00,553][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:30:00,554][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:30:23,809][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:30:23,816][train][INFO] - Instantiating callbacks...
[2024-05-06 21:30:23,816][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:30:23,818][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:30:23,819][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:30:23,819][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:30:23,820][train][INFO] - Instantiating loggers...
[2024-05-06 21:30:23,820][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:30:23,821][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:30:23,859][train][INFO] - Logging hyperparameters!
[2024-05-06 21:30:23,870][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 9/19 ━━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.22it/s v_num: 0.000
[2024-05-06 21:33:03,259][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 9.
[2024-05-06 21:33:03,264][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:33:03,306][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:33:03,324][src.tasks.hpsearch][INFO] - 0.0006252761321550571, lr
[2024-05-06 21:33:03,341][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:33:03,358][src.tasks.hpsearch][INFO] - 0.12162034560081159 prior_scale
[2024-05-06 21:33:03,376][src.tasks.hpsearch][INFO] - 0.0002777731684627197 q_scale
[2024-05-06 21:33:03,393][src.tasks.hpsearch][INFO] - 0.5728174616622954 obs_scale
[2024-05-06 21:33:03,410][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:33:03,410][src.tasks.hpsearch][INFO] - _________________ Starting trial 051 __________________
[2024-05-06 21:33:03,410][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:33:03,410][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:33:26,565][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:33:26,571][train][INFO] - Instantiating callbacks...
[2024-05-06 21:33:26,572][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:33:26,575][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:33:26,576][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:33:26,576][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:33:26,577][train][INFO] - Instantiating loggers...
[2024-05-06 21:33:26,577][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:33:26,578][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:33:26,614][train][INFO] - Logging hyperparameters!
[2024-05-06 21:33:26,621][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:27 • 0:00:00 13.91it/s v_num: 0.000
[2024-05-06 21:37:02,508][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:37:02,510][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/049
[2024-05-06 21:37:02,607][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:37:02,630][src.tasks.hpsearch][INFO] - 0.0005161688047078451, lr
[2024-05-06 21:37:02,654][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:37:02,681][src.tasks.hpsearch][INFO] - 0.03295721040603395 prior_scale
[2024-05-06 21:37:02,707][src.tasks.hpsearch][INFO] - 0.00033882896223158586 q_scale
[2024-05-06 21:37:02,733][src.tasks.hpsearch][INFO] - 0.3779137835283646 obs_scale
[2024-05-06 21:37:02,758][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:37:02,758][src.tasks.hpsearch][INFO] - _________________ Starting trial 050 __________________
[2024-05-06 21:37:02,759][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:37:02,759][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:37:28,055][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:37:28,062][train][INFO] - Instantiating callbacks...
[2024-05-06 21:37:28,063][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:37:28,065][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:37:28,065][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:37:28,066][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:37:28,067][train][INFO] - Instantiating loggers...
[2024-05-06 21:37:28,067][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:37:28,068][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:37:28,109][train][INFO] - Logging hyperparameters!
[2024-05-06 21:37:28,120][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.06it/s v_num: 0.000
[2024-05-06 21:38:58,692][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:38:58,694][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/051
[2024-05-06 21:38:58,800][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:38:58,825][src.tasks.hpsearch][INFO] - 0.00057672293689978, lr
[2024-05-06 21:38:58,850][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:38:58,874][src.tasks.hpsearch][INFO] - 0.0810888439790518 prior_scale
[2024-05-06 21:38:58,899][src.tasks.hpsearch][INFO] - 0.0002745559474627713 q_scale
[2024-05-06 21:38:58,921][src.tasks.hpsearch][INFO] - 0.48937845611713776 obs_scale
[2024-05-06 21:38:58,944][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:38:58,945][src.tasks.hpsearch][INFO] - _________________ Starting trial 052 __________________
[2024-05-06 21:38:58,945][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:38:58,946][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:39:24,352][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:39:24,358][train][INFO] - Instantiating callbacks...
[2024-05-06 21:39:24,359][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:39:24,361][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:39:24,362][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:39:24,363][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:39:24,363][train][INFO] - Instantiating loggers...
[2024-05-06 21:39:24,364][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:39:24,365][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:39:24,402][train][INFO] - Logging hyperparameters!
[2024-05-06 21:39:24,409][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.92it/s v_num: 0.000
[2024-05-06 21:44:11,515][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:44:11,517][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/050
[2024-05-06 21:44:11,620][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:44:11,647][src.tasks.hpsearch][INFO] - 0.0007857919248700869, lr
[2024-05-06 21:44:11,671][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:44:11,697][src.tasks.hpsearch][INFO] - 0.048492663024245465 prior_scale
[2024-05-06 21:44:11,724][src.tasks.hpsearch][INFO] - 0.0002844585354152384 q_scale
[2024-05-06 21:44:11,749][src.tasks.hpsearch][INFO] - 0.3178077310582615 obs_scale
[2024-05-06 21:44:11,772][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:44:11,773][src.tasks.hpsearch][INFO] - _________________ Starting trial 051 __________________
[2024-05-06 21:44:11,773][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:44:11,773][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:44:36,582][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:44:36,589][train][INFO] - Instantiating callbacks...
[2024-05-06 21:44:36,589][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:44:36,592][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:44:36,593][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:44:36,594][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:44:36,595][train][INFO] - Instantiating loggers...
[2024-05-06 21:44:36,595][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:44:36,596][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:44:36,639][train][INFO] - Logging hyperparameters!
[2024-05-06 21:44:36,647][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.61it/s v_num: 0.000
[2024-05-06 21:46:14,527][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:46:14,528][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/052
[2024-05-06 21:46:14,626][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:46:14,652][src.tasks.hpsearch][INFO] - 0.0005303365562365908, lr
[2024-05-06 21:46:14,678][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:46:14,705][src.tasks.hpsearch][INFO] - 0.06839117634296193 prior_scale
[2024-05-06 21:46:14,732][src.tasks.hpsearch][INFO] - 0.00012310502142375544 q_scale
[2024-05-06 21:46:14,759][src.tasks.hpsearch][INFO] - 0.48922743306635236 obs_scale
[2024-05-06 21:46:14,779][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:46:14,780][src.tasks.hpsearch][INFO] - _________________ Starting trial 053 __________________
[2024-05-06 21:46:14,780][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:46:14,780][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:46:40,589][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:46:40,595][train][INFO] - Instantiating callbacks...
[2024-05-06 21:46:40,596][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:46:40,600][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:46:40,600][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:46:40,601][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:46:40,602][train][INFO] - Instantiating loggers...
[2024-05-06 21:46:40,602][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:46:40,603][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:46:40,639][train][INFO] - Logging hyperparameters!
[2024-05-06 21:46:40,650][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.24it/s v_num: 0.000
[2024-05-06 21:50:57,647][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:50:57,648][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/051
[2024-05-06 21:50:57,730][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:50:57,750][src.tasks.hpsearch][INFO] - 0.0006552714893977419, lr
[2024-05-06 21:50:57,769][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:50:57,788][src.tasks.hpsearch][INFO] - 0.06033693894257304 prior_scale
[2024-05-06 21:50:57,811][src.tasks.hpsearch][INFO] - 0.00039113102011199136 q_scale
[2024-05-06 21:50:57,835][src.tasks.hpsearch][INFO] - 0.27290010451939817 obs_scale
[2024-05-06 21:50:57,856][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:50:57,856][src.tasks.hpsearch][INFO] - _________________ Starting trial 052 __________________
[2024-05-06 21:50:57,856][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:50:57,856][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:51:22,637][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:51:22,644][train][INFO] - Instantiating callbacks...
[2024-05-06 21:51:22,645][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:51:22,651][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:51:22,652][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:51:22,653][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:51:22,654][train][INFO] - Instantiating loggers...
[2024-05-06 21:51:22,654][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:51:22,655][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:51:22,695][train][INFO] - Logging hyperparameters!
[2024-05-06 21:51:22,702][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.00it/s v_num: 0.000
[2024-05-06 21:53:31,437][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:53:31,439][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/053
[2024-05-06 21:53:31,536][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:53:31,558][src.tasks.hpsearch][INFO] - 0.00043622157550123736, lr
[2024-05-06 21:53:31,579][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:53:31,600][src.tasks.hpsearch][INFO] - 0.06531714902932252 prior_scale
[2024-05-06 21:53:31,622][src.tasks.hpsearch][INFO] - 0.00012938791140128085 q_scale
[2024-05-06 21:53:31,644][src.tasks.hpsearch][INFO] - 0.39414683318886357 obs_scale
[2024-05-06 21:53:31,664][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:53:31,665][src.tasks.hpsearch][INFO] - _________________ Starting trial 054 __________________
[2024-05-06 21:53:31,665][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:53:31,665][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:53:56,757][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:53:56,763][train][INFO] - Instantiating callbacks...
[2024-05-06 21:53:56,764][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:53:56,767][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:53:56,768][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:53:56,768][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:53:56,769][train][INFO] - Instantiating loggers...
[2024-05-06 21:53:56,769][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:53:56,770][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:53:56,806][train][INFO] - Logging hyperparameters!
[2024-05-06 21:53:56,813][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.43it/s v_num: 0.000
[2024-05-06 21:57:58,597][utils.utils][INFO] - Closing loggers...
[2024-05-06 21:57:58,600][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/052
[2024-05-06 21:57:58,697][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 21:57:58,719][src.tasks.hpsearch][INFO] - 0.0008747450703666922, lr
[2024-05-06 21:57:58,740][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 21:57:58,765][src.tasks.hpsearch][INFO] - 0.08412953931834553 prior_scale
[2024-05-06 21:57:58,790][src.tasks.hpsearch][INFO] - 0.0001210500536314693 q_scale
[2024-05-06 21:57:58,815][src.tasks.hpsearch][INFO] - 0.4396061403761943 obs_scale
[2024-05-06 21:57:58,835][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 21:57:58,836][src.tasks.hpsearch][INFO] - _________________ Starting trial 053 __________________
[2024-05-06 21:57:58,836][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 21:57:58,836][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 21:58:23,892][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 21:58:23,900][train][INFO] - Instantiating callbacks...
[2024-05-06 21:58:23,900][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 21:58:23,902][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 21:58:23,903][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 21:58:23,903][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 21:58:23,904][train][INFO] - Instantiating loggers...
[2024-05-06 21:58:23,904][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 21:58:23,905][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 21:58:23,941][train][INFO] - Logging hyperparameters!
[2024-05-06 21:58:23,949][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.07it/s v_num: 0.000
[2024-05-06 22:00:47,967][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:00:47,969][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/054
[2024-05-06 22:00:48,061][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:00:48,080][src.tasks.hpsearch][INFO] - 0.0008222252981489552, lr
[2024-05-06 22:00:48,099][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:00:48,118][src.tasks.hpsearch][INFO] - 0.05105937607065532 prior_scale
[2024-05-06 22:00:48,137][src.tasks.hpsearch][INFO] - 0.00010275622081209195 q_scale
[2024-05-06 22:00:48,157][src.tasks.hpsearch][INFO] - 0.45011958430221016 obs_scale
[2024-05-06 22:00:48,177][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 22:00:48,177][src.tasks.hpsearch][INFO] - _________________ Starting trial 055 __________________
[2024-05-06 22:00:48,177][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:00:48,178][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:01:13,020][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:01:13,027][train][INFO] - Instantiating callbacks...
[2024-05-06 22:01:13,028][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:01:13,030][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:01:13,031][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:01:13,031][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:01:13,032][train][INFO] - Instantiating loggers...
[2024-05-06 22:01:13,032][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:01:13,033][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:01:13,080][train][INFO] - Logging hyperparameters!
[2024-05-06 22:01:13,091][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.48it/s v_num: 0.000
[2024-05-06 22:04:52,188][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:04:52,190][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/053
[2024-05-06 22:04:52,267][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:04:52,286][src.tasks.hpsearch][INFO] - 0.0004013164755756807, lr
[2024-05-06 22:04:52,299][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:04:52,313][src.tasks.hpsearch][INFO] - 0.0726451692174063 prior_scale
[2024-05-06 22:04:52,330][src.tasks.hpsearch][INFO] - 0.0001889523563104369 q_scale
[2024-05-06 22:04:52,345][src.tasks.hpsearch][INFO] - 0.25011395394584646 obs_scale
[2024-05-06 22:04:52,359][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:04:52,359][src.tasks.hpsearch][INFO] - _________________ Starting trial 054 __________________
[2024-05-06 22:04:52,360][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:04:52,360][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:04:49,119][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:04:49,125][train][INFO] - Instantiating callbacks...
[2024-05-06 22:04:49,125][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:04:49,129][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:04:49,129][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:04:49,130][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:04:49,130][train][INFO] - Instantiating loggers...
[2024-05-06 22:04:49,131][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:04:49,132][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:04:49,166][train][INFO] - Logging hyperparameters!
[2024-05-06 22:04:49,175][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:05:17,071][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:05:17,078][train][INFO] - Instantiating callbacks...
[2024-05-06 22:05:17,079][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:05:17,082][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:05:17,083][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:05:17,084][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:05:17,085][train][INFO] - Instantiating loggers...
[2024-05-06 22:05:17,085][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:05:17,086][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:05:17,121][train][INFO] - Logging hyperparameters!
[2024-05-06 22:05:17,129][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 15/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.40it/s v_num: 0.000
[2024-05-06 22:10:26,405][utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/src/tasks/train.py", line 90, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bayesian/lib/python3.12/site-packages/optuna/integration/pytorch_lightning.py", line 58, in on_validation_end
    raise optuna.TrialPruned(message)
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[2024-05-06 22:10:26,410][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:10:26,455][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:10:26,476][src.tasks.hpsearch][INFO] - 0.0006982660246876976, lr
[2024-05-06 22:10:26,498][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:10:26,523][src.tasks.hpsearch][INFO] - 0.04668689387609643 prior_scale
[2024-05-06 22:10:26,547][src.tasks.hpsearch][INFO] - 0.0002554746572720036 q_scale
[2024-05-06 22:10:26,573][src.tasks.hpsearch][INFO] - 0.7148476211986126 obs_scale
[2024-05-06 22:10:26,600][src.tasks.hpsearch][INFO] - 64 batch_size
[2024-05-06 22:10:26,601][src.tasks.hpsearch][INFO] - _________________ Starting trial 055 __________________
[2024-05-06 22:10:26,601][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:10:26,601][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:10:52,323][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:10:52,330][train][INFO] - Instantiating callbacks...
[2024-05-06 22:10:52,331][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:10:52,333][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:10:52,334][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:10:52,335][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:10:52,336][train][INFO] - Instantiating loggers...
[2024-05-06 22:10:52,336][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:10:52,337][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:10:52,375][train][INFO] - Logging hyperparameters!
[2024-05-06 22:10:52,383][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 23.37it/s v_num: 0.000
[2024-05-06 22:14:25,180][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:14:25,182][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/055
[2024-05-06 22:14:25,353][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:14:25,376][src.tasks.hpsearch][INFO] - 0.0004912931225240278, lr
[2024-05-06 22:14:25,395][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:14:25,416][src.tasks.hpsearch][INFO] - 0.10971846560302197 prior_scale
[2024-05-06 22:14:25,438][src.tasks.hpsearch][INFO] - 0.0004915961649172978 q_scale
[2024-05-06 22:14:25,459][src.tasks.hpsearch][INFO] - 0.3701729395879807 obs_scale
[2024-05-06 22:14:25,479][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:14:25,479][src.tasks.hpsearch][INFO] - _________________ Starting trial 056 __________________
[2024-05-06 22:14:25,480][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:14:25,480][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:14:50,822][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:14:50,829][train][INFO] - Instantiating callbacks...
[2024-05-06 22:14:50,830][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:14:50,833][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:14:50,834][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:14:50,834][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:14:50,835][train][INFO] - Instantiating loggers...
[2024-05-06 22:14:50,835][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:14:50,837][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:14:50,885][train][INFO] - Logging hyperparameters!
[2024-05-06 22:14:50,896][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 29.91it/s v_num: 0.000
[2024-05-06 22:16:01,151][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:16:01,152][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/057
[2024-05-06 22:16:01,230][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:16:01,246][src.tasks.hpsearch][INFO] - 0.0007170644205337213, lr
[2024-05-06 22:16:01,262][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:16:01,277][src.tasks.hpsearch][INFO] - 0.07086393775484076 prior_scale
[2024-05-06 22:16:01,294][src.tasks.hpsearch][INFO] - 0.000555968380014563 q_scale
[2024-05-06 22:16:01,311][src.tasks.hpsearch][INFO] - 0.5336891015067624 obs_scale
[2024-05-06 22:16:01,326][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:16:01,326][src.tasks.hpsearch][INFO] - _________________ Starting trial 058 __________________
[2024-05-06 22:16:01,327][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:16:01,327][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:16:24,478][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:16:24,484][train][INFO] - Instantiating callbacks...
[2024-05-06 22:16:24,484][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:16:24,486][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:16:24,487][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:16:24,487][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:16:24,488][train][INFO] - Instantiating loggers...
[2024-05-06 22:16:24,488][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:16:24,489][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:16:24,520][train][INFO] - Logging hyperparameters!
[2024-05-06 22:16:24,526][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.30it/s v_num: 0.000
[2024-05-06 22:20:42,710][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:20:42,728][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/056
[2024-05-06 22:20:42,856][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:20:42,879][src.tasks.hpsearch][INFO] - 0.0008019708555864843, lr
[2024-05-06 22:20:42,901][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:20:42,921][src.tasks.hpsearch][INFO] - 0.056558907754717114 prior_scale
[2024-05-06 22:20:42,942][src.tasks.hpsearch][INFO] - 0.0007633159270988318 q_scale
[2024-05-06 22:20:42,962][src.tasks.hpsearch][INFO] - 0.5765651785452727 obs_scale
[2024-05-06 22:20:42,984][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:20:42,985][src.tasks.hpsearch][INFO] - _________________ Starting trial 057 __________________
[2024-05-06 22:20:42,985][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:20:42,985][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:21:07,791][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:21:07,798][train][INFO] - Instantiating callbacks...
[2024-05-06 22:21:07,799][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:21:07,801][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:21:07,802][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:21:07,802][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:21:07,803][train][INFO] - Instantiating loggers...
[2024-05-06 22:21:07,803][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:21:07,804][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:21:07,844][train][INFO] - Logging hyperparameters!
[2024-05-06 22:21:07,900][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.52it/s v_num: 0.000
[2024-05-06 22:21:43,467][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:21:43,468][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_fo/runs/2024-05-06_16-37-24/058
[2024-05-06 22:21:43,543][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:21:43,560][src.tasks.hpsearch][INFO] - 0.0002708650199615613, lr
[2024-05-06 22:21:43,577][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:21:43,593][src.tasks.hpsearch][INFO] - 0.026050829318738776 prior_scale
[2024-05-06 22:21:43,609][src.tasks.hpsearch][INFO] - 0.0005156072233060008 q_scale
[2024-05-06 22:21:43,625][src.tasks.hpsearch][INFO] - 0.848106358310356 obs_scale
[2024-05-06 22:21:43,641][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:21:43,641][src.tasks.hpsearch][INFO] - _________________ Starting trial 059 __________________
[2024-05-06 22:21:43,641][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:21:43,641][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:22:07,000][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:22:07,006][train][INFO] - Instantiating callbacks...
[2024-05-06 22:22:07,006][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:22:07,008][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:22:07,009][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:22:07,009][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:22:07,010][train][INFO] - Instantiating loggers...
[2024-05-06 22:22:07,010][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:22:07,011][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:22:07,048][train][INFO] - Logging hyperparameters!
[2024-05-06 22:22:07,055][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.39it/s v_num: 0.000
[2024-05-06 22:27:25,072][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:27:25,074][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/057
[2024-05-06 22:27:25,167][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:27:25,189][src.tasks.hpsearch][INFO] - 0.0005968427457125611, lr
[2024-05-06 22:27:25,208][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:27:25,228][src.tasks.hpsearch][INFO] - 0.13239244191569832 prior_scale
[2024-05-06 22:27:25,255][src.tasks.hpsearch][INFO] - 0.00016820698298006503 q_scale
[2024-05-06 22:27:25,280][src.tasks.hpsearch][INFO] - 0.4809188985365721 obs_scale
[2024-05-06 22:27:25,300][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:27:25,301][src.tasks.hpsearch][INFO] - _________________ Starting trial 058 __________________
[2024-05-06 22:27:25,301][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:27:25,301][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:27:49,766][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:27:49,773][train][INFO] - Instantiating callbacks...
[2024-05-06 22:27:49,774][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:27:49,778][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:27:49,779][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:27:49,779][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:27:49,780][train][INFO] - Instantiating loggers...
[2024-05-06 22:27:49,780][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:27:49,781][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:27:49,818][train][INFO] - Logging hyperparameters!
[2024-05-06 22:27:49,845][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:25 • 0:00:00 15.32it/s v_num: 0.000
[2024-05-06 22:34:11,857][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:34:11,859][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/058
[2024-05-06 22:34:11,964][src.tasks.hpsearch][INFO] - 0 pretrain_epochs
[2024-05-06 22:34:11,985][src.tasks.hpsearch][INFO] - 0.0005853047195913743, lr
[2024-05-06 22:34:12,005][src.tasks.hpsearch][INFO] - 1 mc_samples_train
[2024-05-06 22:34:12,024][src.tasks.hpsearch][INFO] - 0.13766111616714927 prior_scale
[2024-05-06 22:34:12,050][src.tasks.hpsearch][INFO] - 0.0001400921296006223 q_scale
[2024-05-06 22:34:12,069][src.tasks.hpsearch][INFO] - 0.8279902915596279 obs_scale
[2024-05-06 22:34:12,089][src.tasks.hpsearch][INFO] - 32 batch_size
[2024-05-06 22:34:12,090][src.tasks.hpsearch][INFO] - _________________ Starting trial 059 __________________
[2024-05-06 22:34:12,090][utils.utils][WARNING] - Extras config not found! <cfg.extras=null>
[2024-05-06 22:34:12,090][train][INFO] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[2024-05-06 22:34:41,998][train][INFO] - Instantiating model <src.models.bnn.BNN>
[2024-05-06 22:34:42,007][train][INFO] - Instantiating callbacks...
[2024-05-06 22:34:42,009][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2024-05-06 22:34:42,020][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
[2024-05-06 22:34:42,022][utils.utils][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2024-05-06 22:34:42,022][utils.utils][INFO] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>
[2024-05-06 22:34:42,024][train][INFO] - Instantiating loggers...
[2024-05-06 22:34:42,024][utils.utils][INFO] - Instantiating logger <pytorch_lightning.loggers.tensorboard.TensorBoardLogger>
[2024-05-06 22:34:42,025][train][INFO] - Instantiating trainer <pytorch_lightning.trainer.Trainer>
[2024-05-06 22:34:42,092][train][INFO] - Logging hyperparameters!
[2024-05-06 22:34:42,112][train][INFO] - Starting training!
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.14it/s v_num: 0.000
[2024-05-06 22:41:19,813][utils.utils][INFO] - Closing loggers...
[2024-05-06 22:41:19,814][utils.utils][INFO] - Output dir: /home/g15farris/bin/bayesaenet/src/logs/hps_lrt/runs/2024-05-06_16-34-37/059
[2024-05-06 22:41:19,881][__main__][INFO] - Number of finished trials: 60
