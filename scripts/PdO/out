{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-05-24 12:18:48,126[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-05-24 12:18:48,176[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-05-24 12:18:48,544[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-05-24 12:18:49,061[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-05-24 12:18:49,069[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-05-24 12:18:49,096[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-05-24 12:18:49,102[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-05-24 12:18:49,105[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-05-24 12:18:49,115[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-05-24 12:18:49,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:18:49,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-05-24 12:18:49,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:18:49,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:18:49,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-05-24 12:18:49,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-05-24 12:18:49,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:18:49,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:18:49,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-05-24 12:18:49,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-05-24 12:18:49,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-05-24 12:18:49,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-05-24 12:18:49,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:18:49,255[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-05-24 12:18:49,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 12:18:49,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-05-24 12:18:49,257[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:18:49,257[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-05-24 12:18:49,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-05-24 12:18:49,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-05-24 12:18:49,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-05-24 12:18:49,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 12:18:49,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-05-24 12:18:49,289[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:18:49,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-05-24 12:18:49,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-05-24 12:18:49,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 12:18:49,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-05-24 12:18:49,311[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:18:49,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:19:19,453[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:19:19,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:19:19,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:19:19,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:19:19,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:19:19,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:19:19,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:19:19,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:19:19,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:19:19,727[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:19:20,138[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:19:20,143[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:19:21,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:19:21,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:19:21,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:19:21,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:19:21,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:19:21,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:19:21,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:19:21,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:19:21,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:19:21,688[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:19:21,822[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:19:21,827[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:19:21,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:19:21,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:19:21,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:19:21,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:19:21,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:19:21,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:19:21,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:19:21,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:19:21,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
[[36m2024-05-24 12:19:22,153[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:19:22,232[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:19:22,235[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 27.93it/s v_num: 0.000
[[36m2024-05-24 12:25:07,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:25:07,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/000[0m
[[36m2024-05-24 12:25:07,826[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:25:07,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-05-24 12:25:07,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:25:07,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-05-24 12:25:07,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-05-24 12:25:07,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-05-24 12:25:07,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:25:07,893[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-05-24 12:25:07,893[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:25:07,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.02it/s v_num: 0.000
[[36m2024-05-24 12:25:11,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:25:11,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/000[0m
[[36m2024-05-24 12:25:11,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:25:11,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-05-24 12:25:11,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:25:11,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-05-24 12:25:11,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-05-24 12:25:11,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-05-24 12:25:11,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:25:11,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-05-24 12:25:11,802[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:25:11,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:25:40,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:25:40,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:25:40,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:25:40,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:25:40,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:25:40,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:25:40,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:25:40,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:25:40,017[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:25:40,060[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:25:40,068[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:25:47,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:25:47,007[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:25:47,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:25:47,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:25:47,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:25:47,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:25:47,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:25:47,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:25:47,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:25:47,046[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:25:47,054[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.32it/s v_num: 0.000
[[36m2024-05-24 12:26:11,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:26:11,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/000[0m
[[36m2024-05-24 12:26:11,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:26:11,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-05-24 12:26:11,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:26:11,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-05-24 12:26:11,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-05-24 12:26:11,255[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-05-24 12:26:11,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:26:11,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-05-24 12:26:11,271[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:26:11,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:26:48,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:26:48,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:26:48,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:26:48,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:26:48,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:26:48,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:26:48,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:26:48,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:26:48,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:26:48,270[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:26:48,279[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 18.40it/s v_num: 0.000
[[36m2024-05-24 12:27:02,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:27:02,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/001[0m
[[36m2024-05-24 12:27:02,243[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:27:02,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-05-24 12:27:02,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:27:02,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-05-24 12:27:02,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-05-24 12:27:02,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-05-24 12:27:02,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:27:02,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-05-24 12:27:02,323[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:27:02,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.78it/s v_num: 0.000
[[36m2024-05-24 12:27:31,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:27:31,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/001[0m
[[36m2024-05-24 12:27:31,799[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:27:31,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-05-24 12:27:31,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:27:31,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-05-24 12:27:31,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-05-24 12:27:31,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-05-24 12:27:31,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:27:31,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-05-24 12:27:31,885[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:27:31,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:27:38,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:27:38,378[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:27:38,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:27:38,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:27:38,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:27:38,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:27:38,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:27:38,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:27:38,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:27:38,418[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:27:38,426[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:27:38,429[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:28:04,360[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:28:04,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:28:04,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:28:04,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:28:04,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:28:04,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:28:04,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:28:04,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:28:04,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:28:04,409[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:28:04,416[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:28:04,419[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 12.26it/s v_num: 0.000
[[36m2024-05-24 12:28:32,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:28:32,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/001[0m
[[36m2024-05-24 12:28:32,248[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:28:32,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-05-24 12:28:32,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:28:32,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-05-24 12:28:32,302[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-05-24 12:28:32,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-05-24 12:28:32,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:28:32,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-05-24 12:28:32,330[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:28:32,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:29:09,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:29:09,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:29:09,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:29:09,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:29:09,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:29:09,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:29:09,174[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:29:09,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:29:09,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:29:09,218[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:29:09,227[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:29:09,230[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 10.42it/s v_num: 0.000
[[36m2024-05-24 12:29:38,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:29:38,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/002[0m
[[36m2024-05-24 12:29:39,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:29:39,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-05-24 12:29:39,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:29:39,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-05-24 12:29:39,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-05-24 12:29:39,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-05-24 12:29:39,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 12:29:39,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-05-24 12:29:39,174[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:29:39,174[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:30:17,542[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:30:17,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:30:17,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:30:17,553[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:30:17,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:30:17,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:30:17,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:30:17,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:30:17,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:30:17,588[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:30:17,597[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:07 • 0:00:00 6.15it/s v_num: 0.000
[[36m2024-05-24 12:31:04,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:31:04,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/002[0m
[[36m2024-05-24 12:31:04,707[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:31:04,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-05-24 12:31:04,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:31:04,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-05-24 12:31:04,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-05-24 12:31:04,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-05-24 12:31:04,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 12:31:04,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-05-24 12:31:04,804[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:31:04,804[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:31:39,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:31:39,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:31:39,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:31:39,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:31:39,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:31:39,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:31:39,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:31:39,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:31:39,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:31:39,088[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:31:39,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.09it/s v_num: 0.000
[[36m2024-05-24 12:31:44,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:31:44,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/003[0m
[[36m2024-05-24 12:31:44,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:31:44,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-05-24 12:31:44,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:31:44,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-05-24 12:31:44,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-05-24 12:31:44,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-05-24 12:31:44,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:31:44,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-05-24 12:31:44,911[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:31:44,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:07 • 0:00:00 6.45it/s v_num: 0.000
[[36m2024-05-24 12:32:12,773[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:32:12,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/002[0m
[[36m2024-05-24 12:32:12,956[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:32:12,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-05-24 12:32:12,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:32:13,001[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-05-24 12:32:13,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-05-24 12:32:13,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-05-24 12:32:13,049[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 12:32:13,050[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-05-24 12:32:13,051[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:32:13,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:32:16,303[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:32:16,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:32:16,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:32:16,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:32:16,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:32:16,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:32:16,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:32:16,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:32:16,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:32:16,348[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:32:16,532[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:32:50,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:32:50,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:32:50,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:32:50,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:32:50,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:32:50,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:32:50,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:32:50,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:32:50,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:32:50,725[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:32:50,732[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:06 • 0:00:00 3.75it/s v_num: 0.000
[[36m2024-05-24 12:34:10,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:34:10,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/003[0m
[[36m2024-05-24 12:34:11,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:34:11,020[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-05-24 12:34:11,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:34:11,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-05-24 12:34:11,052[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-05-24 12:34:11,063[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-05-24 12:34:11,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:34:11,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-05-24 12:34:11,076[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:34:11,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:34:41,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:34:41,566[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:34:41,567[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:34:41,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:34:41,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:34:41,574[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:34:41,575[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:34:41,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:34:41,576[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:34:41,621[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:34:41,630[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:05 • 0:00:00 4.26it/s v_num: 0.000
[[36m2024-05-24 12:34:57,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:34:57,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/003[0m
[[36m2024-05-24 12:34:57,709[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:34:57,720[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-05-24 12:34:57,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:34:57,744[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-05-24 12:34:57,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-05-24 12:34:57,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-05-24 12:34:57,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:34:57,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-05-24 12:34:57,782[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:34:57,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 30.45it/s v_num: 0.000
[[36m2024-05-24 12:35:28,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:35:28,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/004[0m
[[36m2024-05-24 12:35:28,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:35:28,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-05-24 12:35:28,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:35:28,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-05-24 12:35:28,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-05-24 12:35:28,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-05-24 12:35:28,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:35:28,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-05-24 12:35:28,912[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:35:28,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:35:30,648[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:35:30,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:35:30,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:35:30,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:35:30,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:35:30,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:35:30,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:35:30,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:35:30,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:35:30,699[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:35:30,707[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:36:01,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:36:01,428[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:36:01,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:36:01,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:36:01,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:36:01,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:36:01,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:36:01,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:36:01,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:36:01,467[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:36:01,475[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:36:01,477[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 25.80it/s v_num: 0.000
[[36m2024-05-24 12:37:47,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:37:47,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/005[0m
[[36m2024-05-24 12:37:47,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:37:47,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-05-24 12:37:47,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:37:47,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-05-24 12:37:47,766[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-05-24 12:37:47,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-05-24 12:37:47,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:37:47,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-05-24 12:37:47,791[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:37:47,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 22.05it/s v_num: 0.000
[[36m2024-05-24 12:38:15,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:38:15,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/004[0m
[[36m2024-05-24 12:38:15,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:38:15,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-05-24 12:38:15,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:38:15,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-05-24 12:38:15,886[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-05-24 12:38:15,900[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-05-24 12:38:15,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:38:15,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-05-24 12:38:15,916[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:38:15,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:38:20,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:38:20,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:38:20,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:38:20,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:38:20,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:38:20,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:38:20,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:38:20,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:38:20,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:38:20,798[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:38:20,806[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:38:20,808[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:38:48,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:38:48,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:38:48,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:38:48,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:38:48,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:38:48,291[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:38:48,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:38:48,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:38:48,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:38:48,323[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:38:48,330[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:38:48,332[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 24.05it/s v_num: 0.000
[[36m2024-05-24 12:39:03,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:39:03,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/004[0m
[[36m2024-05-24 12:39:04,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:39:04,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-05-24 12:39:04,085[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:39:04,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-05-24 12:39:04,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-05-24 12:39:04,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-05-24 12:39:04,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:39:04,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-05-24 12:39:04,131[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:39:04,132[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:39:37,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:39:37,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:39:37,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:39:37,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:39:37,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:39:37,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:39:37,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:39:37,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:39:37,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:39:37,764[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:39:37,772[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:39:37,774[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 15.63it/s v_num: 0.000
[[36m2024-05-24 12:41:19,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:41:19,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/005[0m
[[36m2024-05-24 12:41:19,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:41:19,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-05-24 12:41:19,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:41:19,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-05-24 12:41:19,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-05-24 12:41:19,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-05-24 12:41:19,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:41:19,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-05-24 12:41:19,324[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:41:19,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 18.42it/s v_num: 0.000
[[36m2024-05-24 12:41:50,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:41:50,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/005[0m
[[36m2024-05-24 12:41:50,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:41:50,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-05-24 12:41:50,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:41:50,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-05-24 12:41:50,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-05-24 12:41:50,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-05-24 12:41:50,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:41:50,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-05-24 12:41:50,748[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:41:50,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:41:51,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:41:51,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:41:51,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:41:51,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:41:51,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:41:51,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:41:51,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:41:51,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:41:51,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:41:51,075[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:41:51,083[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:41:51,086[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:42:22,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:42:22,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:42:22,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:42:22,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:42:22,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:42:22,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:42:22,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:42:22,643[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:42:22,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:42:22,676[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:42:22,683[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:42:22,686[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:12 • 0:00:00 15.76it/s v_num: 0.000
[[36m2024-05-24 12:42:34,584[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[[36m2024-05-24 12:42:34,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:42:34,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:42:34,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-05-24 12:42:34,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:42:34,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-05-24 12:42:34,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-05-24 12:42:34,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-05-24 12:42:34,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:42:34,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-05-24 12:42:34,855[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:42:34,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:43:08,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:43:08,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:43:08,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:43:08,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:43:08,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:43:08,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:43:08,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:43:08,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:43:08,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:43:08,266[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:43:08,758[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.69it/s v_num: 0.000
[[36m2024-05-24 12:45:01,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:45:01,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/007[0m
[[36m2024-05-24 12:45:01,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:45:01,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-05-24 12:45:01,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:45:01,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-05-24 12:45:01,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-05-24 12:45:01,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-05-24 12:45:01,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:45:01,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-05-24 12:45:01,831[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:45:01,832[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:45:33,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:45:33,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:45:33,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:45:33,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:45:33,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:45:33,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:45:33,926[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:45:33,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:45:33,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:45:33,967[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:45:33,975[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:16 • 0:00:00 11.70it/s v_num: 0.000
[[36m2024-05-24 12:46:52,992[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 13.
[[36m2024-05-24 12:46:53,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:46:53,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:46:53,105[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-05-24 12:46:53,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:46:53,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-05-24 12:46:53,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-05-24 12:46:53,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-05-24 12:46:53,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:46:53,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-05-24 12:46:53,166[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:46:53,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:47:26,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:47:26,634[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:47:26,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:47:26,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:47:26,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:47:26,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:47:26,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:47:26,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:47:26,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:47:26,673[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:47:26,682[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:18 • 0:00:00 10.20it/s v_num: 0.000
[[36m2024-05-24 12:48:02,715[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[[36m2024-05-24 12:48:02,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:48:02,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:48:02,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-05-24 12:48:02,868[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:48:02,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-05-24 12:48:02,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-05-24 12:48:02,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-05-24 12:48:02,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 12:48:02,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-05-24 12:48:02,931[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:48:02,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 30.16it/s v_num: 0.000
[[36m2024-05-24 12:48:33,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:48:33,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/008[0m
[[36m2024-05-24 12:48:33,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:48:33,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-05-24 12:48:33,697[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:48:33,708[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-05-24 12:48:33,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-05-24 12:48:33,730[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-05-24 12:48:33,743[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:48:33,743[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-05-24 12:48:33,744[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:48:33,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:48:37,803[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:48:37,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:48:37,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:48:37,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:48:37,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:48:37,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:48:37,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:48:37,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:48:37,819[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:48:37,864[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:48:37,872[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:49:06,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:49:06,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:49:06,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:49:06,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:49:06,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:49:06,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:49:06,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:49:06,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:49:06,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:49:06,960[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:49:06,969[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:49:06,972[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:06 • 0:00:00 6.98it/s v_num: 0.000
[[36m2024-05-24 12:50:11,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:50:11,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/007[0m
[[36m2024-05-24 12:50:11,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:50:11,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-05-24 12:50:11,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:50:11,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-05-24 12:50:11,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-05-24 12:50:11,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-05-24 12:50:11,480[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:50:11,480[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-05-24 12:50:11,481[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:50:11,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:50:43,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:50:43,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:50:43,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:50:43,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:50:43,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:50:43,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:50:43,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:50:43,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:50:43,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:50:43,295[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:50:43,302[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 15.49it/s v_num: 0.000
[[36m2024-05-24 12:52:01,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:52:01,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/009[0m
[[36m2024-05-24 12:52:01,728[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:52:01,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002821061536892598, lr[0m
[[36m2024-05-24 12:52:01,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:52:01,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-05-24 12:52:01,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013031811167352414 q_scale[0m
[[36m2024-05-24 12:52:01,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-05-24 12:52:01,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:52:01,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-05-24 12:52:01,816[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:52:01,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:09 • 0:00:00 5.28it/s v_num: 0.000
[[36m2024-05-24 12:52:08,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:52:08,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/007[0m
[[36m2024-05-24 12:52:08,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:52:08,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-05-24 12:52:09,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:52:09,023[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-05-24 12:52:09,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-05-24 12:52:09,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-05-24 12:52:09,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:52:09,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-05-24 12:52:09,071[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:52:09,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:52:33,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:52:33,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:52:33,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:52:33,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:52:33,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:52:33,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:52:33,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:52:33,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:52:33,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:52:33,357[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:52:33,364[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:52:42,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:52:42,024[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:52:42,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:52:42,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:52:42,029[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:52:42,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:52:42,031[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:52:42,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:52:42,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:52:42,065[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:52:42,075[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 22.70it/s v_num: 0.000
[[36m2024-05-24 12:54:21,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:54:21,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/008[0m
[[36m2024-05-24 12:54:21,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:54:21,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-05-24 12:54:21,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:54:21,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-05-24 12:54:21,518[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-05-24 12:54:21,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-05-24 12:54:21,545[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:54:21,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-05-24 12:54:21,546[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:54:21,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:54:55,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:54:55,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:54:55,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:54:55,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:54:55,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:54:55,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:54:55,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:54:55,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:54:55,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:54:55,604[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:54:55,612[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:54:55,614[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:05 • 0:00:00 32.82it/s v_num: 0.000
[[36m2024-05-24 12:55:17,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:55:17,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/010[0m
[[36m2024-05-24 12:55:18,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:55:18,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023494228630274735, lr[0m
[[36m2024-05-24 12:55:18,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:55:18,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011706067857616107 prior_scale[0m
[[36m2024-05-24 12:55:18,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011539328391897615 q_scale[0m
[[36m2024-05-24 12:55:18,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-05-24 12:55:18,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:55:18,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-05-24 12:55:18,199[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:55:18,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:55:49,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:55:49,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:55:49,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:55:49,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:55:49,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:55:49,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:55:49,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:55:49,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:55:49,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:55:49,630[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:55:49,639[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 19.59it/s v_num: 0.000
[[36m2024-05-24 12:56:50,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:56:50,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/008[0m
[[36m2024-05-24 12:56:51,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 12:56:51,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-05-24 12:56:51,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 12:56:51,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-05-24 12:56:51,202[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-05-24 12:56:51,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-05-24 12:56:51,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 12:56:51,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-05-24 12:56:51,233[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:56:51,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:57:24,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:57:24,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:57:24,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:57:24,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:57:25,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:57:25,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:57:25,002[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:57:25,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:57:25,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:57:25,046[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:57:25,054[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 12:57:25,056[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 30.16it/s v_num: 0.000
[[36m2024-05-24 12:58:29,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:58:29,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/011[0m
[[36m2024-05-24 12:58:29,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:58:29,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000356801404529351, lr[0m
[[36m2024-05-24 12:58:29,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:58:29,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016283693256007512 prior_scale[0m
[[36m2024-05-24 12:58:29,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009783947466441949 q_scale[0m
[[36m2024-05-24 12:58:29,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8975518465396407 obs_scale[0m
[[36m2024-05-24 12:58:29,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:58:29,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-05-24 12:58:29,286[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:58:29,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:59:00,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:59:00,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:59:00,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:59:00,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:59:00,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:59:00,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:59:00,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:59:00,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:59:00,499[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:59:00,541[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:59:00,551[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:10 • 0:00:00 8.87it/s v_num: 0.000
[[36m2024-05-24 12:59:10,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 12:59:10,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/009[0m
[[36m2024-05-24 12:59:10,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 12:59:10,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002821061536892598, lr[0m
[[36m2024-05-24 12:59:10,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 12:59:10,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-05-24 12:59:10,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013031811167352414 q_scale[0m
[[36m2024-05-24 12:59:10,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-05-24 12:59:10,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 12:59:10,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-05-24 12:59:10,909[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 12:59:10,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 12:59:44,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 12:59:44,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 12:59:44,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 12:59:44,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 12:59:44,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 12:59:44,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 12:59:44,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 12:59:44,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 12:59:44,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 12:59:44,333[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 12:59:45,524[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:11 • 0:00:00 8.02it/s v_num: 0.000
[[36m2024-05-24 13:02:06,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:02:06,951[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/009[0m
[[36m2024-05-24 13:02:07,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:02:07,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002821061536892598, lr[0m
[[36m2024-05-24 13:02:07,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:02:07,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-05-24 13:02:07,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013031811167352414 q_scale[0m
[[36m2024-05-24 13:02:07,206[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-05-24 13:02:07,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:02:07,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-05-24 13:02:07,225[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:02:07,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:07 • 0:00:00 27.41it/s v_num: 0.000
[[36m2024-05-24 13:02:15,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:02:15,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/012[0m
[[36m2024-05-24 13:02:15,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:02:15,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004187758560483171, lr[0m
[[36m2024-05-24 13:02:15,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:02:15,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029998790133936113 prior_scale[0m
[[36m2024-05-24 13:02:15,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009940889714004643 q_scale[0m
[[36m2024-05-24 13:02:15,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7555075323585012 obs_scale[0m
[[36m2024-05-24 13:02:15,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:02:15,625[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-05-24 13:02:15,625[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:02:15,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:02:39,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:02:39,162[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:02:39,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:02:39,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:02:39,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:02:39,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:02:39,170[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:02:39,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:02:39,172[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:02:39,217[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:02:39,226[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:02:48,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:02:48,800[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:02:48,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:02:48,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:02:48,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:02:48,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:02:48,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:02:48,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:02:48,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:02:48,842[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:02:48,851[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.45it/s v_num: 0.000
[[36m2024-05-24 13:03:35,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:03:35,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/010[0m
[[36m2024-05-24 13:03:35,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:03:36,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023494228630274735, lr[0m
[[36m2024-05-24 13:03:36,028[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:03:36,049[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011706067857616107 prior_scale[0m
[[36m2024-05-24 13:03:36,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011539328391897615 q_scale[0m
[[36m2024-05-24 13:03:36,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-05-24 13:03:36,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:03:36,112[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-05-24 13:03:36,112[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:03:36,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:04:09,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:04:09,163[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:04:09,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:04:09,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:04:09,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:04:09,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:04:09,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:04:09,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:04:09,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:04:09,203[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:04:09,211[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 29.60it/s v_num: 0.000
[[36m2024-05-24 13:06:02,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:06:02,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/013[0m
[[36m2024-05-24 13:06:02,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:06:02,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047099056233148326, lr[0m
[[36m2024-05-24 13:06:02,372[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:06:02,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.027265739595470306 prior_scale[0m
[[36m2024-05-24 13:06:02,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008086747435543934 q_scale[0m
[[36m2024-05-24 13:06:02,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7168746872185714 obs_scale[0m
[[36m2024-05-24 13:06:02,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 13:06:02,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-05-24 13:06:02,452[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:06:02,452[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 20.37it/s v_num: 0.000
[[36m2024-05-24 13:06:36,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:06:36,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/010[0m
[[36m2024-05-24 13:06:36,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:06:37,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023494228630274735, lr[0m
[[36m2024-05-24 13:06:37,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:06:37,050[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011706067857616107 prior_scale[0m
[[36m2024-05-24 13:06:37,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011539328391897615 q_scale[0m
[[36m2024-05-24 13:06:37,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-05-24 13:06:37,117[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:06:37,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-05-24 13:06:37,118[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:06:37,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:06:39,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:06:39,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:06:39,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:06:39,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:06:39,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:06:39,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:06:39,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:06:39,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:06:39,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:06:39,244[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:06:39,253[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:07:09,422[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:07:09,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:07:09,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:07:09,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:07:09,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:07:09,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:07:09,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:07:09,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:07:09,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:07:09,478[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:07:09,491[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 15.34it/s v_num: 0.000
[[36m2024-05-24 13:07:33,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:07:33,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/014[0m
[[36m2024-05-24 13:07:33,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:07:33,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004719332263015136, lr[0m
[[36m2024-05-24 13:07:33,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:07:33,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02201666456969736 prior_scale[0m
[[36m2024-05-24 13:07:33,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025463997550914342 q_scale[0m
[[36m2024-05-24 13:07:34,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6299642046168042 obs_scale[0m
[[36m2024-05-24 13:07:34,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:07:34,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-05-24 13:07:34,017[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:07:34,017[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 23.10it/s v_num: 0.000
[[36m2024-05-24 13:08:00,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:08:00,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/011[0m
[[36m2024-05-24 13:08:00,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:08:00,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000356801404529351, lr[0m
[[36m2024-05-24 13:08:00,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:08:00,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016283693256007512 prior_scale[0m
[[36m2024-05-24 13:08:00,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009783947466441949 q_scale[0m
[[36m2024-05-24 13:08:00,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8975518465396407 obs_scale[0m
[[36m2024-05-24 13:08:00,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:08:00,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-05-24 13:08:00,663[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:08:00,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:08:04,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:08:04,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:08:04,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:08:04,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:08:04,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:08:04,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:08:04,819[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:08:04,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:08:04,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:08:04,861[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:08:04,873[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:08:32,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:08:32,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:08:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:08:32,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:08:32,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:08:32,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:08:32,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:08:32,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:08:32,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:08:32,955[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:08:32,964[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 19.92it/s v_num: 0.000
[[36m2024-05-24 13:11:08,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:11:08,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/011[0m
[[36m2024-05-24 13:11:08,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:11:08,702[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000356801404529351, lr[0m
[[36m2024-05-24 13:11:08,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:11:08,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016283693256007512 prior_scale[0m
[[36m2024-05-24 13:11:08,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009783947466441949 q_scale[0m
[[36m2024-05-24 13:11:08,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8975518465396407 obs_scale[0m
[[36m2024-05-24 13:11:08,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:11:08,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-05-24 13:11:08,825[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:11:08,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:11:40,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:11:40,406[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:11:40,407[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:11:40,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:11:40,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:11:40,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:11:40,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:11:40,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:11:40,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:11:40,462[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:11:40,471[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.80it/s v_num: 0.000
[[36m2024-05-24 13:12:19,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:12:19,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/012[0m
[[36m2024-05-24 13:12:19,390[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:12:19,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004187758560483171, lr[0m
[[36m2024-05-24 13:12:19,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:12:19,449[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029998790133936113 prior_scale[0m
[[36m2024-05-24 13:12:19,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009940889714004643 q_scale[0m
[[36m2024-05-24 13:12:19,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7555075323585012 obs_scale[0m
[[36m2024-05-24 13:12:19,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:12:19,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-05-24 13:12:19,506[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:12:19,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:12:51,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:12:51,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:12:51,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:12:51,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:12:51,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:12:51,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:12:51,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:12:51,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:12:51,961[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:12:51,997[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:12:52,006[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.59it/s v_num: 0.000
[[36m2024-05-24 13:13:51,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:13:51,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/015[0m
[[36m2024-05-24 13:13:52,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:13:52,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000547121976155859, lr[0m
[[36m2024-05-24 13:13:52,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:13:52,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04133742496369647 prior_scale[0m
[[36m2024-05-24 13:13:52,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025555101989354345 q_scale[0m
[[36m2024-05-24 13:13:52,124[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5485259914682613 obs_scale[0m
[[36m2024-05-24 13:13:52,140[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:13:52,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-05-24 13:13:52,141[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:13:52,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:14:26,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:14:26,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:14:26,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:14:26,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:14:26,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:14:26,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:14:26,305[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:14:26,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:14:26,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:14:26,350[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:14:26,358[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 19.79it/s v_num: 0.000
[[36m2024-05-24 13:15:39,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:15:39,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/012[0m
[[36m2024-05-24 13:15:39,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:15:39,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004187758560483171, lr[0m
[[36m2024-05-24 13:15:39,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:15:39,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029998790133936113 prior_scale[0m
[[36m2024-05-24 13:15:39,956[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009940889714004643 q_scale[0m
[[36m2024-05-24 13:15:39,977[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7555075323585012 obs_scale[0m
[[36m2024-05-24 13:15:39,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 13:15:39,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-05-24 13:15:39,995[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:15:39,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:16:12,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:16:12,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:16:12,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:16:12,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:16:12,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:16:12,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:16:12,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:16:12,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:16:12,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:16:12,710[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:16:12,719[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.55it/s v_num: 0.000
[[36m2024-05-24 13:16:41,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:16:41,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/013[0m
[[36m2024-05-24 13:16:41,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:16:41,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047099056233148326, lr[0m
[[36m2024-05-24 13:16:41,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:16:41,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.027265739595470306 prior_scale[0m
[[36m2024-05-24 13:16:41,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008086747435543934 q_scale[0m
[[36m2024-05-24 13:16:41,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7168746872185714 obs_scale[0m
[[36m2024-05-24 13:16:41,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 13:16:41,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-05-24 13:16:41,284[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:16:41,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:17:18,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:17:18,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:17:18,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:17:18,821[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:17:18,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:17:18,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:17:18,823[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:17:18,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:17:18,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:17:18,857[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:17:18,865[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.53it/s v_num: 0.000
[[36m2024-05-24 13:18:36,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:18:36,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/014[0m
[[36m2024-05-24 13:18:37,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:18:37,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004719332263015136, lr[0m
[[36m2024-05-24 13:18:37,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:18:37,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02201666456969736 prior_scale[0m
[[36m2024-05-24 13:18:37,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025463997550914342 q_scale[0m
[[36m2024-05-24 13:18:37,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6299642046168042 obs_scale[0m
[[36m2024-05-24 13:18:37,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:18:37,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-05-24 13:18:37,184[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:18:37,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:19:09,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:19:09,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:19:09,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:19:09,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:19:09,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:19:09,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:19:09,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:19:09,537[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:19:09,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:19:09,581[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:19:09,592[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:09 • 0:00:00 20.37it/s v_num: 0.000
[[36m2024-05-24 13:20:13,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:20:13,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/013[0m
[[36m2024-05-24 13:20:13,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:20:13,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047099056233148326, lr[0m
[[36m2024-05-24 13:20:13,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:20:13,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.027265739595470306 prior_scale[0m
[[36m2024-05-24 13:20:13,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008086747435543934 q_scale[0m
[[36m2024-05-24 13:20:13,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7168746872185714 obs_scale[0m
[[36m2024-05-24 13:20:13,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 13:20:13,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-05-24 13:20:13,789[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:20:13,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.21it/s v_num: 0.000
[[36m2024-05-24 13:20:34,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:20:34,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/016[0m
[[36m2024-05-24 13:20:34,826[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:20:34,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000691180961207589, lr[0m
[[36m2024-05-24 13:20:34,873[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:20:34,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049317027736280133 prior_scale[0m
[[36m2024-05-24 13:20:34,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006396905880911569 q_scale[0m
[[36m2024-05-24 13:20:34,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4932620022483778 obs_scale[0m
[[36m2024-05-24 13:20:34,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:20:34,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-05-24 13:20:34,948[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:20:34,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:20:52,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:20:52,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:20:52,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:20:52,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:20:52,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:20:52,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:20:52,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:20:52,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:20:52,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:20:52,193[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:20:52,203[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:21:08,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:21:08,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:21:08,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:21:08,104[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:21:08,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:21:08,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:21:08,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:21:08,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:21:08,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:21:08,140[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:21:08,149[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 5.99it/s v_num: 0.000
[[36m2024-05-24 13:22:29,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:22:29,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/014[0m
[[36m2024-05-24 13:22:29,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:22:29,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004719332263015136, lr[0m
[[36m2024-05-24 13:22:29,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:22:29,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02201666456969736 prior_scale[0m
[[36m2024-05-24 13:22:29,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025463997550914342 q_scale[0m
[[36m2024-05-24 13:22:29,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6299642046168042 obs_scale[0m
[[36m2024-05-24 13:22:29,800[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:22:29,800[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-05-24 13:22:29,801[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:22:29,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:23:01,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:23:01,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:23:01,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:23:01,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:23:01,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:23:01,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:23:01,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:23:01,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:23:01,350[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:23:01,409[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:23:01,420[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.77it/s v_num: 0.000
[[36m2024-05-24 13:26:01,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:26:01,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/015[0m
[[36m2024-05-24 13:26:01,280[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:26:01,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000547121976155859, lr[0m
[[36m2024-05-24 13:26:01,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:26:01,334[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04133742496369647 prior_scale[0m
[[36m2024-05-24 13:26:01,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025555101989354345 q_scale[0m
[[36m2024-05-24 13:26:01,372[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5485259914682613 obs_scale[0m
[[36m2024-05-24 13:26:01,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:26:01,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-05-24 13:26:01,388[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:26:01,388[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:26:34,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:26:34,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:26:34,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:26:34,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:26:34,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:26:34,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:26:34,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:26:34,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:26:34,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:26:34,999[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:26:35,007[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.04it/s v_num: 0.000
[[36m2024-05-24 13:27:14,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:27:14,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/017[0m
[[36m2024-05-24 13:27:14,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:27:14,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007263091335083298, lr[0m
[[36m2024-05-24 13:27:14,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:27:14,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049890828546736765 prior_scale[0m
[[36m2024-05-24 13:27:14,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006414587910215425 q_scale[0m
[[36m2024-05-24 13:27:14,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48413666873004657 obs_scale[0m
[[36m2024-05-24 13:27:14,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:27:14,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-05-24 13:27:14,692[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:27:14,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:27:47,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:27:47,207[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:27:47,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:27:47,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:27:47,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:27:47,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:27:47,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:27:47,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:27:47,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:27:47,254[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:27:47,262[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.87it/s v_num: 0.000
[[36m2024-05-24 13:29:39,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:29:40,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/015[0m
[[36m2024-05-24 13:29:40,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:29:40,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000547121976155859, lr[0m
[[36m2024-05-24 13:29:40,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:29:40,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04133742496369647 prior_scale[0m
[[36m2024-05-24 13:29:40,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025555101989354345 q_scale[0m
[[36m2024-05-24 13:29:40,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5485259914682613 obs_scale[0m
[[36m2024-05-24 13:29:40,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:29:40,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-05-24 13:29:40,237[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:29:40,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:30:11,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:30:11,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:30:11,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:30:11,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:30:11,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:30:11,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:30:11,470[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:30:11,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:30:11,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:30:11,513[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:30:11,521[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.28it/s v_num: 0.000
[[36m2024-05-24 13:33:05,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:33:05,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/016[0m
[[36m2024-05-24 13:33:05,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:33:05,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000691180961207589, lr[0m
[[36m2024-05-24 13:33:05,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:33:05,709[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049317027736280133 prior_scale[0m
[[36m2024-05-24 13:33:05,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006396905880911569 q_scale[0m
[[36m2024-05-24 13:33:05,744[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4932620022483778 obs_scale[0m
[[36m2024-05-24 13:33:05,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:33:05,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-05-24 13:33:05,759[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:33:05,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.61it/s v_num: 0.000
[[36m2024-05-24 13:33:21,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:33:21,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/018[0m
[[36m2024-05-24 13:33:21,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:33:21,507[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007595257909698891, lr[0m
[[36m2024-05-24 13:33:21,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:33:21,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0553052327399875 prior_scale[0m
[[36m2024-05-24 13:33:21,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006518197309155569 q_scale[0m
[[36m2024-05-24 13:33:21,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39668240749227973 obs_scale[0m
[[36m2024-05-24 13:33:21,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:33:21,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-05-24 13:33:21,587[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:33:21,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:33:37,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:33:37,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:33:37,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:33:37,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:33:37,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:33:37,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:33:37,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:33:37,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:33:37,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:33:37,982[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:33:37,990[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:33:53,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:33:53,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:33:53,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:33:53,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:33:53,968[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:33:53,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:33:53,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:33:53,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:33:53,971[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:33:54,001[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:33:54,009[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.18it/s v_num: 0.000
[[36m2024-05-24 13:36:53,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:36:53,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/016[0m
[[36m2024-05-24 13:36:53,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:36:53,956[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000691180961207589, lr[0m
[[36m2024-05-24 13:36:53,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:36:53,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049317027736280133 prior_scale[0m
[[36m2024-05-24 13:36:54,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006396905880911569 q_scale[0m
[[36m2024-05-24 13:36:54,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4932620022483778 obs_scale[0m
[[36m2024-05-24 13:36:54,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:36:54,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-05-24 13:36:54,043[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:36:54,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:37:25,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:37:25,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:37:25,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:37:25,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:37:25,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:37:25,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:37:25,316[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:37:25,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:37:25,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:37:25,358[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:37:25,380[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.02it/s v_num: 0.000
[[36m2024-05-24 13:39:43,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:39:43,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/019[0m
[[36m2024-05-24 13:39:44,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:39:44,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009410248956021665, lr[0m
[[36m2024-05-24 13:39:44,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:39:44,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06343664261871748 prior_scale[0m
[[36m2024-05-24 13:39:44,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020116582693680395 q_scale[0m
[[36m2024-05-24 13:39:44,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35557138721173415 obs_scale[0m
[[36m2024-05-24 13:39:44,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:39:44,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-05-24 13:39:44,284[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:39:44,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.64it/s v_num: 0.000
[[36m2024-05-24 13:39:57,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:39:57,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/017[0m
[[36m2024-05-24 13:39:58,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:39:58,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007263091335083298, lr[0m
[[36m2024-05-24 13:39:58,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:39:58,091[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049890828546736765 prior_scale[0m
[[36m2024-05-24 13:39:58,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006414587910215425 q_scale[0m
[[36m2024-05-24 13:39:58,124[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48413666873004657 obs_scale[0m
[[36m2024-05-24 13:39:58,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:39:58,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-05-24 13:39:58,138[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:39:58,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:40:15,804[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:40:15,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:40:15,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:40:15,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:40:15,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:40:15,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:40:15,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:40:15,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:40:15,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:40:15,854[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:40:15,977[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:40:29,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:40:29,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:40:29,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:40:29,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:40:29,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:40:29,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:40:29,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:40:29,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:40:29,565[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:40:29,596[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:40:29,605[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.55it/s v_num: 0.000
[[36m2024-05-24 13:43:42,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:43:42,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/017[0m
[[36m2024-05-24 13:43:42,445[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:43:42,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007263091335083298, lr[0m
[[36m2024-05-24 13:43:42,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:43:42,515[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049890828546736765 prior_scale[0m
[[36m2024-05-24 13:43:42,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006414587910215425 q_scale[0m
[[36m2024-05-24 13:43:42,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48413666873004657 obs_scale[0m
[[36m2024-05-24 13:43:42,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:43:42,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-05-24 13:43:42,587[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:43:42,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:44:13,281[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:44:13,288[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:44:13,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:44:13,291[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:44:13,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:44:13,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:44:13,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:44:13,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:44:13,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:44:13,334[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:44:13,342[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.44it/s v_num: 0.000
[[36m2024-05-24 13:45:51,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:45:51,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/020[0m
[[36m2024-05-24 13:45:51,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:45:51,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000862223487183857, lr[0m
[[36m2024-05-24 13:45:51,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:45:51,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06740901007980604 prior_scale[0m
[[36m2024-05-24 13:45:51,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022427661372579052 q_scale[0m
[[36m2024-05-24 13:45:51,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3374818790903625 obs_scale[0m
[[36m2024-05-24 13:45:51,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:45:51,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-05-24 13:45:51,770[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:45:51,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:46:23,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:46:23,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:46:23,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:46:23,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:46:23,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:46:23,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:46:23,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:46:23,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:46:23,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:46:23,764[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:46:23,774[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.74it/s v_num: 0.000
[[36m2024-05-24 13:46:50,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:46:50,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/018[0m
[[36m2024-05-24 13:46:50,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:46:50,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007595257909698891, lr[0m
[[36m2024-05-24 13:46:50,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:46:50,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0553052327399875 prior_scale[0m
[[36m2024-05-24 13:46:50,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006518197309155569 q_scale[0m
[[36m2024-05-24 13:46:50,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39668240749227973 obs_scale[0m
[[36m2024-05-24 13:46:50,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:46:50,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-05-24 13:46:50,963[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:46:50,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:47:23,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:47:23,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:47:23,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:47:23,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:47:23,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:47:23,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:47:23,700[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:47:23,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:47:23,701[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:47:23,736[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:47:23,745[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.59it/s v_num: 0.000
[[36m2024-05-24 13:50:23,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:50:23,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/018[0m
[[36m2024-05-24 13:50:23,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:50:23,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005257884343407172, lr[0m
[[36m2024-05-24 13:50:23,969[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:50:23,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04778396272199133 prior_scale[0m
[[36m2024-05-24 13:50:24,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000650326152249017 q_scale[0m
[[36m2024-05-24 13:50:24,022[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39005208596186086 obs_scale[0m
[[36m2024-05-24 13:50:24,036[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:50:24,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-05-24 13:50:24,037[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:50:24,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:50:55,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:50:55,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:50:55,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:50:55,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:50:55,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:50:55,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:50:55,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:50:55,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:50:55,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:50:55,258[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:50:55,267[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.44it/s v_num: 0.000
[[36m2024-05-24 13:52:17,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:52:17,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/021[0m
[[36m2024-05-24 13:52:18,036[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:52:18,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009874924234262205, lr[0m
[[36m2024-05-24 13:52:18,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:52:18,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04016065945973905 prior_scale[0m
[[36m2024-05-24 13:52:18,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007650825946406088 q_scale[0m
[[36m2024-05-24 13:52:18,133[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3797663199026178 obs_scale[0m
[[36m2024-05-24 13:52:18,150[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:52:18,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-05-24 13:52:18,151[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:52:18,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:52:51,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:52:51,073[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:52:51,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:52:51,076[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:52:51,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:52:51,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:52:51,078[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:52:51,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:52:51,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:52:51,121[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:52:52,142[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.80it/s v_num: 0.000
[[36m2024-05-24 13:54:17,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:54:17,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/019[0m
[[36m2024-05-24 13:54:17,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:54:17,243[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009410248956021665, lr[0m
[[36m2024-05-24 13:54:17,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:54:17,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06343664261871748 prior_scale[0m
[[36m2024-05-24 13:54:17,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020116582693680395 q_scale[0m
[[36m2024-05-24 13:54:17,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35557138721173415 obs_scale[0m
[[36m2024-05-24 13:54:17,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:54:17,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-05-24 13:54:17,332[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:54:17,332[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:54:49,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:54:49,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:54:49,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:54:49,908[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:54:49,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:54:49,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:54:49,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:54:49,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:54:49,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:54:49,960[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:54:49,969[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.51it/s v_num: 0.000
[[36m2024-05-24 13:57:23,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:57:23,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/019[0m
[[36m2024-05-24 13:57:24,130[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:57:24,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016341722830749965, lr[0m
[[36m2024-05-24 13:57:24,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:57:24,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0685974414213973 prior_scale[0m
[[36m2024-05-24 13:57:24,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020089389141657326 q_scale[0m
[[36m2024-05-24 13:57:24,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35557138721173415 obs_scale[0m
[[36m2024-05-24 13:57:24,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:57:24,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-05-24 13:57:24,236[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:57:24,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:57:56,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:57:56,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:57:56,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:57:56,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:57:56,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:57:56,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:57:56,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:57:56,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:57:56,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:57:56,638[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:57:56,647[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.20it/s v_num: 0.000
[[36m2024-05-24 13:58:35,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 13:58:35,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/022[0m
[[36m2024-05-24 13:58:35,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 13:58:35,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005520705419775921, lr[0m
[[36m2024-05-24 13:58:35,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 13:58:35,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10613466247626048 prior_scale[0m
[[36m2024-05-24 13:58:35,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024345544575973615 q_scale[0m
[[36m2024-05-24 13:58:35,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27667843921397695 obs_scale[0m
[[36m2024-05-24 13:58:35,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 13:58:35,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-05-24 13:58:35,429[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 13:58:35,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 13:59:08,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 13:59:08,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 13:59:08,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 13:59:08,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 13:59:08,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 13:59:08,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 13:59:08,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 13:59:08,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 13:59:08,344[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 13:59:08,374[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 13:59:08,439[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.18it/s v_num: 0.000
[[36m2024-05-24 14:01:19,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:01:19,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/020[0m
[[36m2024-05-24 14:01:19,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:01:19,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000862223487183857, lr[0m
[[36m2024-05-24 14:01:19,784[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:01:19,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06740901007980604 prior_scale[0m
[[36m2024-05-24 14:01:19,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022427661372579052 q_scale[0m
[[36m2024-05-24 14:01:19,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3374818790903625 obs_scale[0m
[[36m2024-05-24 14:01:19,855[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:01:19,855[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-05-24 14:01:19,856[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:01:19,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:01:51,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:01:51,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:01:51,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:01:51,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:01:51,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:01:51,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:01:51,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:01:51,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:01:51,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:01:51,277[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:01:51,285[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 10/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.72it/s v_num: 0.000
[[36m2024-05-24 14:02:17,788[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 10.
[[36m2024-05-24 14:02:18,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:02:18,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:02:18,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018191293917234794, lr[0m
[[36m2024-05-24 14:02:18,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:02:18,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07276046906957684 prior_scale[0m
[[36m2024-05-24 14:02:18,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004960791867825049 q_scale[0m
[[36m2024-05-24 14:02:18,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23646204862668876 obs_scale[0m
[[36m2024-05-24 14:02:18,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:02:18,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-05-24 14:02:18,603[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:02:18,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:02:53,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:02:53,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:02:53,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:02:53,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:02:53,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:02:53,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:02:53,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:02:53,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:02:53,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:02:53,092[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:02:53,100[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.31it/s v_num: 0.000
[[36m2024-05-24 14:04:07,417[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2024-05-24 14:04:07,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:04:07,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:04:07,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006027416098410279, lr[0m
[[36m2024-05-24 14:04:07,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:04:07,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.044525246619667135 prior_scale[0m
[[36m2024-05-24 14:04:07,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007910538045185004 q_scale[0m
[[36m2024-05-24 14:04:07,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.483370413879867 obs_scale[0m
[[36m2024-05-24 14:04:07,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:04:07,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-05-24 14:04:07,667[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:04:07,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:04:39,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:04:39,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:04:39,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:04:39,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:04:39,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:04:39,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:04:39,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:04:39,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:04:39,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:04:39,970[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:04:39,980[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.76it/s v_num: 0.000
[[36m2024-05-24 14:07:50,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:07:50,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/021[0m
[[36m2024-05-24 14:07:50,507[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:07:50,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009897517703610693, lr[0m
[[36m2024-05-24 14:07:50,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:07:50,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07940156934878417 prior_scale[0m
[[36m2024-05-24 14:07:50,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021507479225071316 q_scale[0m
[[36m2024-05-24 14:07:50,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.34212097371806827 obs_scale[0m
[[36m2024-05-24 14:07:50,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:07:50,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-05-24 14:07:50,592[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:07:50,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:08:22,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:08:22,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:08:22,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:08:22,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:08:22,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:08:22,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:08:22,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:08:22,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:08:22,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:08:22,160[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:08:22,169[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.70it/s v_num: 0.000
[[36m2024-05-24 14:08:24,973[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[[36m2024-05-24 14:08:24,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:08:25,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:08:25,130[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006748438578408085, lr[0m
[[36m2024-05-24 14:08:25,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:08:25,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13469709642502314 prior_scale[0m
[[36m2024-05-24 14:08:25,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020581642968448062 q_scale[0m
[[36m2024-05-24 14:08:25,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.46591103682903323 obs_scale[0m
[[36m2024-05-24 14:08:25,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:08:25,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-05-24 14:08:25,220[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:08:25,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:08:59,831[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:08:59,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:08:59,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:08:59,842[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:08:59,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:08:59,847[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:08:59,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:08:59,848[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:08:59,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:08:59,881[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:08:59,892[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.79it/s v_num: 0.000
[[36m2024-05-24 14:11:34,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:11:34,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/021[0m
[[36m2024-05-24 14:11:34,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:11:35,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009759889358631576, lr[0m
[[36m2024-05-24 14:11:35,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:11:35,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04016065945973905 prior_scale[0m
[[36m2024-05-24 14:11:35,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006801449341523249 q_scale[0m
[[36m2024-05-24 14:11:35,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2677685950195412 obs_scale[0m
[[36m2024-05-24 14:11:35,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:11:35,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-05-24 14:11:35,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:11:35,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:12:07,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:12:07,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:12:07,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:12:07,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:12:07,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:12:07,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:12:07,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:12:07,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:12:07,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:12:07,191[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:12:07,259[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.39it/s v_num: 0.000
[[36m2024-05-24 14:14:48,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:14:48,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/022[0m
[[36m2024-05-24 14:14:48,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:14:48,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005971919166727717, lr[0m
[[36m2024-05-24 14:14:48,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:14:48,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11788112679105546 prior_scale[0m
[[36m2024-05-24 14:14:48,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00027425246065001445 q_scale[0m
[[36m2024-05-24 14:14:48,499[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23001124617088642 obs_scale[0m
[[36m2024-05-24 14:14:48,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:14:48,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-05-24 14:14:48,521[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:14:48,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.14it/s v_num: 0.000
[[36m2024-05-24 14:15:01,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:15:01,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/025[0m
[[36m2024-05-24 14:15:01,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 14:15:02,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003309168926504286, lr[0m
[[36m2024-05-24 14:15:02,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 14:15:02,064[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16003439990235888 prior_scale[0m
[[36m2024-05-24 14:15:02,085[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018157955174446106 q_scale[0m
[[36m2024-05-24 14:15:02,105[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21141877978280718 obs_scale[0m
[[36m2024-05-24 14:15:02,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:15:02,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-05-24 14:15:02,120[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:15:02,121[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:15:23,030[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:15:23,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:15:23,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:15:23,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:15:23,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:15:23,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:15:23,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:15:23,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:15:23,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:15:23,085[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:15:23,093[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:15:35,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:15:35,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:15:35,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:15:35,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:15:35,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:15:35,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:15:35,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:15:35,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:15:35,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:15:35,728[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:15:35,752[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 14:15:35,768[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.46it/s v_num: 0.000
[[36m2024-05-24 14:19:01,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:19:01,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/022[0m
[[36m2024-05-24 14:19:01,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:19:01,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006227221732994119, lr[0m
[[36m2024-05-24 14:19:01,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:19:01,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0668941358360474 prior_scale[0m
[[36m2024-05-24 14:19:01,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003126425480395599 q_scale[0m
[[36m2024-05-24 14:19:01,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4151409793914799 obs_scale[0m
[[36m2024-05-24 14:19:01,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:19:01,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-05-24 14:19:01,672[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:19:01,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:19:34,326[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:19:34,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:19:34,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:19:34,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:19:34,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:19:34,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:19:34,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:19:34,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:19:34,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:19:34,383[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:19:34,433[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.62it/s v_num: 0.000
[[36m2024-05-24 14:22:13,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:22:13,981[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/023[0m
[[36m2024-05-24 14:22:14,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:22:14,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018191293917234794, lr[0m
[[36m2024-05-24 14:22:14,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:22:14,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06428450868917905 prior_scale[0m
[[36m2024-05-24 14:22:14,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018013891144046316 q_scale[0m
[[36m2024-05-24 14:22:14,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3630931498618861 obs_scale[0m
[[36m2024-05-24 14:22:14,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:22:14,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-05-24 14:22:14,287[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:22:14,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:22:47,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:22:47,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:22:47,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:22:47,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:22:47,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:22:47,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:22:47,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:22:47,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:22:47,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:22:47,455[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:22:47,472[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:24 • 0:00:00 15.47it/s v_num: 0.000
[[36m2024-05-24 14:24:14,985[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[[36m2024-05-24 14:24:14,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:24:15,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:24:15,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006167782848423004, lr[0m
[[36m2024-05-24 14:24:15,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:24:15,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2763705310792614 prior_scale[0m
[[36m2024-05-24 14:24:15,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002904082597194098 q_scale[0m
[[36m2024-05-24 14:24:15,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3746859534867914 obs_scale[0m
[[36m2024-05-24 14:24:15,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:24:15,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-05-24 14:24:15,232[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:24:15,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:24:48,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:24:48,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:24:48,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:24:48,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:24:48,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:24:48,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:24:48,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:24:48,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:24:48,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:24:48,999[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:24:49,008[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.23it/s v_num: 0.000
[[36m2024-05-24 14:26:51,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:26:51,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/023[0m
[[36m2024-05-24 14:26:51,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:26:51,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006681762479256583, lr[0m
[[36m2024-05-24 14:26:51,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:26:51,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08554798474183566 prior_scale[0m
[[36m2024-05-24 14:26:51,826[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033011851205550185 q_scale[0m
[[36m2024-05-24 14:26:51,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5105715736300651 obs_scale[0m
[[36m2024-05-24 14:26:51,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:26:51,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-05-24 14:26:51,862[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:26:51,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:27:24,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:27:24,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:27:24,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:27:24,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:27:24,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:27:24,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:27:24,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:27:24,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:27:24,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:27:24,578[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:27:24,587[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.65it/s v_num: 0.000
[[36m2024-05-24 14:27:49,201[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[[36m2024-05-24 14:27:49,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:27:49,337[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:27:49,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009893755800209887, lr[0m
[[36m2024-05-24 14:27:49,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:27:49,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.034219793325451595 prior_scale[0m
[[36m2024-05-24 14:27:49,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006427159858661907 q_scale[0m
[[36m2024-05-24 14:27:49,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2620362868752414 obs_scale[0m
[[36m2024-05-24 14:27:49,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:27:49,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-05-24 14:27:49,446[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:27:49,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:28:21,345[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:28:21,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:28:21,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:28:21,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:28:21,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:28:21,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:28:21,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:28:21,358[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:28:21,359[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:28:21,389[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:28:21,411[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.13it/s v_num: 0.000
[[36m2024-05-24 14:30:50,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:30:50,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/027[0m
[[36m2024-05-24 14:30:50,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:30:51,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011398430345573024, lr[0m
[[36m2024-05-24 14:30:51,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:30:51,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30186663651042894 prior_scale[0m
[[36m2024-05-24 14:30:51,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015935445456431618 q_scale[0m
[[36m2024-05-24 14:30:51,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3065174459109755 obs_scale[0m
[[36m2024-05-24 14:30:51,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 14:30:51,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-05-24 14:30:51,129[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:30:51,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:31:24,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:31:24,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:31:24,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:31:24,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:31:24,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:31:24,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:31:24,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:31:24,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:31:24,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:31:24,195[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:31:24,222[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 24.50it/s v_num: 0.000
[[36m2024-05-24 14:33:19,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:33:19,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/028[0m
[[36m2024-05-24 14:33:19,544[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 14:33:19,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.702364224005333e-05, lr[0m
[[36m2024-05-24 14:33:19,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:33:19,599[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13720478443334658 prior_scale[0m
[[36m2024-05-24 14:33:19,618[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000383518181805017 q_scale[0m
[[36m2024-05-24 14:33:19,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5748625129590914 obs_scale[0m
[[36m2024-05-24 14:33:19,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 14:33:19,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-05-24 14:33:19,654[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:33:19,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:33:57,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:33:57,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:33:57,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:33:57,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:33:57,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:33:57,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:33:57,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:33:57,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:33:57,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:33:57,540[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:33:57,551[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 14:33:57,554[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 14.07it/s v_num: 0.000
[[36m2024-05-24 14:34:50,962[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:34:50,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/029[0m
[[36m2024-05-24 14:34:51,124[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:34:51,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038396701131185356, lr[0m
[[36m2024-05-24 14:34:51,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:34:51,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0861232110600651 prior_scale[0m
[[36m2024-05-24 14:34:51,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002912461426991157 q_scale[0m
[[36m2024-05-24 14:34:51,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4370098510594135 obs_scale[0m
[[36m2024-05-24 14:34:51,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:34:51,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-05-24 14:34:51,259[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:34:51,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.50it/s v_num: 0.000
[[36m2024-05-24 14:34:55,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:34:55,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/024[0m
[[36m2024-05-24 14:34:55,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:34:55,209[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003394050757930824, lr[0m
[[36m2024-05-24 14:34:55,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:34:55,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13469709642502314 prior_scale[0m
[[36m2024-05-24 14:34:55,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029198439611751305 q_scale[0m
[[36m2024-05-24 14:34:55,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32572674772294435 obs_scale[0m
[[36m2024-05-24 14:34:55,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:34:55,305[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-05-24 14:34:55,305[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:34:55,306[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.78it/s v_num: 0.000
[[36m2024-05-24 14:34:55,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:34:55,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/025[0m
[[36m2024-05-24 14:34:56,045[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 14:34:56,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003628689069010046, lr[0m
[[36m2024-05-24 14:34:56,093[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 14:34:56,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15479700679466418 prior_scale[0m
[[36m2024-05-24 14:34:56,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018157955174446106 q_scale[0m
[[36m2024-05-24 14:34:56,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3987880946462159 obs_scale[0m
[[36m2024-05-24 14:34:56,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:34:56,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-05-24 14:34:56,187[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:34:56,187[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:35:24,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:35:24,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:35:24,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:35:24,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:35:24,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:35:24,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:35:24,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:35:24,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:35:24,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:35:24,148[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:35:25,352[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:35:27,971[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:35:27,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:35:27,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:35:27,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:35:27,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:35:27,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:35:27,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:35:27,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:35:27,986[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:35:28,019[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:35:28,369[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:35:29,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:35:29,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:35:29,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:35:29,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:35:29,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:35:29,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:35:29,122[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:35:29,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:35:29,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:35:29,155[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:35:31,044[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 14:35:31,047[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.09it/s v_num: 0.000
[[36m2024-05-24 14:41:17,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:41:17,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/030[0m
[[36m2024-05-24 14:41:17,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:41:17,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006680368066976181, lr[0m
[[36m2024-05-24 14:41:17,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:41:17,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05579858997767185 prior_scale[0m
[[36m2024-05-24 14:41:17,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007242189305787746 q_scale[0m
[[36m2024-05-24 14:41:17,857[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4786387433445233 obs_scale[0m
[[36m2024-05-24 14:41:17,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:41:17,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-05-24 14:41:17,873[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:41:17,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:41:51,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:41:51,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:41:51,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:41:51,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:41:51,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:41:51,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:41:51,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:41:51,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:41:51,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:41:51,541[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:41:53,905[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.38it/s v_num: 0.000
[[36m2024-05-24 14:42:38,578[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:42:38,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/025[0m
[[36m2024-05-24 14:42:38,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 14:42:38,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002178416264960444, lr[0m
[[36m2024-05-24 14:42:38,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 14:42:38,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07455230132082018 prior_scale[0m
[[36m2024-05-24 14:42:38,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023274249435730555 q_scale[0m
[[36m2024-05-24 14:42:38,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2299898013343446 obs_scale[0m
[[36m2024-05-24 14:42:38,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:42:38,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-05-24 14:42:38,984[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:42:38,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:43:12,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:43:12,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:43:12,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:43:12,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:43:12,427[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:43:12,428[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:43:12,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:43:12,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:43:12,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:43:12,463[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:43:12,552[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 14:43:12,554[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.46it/s v_num: 0.000
[[36m2024-05-24 14:47:34,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:47:34,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/026[0m
[[36m2024-05-24 14:47:34,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:47:34,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006167782848423004, lr[0m
[[36m2024-05-24 14:47:34,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:47:34,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07078082608673841 prior_scale[0m
[[36m2024-05-24 14:47:34,841[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004018287278718421 q_scale[0m
[[36m2024-05-24 14:47:34,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1980958002490439 obs_scale[0m
[[36m2024-05-24 14:47:34,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:47:34,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-05-24 14:47:34,872[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:47:34,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 29.96it/s v_num: 0.000
[[36m2024-05-24 14:47:37,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:47:37,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/031[0m
[[36m2024-05-24 14:47:37,737[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:47:37,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006182721622361482, lr[0m
[[36m2024-05-24 14:47:37,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:47:37,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0650746397020037 prior_scale[0m
[[36m2024-05-24 14:47:37,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007985508727179825 q_scale[0m
[[36m2024-05-24 14:47:37,826[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6680718428263864 obs_scale[0m
[[36m2024-05-24 14:47:37,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:47:37,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-05-24 14:47:37,841[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:47:37,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:48:07,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:48:07,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:48:07,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:48:07,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:48:07,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:48:07,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:48:07,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:48:07,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:48:07,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:48:07,569[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:48:07,577[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:48:10,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:48:10,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:48:10,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:48:10,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:48:10,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:48:10,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:48:10,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:48:10,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:48:10,345[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:48:10,395[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:48:10,433[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.84it/s v_num: 0.000
[[36m2024-05-24 14:53:56,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:53:56,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/032[0m
[[36m2024-05-24 14:53:56,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:53:56,795[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007266156417882247, lr[0m
[[36m2024-05-24 14:53:56,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:53:56,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.036816549565905674 prior_scale[0m
[[36m2024-05-24 14:53:56,896[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018067715999785274 q_scale[0m
[[36m2024-05-24 14:53:56,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.34141996198473634 obs_scale[0m
[[36m2024-05-24 14:53:56,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:53:56,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-05-24 14:53:56,933[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:53:56,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:54:29,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:54:29,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:54:29,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:54:29,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:54:29,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:54:29,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:54:29,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:54:29,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:54:29,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:54:29,338[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:54:29,345[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.71it/s v_num: 0.000
[[36m2024-05-24 14:54:47,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:54:47,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/027[0m
[[36m2024-05-24 14:54:47,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:54:47,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.0174518409972304e-05, lr[0m
[[36m2024-05-24 14:54:47,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:54:47,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30186663651042894 prior_scale[0m
[[36m2024-05-24 14:54:47,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003025192277530568 q_scale[0m
[[36m2024-05-24 14:54:47,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3065174459109755 obs_scale[0m
[[36m2024-05-24 14:54:47,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 14:54:47,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-05-24 14:54:47,705[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:54:47,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:55:21,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:55:21,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:55:21,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:55:21,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:55:21,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:55:21,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:55:21,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:55:21,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:55:21,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:55:21,692[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:55:21,901[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:34 • 0:00:00 10.98it/s v_num: 0.000
[[36m2024-05-24 14:55:51,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:55:51,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/026[0m
[[36m2024-05-24 14:55:52,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:55:52,121[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006746258891313132, lr[0m
[[36m2024-05-24 14:55:52,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:55:52,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14732222903843126 prior_scale[0m
[[36m2024-05-24 14:55:52,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004018287278718421 q_scale[0m
[[36m2024-05-24 14:55:52,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5895199043485567 obs_scale[0m
[[36m2024-05-24 14:55:52,209[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:55:52,210[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-05-24 14:55:52,210[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:55:52,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:56:23,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:56:23,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:56:23,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:56:23,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:56:23,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:56:23,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:56:23,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:56:23,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:56:23,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:56:23,711[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:56:23,720[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 18.79it/s v_num: 0.000
[[36m2024-05-24 14:57:37,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:57:37,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/028[0m
[[36m2024-05-24 14:57:37,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 14:57:37,652[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.921553289851606e-05, lr[0m
[[36m2024-05-24 14:57:37,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:57:37,690[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.039413706203980936 prior_scale[0m
[[36m2024-05-24 14:57:37,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008515088472132865 q_scale[0m
[[36m2024-05-24 14:57:37,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5822297899801441 obs_scale[0m
[[36m2024-05-24 14:57:37,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 14:57:37,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-05-24 14:57:37,754[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:57:37,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:58:13,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:58:13,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:58:13,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:58:13,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:58:13,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:58:13,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:58:13,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:58:13,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:58:13,347[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:58:13,386[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:58:13,393[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 14:58:13,396[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 8.75it/s v_num: 0.000
[[36m2024-05-24 14:59:28,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 14:59:28,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/029[0m
[[36m2024-05-24 14:59:28,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 14:59:28,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033887516581264203, lr[0m
[[36m2024-05-24 14:59:28,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 14:59:28,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.022689658887318588 prior_scale[0m
[[36m2024-05-24 14:59:28,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047528042867711856 q_scale[0m
[[36m2024-05-24 14:59:28,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4370098510594135 obs_scale[0m
[[36m2024-05-24 14:59:28,394[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 14:59:28,394[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-05-24 14:59:28,395[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 14:59:28,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 14:59:59,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 14:59:59,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 14:59:59,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 14:59:59,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 14:59:59,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 14:59:59,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 14:59:59,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 14:59:59,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 14:59:59,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 14:59:59,724[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 14:59:59,771[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.14it/s v_num: 0.000
[[36m2024-05-24 15:00:25,360[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:00:25,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/033[0m
[[36m2024-05-24 15:00:25,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:00:25,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.7136632515214375e-05, lr[0m
[[36m2024-05-24 15:00:25,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:00:25,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.059480207834859085 prior_scale[0m
[[36m2024-05-24 15:00:25,595[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011170018507351946 q_scale[0m
[[36m2024-05-24 15:00:25,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27342775354008636 obs_scale[0m
[[36m2024-05-24 15:00:25,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 15:00:25,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-05-24 15:00:25,629[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:00:25,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:01:00,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:01:00,780[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:01:00,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:01:00,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:01:00,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:01:00,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:01:00,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:01:00,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:01:00,790[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:01:00,823[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:01:00,831[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 19.15it/s v_num: 0.000
[[36m2024-05-24 15:02:24,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:02:24,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/034[0m
[[36m2024-05-24 15:02:24,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:02:24,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009697184655036393, lr[0m
[[36m2024-05-24 15:02:24,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:02:24,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12538829146846445 prior_scale[0m
[[36m2024-05-24 15:02:24,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033818982970098166 q_scale[0m
[[36m2024-05-24 15:02:24,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8473948045312067 obs_scale[0m
[[36m2024-05-24 15:02:24,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:02:24,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-05-24 15:02:24,684[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:02:24,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:02:57,449[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:02:57,456[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:02:57,457[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:02:57,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:02:57,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:02:57,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:02:57,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:02:57,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:02:57,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:02:57,504[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:02:57,539[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.08it/s v_num: 0.000
[[36m2024-05-24 15:03:37,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:03:37,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/027[0m
[[36m2024-05-24 15:03:38,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:03:38,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010665795465083976, lr[0m
[[36m2024-05-24 15:03:38,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:03:38,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30186663651042894 prior_scale[0m
[[36m2024-05-24 15:03:38,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017234324760472387 q_scale[0m
[[36m2024-05-24 15:03:38,206[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8753756893535367 obs_scale[0m
[[36m2024-05-24 15:03:38,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 15:03:38,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-05-24 15:03:38,222[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:03:38,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:04:11,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:04:11,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:04:11,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:04:11,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:04:11,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:04:11,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:04:11,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:04:11,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:04:11,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:04:11,642[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:04:12,532[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.01it/s v_num: 0.000
[[36m2024-05-24 15:06:16,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:06:16,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/030[0m
[[36m2024-05-24 15:06:16,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:06:16,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007178839930599398, lr[0m
[[36m2024-05-24 15:06:16,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:06:16,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04902796638075531 prior_scale[0m
[[36m2024-05-24 15:06:16,305[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006305977822506084 q_scale[0m
[[36m2024-05-24 15:06:16,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.44583708052282817 obs_scale[0m
[[36m2024-05-24 15:06:16,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:06:16,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-05-24 15:06:16,340[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:06:16,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:06:48,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:06:48,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:06:48,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:06:48,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:06:48,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:06:48,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:06:48,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:06:48,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:06:48,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:06:48,096[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:06:48,166[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 14.07it/s v_num: 0.000
[[36m2024-05-24 15:07:03,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:07:03,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/028[0m
[[36m2024-05-24 15:07:03,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:07:03,938[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.236894882777535e-05, lr[0m
[[36m2024-05-24 15:07:03,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:07:03,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14118427219031313 prior_scale[0m
[[36m2024-05-24 15:07:03,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045795540155435196 q_scale[0m
[[36m2024-05-24 15:07:04,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4135697881067528 obs_scale[0m
[[36m2024-05-24 15:07:04,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 15:07:04,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-05-24 15:07:04,042[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:07:04,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:07:40,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:07:40,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:07:40,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:07:40,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:07:40,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:07:40,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:07:40,976[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:07:40,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:07:40,977[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:07:41,010[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:07:41,301[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:07:41,303[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:04 • 0:00:00 5.88it/s v_num: 0.000
[[36m2024-05-24 15:09:16,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:09:16,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/029[0m
[[36m2024-05-24 15:09:16,281[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:09:16,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009591845442225177, lr[0m
[[36m2024-05-24 15:09:16,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:09:16,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2796765149103996 prior_scale[0m
[[36m2024-05-24 15:09:16,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004154979524846102 q_scale[0m
[[36m2024-05-24 15:09:16,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6208861958467037 obs_scale[0m
[[36m2024-05-24 15:09:16,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:09:16,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-05-24 15:09:16,393[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:09:16,393[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:09:48,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:09:48,713[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:09:48,714[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:09:48,716[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:09:48,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:09:48,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:09:48,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:09:48,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:09:48,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:09:48,767[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:09:49,478[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:24 • 0:00:00 15.76it/s v_num: 0.000
[[36m2024-05-24 15:12:49,200[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:12:49,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/035[0m
[[36m2024-05-24 15:12:49,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:12:49,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336178932942835e-05, lr[0m
[[36m2024-05-24 15:12:49,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:12:49,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09085987402195016 prior_scale[0m
[[36m2024-05-24 15:12:49,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005395308954875394 q_scale[0m
[[36m2024-05-24 15:12:49,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.46723865281277066 obs_scale[0m
[[36m2024-05-24 15:12:49,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:12:49,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-05-24 15:12:49,526[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:12:49,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.32it/s v_num: 0.000
[[36m2024-05-24 15:13:01,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:13:01,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/031[0m
[[36m2024-05-24 15:13:01,610[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:13:01,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000729074396149963, lr[0m
[[36m2024-05-24 15:13:01,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:13:01,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09817041163299439 prior_scale[0m
[[36m2024-05-24 15:13:01,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026318471896278 q_scale[0m
[[36m2024-05-24 15:13:01,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31997177793407683 obs_scale[0m
[[36m2024-05-24 15:13:01,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:13:01,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-05-24 15:13:01,714[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:13:01,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:13:22,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:13:22,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:13:22,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:13:22,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:13:22,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:13:22,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:13:22,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:13:22,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:13:22,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:13:22,274[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:13:22,959[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:13:22,963[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:13:32,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:13:32,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:13:32,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:13:32,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:13:32,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:13:32,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:13:32,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:13:32,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:13:32,842[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:13:32,875[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:13:32,883[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.64it/s v_num: 0.000
[[36m2024-05-24 15:17:03,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:17:03,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/030[0m
[[36m2024-05-24 15:17:03,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:17:03,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006557811813299671, lr[0m
[[36m2024-05-24 15:17:03,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:17:03,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0946187101144961 prior_scale[0m
[[36m2024-05-24 15:17:03,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024787379924768026 q_scale[0m
[[36m2024-05-24 15:17:03,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.46632986902004936 obs_scale[0m
[[36m2024-05-24 15:17:03,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:17:03,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-05-24 15:17:03,779[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:17:03,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:17:35,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:17:35,691[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:17:35,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:17:35,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:17:35,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:17:35,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:17:35,697[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:17:35,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:17:35,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:17:35,740[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:17:35,764[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.45it/s v_num: 0.000
[[36m2024-05-24 15:19:06,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:19:06,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/036[0m
[[36m2024-05-24 15:19:06,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:19:07,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000213940624590804, lr[0m
[[36m2024-05-24 15:19:07,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:19:07,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03194832541554563 prior_scale[0m
[[36m2024-05-24 15:19:07,068[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016035412310709174 q_scale[0m
[[36m2024-05-24 15:19:07,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.565952259567061 obs_scale[0m
[[36m2024-05-24 15:19:07,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 15:19:07,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-05-24 15:19:07,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:19:07,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:19:43,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:19:43,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:19:43,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:19:43,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:19:43,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:19:43,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:19:43,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:19:43,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:19:43,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:19:43,801[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:19:44,226[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.34it/s v_num: 0.000
[[36m2024-05-24 15:19:54,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:19:54,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/032[0m
[[36m2024-05-24 15:19:54,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:19:54,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005535194318895576, lr[0m
[[36m2024-05-24 15:19:54,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:19:54,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09775279828274265 prior_scale[0m
[[36m2024-05-24 15:19:54,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003244161371558254 q_scale[0m
[[36m2024-05-24 15:19:54,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2946122456648841 obs_scale[0m
[[36m2024-05-24 15:19:54,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:19:54,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-05-24 15:19:54,733[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:19:54,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:20:27,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:20:27,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:20:27,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:20:27,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:20:27,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:20:27,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:20:27,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:20:27,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:20:27,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:20:27,505[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:20:27,515[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 14.22it/s v_num: 0.000
[[36m2024-05-24 15:20:37,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:20:37,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/037[0m
[[36m2024-05-24 15:20:37,649[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:20:37,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004966402699781978, lr[0m
[[36m2024-05-24 15:20:37,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:20:37,720[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02307798890182511 prior_scale[0m
[[36m2024-05-24 15:20:37,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008677919586673049 q_scale[0m
[[36m2024-05-24 15:20:37,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3422976092490253 obs_scale[0m
[[36m2024-05-24 15:20:37,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 15:20:37,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-05-24 15:20:37,792[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:20:37,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:21:11,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:21:11,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:21:11,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:21:11,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:21:11,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:21:11,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:21:11,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:21:11,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:21:11,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:21:11,050[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:21:11,066[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 10.86it/s v_num: 0.000
[[36m2024-05-24 15:23:10,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:23:10,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/038[0m
[[36m2024-05-24 15:23:10,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:23:10,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013788557993523379, lr[0m
[[36m2024-05-24 15:23:10,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:23:10,728[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.046750137490587707 prior_scale[0m
[[36m2024-05-24 15:23:10,746[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014573544217320089 q_scale[0m
[[36m2024-05-24 15:23:10,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.38723031042750894 obs_scale[0m
[[36m2024-05-24 15:23:10,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 15:23:10,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-05-24 15:23:10,781[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:23:10,781[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:23:44,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:23:44,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:23:44,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:23:44,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:23:44,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:23:44,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:23:44,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:23:44,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:23:44,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:23:44,387[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:23:44,409[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:23:44,412[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.91it/s v_num: 0.000
[[36m2024-05-24 15:24:25,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:24:25,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/031[0m
[[36m2024-05-24 15:24:25,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:24:25,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003567555044956278, lr[0m
[[36m2024-05-24 15:24:25,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:24:25,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.058151040776631205 prior_scale[0m
[[36m2024-05-24 15:24:25,527[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002694232980195212 q_scale[0m
[[36m2024-05-24 15:24:25,544[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3967240791658831 obs_scale[0m
[[36m2024-05-24 15:24:25,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:24:25,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-05-24 15:24:25,561[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:24:25,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:24:56,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:24:56,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:24:56,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:24:56,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:24:56,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:24:56,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:24:56,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:24:56,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:24:56,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:24:56,469[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:24:56,517[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 26.77it/s v_num: 0.000
[[36m2024-05-24 15:25:34,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:25:34,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/039[0m
[[36m2024-05-24 15:25:34,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:25:34,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.8058268402712556e-05, lr[0m
[[36m2024-05-24 15:25:34,643[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:25:34,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1497377510726038 prior_scale[0m
[[36m2024-05-24 15:25:34,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040784703330132467 q_scale[0m
[[36m2024-05-24 15:25:34,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.197849658450045 obs_scale[0m
[[36m2024-05-24 15:25:34,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:25:34,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-05-24 15:25:34,715[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:25:34,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:26:06,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:26:06,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:26:06,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:26:06,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:26:06,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:26:06,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:26:06,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:26:06,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:26:06,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:26:06,101[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:26:06,111[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.68it/s v_num: 0.000
[[36m2024-05-24 15:26:52,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:26:52,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/033[0m
[[36m2024-05-24 15:26:53,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:26:53,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007076858351289794, lr[0m
[[36m2024-05-24 15:26:53,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:26:53,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1360646567566201 prior_scale[0m
[[36m2024-05-24 15:26:53,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008187195374374731 q_scale[0m
[[36m2024-05-24 15:26:53,218[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27342775354008636 obs_scale[0m
[[36m2024-05-24 15:26:53,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 15:26:53,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-05-24 15:26:53,235[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:26:53,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:27:26,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:27:26,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:27:26,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:27:26,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:27:26,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:27:26,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:27:26,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:27:26,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:27:26,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:27:27,022[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:27:27,030[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 15/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:03 • 0:00:00 12.61it/s v_num: 0.000
[[36m2024-05-24 15:28:45,054[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[[36m2024-05-24 15:28:45,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:28:45,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:28:45,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021171134279289916, lr[0m
[[36m2024-05-24 15:28:45,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:28:45,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.051783450179937934 prior_scale[0m
[[36m2024-05-24 15:28:45,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014643302226281842 q_scale[0m
[[36m2024-05-24 15:28:45,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20296499173499521 obs_scale[0m
[[36m2024-05-24 15:28:45,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:28:45,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-05-24 15:28:45,468[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:28:45,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:29:18,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:29:18,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:29:18,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:29:18,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:29:18,714[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:29:18,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:29:18,716[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:29:18,716[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:29:18,717[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:29:18,757[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:29:19,694[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.81it/s v_num: 0.000
[[36m2024-05-24 15:31:10,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:31:10,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/032[0m
[[36m2024-05-24 15:31:10,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:31:10,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006432693407615532, lr[0m
[[36m2024-05-24 15:31:10,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:31:10,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10207232513038603 prior_scale[0m
[[36m2024-05-24 15:31:10,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005500044262222234 q_scale[0m
[[36m2024-05-24 15:31:10,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30365015814208135 obs_scale[0m
[[36m2024-05-24 15:31:10,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:31:10,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-05-24 15:31:10,389[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:31:10,389[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:31:41,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:31:41,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:31:41,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:31:41,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:31:41,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:31:41,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:31:41,314[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:31:41,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:31:41,316[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:31:41,358[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:31:42,164[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:23 • 0:00:00 16.59it/s v_num: 0.000
[[36m2024-05-24 15:35:22,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:35:22,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/040[0m
[[36m2024-05-24 15:35:22,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:35:22,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007387085317501385, lr[0m
[[36m2024-05-24 15:35:22,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:35:22,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05505225727543 prior_scale[0m
[[36m2024-05-24 15:35:22,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000597938933323071 q_scale[0m
[[36m2024-05-24 15:35:22,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5057735821068052 obs_scale[0m
[[36m2024-05-24 15:35:22,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:35:22,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-05-24 15:35:22,250[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:35:22,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:35:54,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:35:54,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:35:54,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:35:54,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:35:54,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:35:54,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:35:54,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:35:54,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:35:54,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:35:54,464[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:35:54,473[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.41it/s v_num: 0.000
[[36m2024-05-24 15:38:01,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:38:01,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/033[0m
[[36m2024-05-24 15:38:01,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:38:01,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007349925665405387, lr[0m
[[36m2024-05-24 15:38:01,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:38:01,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1772194409452042 prior_scale[0m
[[36m2024-05-24 15:38:01,718[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015856821017201222 q_scale[0m
[[36m2024-05-24 15:38:01,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6293638887691918 obs_scale[0m
[[36m2024-05-24 15:38:01,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 15:38:01,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-05-24 15:38:01,757[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:38:01,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 14/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.58it/s v_num: 0.000
[[36m2024-05-24 15:38:10,338[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[[36m2024-05-24 15:38:10,358[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:38:10,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:38:10,513[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012365570583686662, lr[0m
[[36m2024-05-24 15:38:10,530[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:38:10,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09258552177020683 prior_scale[0m
[[36m2024-05-24 15:38:10,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00107759808629228 q_scale[0m
[[36m2024-05-24 15:38:10,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4131810901021061 obs_scale[0m
[[36m2024-05-24 15:38:10,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:38:10,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-05-24 15:38:10,614[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:38:10,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:38:35,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:38:35,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:38:35,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:38:35,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:38:35,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:38:35,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:38:35,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:38:35,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:38:35,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:38:35,791[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:38:37,440[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:38:44,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:38:44,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:38:44,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:38:44,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:38:44,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:38:44,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:38:44,172[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:38:44,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:38:44,174[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:38:44,206[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:38:44,294[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:38:44,297[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 10.55it/s v_num: 0.000
[[36m2024-05-24 15:40:30,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:40:30,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/034[0m
[[36m2024-05-24 15:40:30,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:40:30,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.7722032902337684e-05, lr[0m
[[36m2024-05-24 15:40:30,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:40:30,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06440353872516405 prior_scale[0m
[[36m2024-05-24 15:40:30,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009456229874537455 q_scale[0m
[[36m2024-05-24 15:40:30,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0976679165359347 obs_scale[0m
[[36m2024-05-24 15:40:30,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:40:30,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-05-24 15:40:30,380[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:40:30,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:41:01,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:41:02,002[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:41:02,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:41:02,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:41:02,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:41:02,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:41:02,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:41:02,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:41:02,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:41:02,052[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:41:02,080[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 29.84it/s v_num: 0.000
[[36m2024-05-24 15:41:34,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:41:34,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/041[0m
[[36m2024-05-24 15:41:34,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:41:34,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007810047860749132, lr[0m
[[36m2024-05-24 15:41:34,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:41:34,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04977734063670971 prior_scale[0m
[[36m2024-05-24 15:41:34,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009870864144858303 q_scale[0m
[[36m2024-05-24 15:41:34,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.44001273653437667 obs_scale[0m
[[36m2024-05-24 15:41:34,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:41:34,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-05-24 15:41:34,520[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:41:34,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:42:07,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:42:07,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:42:07,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:42:07,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:42:07,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:42:07,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:42:07,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:42:07,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:42:07,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:42:07,783[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:42:07,795[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.84it/s v_num: 0.000
[[36m2024-05-24 15:45:45,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:45:45,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/036[0m
[[36m2024-05-24 15:45:46,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:45:46,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.1808411700953774e-05, lr[0m
[[36m2024-05-24 15:45:46,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:45:46,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06061037395940925 prior_scale[0m
[[36m2024-05-24 15:45:46,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004969930137889893 q_scale[0m
[[36m2024-05-24 15:45:46,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5064516163789641 obs_scale[0m
[[36m2024-05-24 15:45:46,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 15:45:46,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-05-24 15:45:46,267[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:45:46,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:46:25,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:46:25,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:46:25,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:46:25,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:46:25,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:46:25,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:46:25,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:46:25,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:46:25,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:46:25,109[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:46:25,117[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.51it/s v_num: 0.000
[[36m2024-05-24 15:47:49,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:47:49,391[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/037[0m
[[36m2024-05-24 15:47:49,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:47:49,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044206432115025064, lr[0m
[[36m2024-05-24 15:47:49,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:47:49,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03550002544853652 prior_scale[0m
[[36m2024-05-24 15:47:49,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017704988662195682 q_scale[0m
[[36m2024-05-24 15:47:49,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6484039653175203 obs_scale[0m
[[36m2024-05-24 15:47:49,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 15:47:49,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-05-24 15:47:49,664[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:47:49,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:48:25,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:48:25,875[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:48:25,877[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:48:25,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:48:25,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:48:25,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:48:25,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:48:25,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:48:25,887[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:48:25,931[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:48:25,940[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 28.55it/s v_num: 0.000
[[36m2024-05-24 15:48:28,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:48:28,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/042[0m
[[36m2024-05-24 15:48:28,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:48:28,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003059323051072793, lr[0m
[[36m2024-05-24 15:48:28,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:48:28,484[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07666832790534799 prior_scale[0m
[[36m2024-05-24 15:48:28,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002006732782072307 q_scale[0m
[[36m2024-05-24 15:48:28,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32525410530092974 obs_scale[0m
[[36m2024-05-24 15:48:28,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:48:28,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-05-24 15:48:28,543[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:48:28,543[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:49:02,968[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:49:02,976[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:49:02,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:49:02,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:49:02,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:49:02,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:49:02,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:49:02,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:49:02,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:49:03,016[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:49:03,024[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:07 • 0:00:00 6.20it/s v_num: 0.000
[[36m2024-05-24 15:51:21,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:51:21,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/038[0m
[[36m2024-05-24 15:51:21,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:51:21,821[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.779960128170813e-05, lr[0m
[[36m2024-05-24 15:51:21,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:51:21,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04258309931113826 prior_scale[0m
[[36m2024-05-24 15:51:21,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024697338723663815 q_scale[0m
[[36m2024-05-24 15:51:21,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2890153691753936 obs_scale[0m
[[36m2024-05-24 15:51:21,919[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 15:51:21,919[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-05-24 15:51:21,919[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:51:21,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:51:56,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:51:56,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:51:56,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:51:56,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:51:56,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:51:56,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:51:56,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:51:56,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:51:56,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:51:57,022[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:51:57,029[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:51:57,032[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:30 • 0:00:00 12.45it/s v_num: 0.000
[[36m2024-05-24 15:52:57,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:52:57,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/035[0m
[[36m2024-05-24 15:52:57,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 15:52:57,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040543093472549224, lr[0m
[[36m2024-05-24 15:52:57,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:52:57,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0321829215948626 prior_scale[0m
[[36m2024-05-24 15:52:57,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024526562363288333 q_scale[0m
[[36m2024-05-24 15:52:57,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4436003451948286 obs_scale[0m
[[36m2024-05-24 15:52:57,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:52:57,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-05-24 15:52:57,387[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:52:57,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:53:29,345[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:53:29,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:53:29,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:53:29,355[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:53:29,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:53:29,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:53:29,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:53:29,358[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:53:29,359[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:53:29,400[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:53:29,410[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 15:53:29,414[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 17.03it/s v_num: 0.000
[[36m2024-05-24 15:54:20,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:54:20,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/039[0m
[[36m2024-05-24 15:54:21,065[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:54:21,096[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032287340305940546, lr[0m
[[36m2024-05-24 15:54:21,117[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 15:54:21,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1152109815590333 prior_scale[0m
[[36m2024-05-24 15:54:21,157[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037533680472094904 q_scale[0m
[[36m2024-05-24 15:54:21,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1386909776011664 obs_scale[0m
[[36m2024-05-24 15:54:21,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:54:21,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-05-24 15:54:21,196[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:54:21,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:54:54,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:55:57,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:55:57,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:55:57,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:55:57,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:55:57,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:55:57,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:55:57,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:55:57,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:55:57,712[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:55:57,826[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 29.67it/s v_num: 0.000
[[36m2024-05-24 15:56:15,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 15:56:15,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/043[0m
[[36m2024-05-24 15:56:16,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 15:56:16,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006332625350956344, lr[0m
[[36m2024-05-24 15:56:16,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 15:56:16,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05946211542099247 prior_scale[0m
[[36m2024-05-24 15:56:16,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010174879441412058 q_scale[0m
[[36m2024-05-24 15:56:16,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.43006409907209103 obs_scale[0m
[[36m2024-05-24 15:56:16,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 15:56:16,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-05-24 15:56:16,156[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 15:56:16,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 15:56:48,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 15:56:48,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 15:56:48,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 15:56:48,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 15:56:48,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 15:56:48,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 15:56:48,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 15:56:48,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 15:56:48,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 15:56:48,782[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 15:56:48,792[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.19it/s v_num: 0.000
[[36m2024-05-24 16:01:30,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:01:30,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/036[0m
[[36m2024-05-24 16:01:30,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:01:30,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014913593738818511, lr[0m
[[36m2024-05-24 16:01:30,706[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:01:30,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09120439297552839 prior_scale[0m
[[36m2024-05-24 16:01:30,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038203459962374433 q_scale[0m
[[36m2024-05-24 16:01:30,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.563411466321853 obs_scale[0m
[[36m2024-05-24 16:01:30,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 16:01:30,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-05-24 16:01:30,772[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:01:30,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:02:06,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:02:06,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:02:06,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:02:06,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:02:06,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:02:06,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:02:06,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:02:06,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:02:06,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:02:06,651[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:02:06,662[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 29.43it/s v_num: 0.000
[[36m2024-05-24 16:02:43,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:02:43,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/044[0m
[[36m2024-05-24 16:02:43,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:02:43,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042537631512919893, lr[0m
[[36m2024-05-24 16:02:43,938[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:02:43,957[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09855865418199686 prior_scale[0m
[[36m2024-05-24 16:02:43,977[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010158363528356515 q_scale[0m
[[36m2024-05-24 16:02:43,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2743425869975343 obs_scale[0m
[[36m2024-05-24 16:02:44,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 16:02:44,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-05-24 16:02:44,013[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:02:44,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:03:18,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:03:18,616[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:03:18,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:03:18,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:03:18,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:03:18,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:03:18,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:03:18,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:03:18,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:03:18,659[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:03:18,994[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 6.15it/s v_num: 0.000
[[36m2024-05-24 16:03:43,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:03:43,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/037[0m
[[36m2024-05-24 16:03:43,808[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:03:43,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002972840099043218, lr[0m
[[36m2024-05-24 16:03:43,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 16:03:43,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14271947763354037 prior_scale[0m
[[36m2024-05-24 16:03:43,882[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011046943371972213 q_scale[0m
[[36m2024-05-24 16:03:43,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7681695633728916 obs_scale[0m
[[36m2024-05-24 16:03:43,920[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 16:03:43,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-05-24 16:03:43,921[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:03:43,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:04:18,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:04:18,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:04:18,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:04:18,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:04:18,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:04:18,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:04:18,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:04:18,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:04:18,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:04:18,636[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:04:19,355[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 21.94it/s v_num: 0.000
[[36m2024-05-24 16:04:29,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:04:29,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/045[0m
[[36m2024-05-24 16:04:29,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:04:30,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000997930783240949, lr[0m
[[36m2024-05-24 16:04:30,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:04:30,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.060833387752002394 prior_scale[0m
[[36m2024-05-24 16:04:30,063[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021041204788870645 q_scale[0m
[[36m2024-05-24 16:04:30,087[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4285221668982412 obs_scale[0m
[[36m2024-05-24 16:04:30,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:04:30,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-05-24 16:04:30,110[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:04:30,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:05:01,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:05:01,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:05:01,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:05:01,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:05:01,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:05:01,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:05:01,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:05:01,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:05:01,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:05:01,656[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:05:01,668[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:27 • 0:00:00 13.86it/s v_num: 0.000
[[36m2024-05-24 16:07:10,897[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 19.
[[36m2024-05-24 16:07:10,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:07:11,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:07:11,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007810047684009159, lr[0m
[[36m2024-05-24 16:07:11,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:07:11,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07460398630428074 prior_scale[0m
[[36m2024-05-24 16:07:11,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021009633065040994 q_scale[0m
[[36m2024-05-24 16:07:11,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30742537370637046 obs_scale[0m
[[36m2024-05-24 16:07:11,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:07:11,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-05-24 16:07:11,137[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:07:11,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:07:42,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:07:42,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:07:42,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:07:42,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:07:42,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:07:42,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:07:42,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:07:42,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:07:42,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:07:42,334[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:07:42,345[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:09 • 0:00:00 5.05it/s v_num: 0.000
[[36m2024-05-24 16:07:58,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:07:58,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/038[0m
[[36m2024-05-24 16:07:58,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 16:07:58,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008037234347984701, lr[0m
[[36m2024-05-24 16:07:58,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:07:58,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12015069252918972 prior_scale[0m
[[36m2024-05-24 16:07:58,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005018583527468872 q_scale[0m
[[36m2024-05-24 16:07:58,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20329334720403028 obs_scale[0m
[[36m2024-05-24 16:07:58,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 16:07:58,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-05-24 16:07:58,415[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:07:58,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:08:31,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:08:31,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:08:31,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:08:31,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:08:31,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:08:31,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:08:31,785[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:08:31,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:08:31,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:08:31,820[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:08:31,831[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 16:08:31,833[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.21it/s v_num: 0.000
[[36m2024-05-24 16:10:08,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:10:08,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/046[0m
[[36m2024-05-24 16:10:08,612[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 16:10:08,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006000414195743819, lr[0m
[[36m2024-05-24 16:10:08,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:10:08,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.035258651824255624 prior_scale[0m
[[36m2024-05-24 16:10:08,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011985097304494243 q_scale[0m
[[36m2024-05-24 16:10:08,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6081792816161671 obs_scale[0m
[[36m2024-05-24 16:10:08,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 16:10:08,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-05-24 16:10:08,715[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:10:08,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:10:40,634[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:10:40,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:10:40,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:10:40,645[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:10:40,646[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:10:40,646[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:10:40,647[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:10:40,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:10:40,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:10:40,687[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:10:40,697[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 16:10:40,698[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 14.02it/s v_num: 0.000
[[36m2024-05-24 16:11:15,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:11:15,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/039[0m
[[36m2024-05-24 16:11:15,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:11:15,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.15690020581792e-05, lr[0m
[[36m2024-05-24 16:11:15,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 16:11:15,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17083483372328492 prior_scale[0m
[[36m2024-05-24 16:11:15,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034775158827545486 q_scale[0m
[[36m2024-05-24 16:11:15,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.33681574877144815 obs_scale[0m
[[36m2024-05-24 16:11:15,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:11:15,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-05-24 16:11:15,413[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:11:15,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:11:47,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:11:47,344[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:11:47,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:11:47,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:11:47,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:11:47,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:11:47,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:11:47,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:11:47,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:11:47,385[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:11:47,438[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:03 • 0:00:00 28.14it/s v_num: 0.000
[[36m2024-05-24 16:12:18,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:12:18,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/047[0m
[[36m2024-05-24 16:12:19,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:12:19,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0125058472109033e-05, lr[0m
[[36m2024-05-24 16:12:19,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:12:19,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20075418565349623 prior_scale[0m
[[36m2024-05-24 16:12:19,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014861953629173865 q_scale[0m
[[36m2024-05-24 16:12:19,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13470210895997695 obs_scale[0m
[[36m2024-05-24 16:12:19,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 16:12:19,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-05-24 16:12:19,143[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:12:19,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:12:54,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:12:54,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:12:54,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:12:54,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:12:54,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:12:54,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:12:54,821[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:12:54,821[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:12:54,822[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:12:54,850[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:12:54,860[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 15.26it/s v_num: 0.000
[[36m2024-05-24 16:13:46,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:13:46,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/048[0m
[[36m2024-05-24 16:13:46,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:13:46,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000397903957099914, lr[0m
[[36m2024-05-24 16:13:46,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 16:13:46,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08101161562963576 prior_scale[0m
[[36m2024-05-24 16:13:46,896[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032262214400778926 q_scale[0m
[[36m2024-05-24 16:13:46,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8285181121952915 obs_scale[0m
[[36m2024-05-24 16:13:46,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:13:46,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-05-24 16:13:46,942[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:13:46,942[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.74it/s v_num: 0.000
[[36m2024-05-24 16:14:16,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:14:16,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/041[0m
[[36m2024-05-24 16:14:16,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:14:16,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000833823738406125, lr[0m
[[36m2024-05-24 16:14:16,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:14:16,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05936172622629903 prior_scale[0m
[[36m2024-05-24 16:14:16,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015915366241471443 q_scale[0m
[[36m2024-05-24 16:14:16,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3313858318021942 obs_scale[0m
[[36m2024-05-24 16:14:16,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:14:16,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-05-24 16:14:16,546[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:14:16,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:14:18,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:14:18,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:14:18,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:14:18,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:14:18,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:14:18,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:14:18,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:14:18,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:14:18,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:14:18,491[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:14:18,778[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:14:48,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:14:48,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:14:48,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:14:48,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:14:48,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:14:48,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:14:48,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:14:48,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:14:48,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:14:48,302[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:14:48,602[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.20it/s v_num: 0.000
[[36m2024-05-24 16:21:14,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:21:14,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/042[0m
[[36m2024-05-24 16:21:14,868[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:21:14,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008056697292903502, lr[0m
[[36m2024-05-24 16:21:14,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:21:14,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05667581375668678 prior_scale[0m
[[36m2024-05-24 16:21:14,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010713881154318892 q_scale[0m
[[36m2024-05-24 16:21:14,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4036477633290455 obs_scale[0m
[[36m2024-05-24 16:21:14,979[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:21:14,979[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-05-24 16:21:14,980[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:21:14,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:21:48,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:21:48,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:21:48,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:21:48,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:21:48,543[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:21:48,544[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:21:48,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:21:48,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:21:48,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:21:48,587[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:21:48,599[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:20 • 0:00:00 19.10it/s v_num: 0.000
[[36m2024-05-24 16:22:37,360[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:22:37,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/049[0m
[[36m2024-05-24 16:22:37,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:22:37,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005139276323224396, lr[0m
[[36m2024-05-24 16:22:37,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:22:37,530[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11137203206290164 prior_scale[0m
[[36m2024-05-24 16:22:37,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00362677016245377 q_scale[0m
[[36m2024-05-24 16:22:37,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0145434612062143 obs_scale[0m
[[36m2024-05-24 16:22:37,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:22:37,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-05-24 16:22:37,578[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:22:37,578[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:23:08,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:23:08,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:23:08,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:23:08,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:23:08,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:23:08,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:23:08,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:23:08,763[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:23:08,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:23:08,794[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:23:09,230[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:32 • 0:00:00 11.90it/s v_num: 0.000
[[36m2024-05-24 16:24:17,993[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:24:17,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/040[0m
[[36m2024-05-24 16:24:18,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:24:18,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000631737331581124, lr[0m
[[36m2024-05-24 16:24:18,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:24:18,202[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09461612618755091 prior_scale[0m
[[36m2024-05-24 16:24:18,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002973573624642535 q_scale[0m
[[36m2024-05-24 16:24:18,244[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5200950570914034 obs_scale[0m
[[36m2024-05-24 16:24:18,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:24:18,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-05-24 16:24:18,262[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:24:18,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:24:51,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:24:51,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:24:51,200[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:24:51,204[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:24:51,205[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:24:51,206[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:24:51,207[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:24:51,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:24:51,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:24:51,251[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:24:51,260[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 34.62it/s v_num: 0.000
[[36m2024-05-24 16:28:12,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:28:12,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/050[0m
[[36m2024-05-24 16:28:13,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:28:13,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007834564129333778, lr[0m
[[36m2024-05-24 16:28:13,133[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:28:13,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04784075629852243 prior_scale[0m
[[36m2024-05-24 16:28:13,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00142397504288141 q_scale[0m
[[36m2024-05-24 16:28:13,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.49683402466956833 obs_scale[0m
[[36m2024-05-24 16:28:13,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:28:13,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-05-24 16:28:13,214[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:28:13,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:28:44,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:28:44,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:28:44,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:28:44,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:28:44,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:28:44,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:28:44,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:28:44,531[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:28:44,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:28:44,572[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:28:44,581[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.14it/s v_num: 0.000
[[36m2024-05-24 16:29:02,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:29:02,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/043[0m
[[36m2024-05-24 16:29:02,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:29:02,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005441983505767138, lr[0m
[[36m2024-05-24 16:29:02,499[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:29:02,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.088647133176808 prior_scale[0m
[[36m2024-05-24 16:29:02,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001452635275060882 q_scale[0m
[[36m2024-05-24 16:29:02,561[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35064533938700687 obs_scale[0m
[[36m2024-05-24 16:29:02,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:29:02,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-05-24 16:29:02,580[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:29:02,580[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:29:34,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:29:34,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:29:34,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:29:34,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:29:34,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:29:34,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:29:34,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:29:34,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:29:34,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:29:34,972[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:29:35,006[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 25.63it/s v_num: 0.000
[[36m2024-05-24 16:31:58,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:31:58,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/041[0m
[[36m2024-05-24 16:31:58,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:31:58,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005752880938533469, lr[0m
[[36m2024-05-24 16:31:58,906[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:31:58,925[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09932446036472461 prior_scale[0m
[[36m2024-05-24 16:31:58,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019597689702210828 q_scale[0m
[[36m2024-05-24 16:31:58,965[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4404073995649561 obs_scale[0m
[[36m2024-05-24 16:31:58,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:31:58,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-05-24 16:31:58,981[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:31:58,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:32:29,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:32:29,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:32:29,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:32:29,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:32:29,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:32:29,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:32:29,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:32:29,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:32:29,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:32:29,752[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:32:29,762[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:13 • 0:00:00 27.51it/s v_num: 0.000
[[36m2024-05-24 16:34:35,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:34:35,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/051[0m
[[36m2024-05-24 16:34:35,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:34:36,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006552714893977413, lr[0m
[[36m2024-05-24 16:34:36,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:34:36,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04210916466264082 prior_scale[0m
[[36m2024-05-24 16:34:36,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000661531658818666 q_scale[0m
[[36m2024-05-24 16:34:36,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.37891561501423027 obs_scale[0m
[[36m2024-05-24 16:34:36,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:34:36,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-05-24 16:34:36,160[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:34:36,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:35:11,183[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:35:11,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:35:11,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:35:11,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:35:11,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:35:11,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:35:11,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:35:11,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:35:11,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:35:11,241[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:35:11,250[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.79it/s v_num: 0.000
[[36m2024-05-24 16:36:08,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:36:08,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/044[0m
[[36m2024-05-24 16:36:08,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:36:08,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009667551493626546, lr[0m
[[36m2024-05-24 16:36:08,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:36:08,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23576264943607209 prior_scale[0m
[[36m2024-05-24 16:36:08,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015870411810596594 q_scale[0m
[[36m2024-05-24 16:36:08,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2284740192713978 obs_scale[0m
[[36m2024-05-24 16:36:08,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 16:36:08,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-05-24 16:36:08,936[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:36:08,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:36:46,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:36:46,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:36:46,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:36:46,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:36:46,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:36:46,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:36:46,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:36:46,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:36:46,819[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:36:46,856[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:36:46,863[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 11.77it/s v_num: 0.000
[[36m2024-05-24 16:38:34,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:38:34,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/045[0m
[[36m2024-05-24 16:38:34,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:38:34,209[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006652190222180234, lr[0m
[[36m2024-05-24 16:38:34,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:38:34,243[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0441845152640731 prior_scale[0m
[[36m2024-05-24 16:38:34,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034283844133024317 q_scale[0m
[[36m2024-05-24 16:38:34,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4660954531867439 obs_scale[0m
[[36m2024-05-24 16:38:34,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:38:34,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-05-24 16:38:34,298[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:38:34,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.20it/s v_num: 0.000
[[36m2024-05-24 16:38:49,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:38:49,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/042[0m
[[36m2024-05-24 16:38:49,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:38:49,484[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000489350653732724, lr[0m
[[36m2024-05-24 16:38:49,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:38:49,515[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10190403880637247 prior_scale[0m
[[36m2024-05-24 16:38:49,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016050009896061184 q_scale[0m
[[36m2024-05-24 16:38:49,549[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4322039322666469 obs_scale[0m
[[36m2024-05-24 16:38:49,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:38:49,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-05-24 16:38:49,564[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:38:49,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:39:08,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:39:08,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:39:08,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:39:08,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:39:08,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:39:08,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:39:08,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:39:08,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:39:08,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:39:08,786[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:39:08,796[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:39:20,798[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:39:20,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:39:20,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:39:20,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:39:20,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:39:20,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:39:20,812[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:39:20,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:39:20,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:39:20,845[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:39:20,854[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:10 • 0:00:00 34.96it/s v_num: 0.000
[[36m2024-05-24 16:40:12,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:40:12,548[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/052[0m
[[36m2024-05-24 16:40:12,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:40:12,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006568117881031401, lr[0m
[[36m2024-05-24 16:40:12,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:40:12,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04213674639680718 prior_scale[0m
[[36m2024-05-24 16:40:12,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026096594583978404 q_scale[0m
[[36m2024-05-24 16:40:12,749[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3816046867756409 obs_scale[0m
[[36m2024-05-24 16:40:12,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:40:12,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-05-24 16:40:12,765[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:40:12,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:40:43,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:40:43,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:40:43,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:40:43,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:40:43,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:40:43,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:40:43,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:40:43,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:40:43,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:40:43,789[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:40:43,796[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.85it/s v_num: 0.000
[[36m2024-05-24 16:46:00,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:46:00,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/046[0m
[[36m2024-05-24 16:46:00,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 16:46:00,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004183055130992373, lr[0m
[[36m2024-05-24 16:46:00,445[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:46:00,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.026225593261762777 prior_scale[0m
[[36m2024-05-24 16:46:00,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005739361875658825 q_scale[0m
[[36m2024-05-24 16:46:00,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9213452991226261 obs_scale[0m
[[36m2024-05-24 16:46:00,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 16:46:00,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-05-24 16:46:00,534[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:46:00,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:46:34,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:46:34,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:46:34,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:46:34,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:46:34,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:46:34,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:46:34,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:46:34,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:46:34,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:46:35,019[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:46:35,033[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 16:46:35,036[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 30.90it/s v_num: 0.000
[[36m2024-05-24 16:46:39,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:46:39,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/053[0m
[[36m2024-05-24 16:46:39,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:46:39,737[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008405087462915266, lr[0m
[[36m2024-05-24 16:46:39,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:46:39,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.025823816505289577 prior_scale[0m
[[36m2024-05-24 16:46:39,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002568817698408131 q_scale[0m
[[36m2024-05-24 16:46:39,822[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3628072411901558 obs_scale[0m
[[36m2024-05-24 16:46:39,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:46:39,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-05-24 16:46:39,844[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:46:39,844[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:47:11,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:47:11,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:47:11,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:47:11,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:47:11,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:47:11,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:47:11,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:47:11,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:47:11,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:47:11,316[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:47:11,325[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.06it/s v_num: 0.000
[[36m2024-05-24 16:47:46,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:47:46,981[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/043[0m
[[36m2024-05-24 16:47:47,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:47:47,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1818092032455127e-05, lr[0m
[[36m2024-05-24 16:47:47,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:47:47,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05946211542099247 prior_scale[0m
[[36m2024-05-24 16:47:47,221[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010407011758375458 q_scale[0m
[[36m2024-05-24 16:47:47,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3666043592179568 obs_scale[0m
[[36m2024-05-24 16:47:47,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:47:47,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-05-24 16:47:47,260[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:47:47,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:48:19,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:48:19,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:48:19,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:48:19,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:48:19,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:48:19,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:48:19,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:48:19,895[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:48:19,896[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:48:19,932[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:48:19,942[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:05 • 0:00:00 17.52it/s v_num: 0.000
[[36m2024-05-24 16:49:07,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:49:07,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/047[0m
[[36m2024-05-24 16:49:07,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:49:07,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028230392745546906, lr[0m
[[36m2024-05-24 16:49:07,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:49:07,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.041490269688819935 prior_scale[0m
[[36m2024-05-24 16:49:07,652[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012648184594538834 q_scale[0m
[[36m2024-05-24 16:49:07,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.46141397715447313 obs_scale[0m
[[36m2024-05-24 16:49:07,688[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 16:49:07,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-05-24 16:49:07,689[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:49:07,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:49:44,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:49:44,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:49:44,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:49:44,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:49:44,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:49:44,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:49:44,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:49:44,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:49:44,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:49:44,496[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:49:44,509[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 7.76it/s v_num: 0.000
[[36m2024-05-24 16:51:06,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:51:06,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/048[0m
[[36m2024-05-24 16:51:07,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:51:07,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006466897260547845, lr[0m
[[36m2024-05-24 16:51:07,172[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 16:51:07,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.018941288452430514 prior_scale[0m
[[36m2024-05-24 16:51:07,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008421853275663296 q_scale[0m
[[36m2024-05-24 16:51:07,230[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.542058047211006 obs_scale[0m
[[36m2024-05-24 16:51:07,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:51:07,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-05-24 16:51:07,247[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:51:07,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:51:39,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:51:39,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:51:39,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:51:39,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:51:40,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:51:40,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:51:40,002[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:51:40,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:51:40,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:51:40,043[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:51:40,054[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:11 • 0:00:00 32.03it/s v_num: 0.000
[[36m2024-05-24 16:52:41,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:52:41,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/054[0m
[[36m2024-05-24 16:52:41,796[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:52:41,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000452781567021585, lr[0m
[[36m2024-05-24 16:52:41,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:52:41,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016406974173362135 prior_scale[0m
[[36m2024-05-24 16:52:41,876[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010198033354634238 q_scale[0m
[[36m2024-05-24 16:52:41,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.40651798136028805 obs_scale[0m
[[36m2024-05-24 16:52:41,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 16:52:41,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-05-24 16:52:41,922[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:52:41,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:53:14,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:53:14,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:53:14,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:53:14,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:53:14,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:53:14,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:53:14,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:53:14,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:53:14,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:53:14,321[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:53:14,334[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.60it/s v_num: 0.000
[[36m2024-05-24 16:55:25,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:55:25,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/044[0m
[[36m2024-05-24 16:55:25,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:55:25,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007852634527765138, lr[0m
[[36m2024-05-24 16:55:25,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:55:25,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07574169818571778 prior_scale[0m
[[36m2024-05-24 16:55:25,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020601772876121881 q_scale[0m
[[36m2024-05-24 16:55:25,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29802886348401114 obs_scale[0m
[[36m2024-05-24 16:55:25,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 16:55:25,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-05-24 16:55:25,419[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:55:25,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:55:59,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:55:59,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:55:59,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:55:59,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:55:59,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:55:59,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:55:59,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:55:59,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:55:59,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:55:59,906[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:55:59,915[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:06 • 0:00:00 31.22it/s v_num: 0.000
[[36m2024-05-24 16:56:17,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:56:17,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/055[0m
[[36m2024-05-24 16:56:17,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:56:17,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005683201359350743, lr[0m
[[36m2024-05-24 16:56:17,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:56:17,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03981217361728262 prior_scale[0m
[[36m2024-05-24 16:56:17,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004498881918430304 q_scale[0m
[[36m2024-05-24 16:56:17,588[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3000366761205295 obs_scale[0m
[[36m2024-05-24 16:56:17,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:56:17,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-05-24 16:56:17,609[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:56:17,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:56:49,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:56:49,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:56:49,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:56:49,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:56:49,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:56:49,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:56:49,203[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:56:49,204[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:56:49,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:56:49,239[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:56:49,252[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:04 • 0:00:00 10.17it/s v_num: 0.000
[[36m2024-05-24 16:57:51,255[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2024-05-24 16:57:51,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 16:57:51,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 16:57:51,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020097100557417953, lr[0m
[[36m2024-05-24 16:57:51,404[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 16:57:51,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09255960399818662 prior_scale[0m
[[36m2024-05-24 16:57:51,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031168565781048276 q_scale[0m
[[36m2024-05-24 16:57:51,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.43880498015587344 obs_scale[0m
[[36m2024-05-24 16:57:51,477[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 16:57:51,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-05-24 16:57:51,478[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 16:57:51,478[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 16:58:24,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 16:58:24,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 16:58:24,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 16:58:24,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 16:58:24,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 16:58:24,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 16:58:24,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 16:58:24,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 16:58:24,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 16:58:24,126[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 16:58:24,154[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.52it/s v_num: 0.000
[[36m2024-05-24 17:02:21,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:02:21,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/056[0m
[[36m2024-05-24 17:02:21,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:02:21,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002623861528802141, lr[0m
[[36m2024-05-24 17:02:21,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:02:21,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04328590310669612 prior_scale[0m
[[36m2024-05-24 17:02:21,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002083790625223039 q_scale[0m
[[36m2024-05-24 17:02:21,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23533756673077186 obs_scale[0m
[[36m2024-05-24 17:02:21,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:02:21,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-05-24 17:02:21,732[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:02:21,732[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:02:53,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:02:53,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:02:53,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:02:53,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:02:53,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:02:53,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:02:53,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:02:53,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:02:53,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:02:53,735[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:02:53,743[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:28 • 0:00:00 13.57it/s v_num: 0.000
[[36m2024-05-24 17:02:58,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:02:58,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/049[0m
[[36m2024-05-24 17:02:58,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:02:58,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005161688047078451, lr[0m
[[36m2024-05-24 17:02:58,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:02:58,273[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.032957210406033936 prior_scale[0m
[[36m2024-05-24 17:02:58,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033882896223158586 q_scale[0m
[[36m2024-05-24 17:02:58,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3779137835283647 obs_scale[0m
[[36m2024-05-24 17:02:58,350[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:02:58,350[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-05-24 17:02:58,351[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:02:58,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:03:29,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:03:29,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:03:29,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:03:29,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:03:29,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:03:29,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:03:29,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:03:29,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:03:29,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:03:29,708[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:03:29,717[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.68it/s v_num: 0.000
[[36m2024-05-24 17:05:28,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:05:28,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/046[0m
[[36m2024-05-24 17:05:28,452[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 17:05:28,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004082199577692091, lr[0m
[[36m2024-05-24 17:05:28,493[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:05:28,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.037169078384831494 prior_scale[0m
[[36m2024-05-24 17:05:28,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013749487855856677 q_scale[0m
[[36m2024-05-24 17:05:28,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6975201192592541 obs_scale[0m
[[36m2024-05-24 17:05:28,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-05-24 17:05:28,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-05-24 17:05:28,576[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:05:28,576[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:06:02,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:06:02,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:06:02,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:06:02,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:06:02,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:06:02,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:06:02,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:06:02,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:06:02,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:06:02,616[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:06:02,626[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 17:06:02,629[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 96/96 0:00:06 • 0:00:00 14.77it/s v_num: 0.000
[[36m2024-05-24 17:08:46,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:08:46,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/047[0m
[[36m2024-05-24 17:08:47,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:08:47,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000557106195883259, lr[0m
[[36m2024-05-24 17:08:47,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:08:47,199[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11369743725583477 prior_scale[0m
[[36m2024-05-24 17:08:47,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021692437473279705 q_scale[0m
[[36m2024-05-24 17:08:47,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5148631572775434 obs_scale[0m
[[36m2024-05-24 17:08:47,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-05-24 17:08:47,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-05-24 17:08:47,260[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:08:47,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.57it/s v_num: 0.000
[[36m2024-05-24 17:08:48,170[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 19.
[[36m2024-05-24 17:08:48,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:08:48,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:08:48,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035329799697589103, lr[0m
[[36m2024-05-24 17:08:48,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:08:48,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.032428970570311355 prior_scale[0m
[[36m2024-05-24 17:08:48,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018374432732042888 q_scale[0m
[[36m2024-05-24 17:08:48,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35855682474003225 obs_scale[0m
[[36m2024-05-24 17:08:48,401[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:08:48,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-05-24 17:08:48,402[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:08:48,402[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:09:20,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:09:20,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:09:20,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:09:20,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:09:20,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:09:20,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:09:20,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:09:20,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:09:20,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:09:20,543[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:09:20,552[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:09:23,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:09:23,906[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:09:23,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:09:23,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:09:23,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:09:23,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:09:23,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:09:23,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:09:23,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:09:23,950[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:09:23,961[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.43it/s v_num: 0.000
[[36m2024-05-24 17:09:54,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:09:54,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/050[0m
[[36m2024-05-24 17:09:54,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:09:54,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007857919248700869, lr[0m
[[36m2024-05-24 17:09:54,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:09:54,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.048492663024245444 prior_scale[0m
[[36m2024-05-24 17:09:54,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002844585354152384 q_scale[0m
[[36m2024-05-24 17:09:54,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3178077310582613 obs_scale[0m
[[36m2024-05-24 17:09:54,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:09:54,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-05-24 17:09:54,365[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:09:54,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:10:26,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:10:26,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:10:26,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:10:26,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:10:26,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:10:26,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:10:26,478[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:10:26,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:10:26,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:10:26,511[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:10:26,521[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:03 • 0:00:00 6.81it/s v_num: 0.000
[[36m2024-05-24 17:10:58,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:10:58,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/048[0m
[[36m2024-05-24 17:10:58,891[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:10:58,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000298766757232606, lr[0m
[[36m2024-05-24 17:10:58,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-05-24 17:10:58,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21305216672969637 prior_scale[0m
[[36m2024-05-24 17:10:58,987[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018609609268027566 q_scale[0m
[[36m2024-05-24 17:10:59,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8994594276110932 obs_scale[0m
[[36m2024-05-24 17:10:59,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:10:59,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-05-24 17:10:59,031[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:10:59,031[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:11:30,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:11:30,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:11:30,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:11:30,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:11:30,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:11:30,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:11:30,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:11:30,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:11:30,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:11:30,278[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:11:30,288[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:12 • 0:00:00 31.47it/s v_num: 0.000
[[36m2024-05-24 17:14:38,763[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2024-05-24 17:14:38,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:14:38,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-05-24 17:14:38,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000883647434773169, lr[0m
[[36m2024-05-24 17:14:38,913[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:14:38,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06987808840349534 prior_scale[0m
[[36m2024-05-24 17:14:38,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001281002446001285 q_scale[0m
[[36m2024-05-24 17:14:38,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2614789338988419 obs_scale[0m
[[36m2024-05-24 17:14:38,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-05-24 17:14:38,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-05-24 17:14:38,988[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:14:38,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:15:13,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:15:13,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:15:13,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:15:13,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:15:13,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:15:13,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:15:13,393[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:15:13,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:15:13,394[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:15:13,438[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:15:13,447[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-05-24 17:15:13,449[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/PdO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 48/48 0:00:02 • 0:00:00 21.17it/s v_num: 0.000
[[36m2024-05-24 17:16:22,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:16:22,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-05-24_12-18-48/059[0m
[[36m2024-05-24 17:16:22,451[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.29it/s v_num: 0.000
[[36m2024-05-24 17:17:04,541[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:17:04,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/051[0m
[[36m2024-05-24 17:17:04,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:17:04,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006552714893977413, lr[0m
[[36m2024-05-24 17:17:04,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:17:04,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06033693894257304 prior_scale[0m
[[36m2024-05-24 17:17:04,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00039113102011199174 q_scale[0m
[[36m2024-05-24 17:17:04,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27290010451939806 obs_scale[0m
[[36m2024-05-24 17:17:04,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:17:04,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-05-24 17:17:04,797[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:17:04,797[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:17:35,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:17:35,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:17:35,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:17:35,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:17:35,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:17:35,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:17:35,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:17:35,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:17:35,843[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:17:35,884[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:17:35,894[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:35 • 0:00:00 10.68it/s v_num: 0.000
[[36m2024-05-24 17:22:56,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:22:56,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/049[0m
[[36m2024-05-24 17:22:56,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:22:56,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009024673560340769, lr[0m
[[36m2024-05-24 17:22:56,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:22:56,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05444743108973499 prior_scale[0m
[[36m2024-05-24 17:22:56,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016463811168018153 q_scale[0m
[[36m2024-05-24 17:22:56,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2641259170431869 obs_scale[0m
[[36m2024-05-24 17:22:56,553[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:22:56,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-05-24 17:22:56,554[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:22:56,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:23:28,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:23:28,328[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:23:28,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:23:28,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:23:28,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:23:28,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:23:28,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:23:28,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:23:28,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:23:28,375[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:23:28,461[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.47it/s v_num: 0.000
[[36m2024-05-24 17:23:55,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:23:55,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/052[0m
[[36m2024-05-24 17:23:56,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:23:56,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008747450703666922, lr[0m
[[36m2024-05-24 17:23:56,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:23:56,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08412953931834553 prior_scale[0m
[[36m2024-05-24 17:23:56,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001210500536314693 q_scale[0m
[[36m2024-05-24 17:23:56,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.43960614037619417 obs_scale[0m
[[36m2024-05-24 17:23:56,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:23:56,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-05-24 17:23:56,223[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:23:56,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:24:27,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:24:27,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:24:27,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:24:27,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:24:27,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:24:27,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:24:27,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:24:27,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:24:27,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:24:27,871[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:24:27,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 9/19 ━━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 24.68it/s v_num: 0.000
[[36m2024-05-24 17:26:47,821[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 9.
[[36m2024-05-24 17:26:47,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:26:47,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:26:47,975[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006252761321550576, lr[0m
[[36m2024-05-24 17:26:47,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:26:48,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12162034560081164 prior_scale[0m
[[36m2024-05-24 17:26:48,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002777731684627197 q_scale[0m
[[36m2024-05-24 17:26:48,052[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5728174616622953 obs_scale[0m
[[36m2024-05-24 17:26:48,066[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:26:48,066[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-05-24 17:26:48,066[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:26:48,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:27:20,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:27:20,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:27:20,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:27:20,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:27:20,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:27:20,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:27:20,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:27:20,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:27:20,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:27:20,105[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:27:20,114[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.08it/s v_num: 0.000
[[36m2024-05-24 17:31:01,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:31:01,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/053[0m
[[36m2024-05-24 17:31:01,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:31:01,855[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000401316475575681, lr[0m
[[36m2024-05-24 17:31:01,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:31:01,891[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07264516921740627 prior_scale[0m
[[36m2024-05-24 17:31:01,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001889523563104369 q_scale[0m
[[36m2024-05-24 17:31:01,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2501139539458464 obs_scale[0m
[[36m2024-05-24 17:31:01,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:31:01,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-05-24 17:31:01,947[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:31:01,947[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:31:33,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:31:33,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:31:33,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:31:33,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:31:33,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:31:33,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:31:33,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:31:33,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:31:33,373[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:31:33,423[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:31:33,436[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.09it/s v_num: 0.000
[[36m2024-05-24 17:34:54,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:34:54,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/051[0m
[[36m2024-05-24 17:34:54,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:34:54,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00057672293689978, lr[0m
[[36m2024-05-24 17:34:54,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:34:54,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08108884397905183 prior_scale[0m
[[36m2024-05-24 17:34:55,006[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002745559474627713 q_scale[0m
[[36m2024-05-24 17:34:55,028[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48937845611713765 obs_scale[0m
[[36m2024-05-24 17:34:55,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:34:55,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-05-24 17:34:55,048[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:34:55,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:35:28,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:35:28,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:35:28,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:35:28,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:35:28,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:35:28,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:35:28,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:35:28,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:35:28,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:35:28,166[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:35:28,898[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 15/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:15 • 0:00:00 25.40it/s v_num: 0.000
[[36m2024-05-24 17:36:50,961[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[[36m2024-05-24 17:36:50,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:36:51,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:36:51,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006982660246876976, lr[0m
[[36m2024-05-24 17:36:51,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:36:51,140[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04668689387609643 prior_scale[0m
[[36m2024-05-24 17:36:51,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002554746572720036 q_scale[0m
[[36m2024-05-24 17:36:51,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7148476211986122 obs_scale[0m
[[36m2024-05-24 17:36:51,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 17:36:51,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-05-24 17:36:51,199[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:36:51,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:37:23,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:37:23,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:37:23,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:37:23,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:37:23,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:37:23,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:37:23,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:37:23,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:37:23,091[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:37:23,135[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:37:23,162[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:08 • 0:00:00 21.50it/s v_num: 0.000
[[36m2024-05-24 17:41:02,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:41:02,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/055[0m
[[36m2024-05-24 17:41:02,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:41:02,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004912931225240278, lr[0m
[[36m2024-05-24 17:41:02,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:41:02,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10971846560302191 prior_scale[0m
[[36m2024-05-24 17:41:02,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004915961649172973 q_scale[0m
[[36m2024-05-24 17:41:02,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.37017293958798064 obs_scale[0m
[[36m2024-05-24 17:41:02,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:41:02,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-05-24 17:41:02,816[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:41:02,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:41:33,908[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:41:33,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:41:33,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:41:33,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:41:33,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:41:33,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:41:33,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:41:33,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:41:33,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:41:33,963[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:41:33,973[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:18 • 0:00:00 20.43it/s v_num: 0.000
[[36m2024-05-24 17:43:30,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:43:30,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/052[0m
[[36m2024-05-24 17:43:30,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:43:30,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005303365562365908, lr[0m
[[36m2024-05-24 17:43:30,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:43:30,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06839117634296193 prior_scale[0m
[[36m2024-05-24 17:43:30,874[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012310502142375544 q_scale[0m
[[36m2024-05-24 17:43:30,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48922743306635214 obs_scale[0m
[[36m2024-05-24 17:43:30,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:43:30,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-05-24 17:43:30,922[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:43:30,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:44:04,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:44:04,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:44:04,458[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:44:04,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:44:04,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:44:04,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:44:04,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:44:04,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:44:04,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:44:04,523[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:44:05,022[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 27.06it/s v_num: 0.000
[[36m2024-05-24 17:47:58,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:47:58,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/056[0m
[[36m2024-05-24 17:47:58,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:47:58,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008019708555864843, lr[0m
[[36m2024-05-24 17:47:58,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:47:58,873[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.056558907754717086 prior_scale[0m
[[36m2024-05-24 17:47:58,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007633159270988318 q_scale[0m
[[36m2024-05-24 17:47:58,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5765651785452724 obs_scale[0m
[[36m2024-05-24 17:47:58,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:47:58,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-05-24 17:47:58,943[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:47:58,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:48:30,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:48:30,345[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:48:30,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:48:30,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:48:30,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:48:30,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:48:30,350[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:48:30,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:48:30,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:48:30,391[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:48:30,704[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.67it/s v_num: 0.000
[[36m2024-05-24 17:50:57,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:50:57,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/053[0m
[[36m2024-05-24 17:50:57,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:50:57,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043622157550123736, lr[0m
[[36m2024-05-24 17:50:57,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:50:57,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06531714902932258 prior_scale[0m
[[36m2024-05-24 17:50:57,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012938791140128063 q_scale[0m
[[36m2024-05-24 17:50:57,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39414683318886345 obs_scale[0m
[[36m2024-05-24 17:50:57,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:50:57,493[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-05-24 17:50:57,493[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:50:57,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:51:28,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:51:28,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:51:28,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:51:28,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:51:28,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:51:28,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:51:28,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:51:28,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:51:28,683[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:51:28,725[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:51:28,945[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:14 • 0:00:00 26.97it/s v_num: 0.000
[[36m2024-05-24 17:54:40,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:54:40,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/057[0m
[[36m2024-05-24 17:54:40,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:54:40,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005968427457125606, lr[0m
[[36m2024-05-24 17:54:40,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:54:40,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13239244191569838 prior_scale[0m
[[36m2024-05-24 17:54:40,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016820698298006503 q_scale[0m
[[36m2024-05-24 17:54:40,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.480918898536572 obs_scale[0m
[[36m2024-05-24 17:54:40,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 17:54:40,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-05-24 17:54:40,408[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:54:40,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:55:13,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:55:13,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:55:13,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:55:13,895[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:55:13,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:55:13,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:55:13,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:55:13,898[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:55:13,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:55:13,948[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:55:15,015[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 22.44it/s v_num: 0.000
[[36m2024-05-24 17:58:18,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 17:58:18,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/054[0m
[[36m2024-05-24 17:58:18,493[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 17:58:18,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008222252981489558, lr[0m
[[36m2024-05-24 17:58:18,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 17:58:18,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.051059376070655346 prior_scale[0m
[[36m2024-05-24 17:58:18,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010275622081209195 q_scale[0m
[[36m2024-05-24 17:58:18,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4501195843022101 obs_scale[0m
[[36m2024-05-24 17:58:18,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-05-24 17:58:18,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-05-24 17:58:18,647[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 17:58:18,647[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 17:58:52,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 17:58:52,078[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 17:58:52,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 17:58:52,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 17:58:52,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 17:58:52,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 17:58:52,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 17:58:52,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 17:58:52,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 17:58:52,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 17:58:52,148[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.67it/s v_num: 0.000
[[36m2024-05-24 18:02:09,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:02:09,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/058[0m
[[36m2024-05-24 18:02:09,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 18:02:09,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005853047195913743, lr[0m
[[36m2024-05-24 18:02:09,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 18:02:09,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13766111616714935 prior_scale[0m
[[36m2024-05-24 18:02:09,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001400921296006223 q_scale[0m
[[36m2024-05-24 18:02:09,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8279902915596273 obs_scale[0m
[[36m2024-05-24 18:02:09,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 18:02:09,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-05-24 18:02:09,644[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 18:02:09,645[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 18:02:43,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 18:02:43,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 18:02:43,951[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 18:02:43,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 18:02:43,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 18:02:43,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 18:02:43,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 18:02:43,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 18:02:43,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 18:02:44,002[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 18:02:46,310[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 192/192 0:00:10 • 0:00:00 18.68it/s v_num: 0.000
[[36m2024-05-24 18:03:11,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:03:11,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/055[0m
[[36m2024-05-24 18:03:11,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 18:03:11,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004961703323834621, lr[0m
[[36m2024-05-24 18:03:11,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 18:03:11,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03424838737758728 prior_scale[0m
[[36m2024-05-24 18:03:11,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013891056124318974 q_scale[0m
[[36m2024-05-24 18:03:11,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7038010597057657 obs_scale[0m
[[36m2024-05-24 18:03:11,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 18:03:11,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-05-24 18:03:11,420[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 18:03:11,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 18:03:43,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 18:03:43,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 18:03:43,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 18:03:43,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 18:03:43,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 18:03:43,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 18:03:43,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 18:03:43,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 18:03:43,246[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 18:03:43,274[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 18:03:44,056[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.13it/s v_num: 0.000
[[36m2024-05-24 18:09:48,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:09:48,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-05-24_12-18-48/059[0m
[[36m2024-05-24 18:09:48,365[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:17 • 0:00:00 21.81it/s v_num: 0.000
[[36m2024-05-24 18:11:11,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:11:11,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/056[0m
[[36m2024-05-24 18:11:12,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 18:11:12,081[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035602599801649165, lr[0m
[[36m2024-05-24 18:11:12,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 18:11:12,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09249405978305829 prior_scale[0m
[[36m2024-05-24 18:11:12,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018947011247603328 q_scale[0m
[[36m2024-05-24 18:11:12,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3655791031639362 obs_scale[0m
[[36m2024-05-24 18:11:12,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 18:11:12,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-05-24 18:11:12,186[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 18:11:12,186[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 18:11:44,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 18:11:44,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 18:11:44,205[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 18:11:44,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 18:11:44,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 18:11:44,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 18:11:44,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 18:11:44,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 18:11:44,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 18:11:44,253[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 18:11:44,892[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.11it/s v_num: 0.000
[[36m2024-05-24 18:18:44,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:18:44,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/057[0m
[[36m2024-05-24 18:18:44,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 18:18:44,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000717064420533722, lr[0m
[[36m2024-05-24 18:18:44,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 18:18:44,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0708639377548408 prior_scale[0m
[[36m2024-05-24 18:18:44,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005559683800145626 q_scale[0m
[[36m2024-05-24 18:18:44,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5336891015067621 obs_scale[0m
[[36m2024-05-24 18:18:44,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 18:18:44,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-05-24 18:18:44,267[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 18:18:44,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 18:19:15,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 18:19:15,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 18:19:15,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 18:19:15,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 18:19:15,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 18:19:15,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 18:19:15,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 18:19:15,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 18:19:15,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 18:19:15,457[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 18:19:15,465[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 23.59it/s v_num: 0.000
[[36m2024-05-24 18:26:02,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:26:02,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/058[0m
[[36m2024-05-24 18:26:02,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-05-24 18:26:02,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002708650199615613, lr[0m
[[36m2024-05-24 18:26:02,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-05-24 18:26:02,529[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.026050829318738776 prior_scale[0m
[[36m2024-05-24 18:26:02,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005156072233059998 q_scale[0m
[[36m2024-05-24 18:26:02,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.848106358310356 obs_scale[0m
[[36m2024-05-24 18:26:02,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-05-24 18:26:02,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-05-24 18:26:02,595[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-05-24 18:26:02,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[12833, 10600, 4868, 5601, 6351]
0.8 0.1 0.1
[297, 7446, 3021, 11251, 9173]
[[36m2024-05-24 18:26:34,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-05-24 18:26:34,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-05-24 18:26:34,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-05-24 18:26:34,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-05-24 18:26:34,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-05-24 18:26:34,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-05-24 18:26:34,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-05-24 18:26:34,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-05-24 18:26:34,127[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-05-24 18:26:34,167[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-05-24 18:26:35,015[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.9 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.9 K │
│ 5  │ net.functions.0               │ Sequential │    966 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    795 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    160 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    966 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    795 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    160 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.9 K                                                         
Non-trainable params: 0                                                         
Total params: 1.9 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 383/383 0:00:16 • 0:00:00 22.90it/s v_num: 0.000
[[36m2024-05-24 18:33:39,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-05-24 18:33:39,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-05-24_12-18-48/059[0m
[[36m2024-05-24 18:33:39,554[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
