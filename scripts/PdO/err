In 'hpsearch': Could not find 'hpsearch/nn'

Available options in 'hpsearch':
	bnn_fo
	bnn_lrt
	bnn_rad
Config search path:
	provider=hydra, path=pkg://hydra.conf
	provider=main, path=file:///home/g15farris/bin/forks/bayesaenet/src/configs
	provider=hydra-colorlog, path=pkg://hydra_plugins.hydra_colorlog.conf
	provider=schema, path=structured://

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2024-05-24 12:18:49,053] A new study created in RDB with name: bnn_fo
[I 2024-05-24 12:18:49,083] A new study created in RDB with name: bnn_rad
[I 2024-05-24 12:18:49,092] A new study created in RDB with name: bnn_lrt
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:25:07,770] Trial 0 finished with value: 132.83567810058594 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 132.83567810058594.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:25:11,663] Trial 0 finished with value: 133.23934936523438 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 133.23934936523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:26:11,106] Trial 0 finished with value: 133.24490356445312 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 133.24490356445312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:27:02,179] Trial 1 finished with value: 3907.728759765625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 133.23934936523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:27:31,722] Trial 1 finished with value: 4385.154296875 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 132.83567810058594.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:28:32,185] Trial 1 finished with value: 5471.6396484375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 133.24490356445312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:29:39,032] Trial 2 finished with value: 71913.90625 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 133.23934936523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:31:04,628] Trial 2 finished with value: 70738.3359375 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 132.83567810058594.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:31:44,767] Trial 3 finished with value: 15336357.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 133.23934936523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:32:12,861] Trial 2 finished with value: 71688.4296875 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 133.24490356445312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:34:10,947] Trial 3 finished with value: 15338630.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 132.83567810058594.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:34:57,650] Trial 3 finished with value: 15300492.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 133.24490356445312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:35:28,769] Trial 4 finished with value: 97.42511749267578 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 4 with value: 97.42511749267578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:37:47,654] Trial 5 finished with value: 837.3013916015625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 4 with value: 97.42511749267578.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:38:15,751] Trial 4 finished with value: 94.2497787475586 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 4 with value: 94.2497787475586.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:39:04,008] Trial 4 finished with value: 90.15270233154297 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:41:19,181] Trial 5 finished with value: 576.7608642578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 4 with value: 94.2497787475586.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:41:50,616] Trial 5 finished with value: 339.3984375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 12:42:34,721] Trial 6 pruned. Trial was pruned at epoch 16.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:45:01,695] Trial 7 finished with value: 2759.774658203125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 4 with value: 97.42511749267578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 12:46:53,033] Trial 6 pruned. Trial was pruned at epoch 13.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 12:48:02,763] Trial 6 pruned. Trial was pruned at epoch 16.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:48:33,600] Trial 8 finished with value: 90647.5703125 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 4 with value: 97.42511749267578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:50:11,289] Trial 7 finished with value: 3072.71435546875 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:52:01,667] Trial 9 finished with value: 3939.67578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 4 with value: 97.42511749267578.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:52:08,906] Trial 7 finished with value: 2283.271728515625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 4 with value: 94.2497787475586.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:54:21,397] Trial 8 finished with value: 90625.578125 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:55:18,040] Trial 10 finished with value: 100.00790405273438 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002821061536892598, 'mc_samples_train': 1, 'prior_scale': 0.011399374124093269, 'q_scale': 0.00013031811167352414, 'obs_scale': 1.7109716370480204, 'batch_size': 64}. Best is trial 4 with value: 97.42511749267578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:56:51,064] Trial 8 finished with value: 90568.6640625 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 4 with value: 94.2497787475586.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:58:29,081] Trial 11 finished with value: 108.62237548828125 and parameters: {'pretrain_epochs': 0, 'lr': 0.00023494228630274735, 'mc_samples_train': 1, 'prior_scale': 0.011706067857616107, 'q_scale': 0.00011539328391897615, 'obs_scale': 1.9746524398983547, 'batch_size': 64}. Best is trial 4 with value: 97.42511749267578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 12:59:10,731] Trial 9 finished with value: 4431.47021484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:02:07,022] Trial 9 finished with value: 4229.71875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 4 with value: 94.2497787475586.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:02:15,441] Trial 12 finished with value: 67.20296478271484 and parameters: {'pretrain_epochs': 0, 'lr': 0.000356801404529351, 'mc_samples_train': 1, 'prior_scale': 0.016283693256007512, 'q_scale': 0.009783947466441949, 'obs_scale': 0.8975518465396407, 'batch_size': 64}. Best is trial 12 with value: 67.20296478271484.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:03:35,922] Trial 10 finished with value: 99.93174743652344 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002821061536892598, 'mc_samples_train': 1, 'prior_scale': 0.011399374124093269, 'q_scale': 0.00013031811167352414, 'obs_scale': 1.7109716370480204, 'batch_size': 64}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:06:02,260] Trial 13 finished with value: 61.29237747192383 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004187758560483171, 'mc_samples_train': 1, 'prior_scale': 0.029998790133936113, 'q_scale': 0.009940889714004643, 'obs_scale': 0.7555075323585012, 'batch_size': 64}. Best is trial 13 with value: 61.29237747192383.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:06:36,904] Trial 10 finished with value: 99.9677505493164 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002821061536892598, 'mc_samples_train': 1, 'prior_scale': 0.011399374124093269, 'q_scale': 0.00013031811167352414, 'obs_scale': 1.7109716370480204, 'batch_size': 64}. Best is trial 4 with value: 94.2497787475586.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:07:33,859] Trial 14 finished with value: 838.3569946289062 and parameters: {'pretrain_epochs': 0, 'lr': 0.00047099056233148326, 'mc_samples_train': 1, 'prior_scale': 0.027265739595470306, 'q_scale': 0.008086747435543934, 'obs_scale': 0.7168746872185714, 'batch_size': 512}. Best is trial 13 with value: 61.29237747192383.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:08:00,488] Trial 11 finished with value: 108.53236389160156 and parameters: {'pretrain_epochs': 0, 'lr': 0.00023494228630274735, 'mc_samples_train': 1, 'prior_scale': 0.011706067857616107, 'q_scale': 0.00011539328391897615, 'obs_scale': 1.9746524398983547, 'batch_size': 64}. Best is trial 4 with value: 90.15270233154297.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:11:08,588] Trial 11 finished with value: 108.56129455566406 and parameters: {'pretrain_epochs': 0, 'lr': 0.00023494228630274735, 'mc_samples_train': 1, 'prior_scale': 0.011706067857616107, 'q_scale': 0.00011539328391897615, 'obs_scale': 1.9746524398983547, 'batch_size': 64}. Best is trial 4 with value: 94.2497787475586.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:12:19,316] Trial 12 finished with value: 80.00209045410156 and parameters: {'pretrain_epochs': 0, 'lr': 0.000356801404529351, 'mc_samples_train': 1, 'prior_scale': 0.016283693256007512, 'q_scale': 0.009783947466441949, 'obs_scale': 0.8975518465396407, 'batch_size': 64}. Best is trial 12 with value: 80.00209045410156.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:13:51,955] Trial 15 finished with value: 20.623767852783203 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004719332263015136, 'mc_samples_train': 1, 'prior_scale': 0.02201666456969736, 'q_scale': 0.0025463997550914342, 'obs_scale': 0.6299642046168042, 'batch_size': 32}. Best is trial 15 with value: 20.623767852783203.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:15:39,800] Trial 12 finished with value: 79.70401763916016 and parameters: {'pretrain_epochs': 0, 'lr': 0.000356801404529351, 'mc_samples_train': 1, 'prior_scale': 0.016283693256007512, 'q_scale': 0.009783947466441949, 'obs_scale': 0.8975518465396407, 'batch_size': 64}. Best is trial 12 with value: 79.70401763916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:16:41,100] Trial 13 finished with value: 73.79103088378906 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004187758560483171, 'mc_samples_train': 1, 'prior_scale': 0.029998790133936113, 'q_scale': 0.009940889714004643, 'obs_scale': 0.7555075323585012, 'batch_size': 64}. Best is trial 13 with value: 73.79103088378906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:18:37,003] Trial 14 finished with value: 765.8721313476562 and parameters: {'pretrain_epochs': 0, 'lr': 0.00047099056233148326, 'mc_samples_train': 1, 'prior_scale': 0.027265739595470306, 'q_scale': 0.008086747435543934, 'obs_scale': 0.7168746872185714, 'batch_size': 512}. Best is trial 13 with value: 73.79103088378906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:20:13,552] Trial 13 finished with value: 73.91437530517578 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004187758560483171, 'mc_samples_train': 1, 'prior_scale': 0.029998790133936113, 'q_scale': 0.009940889714004643, 'obs_scale': 0.7555075323585012, 'batch_size': 64}. Best is trial 13 with value: 73.91437530517578.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:20:34,755] Trial 16 finished with value: 19.80013656616211 and parameters: {'pretrain_epochs': 0, 'lr': 0.000547121976155859, 'mc_samples_train': 1, 'prior_scale': 0.04133742496369647, 'q_scale': 0.0025555101989354345, 'obs_scale': 0.5485259914682613, 'batch_size': 32}. Best is trial 16 with value: 19.80013656616211.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:22:29,626] Trial 14 finished with value: 899.6783447265625 and parameters: {'pretrain_epochs': 0, 'lr': 0.00047099056233148326, 'mc_samples_train': 1, 'prior_scale': 0.027265739595470306, 'q_scale': 0.008086747435543934, 'obs_scale': 0.7168746872185714, 'batch_size': 512}. Best is trial 13 with value: 73.91437530517578.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:26:01,207] Trial 15 finished with value: 25.53016471862793 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004719332263015136, 'mc_samples_train': 1, 'prior_scale': 0.02201666456969736, 'q_scale': 0.0025463997550914342, 'obs_scale': 0.6299642046168042, 'batch_size': 32}. Best is trial 15 with value: 25.53016471862793.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:27:14,505] Trial 17 finished with value: 18.969884872436523 and parameters: {'pretrain_epochs': 0, 'lr': 0.000691180961207589, 'mc_samples_train': 1, 'prior_scale': 0.049317027736280133, 'q_scale': 0.0006396905880911569, 'obs_scale': 0.4932620022483778, 'batch_size': 32}. Best is trial 17 with value: 18.969884872436523.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:29:40,066] Trial 15 finished with value: 25.21646499633789 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004719332263015136, 'mc_samples_train': 1, 'prior_scale': 0.02201666456969736, 'q_scale': 0.0025463997550914342, 'obs_scale': 0.6299642046168042, 'batch_size': 32}. Best is trial 15 with value: 25.21646499633789.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:33:05,590] Trial 16 finished with value: 24.301305770874023 and parameters: {'pretrain_epochs': 0, 'lr': 0.000547121976155859, 'mc_samples_train': 1, 'prior_scale': 0.04133742496369647, 'q_scale': 0.0025555101989354345, 'obs_scale': 0.5485259914682613, 'batch_size': 32}. Best is trial 16 with value: 24.301305770874023.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:33:21,428] Trial 18 finished with value: 15.644452095031738 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007263091335083298, 'mc_samples_train': 1, 'prior_scale': 0.049890828546736765, 'q_scale': 0.0006414587910215425, 'obs_scale': 0.48413666873004657, 'batch_size': 32}. Best is trial 18 with value: 15.644452095031738.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:36:53,870] Trial 16 finished with value: 25.1272029876709 and parameters: {'pretrain_epochs': 0, 'lr': 0.000547121976155859, 'mc_samples_train': 1, 'prior_scale': 0.04133742496369647, 'q_scale': 0.0025555101989354345, 'obs_scale': 0.5485259914682613, 'batch_size': 32}. Best is trial 16 with value: 25.1272029876709.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:39:43,652] Trial 19 finished with value: 14.385164260864258 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007595257909698891, 'mc_samples_train': 1, 'prior_scale': 0.0553052327399875, 'q_scale': 0.0006518197309155569, 'obs_scale': 0.39668240749227973, 'batch_size': 32}. Best is trial 19 with value: 14.385164260864258.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:39:57,980] Trial 17 finished with value: 22.032838821411133 and parameters: {'pretrain_epochs': 0, 'lr': 0.000691180961207589, 'mc_samples_train': 1, 'prior_scale': 0.049317027736280133, 'q_scale': 0.0006396905880911569, 'obs_scale': 0.4932620022483778, 'batch_size': 32}. Best is trial 17 with value: 22.032838821411133.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:43:42,364] Trial 17 finished with value: 17.95547103881836 and parameters: {'pretrain_epochs': 0, 'lr': 0.000691180961207589, 'mc_samples_train': 1, 'prior_scale': 0.049317027736280133, 'q_scale': 0.0006396905880911569, 'obs_scale': 0.4932620022483778, 'batch_size': 32}. Best is trial 17 with value: 17.95547103881836.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:45:51,589] Trial 20 finished with value: 8.795220375061035 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009410248956021665, 'mc_samples_train': 1, 'prior_scale': 0.06343664261871748, 'q_scale': 0.00020116582693680395, 'obs_scale': 0.35557138721173415, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:46:50,792] Trial 18 finished with value: 19.457761764526367 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007263091335083298, 'mc_samples_train': 1, 'prior_scale': 0.049890828546736765, 'q_scale': 0.0006414587910215425, 'obs_scale': 0.48413666873004657, 'batch_size': 32}. Best is trial 18 with value: 19.457761764526367.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:50:23,871] Trial 18 finished with value: 32.25761032104492 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007263091335083298, 'mc_samples_train': 1, 'prior_scale': 0.049890828546736765, 'q_scale': 0.0006414587910215425, 'obs_scale': 0.48413666873004657, 'batch_size': 32}. Best is trial 17 with value: 17.95547103881836.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:52:17,957] Trial 21 finished with value: 18.392906188964844 and parameters: {'pretrain_epochs': 0, 'lr': 0.000862223487183857, 'mc_samples_train': 1, 'prior_scale': 0.06740901007980604, 'q_scale': 0.00022427661372579052, 'obs_scale': 0.3374818790903625, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:54:17,152] Trial 19 finished with value: 15.569585800170898 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007595257909698891, 'mc_samples_train': 1, 'prior_scale': 0.0553052327399875, 'q_scale': 0.0006518197309155569, 'obs_scale': 0.39668240749227973, 'batch_size': 32}. Best is trial 19 with value: 15.569585800170898.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:57:24,057] Trial 19 finished with value: 23.538394927978516 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005257884343407172, 'mc_samples_train': 1, 'prior_scale': 0.04778396272199133, 'q_scale': 0.000650326152249017, 'obs_scale': 0.39005208596186086, 'batch_size': 32}. Best is trial 17 with value: 17.95547103881836.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 13:58:35,259] Trial 22 finished with value: 21.599315643310547 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009874924234262205, 'mc_samples_train': 1, 'prior_scale': 0.04016065945973905, 'q_scale': 0.0007650825946406088, 'obs_scale': 0.3797663199026178, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:01:19,687] Trial 20 finished with value: 7.570845127105713 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009410248956021665, 'mc_samples_train': 1, 'prior_scale': 0.06343664261871748, 'q_scale': 0.00020116582693680395, 'obs_scale': 0.35557138721173415, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 14:02:18,406] Trial 23 pruned. Trial was pruned at epoch 10.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 14:04:07,463] Trial 20 pruned. Trial was pruned at epoch 17.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:07:50,452] Trial 21 finished with value: 18.58489990234375 and parameters: {'pretrain_epochs': 0, 'lr': 0.000862223487183857, 'mc_samples_train': 1, 'prior_scale': 0.06740901007980604, 'q_scale': 0.00022427661372579052, 'obs_scale': 0.3374818790903625, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 14:08:25,032] Trial 24 pruned. Trial was pruned at epoch 16.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:11:34,922] Trial 21 finished with value: 21.474390029907227 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006027416098410279, 'mc_samples_train': 1, 'prior_scale': 0.044525246619667135, 'q_scale': 0.0007910538045185004, 'obs_scale': 0.483370413879867, 'batch_size': 32}. Best is trial 17 with value: 17.95547103881836.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:14:48,161] Trial 22 finished with value: 59.56106948852539 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009897517703610693, 'mc_samples_train': 1, 'prior_scale': 0.07940156934878417, 'q_scale': 0.00021507479225071316, 'obs_scale': 0.34212097371806827, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:15:01,922] Trial 25 finished with value: 11.02728271484375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006748438578408085, 'mc_samples_train': 1, 'prior_scale': 0.13469709642502314, 'q_scale': 0.00020581642968448062, 'obs_scale': 0.46591103682903323, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:19:01,488] Trial 22 finished with value: 25.201522827148438 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009759889358631576, 'mc_samples_train': 1, 'prior_scale': 0.04016065945973905, 'q_scale': 0.0006801449341523249, 'obs_scale': 0.2677685950195412, 'batch_size': 32}. Best is trial 17 with value: 17.95547103881836.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:22:14,091] Trial 23 finished with value: 54.691471099853516 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005971919166727717, 'mc_samples_train': 1, 'prior_scale': 0.11788112679105546, 'q_scale': 0.00027425246065001445, 'obs_scale': 0.23001124617088642, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 14:24:15,030] Trial 26 pruned. Trial was pruned at epoch 16.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:26:51,673] Trial 23 finished with value: 13.973926544189453 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006227221732994119, 'mc_samples_train': 1, 'prior_scale': 0.0668941358360474, 'q_scale': 0.0003126425480395599, 'obs_scale': 0.4151409793914799, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 14:27:49,255] Trial 24 pruned. Trial was pruned at epoch 14.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:30:50,906] Trial 27 finished with value: 20.729734420776367 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006167782848423004, 'mc_samples_train': 1, 'prior_scale': 0.2763705310792614, 'q_scale': 0.0002904082597194098, 'obs_scale': 0.3746859534867914, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:33:19,470] Trial 28 finished with value: 1380.7530517578125 and parameters: {'pretrain_epochs': 0, 'lr': 0.00011398430345573024, 'mc_samples_train': 1, 'prior_scale': 0.30186663651042894, 'q_scale': 0.00015935445456431618, 'obs_scale': 0.3065174459109755, 'batch_size': 128}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:34:51,031] Trial 29 finished with value: 8875.3515625 and parameters: {'pretrain_epochs': 5, 'lr': 8.702364224005333e-05, 'mc_samples_train': 1, 'prior_scale': 0.13720478443334658, 'q_scale': 0.000383518181805017, 'obs_scale': 0.5748625129590914, 'batch_size': 512}. Best is trial 20 with value: 8.795220375061035.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:34:55,109] Trial 24 finished with value: 20.34653091430664 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006681762479256583, 'mc_samples_train': 1, 'prior_scale': 0.08554798474183566, 'q_scale': 0.00033011851205550185, 'obs_scale': 0.5105715736300651, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:34:55,957] Trial 25 finished with value: 46.617759704589844 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009893755800209887, 'mc_samples_train': 1, 'prior_scale': 0.034219793325451595, 'q_scale': 0.0006427159858661907, 'obs_scale': 0.2620362868752414, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:41:17,657] Trial 30 finished with value: 33.69993209838867 and parameters: {'pretrain_epochs': 0, 'lr': 0.00038396701131185356, 'mc_samples_train': 1, 'prior_scale': 0.0861232110600651, 'q_scale': 0.0002912461426991157, 'obs_scale': 0.4370098510594135, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:42:38,656] Trial 25 finished with value: 104.94136047363281 and parameters: {'pretrain_epochs': 0, 'lr': 0.0003394050757930824, 'mc_samples_train': 1, 'prior_scale': 0.13469709642502314, 'q_scale': 0.00029198439611751305, 'obs_scale': 0.32572674772294435, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:47:34,702] Trial 26 finished with value: 314.4885559082031 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003628689069010046, 'mc_samples_train': 2, 'prior_scale': 0.15479700679466418, 'q_scale': 0.00018157955174446106, 'obs_scale': 0.3987880946462159, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:47:37,671] Trial 31 finished with value: 15.515972137451172 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006680368066976181, 'mc_samples_train': 1, 'prior_scale': 0.05579858997767185, 'q_scale': 0.0007242189305787746, 'obs_scale': 0.4786387433445233, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:53:56,691] Trial 32 finished with value: 24.01712417602539 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006182721622361482, 'mc_samples_train': 1, 'prior_scale': 0.0650746397020037, 'q_scale': 0.0007985508727179825, 'obs_scale': 0.6680718428263864, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:54:47,411] Trial 27 finished with value: 111.48522186279297 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006167782848423004, 'mc_samples_train': 1, 'prior_scale': 0.07078082608673841, 'q_scale': 0.0004018287278718421, 'obs_scale': 0.1980958002490439, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:55:52,034] Trial 26 finished with value: 1111.0069580078125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002178416264960444, 'mc_samples_train': 2, 'prior_scale': 0.07455230132082018, 'q_scale': 0.00023274249435730555, 'obs_scale': 0.2299898013343446, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:57:37,557] Trial 28 finished with value: 7816.98974609375 and parameters: {'pretrain_epochs': 0, 'lr': 4.0174518409972304e-05, 'mc_samples_train': 1, 'prior_scale': 0.30186663651042894, 'q_scale': 0.0003025192277530568, 'obs_scale': 0.3065174459109755, 'batch_size': 128}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 14:59:28,173] Trial 29 finished with value: 7624.8408203125 and parameters: {'pretrain_epochs': 5, 'lr': 9.921553289851606e-05, 'mc_samples_train': 1, 'prior_scale': 0.039413706203980936, 'q_scale': 0.0008515088472132865, 'obs_scale': 0.5822297899801441, 'batch_size': 512}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:00:25,457] Trial 33 finished with value: 35.07633590698242 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007266156417882247, 'mc_samples_train': 1, 'prior_scale': 0.036816549565905674, 'q_scale': 0.00018067715999785274, 'obs_scale': 0.34141996198473634, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:02:24,494] Trial 34 finished with value: 496107.6875 and parameters: {'pretrain_epochs': 0, 'lr': 5.7136632515214375e-05, 'mc_samples_train': 1, 'prior_scale': 0.059480207834859085, 'q_scale': 0.0011170018507351946, 'obs_scale': 0.27342775354008636, 'batch_size': 256}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:03:38,040] Trial 27 finished with value: 19.84027862548828 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006746258891313132, 'mc_samples_train': 1, 'prior_scale': 0.14732222903843126, 'q_scale': 0.0004018287278718421, 'obs_scale': 0.5895199043485567, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:06:16,161] Trial 30 finished with value: 43.544349670410156 and parameters: {'pretrain_epochs': 0, 'lr': 0.00033887516581264203, 'mc_samples_train': 1, 'prior_scale': 0.022689658887318588, 'q_scale': 0.00047528042867711856, 'obs_scale': 0.4370098510594135, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:07:03,836] Trial 28 finished with value: 303.64410400390625 and parameters: {'pretrain_epochs': 0, 'lr': 0.00010665795465083976, 'mc_samples_train': 1, 'prior_scale': 0.30186663651042894, 'q_scale': 0.00017234324760472387, 'obs_scale': 0.8753756893535367, 'batch_size': 128}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:09:16,208] Trial 29 finished with value: 4139.51025390625 and parameters: {'pretrain_epochs': 5, 'lr': 5.236894882777535e-05, 'mc_samples_train': 1, 'prior_scale': 0.14118427219031313, 'q_scale': 0.00045795540155435196, 'obs_scale': 1.4135697881067528, 'batch_size': 512}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:12:49,332] Trial 35 finished with value: 27.9597225189209 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009697184655036393, 'mc_samples_train': 2, 'prior_scale': 0.12538829146846445, 'q_scale': 0.00033818982970098166, 'obs_scale': 0.8473948045312067, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:13:01,547] Trial 31 finished with value: 10.450652122497559 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007178839930599398, 'mc_samples_train': 1, 'prior_scale': 0.04902796638075531, 'q_scale': 0.0006305977822506084, 'obs_scale': 0.44583708052282817, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:17:03,581] Trial 30 finished with value: 26.344907760620117 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009591845442225177, 'mc_samples_train': 1, 'prior_scale': 0.2796765149103996, 'q_scale': 0.0004154979524846102, 'obs_scale': 0.6208861958467037, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:19:06,384] Trial 36 finished with value: 840.2421875 and parameters: {'pretrain_epochs': 5, 'lr': 2.336178932942835e-05, 'mc_samples_train': 1, 'prior_scale': 0.09085987402195016, 'q_scale': 0.0005395308954875394, 'obs_scale': 0.46723865281277066, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:19:54,543] Trial 32 finished with value: 15.852718353271484 and parameters: {'pretrain_epochs': 0, 'lr': 0.000729074396149963, 'mc_samples_train': 1, 'prior_scale': 0.09817041163299439, 'q_scale': 0.00026318471896278, 'obs_scale': 0.31997177793407683, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:20:37,564] Trial 37 finished with value: 20517.439453125 and parameters: {'pretrain_epochs': 0, 'lr': 0.000213940624590804, 'mc_samples_train': 1, 'prior_scale': 0.03194832541554563, 'q_scale': 0.0016035412310709174, 'obs_scale': 0.565952259567061, 'batch_size': 512}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:23:10,615] Trial 38 finished with value: 347.1746520996094 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004966402699781978, 'mc_samples_train': 2, 'prior_scale': 0.02307798890182511, 'q_scale': 0.0008677919586673049, 'obs_scale': 1.3422976092490253, 'batch_size': 256}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:24:25,390] Trial 31 finished with value: 16.535959243774414 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006557811813299671, 'mc_samples_train': 1, 'prior_scale': 0.0946187101144961, 'q_scale': 0.00024787379924768026, 'obs_scale': 0.46632986902004936, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:25:34,542] Trial 39 finished with value: 2168.0634765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00013788557993523379, 'mc_samples_train': 1, 'prior_scale': 0.046750137490587707, 'q_scale': 0.00014573544217320089, 'obs_scale': 0.38723031042750894, 'batch_size': 128}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:26:53,053] Trial 33 finished with value: 49.18193435668945 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005535194318895576, 'mc_samples_train': 1, 'prior_scale': 0.09775279828274265, 'q_scale': 0.0003244161371558254, 'obs_scale': 0.2946122456648841, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 15:28:45,283] Trial 34 pruned. Trial was pruned at epoch 15.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:31:10,172] Trial 32 finished with value: 45.681156158447266 and parameters: {'pretrain_epochs': 0, 'lr': 0.0003567555044956278, 'mc_samples_train': 1, 'prior_scale': 0.058151040776631205, 'q_scale': 0.0002694232980195212, 'obs_scale': 0.3967240791658831, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:35:22,084] Trial 40 finished with value: 3292.11767578125 and parameters: {'pretrain_epochs': 0, 'lr': 2.8058268402712556e-05, 'mc_samples_train': 2, 'prior_scale': 0.1497377510726038, 'q_scale': 0.00040784703330132467, 'obs_scale': 0.197849658450045, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:38:01,574] Trial 33 finished with value: 45.4676399230957 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006432693407615532, 'mc_samples_train': 1, 'prior_scale': 0.10207232513038603, 'q_scale': 0.0005500044262222234, 'obs_scale': 0.30365015814208135, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
[I 2024-05-24 15:38:10,402] Trial 35 pruned. Trial was pruned at epoch 14.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:40:30,204] Trial 34 finished with value: 172.02284240722656 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007349925665405387, 'mc_samples_train': 1, 'prior_scale': 0.1772194409452042, 'q_scale': 0.00015856821017201222, 'obs_scale': 0.6293638887691918, 'batch_size': 256}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:41:34,256] Trial 41 finished with value: 18.006288528442383 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007387085317501385, 'mc_samples_train': 1, 'prior_scale': 0.05505225727543, 'q_scale': 0.000597938933323071, 'obs_scale': 0.5057735821068052, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:45:46,058] Trial 36 finished with value: 505.5638427734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00012365570583686662, 'mc_samples_train': 1, 'prior_scale': 0.09258552177020683, 'q_scale': 0.00107759808629228, 'obs_scale': 0.4131810901021061, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:47:49,461] Trial 37 finished with value: 681046.875 and parameters: {'pretrain_epochs': 0, 'lr': 5.1808411700953774e-05, 'mc_samples_train': 1, 'prior_scale': 0.06061037395940925, 'q_scale': 0.0004969930137889893, 'obs_scale': 0.5064516163789641, 'batch_size': 512}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:48:28,340] Trial 42 finished with value: 21.82976722717285 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007810047860749132, 'mc_samples_train': 1, 'prior_scale': 0.04977734063670971, 'q_scale': 0.0009870864144858303, 'obs_scale': 0.44001273653437667, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:51:21,720] Trial 38 finished with value: 249.6856689453125 and parameters: {'pretrain_epochs': 0, 'lr': 0.00044206432115025064, 'mc_samples_train': 2, 'prior_scale': 0.03550002544853652, 'q_scale': 0.0017704988662195682, 'obs_scale': 0.6484039653175203, 'batch_size': 256}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:52:57,207] Trial 35 finished with value: 220.3529510498047 and parameters: {'pretrain_epochs': 0, 'lr': 2.7722032902337684e-05, 'mc_samples_train': 2, 'prior_scale': 0.06440353872516405, 'q_scale': 0.0009456229874537455, 'obs_scale': 1.0976679165359347, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:54:20,992] Trial 39 finished with value: 1005.53955078125 and parameters: {'pretrain_epochs': 5, 'lr': 1.779960128170813e-05, 'mc_samples_train': 1, 'prior_scale': 0.04258309931113826, 'q_scale': 0.00024697338723663815, 'obs_scale': 1.2890153691753936, 'batch_size': 128}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 15:56:15,970] Trial 43 finished with value: 199.88516235351562 and parameters: {'pretrain_epochs': 0, 'lr': 0.0003059323051072793, 'mc_samples_train': 1, 'prior_scale': 0.07666832790534799, 'q_scale': 0.002006732782072307, 'obs_scale': 0.32525410530092974, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:01:30,611] Trial 36 finished with value: 163.02418518066406 and parameters: {'pretrain_epochs': 5, 'lr': 0.00040543093472549224, 'mc_samples_train': 1, 'prior_scale': 0.0321829215948626, 'q_scale': 0.00024526562363288333, 'obs_scale': 0.4436003451948286, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:02:43,831] Trial 44 finished with value: 12.45425796508789 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006332625350956344, 'mc_samples_train': 1, 'prior_scale': 0.05946211542099247, 'q_scale': 0.00010174879441412058, 'obs_scale': 0.43006409907209103, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:03:43,733] Trial 37 finished with value: 81407.4375 and parameters: {'pretrain_epochs': 0, 'lr': 0.00014913593738818511, 'mc_samples_train': 1, 'prior_scale': 0.09120439297552839, 'q_scale': 0.00038203459962374433, 'obs_scale': 0.563411466321853, 'batch_size': 512}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:04:29,895] Trial 45 finished with value: 485.2985534667969 and parameters: {'pretrain_epochs': 0, 'lr': 0.00042537631512919893, 'mc_samples_train': 1, 'prior_scale': 0.09855865418199686, 'q_scale': 0.00010158363528356515, 'obs_scale': 0.2743425869975343, 'batch_size': 256}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 16:07:10,943] Trial 40 pruned. Trial was pruned at epoch 19.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:07:58,210] Trial 38 finished with value: 256.9300537109375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002972840099043218, 'mc_samples_train': 2, 'prior_scale': 0.14271947763354037, 'q_scale': 0.0011046943371972213, 'obs_scale': 0.7681695633728916, 'batch_size': 256}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:10:08,536] Trial 46 finished with value: 18.140451431274414 and parameters: {'pretrain_epochs': 0, 'lr': 0.000997930783240949, 'mc_samples_train': 1, 'prior_scale': 0.060833387752002394, 'q_scale': 0.00021041204788870645, 'obs_scale': 0.4285221668982412, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:11:15,218] Trial 39 finished with value: 1337.096923828125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008037234347984701, 'mc_samples_train': 1, 'prior_scale': 0.12015069252918972, 'q_scale': 0.0005018583527468872, 'obs_scale': 0.20329334720403028, 'batch_size': 128}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:12:18,926] Trial 47 finished with value: 279.753662109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006000414195743819, 'mc_samples_train': 1, 'prior_scale': 0.035258651824255624, 'q_scale': 0.00011985097304494243, 'obs_scale': 0.6081792816161671, 'batch_size': 128}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:13:46,721] Trial 48 finished with value: 10869380.0 and parameters: {'pretrain_epochs': 0, 'lr': 1.0125058472109033e-05, 'mc_samples_train': 1, 'prior_scale': 0.20075418565349623, 'q_scale': 0.00014861953629173865, 'obs_scale': 0.13470210895997695, 'batch_size': 512}. Best is trial 20 with value: 8.795220375061035.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:14:16,369] Trial 41 finished with value: 28.664762496948242 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007810047684009159, 'mc_samples_train': 1, 'prior_scale': 0.07460398630428074, 'q_scale': 0.00021009633065040994, 'obs_scale': 0.30742537370637046, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:21:14,794] Trial 42 finished with value: 12.07579517364502 and parameters: {'pretrain_epochs': 0, 'lr': 0.000833823738406125, 'mc_samples_train': 1, 'prior_scale': 0.05936172622629903, 'q_scale': 0.00015915366241471443, 'obs_scale': 0.3313858318021942, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:22:37,419] Trial 49 finished with value: 28.50465965270996 and parameters: {'pretrain_epochs': 0, 'lr': 0.000397903957099914, 'mc_samples_train': 2, 'prior_scale': 0.08101161562963576, 'q_scale': 0.00032262214400778926, 'obs_scale': 0.8285181121952915, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:24:18,064] Trial 40 finished with value: 184.36097717285156 and parameters: {'pretrain_epochs': 0, 'lr': 9.15690020581792e-05, 'mc_samples_train': 2, 'prior_scale': 0.17083483372328492, 'q_scale': 0.00034775158827545486, 'obs_scale': 0.33681574877144815, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:28:13,035] Trial 50 finished with value: 33.72554016113281 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005139276323224396, 'mc_samples_train': 1, 'prior_scale': 0.11137203206290164, 'q_scale': 0.00362677016245377, 'obs_scale': 1.0145434612062143, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:29:02,388] Trial 43 finished with value: 39.321624755859375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0008056697292903502, 'mc_samples_train': 1, 'prior_scale': 0.05667581375668678, 'q_scale': 0.00010713881154318892, 'obs_scale': 0.4036477633290455, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:31:58,801] Trial 41 finished with value: 16.550189971923828 and parameters: {'pretrain_epochs': 0, 'lr': 0.000631737331581124, 'mc_samples_train': 1, 'prior_scale': 0.09461612618755091, 'q_scale': 0.0002973573624642535, 'obs_scale': 0.5200950570914034, 'batch_size': 32}. Best is trial 23 with value: 13.973926544189453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:34:35,912] Trial 51 finished with value: 16.635770797729492 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007834564129333778, 'mc_samples_train': 1, 'prior_scale': 0.04784075629852243, 'q_scale': 0.00142397504288141, 'obs_scale': 0.49683402466956833, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:36:08,748] Trial 44 finished with value: 56.859405517578125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005441983505767138, 'mc_samples_train': 1, 'prior_scale': 0.088647133176808, 'q_scale': 0.0001452635275060882, 'obs_scale': 0.35064533938700687, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:38:34,107] Trial 45 finished with value: 274.99420166015625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009667551493626546, 'mc_samples_train': 1, 'prior_scale': 0.23576264943607209, 'q_scale': 0.00015870411810596594, 'obs_scale': 0.2284740192713978, 'batch_size': 256}. Best is trial 20 with value: 7.570845127105713.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:38:49,406] Trial 42 finished with value: 12.648012161254883 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005752880938533469, 'mc_samples_train': 1, 'prior_scale': 0.09932446036472461, 'q_scale': 0.00019597689702210828, 'obs_scale': 0.4404073995649561, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:40:12,606] Trial 52 finished with value: 10.936932563781738 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006552714893977413, 'mc_samples_train': 1, 'prior_scale': 0.04210916466264082, 'q_scale': 0.000661531658818666, 'obs_scale': 0.37891561501423027, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:46:00,319] Trial 46 finished with value: 14.396121978759766 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006652190222180234, 'mc_samples_train': 1, 'prior_scale': 0.0441845152640731, 'q_scale': 0.00034283844133024317, 'obs_scale': 0.4660954531867439, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:46:39,630] Trial 53 finished with value: 12.927022933959961 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006568117881031401, 'mc_samples_train': 1, 'prior_scale': 0.04213674639680718, 'q_scale': 0.00026096594583978404, 'obs_scale': 0.3816046867756409, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:47:47,057] Trial 43 finished with value: 33.670223236083984 and parameters: {'pretrain_epochs': 0, 'lr': 0.000489350653732724, 'mc_samples_train': 1, 'prior_scale': 0.10190403880637247, 'q_scale': 0.00016050009896061184, 'obs_scale': 0.4322039322666469, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:49:07,510] Trial 47 finished with value: 188.7181396484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004183055130992373, 'mc_samples_train': 1, 'prior_scale': 0.026225593261762777, 'q_scale': 0.0005739361875658825, 'obs_scale': 0.9213452991226261, 'batch_size': 128}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:51:07,062] Trial 48 finished with value: 2693.56298828125 and parameters: {'pretrain_epochs': 0, 'lr': 0.00028230392745546906, 'mc_samples_train': 1, 'prior_scale': 0.041490269688819935, 'q_scale': 0.0012648184594538834, 'obs_scale': 0.46141397715447313, 'batch_size': 512}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:52:41,728] Trial 54 finished with value: 23.767887115478516 and parameters: {'pretrain_epochs': 0, 'lr': 0.0008405087462915266, 'mc_samples_train': 1, 'prior_scale': 0.025823816505289577, 'q_scale': 0.0002568817698408131, 'obs_scale': 0.3628072411901558, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:55:25,224] Trial 44 finished with value: 17032.357421875 and parameters: {'pretrain_epochs': 0, 'lr': 1.1818092032455127e-05, 'mc_samples_train': 1, 'prior_scale': 0.05946211542099247, 'q_scale': 0.00010407011758375458, 'obs_scale': 0.3666043592179568, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 16:56:17,374] Trial 55 finished with value: 44.656829833984375 and parameters: {'pretrain_epochs': 0, 'lr': 0.000452781567021585, 'mc_samples_train': 1, 'prior_scale': 0.016406974173362135, 'q_scale': 0.00010198033354634238, 'obs_scale': 0.40651798136028805, 'batch_size': 64}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 16:57:51,300] Trial 45 pruned. Trial was pruned at epoch 18.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:02:21,521] Trial 56 finished with value: 33.51589584350586 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005683201359350743, 'mc_samples_train': 1, 'prior_scale': 0.03981217361728262, 'q_scale': 0.0004498881918430304, 'obs_scale': 0.3000366761205295, 'batch_size': 32}. Best is trial 20 with value: 8.795220375061035.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:02:58,107] Trial 49 finished with value: 17.125045776367188 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006466897260547845, 'mc_samples_train': 2, 'prior_scale': 0.018941288452430514, 'q_scale': 0.0008421853275663296, 'obs_scale': 0.542058047211006, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:05:28,376] Trial 46 finished with value: 94.43193054199219 and parameters: {'pretrain_epochs': 0, 'lr': 0.00020097100557417953, 'mc_samples_train': 1, 'prior_scale': 0.09255960399818662, 'q_scale': 0.00031168565781048276, 'obs_scale': 0.43880498015587344, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:08:47,056] Trial 47 finished with value: 224.98214721679688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004082199577692091, 'mc_samples_train': 1, 'prior_scale': 0.037169078384831494, 'q_scale': 0.00013749487855856677, 'obs_scale': 0.6975201192592541, 'batch_size': 128}. Best is trial 42 with value: 12.648012161254883.
[I 2024-05-24 17:08:48,214] Trial 57 pruned. Trial was pruned at epoch 19.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:09:54,185] Trial 50 finished with value: 27.832813262939453 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005161688047078451, 'mc_samples_train': 1, 'prior_scale': 0.032957210406033936, 'q_scale': 0.00033882896223158586, 'obs_scale': 0.3779137835283647, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:10:58,807] Trial 48 finished with value: 555.4747924804688 and parameters: {'pretrain_epochs': 0, 'lr': 0.000557106195883259, 'mc_samples_train': 1, 'prior_scale': 0.11369743725583477, 'q_scale': 0.00021692437473279705, 'obs_scale': 0.5148631572775434, 'batch_size': 512}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 17:14:38,808] Trial 58 pruned. Trial was pruned at epoch 18.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:16:22,426] Trial 59 finished with value: 1587.27001953125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000883647434773169, 'mc_samples_train': 1, 'prior_scale': 0.06987808840349534, 'q_scale': 0.0001281002446001285, 'obs_scale': 0.2614789338988419, 'batch_size': 256}. Best is trial 20 with value: 8.795220375061035.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:17:04,620] Trial 51 finished with value: 37.77355194091797 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007857919248700869, 'mc_samples_train': 1, 'prior_scale': 0.048492663024245444, 'q_scale': 0.0002844585354152384, 'obs_scale': 0.3178077310582613, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:22:56,326] Trial 49 finished with value: 32.29942321777344 and parameters: {'pretrain_epochs': 0, 'lr': 0.000298766757232606, 'mc_samples_train': 2, 'prior_scale': 0.21305216672969637, 'q_scale': 0.00018609609268027566, 'obs_scale': 0.8994594276110932, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:23:56,021] Trial 52 finished with value: 22.9442195892334 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006552714893977413, 'mc_samples_train': 1, 'prior_scale': 0.06033693894257304, 'q_scale': 0.00039113102011199174, 'obs_scale': 0.27290010451939806, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 17:26:47,863] Trial 50 pruned. Trial was pruned at epoch 9.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:31:01,765] Trial 53 finished with value: 15.987414360046387 and parameters: {'pretrain_epochs': 0, 'lr': 0.0008747450703666922, 'mc_samples_train': 1, 'prior_scale': 0.08412953931834553, 'q_scale': 0.0001210500536314693, 'obs_scale': 0.43960614037619417, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:34:54,844] Trial 51 finished with value: 18.061792373657227 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006252761321550576, 'mc_samples_train': 1, 'prior_scale': 0.12162034560081164, 'q_scale': 0.0002777731684627197, 'obs_scale': 0.5728174616622953, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-24 17:36:51,014] Trial 54 pruned. Trial was pruned at epoch 15.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:41:02,604] Trial 55 finished with value: 52.05315399169922 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006982660246876976, 'mc_samples_train': 1, 'prior_scale': 0.04668689387609643, 'q_scale': 0.0002554746572720036, 'obs_scale': 0.7148476211986122, 'batch_size': 64}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:43:30,719] Trial 52 finished with value: 18.009069442749023 and parameters: {'pretrain_epochs': 0, 'lr': 0.00057672293689978, 'mc_samples_train': 1, 'prior_scale': 0.08108884397905183, 'q_scale': 0.0002745559474627713, 'obs_scale': 0.48937845611713765, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:47:58,719] Trial 56 finished with value: 26.45928192138672 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004912931225240278, 'mc_samples_train': 1, 'prior_scale': 0.10971846560302191, 'q_scale': 0.0004915961649172973, 'obs_scale': 0.37017293958798064, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:50:57,320] Trial 53 finished with value: 15.308282852172852 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005303365562365908, 'mc_samples_train': 1, 'prior_scale': 0.06839117634296193, 'q_scale': 0.00012310502142375544, 'obs_scale': 0.48922743306635214, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:54:40,161] Trial 57 finished with value: 20.866662979125977 and parameters: {'pretrain_epochs': 0, 'lr': 0.0008019708555864843, 'mc_samples_train': 1, 'prior_scale': 0.056558907754717086, 'q_scale': 0.0007633159270988318, 'obs_scale': 0.5765651785452724, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 17:58:18,414] Trial 54 finished with value: 27.19847297668457 and parameters: {'pretrain_epochs': 0, 'lr': 0.00043622157550123736, 'mc_samples_train': 1, 'prior_scale': 0.06531714902932258, 'q_scale': 0.00012938791140128063, 'obs_scale': 0.39414683318886345, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:02:09,423] Trial 58 finished with value: 12.369244575500488 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005968427457125606, 'mc_samples_train': 1, 'prior_scale': 0.13239244191569838, 'q_scale': 0.00016820698298006503, 'obs_scale': 0.480918898536572, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:03:11,188] Trial 55 finished with value: 34.08312225341797 and parameters: {'pretrain_epochs': 0, 'lr': 0.0008222252981489558, 'mc_samples_train': 1, 'prior_scale': 0.051059376070655346, 'q_scale': 0.00010275622081209195, 'obs_scale': 0.4501195843022101, 'batch_size': 64}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:09:48,339] Trial 59 finished with value: 26.081527709960938 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005853047195913743, 'mc_samples_train': 1, 'prior_scale': 0.13766111616714935, 'q_scale': 0.0001400921296006223, 'obs_scale': 0.8279902915596273, 'batch_size': 32}. Best is trial 20 with value: 7.570845127105713.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:11:11,968] Trial 56 finished with value: 26.993165969848633 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004961703323834621, 'mc_samples_train': 1, 'prior_scale': 0.03424838737758728, 'q_scale': 0.00013891056124318974, 'obs_scale': 0.7038010597057657, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:18:44,080] Trial 57 finished with value: 60.58041763305664 and parameters: {'pretrain_epochs': 0, 'lr': 0.00035602599801649165, 'mc_samples_train': 1, 'prior_scale': 0.09249405978305829, 'q_scale': 0.00018947011247603328, 'obs_scale': 0.3655791031639362, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:26:02,380] Trial 58 finished with value: 16.12257194519043 and parameters: {'pretrain_epochs': 0, 'lr': 0.000717064420533722, 'mc_samples_train': 1, 'prior_scale': 0.0708639377548408, 'q_scale': 0.0005559683800145626, 'obs_scale': 0.5336891015067621, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-24 18:33:39,530] Trial 59 finished with value: 29.65960121154785 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002708650199615613, 'mc_samples_train': 1, 'prior_scale': 0.026050829318738776, 'q_scale': 0.0005156072233059998, 'obs_scale': 0.848106358310356, 'batch_size': 32}. Best is trial 42 with value: 12.648012161254883.
