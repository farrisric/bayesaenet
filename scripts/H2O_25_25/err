/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2024-05-22 14:51:11,395] A new study created in RDB with name: bnn_lrt
[I 2024-05-22 14:51:11,395] A new study created in RDB with name: bnn_fo
[I 2024-05-22 14:51:11,503] A new study created in RDB with name: bnn_rad
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 14:57:47,962] Trial 0 finished with value: 11530.7998046875 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:00:21,099] Trial 0 finished with value: 11535.5869140625 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 11535.5869140625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:02:13,835] Trial 1 finished with value: 3652807.25 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 11530.7998046875.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:02:23,256] Trial 0 finished with value: 11534.2587890625 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:07:06,346] Trial 1 finished with value: 3630754.75 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 11535.5869140625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:08:15,281] Trial 2 finished with value: 23056996.0 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:10:19,698] Trial 1 finished with value: 3654488.25 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:14:37,946] Trial 3 finished with value: 172123712.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:17:42,829] Trial 2 finished with value: 23075638.0 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 11535.5869140625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:19:57,046] Trial 4 finished with value: 19197.833984375 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:23:14,687] Trial 2 finished with value: 23010174.0 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 11534.2587890625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:24:45,948] Trial 5 finished with value: 61250.30859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:27:56,522] Trial 3 finished with value: 172272256.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 11535.5869140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:31:29,196] Trial 6 finished with value: 1601367.375 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:33:44,190] Trial 4 finished with value: 19176.0 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 11535.5869140625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:34:12,478] Trial 3 finished with value: 172135792.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:35:56,019] Trial 7 finished with value: 3877661.25 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:38:42,976] Trial 5 finished with value: 59232.19921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 11535.5869140625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:40:28,176] Trial 8 finished with value: 7242929.5 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:41:00,008] Trial 4 finished with value: 19558.994140625 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:46:45,308] Trial 9 finished with value: 745487.125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 11530.7998046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:48:52,857] Trial 5 finished with value: 59529.42578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 11534.2587890625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:50:45,950] Trial 6 finished with value: 1604579.875 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 11535.5869140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 15:54:00,058] Trial 10 finished with value: 1014.3057861328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 1014.3057861328125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:01:11,442] Trial 11 finished with value: 725.1094360351562 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:01:19,492] Trial 7 finished with value: 3717138.0 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 11535.5869140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:03:46,375] Trial 6 finished with value: 1601474.25 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:08:24,821] Trial 12 finished with value: 780.4864501953125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:08:56,536] Trial 8 finished with value: 7241264.5 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 11535.5869140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:14:41,525] Trial 13 finished with value: 846.2107543945312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004805364291548028, 'mc_samples_train': 1, 'prior_scale': 0.010482874946722998, 'q_scale': 0.00010532990129819251, 'obs_scale': 1.8557399609740814, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:15:24,760] Trial 7 finished with value: 3721268.25 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
`Trainer.fit` stopped: `max_epochs=20` reached.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-22 16:17:06,108] Trial 9 finished with value: 746837.875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 11535.5869140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:19:51,578] Trial 14 finished with value: 3589.1396484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00042697878418142905, 'mc_samples_train': 1, 'prior_scale': 0.025598098635809526, 'q_scale': 0.00025604133934126406, 'obs_scale': 0.8078049424337922, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:21:53,279] Trial 8 finished with value: 7242347.5 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 11534.2587890625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:23:09,558] Trial 10 finished with value: 978.8890991210938 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 978.8890991210938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:25:03,131] Trial 15 finished with value: 3897.02783203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005138228537466867, 'mc_samples_train': 1, 'prior_scale': 0.027024810916201885, 'q_scale': 0.0001712476201149009, 'obs_scale': 0.7052783036429959, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:28:21,505] Trial 16 finished with value: 332452.9375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001858988439599671, 'mc_samples_train': 1, 'prior_scale': 0.01723481155469655, 'q_scale': 0.0006897331189673997, 'obs_scale': 1.3052345342320926, 'batch_size': 512}. Best is trial 11 with value: 725.1094360351562.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:30:52,741] Trial 11 finished with value: 790.8419189453125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 11 with value: 790.8419189453125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:32:21,700] Trial 9 finished with value: 747869.375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 11534.2587890625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:35:22,594] Trial 17 finished with value: 6656.349609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00029493452670697866, 'mc_samples_train': 1, 'prior_scale': 0.04983164005349259, 'q_scale': 0.00021683415691757426, 'obs_scale': 0.6301916365616733, 'batch_size': 32}. Best is trial 11 with value: 725.1094360351562.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:41:33,746] Trial 12 finished with value: 776.678955078125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:43:01,341] Trial 18 finished with value: 638.5430908203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000623327345926834, 'mc_samples_train': 1, 'prior_scale': 0.012934001018788954, 'q_scale': 0.0006193545503124616, 'obs_scale': 1.8504266749951648, 'batch_size': 32}. Best is trial 18 with value: 638.5430908203125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:44:24,849] Trial 10 finished with value: 977.9742431640625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 977.9742431640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:50:33,067] Trial 19 finished with value: 7167.9609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007365530308431357, 'mc_samples_train': 1, 'prior_scale': 0.03808194315067731, 'q_scale': 0.0006979403517173231, 'obs_scale': 0.4892292458746359, 'batch_size': 32}. Best is trial 18 with value: 638.5430908203125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:52:03,548] Trial 13 finished with value: 789.0540161132812 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004805364291548028, 'mc_samples_train': 1, 'prior_scale': 0.010482874946722998, 'q_scale': 0.00010532990129819251, 'obs_scale': 1.8557399609740814, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:55:35,291] Trial 20 finished with value: 549692.5 and parameters: {'pretrain_epochs': 5, 'lr': 0.00010398746062615416, 'mc_samples_train': 1, 'prior_scale': 0.01029638255484863, 'q_scale': 0.0005068122780361661, 'obs_scale': 1.3352762117202543, 'batch_size': 512}. Best is trial 18 with value: 638.5430908203125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 16:56:03,257] Trial 11 finished with value: 764.3724975585938 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 11 with value: 764.3724975585938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:01:48,248] Trial 14 finished with value: 3109.8896484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005010915921201378, 'mc_samples_train': 1, 'prior_scale': 0.010694382576736208, 'q_scale': 0.0002066529483682607, 'obs_scale': 0.8129533994689465, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:03:02,131] Trial 21 finished with value: 867.8070678710938 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005078250118444193, 'mc_samples_train': 1, 'prior_scale': 0.017689093703803675, 'q_scale': 0.00017534009393850637, 'obs_scale': 1.734621732715612, 'batch_size': 32}. Best is trial 18 with value: 638.5430908203125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:06:47,238] Trial 12 finished with value: 818.73193359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 11 with value: 764.3724975585938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:09:07,784] Trial 22 finished with value: 1328.022705078125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00031065326061239346, 'mc_samples_train': 1, 'prior_scale': 0.014027304769731203, 'q_scale': 0.0001339666080752519, 'obs_scale': 1.4434989169550396, 'batch_size': 32}. Best is trial 18 with value: 638.5430908203125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:09:51,523] Trial 15 finished with value: 4138.82177734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005127255173196106, 'mc_samples_train': 1, 'prior_scale': 0.028499902751828544, 'q_scale': 0.0002314041680489933, 'obs_scale': 0.7052783036429959, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:14:57,864] Trial 16 finished with value: 324199.1875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001683729748744469, 'mc_samples_train': 1, 'prior_scale': 0.026612552748234822, 'q_scale': 0.0006750641359979788, 'obs_scale': 1.3965506004824642, 'batch_size': 512}. Best is trial 12 with value: 776.678955078125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:15:14,755] Trial 23 finished with value: 637.3792114257812 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006305069628294042, 'mc_samples_train': 1, 'prior_scale': 0.021096409553778835, 'q_scale': 0.0002474266586186133, 'obs_scale': 1.94993290167836, 'batch_size': 32}. Best is trial 23 with value: 637.3792114257812.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:15:38,762] Trial 13 finished with value: 720.3123168945312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004805364291548028, 'mc_samples_train': 1, 'prior_scale': 0.010482874946722998, 'q_scale': 0.00010532990129819251, 'obs_scale': 1.8557399609740814, 'batch_size': 32}. Best is trial 13 with value: 720.3123168945312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:22:28,000] Trial 24 finished with value: 1966.7161865234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006849492954640321, 'mc_samples_train': 1, 'prior_scale': 0.022220571810361894, 'q_scale': 0.0002796008426675704, 'obs_scale': 0.9927672426674916, 'batch_size': 32}. Best is trial 23 with value: 637.3792114257812.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:24:38,707] Trial 17 finished with value: 4893.36865234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006667311236887355, 'mc_samples_train': 1, 'prior_scale': 0.05008224559552991, 'q_scale': 0.00018937647242706838, 'obs_scale': 0.6221357745820894, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:26:40,536] Trial 14 finished with value: 2958.58740234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005010915921201378, 'mc_samples_train': 1, 'prior_scale': 0.010694382576736208, 'q_scale': 0.00025978478168190144, 'obs_scale': 0.8129533994689465, 'batch_size': 32}. Best is trial 13 with value: 720.3123168945312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:27:10,046] Trial 25 finished with value: 13204.7626953125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009893755800209887, 'mc_samples_train': 1, 'prior_scale': 0.034219793325451595, 'q_scale': 0.0003552860014669164, 'obs_scale': 0.8532217481730135, 'batch_size': 128}. Best is trial 23 with value: 637.3792114257812.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:35:09,766] Trial 18 finished with value: 1848.641357421875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00025892224501798867, 'mc_samples_train': 1, 'prior_scale': 0.01915885342177043, 'q_scale': 0.0001454394955154121, 'obs_scale': 1.2369081189299158, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:38:15,241] Trial 15 finished with value: 3849.109130859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005145519904373549, 'mc_samples_train': 1, 'prior_scale': 0.032326627210685015, 'q_scale': 0.0001729459507703868, 'obs_scale': 0.7052783036429959, 'batch_size': 32}. Best is trial 13 with value: 720.3123168945312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:40:07,961] Trial 26 finished with value: 1247.8739013671875 and parameters: {'pretrain_epochs': 0, 'lr': 0.00020608770303331538, 'mc_samples_train': 2, 'prior_scale': 0.019771918115966014, 'q_scale': 0.0005814301682754722, 'obs_scale': 1.4530017248452578, 'batch_size': 32}. Best is trial 23 with value: 637.3792114257812.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:45:25,641] Trial 19 finished with value: 10316.3310546875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003701594295050813, 'mc_samples_train': 1, 'prior_scale': 0.03808194315067731, 'q_scale': 0.00036097163276378226, 'obs_scale': 0.4892292458746359, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:47:41,297] Trial 16 finished with value: 320059.46875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001683729748744469, 'mc_samples_train': 1, 'prior_scale': 0.026612552748234822, 'q_scale': 0.0007044685825518345, 'obs_scale': 1.4053291800180558, 'batch_size': 512}. Best is trial 13 with value: 720.3123168945312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:47:43,876] Trial 27 finished with value: 590.4325561523438 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005683146419998195, 'mc_samples_train': 1, 'prior_scale': 0.011724639355855132, 'q_scale': 0.0009579743972305951, 'obs_scale': 1.9876720485296986, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:52:01,790] Trial 20 finished with value: 1329605.5 and parameters: {'pretrain_epochs': 5, 'lr': 0.00010473759024919465, 'mc_samples_train': 1, 'prior_scale': 0.010246740666581418, 'q_scale': 0.0007215206577361437, 'obs_scale': 0.8562819043114422, 'batch_size': 512}. Best is trial 12 with value: 776.678955078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:54:04,502] Trial 28 finished with value: 1438.01318359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005602798995992894, 'mc_samples_train': 1, 'prior_scale': 0.010863413973341444, 'q_scale': 0.0008358755116550276, 'obs_scale': 1.184947271453087, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:57:16,442] Trial 17 finished with value: 6767.63671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006667311236887355, 'mc_samples_train': 1, 'prior_scale': 0.011123480063279078, 'q_scale': 0.00021683415691757426, 'obs_scale': 0.5687662560496789, 'batch_size': 32}. Best is trial 13 with value: 720.3123168945312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:59:00,652] Trial 21 finished with value: 968.9089965820312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004121786448164478, 'mc_samples_train': 1, 'prior_scale': 0.016343793724636013, 'q_scale': 0.00011442720559890671, 'obs_scale': 1.734621732715612, 'batch_size': 32}. Best is trial 12 with value: 776.678955078125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 17:59:26,462] Trial 29 finished with value: 2048.53759765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006418837644781297, 'mc_samples_train': 1, 'prior_scale': 0.037945001551854755, 'q_scale': 0.000383518181805017, 'obs_scale': 0.9603409554779145, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:02:30,810] Trial 30 finished with value: 112529.796875 and parameters: {'pretrain_epochs': 5, 'lr': 9.413733942503548e-05, 'mc_samples_train': 1, 'prior_scale': 0.023116327972565267, 'q_scale': 0.0010290162292631712, 'obs_scale': 1.582033400644632, 'batch_size': 256}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:05:19,611] Trial 18 finished with value: 1888.0791015625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00025892224501798867, 'mc_samples_train': 1, 'prior_scale': 0.01915885342177043, 'q_scale': 0.00063226443133616, 'obs_scale': 1.2369081189299158, 'batch_size': 32}. Best is trial 13 with value: 720.3123168945312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:06:01,751] Trial 22 finished with value: 726.20751953125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005880352095816291, 'mc_samples_train': 1, 'prior_scale': 0.01383747815056773, 'q_scale': 0.00015118724848500536, 'obs_scale': 1.8276119359639478, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:08:23,455] Trial 31 finished with value: 743.370849609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00037573603422822203, 'mc_samples_train': 1, 'prior_scale': 0.012862435488620951, 'q_scale': 0.00030908930722823777, 'obs_scale': 1.9957207203174112, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:15:13,230] Trial 23 finished with value: 918.8363037109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.000616899165565531, 'mc_samples_train': 1, 'prior_scale': 0.021792872355222724, 'q_scale': 0.00016095497042568365, 'obs_scale': 1.4265500318413384, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:15:50,923] Trial 32 finished with value: 1212.9058837890625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006755234917060186, 'mc_samples_train': 1, 'prior_scale': 0.013487540745749404, 'q_scale': 0.001839951149469393, 'obs_scale': 1.2244340923839967, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:16:13,734] Trial 19 finished with value: 690.365478515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00042057639672998245, 'mc_samples_train': 1, 'prior_scale': 0.04513547759509135, 'q_scale': 0.00014728033278776402, 'obs_scale': 1.9441375642692655, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:23:30,045] Trial 33 finished with value: 1176.9498291015625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004053249192084928, 'mc_samples_train': 1, 'prior_scale': 0.01958667509003954, 'q_scale': 0.000186485561232912, 'obs_scale': 1.5555376660020968, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:25:40,619] Trial 24 finished with value: 1168.494384765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001930336031641678, 'mc_samples_train': 1, 'prior_scale': 0.010183231054645643, 'q_scale': 0.0002689014303713023, 'obs_scale': 1.9394656854437888, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:25:41,341] Trial 20 finished with value: 1406284.875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00010206086805682757, 'mc_samples_train': 1, 'prior_scale': 0.05440818108906184, 'q_scale': 0.00016402104069976838, 'obs_scale': 0.8397869221279838, 'batch_size': 512}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:28:38,824] Trial 34 finished with value: 546143.0625 and parameters: {'pretrain_epochs': 0, 'lr': 5.7136632515214375e-05, 'mc_samples_train': 1, 'prior_scale': 0.03250745828000775, 'q_scale': 0.0001383799274030019, 'obs_scale': 1.9715346020688125, 'batch_size': 512}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:33:28,466] Trial 25 finished with value: 12261.8818359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009893755800209887, 'mc_samples_train': 1, 'prior_scale': 0.01316851447651206, 'q_scale': 0.00010072387120472633, 'obs_scale': 0.9859424874656947, 'batch_size': 128}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:35:44,792] Trial 35 finished with value: 49454.21484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00024127118413134782, 'mc_samples_train': 2, 'prior_scale': 0.01237437220805146, 'q_scale': 0.0027061484579067327, 'obs_scale': 1.5928641366890424, 'batch_size': 256}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:37:32,642] Trial 21 finished with value: 743.9528198242188 and parameters: {'pretrain_epochs': 5, 'lr': 0.00041015852451963154, 'mc_samples_train': 1, 'prior_scale': 0.04449649483622215, 'q_scale': 0.0001250658331406937, 'obs_scale': 1.8578685437446543, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:41:22,011] Trial 36 finished with value: 45681.359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009896070429209322, 'mc_samples_train': 1, 'prior_scale': 0.05201170174823858, 'q_scale': 0.0008318262408417543, 'obs_scale': 0.33089571127845113, 'batch_size': 64}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:45:24,792] Trial 37 finished with value: 67325.953125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001328314988471751, 'mc_samples_train': 1, 'prior_scale': 0.016638583271667614, 'q_scale': 0.0013563922908611345, 'obs_scale': 1.1479967873339936, 'batch_size': 128}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:47:47,677] Trial 22 finished with value: 996.09521484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009754943333075779, 'mc_samples_train': 1, 'prior_scale': 0.04460899182040673, 'q_scale': 0.0003039037819303493, 'obs_scale': 1.3737994450999234, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:47:59,265] Trial 26 finished with value: 978.9827270507812 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002777502491744007, 'mc_samples_train': 2, 'prior_scale': 0.023029747498487643, 'q_scale': 0.00015840070760256788, 'obs_scale': 1.5033076126516498, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:54:17,478] Trial 38 finished with value: 4980.486328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000571682651570822, 'mc_samples_train': 2, 'prior_scale': 0.02142576992371981, 'q_scale': 0.0023753802014655555, 'obs_scale': 0.6007026505962428, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:55:45,253] Trial 27 finished with value: 1110.2958984375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006462239990099816, 'mc_samples_train': 1, 'prior_scale': 0.039164855551974256, 'q_scale': 0.0002842243619846405, 'obs_scale': 1.3118927838300352, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:57:25,451] Trial 23 finished with value: 848.3551635742188 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005186379518449633, 'mc_samples_train': 1, 'prior_scale': 0.03843216756347223, 'q_scale': 0.00016268424389528024, 'obs_scale': 1.5441415644308474, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 18:59:39,041] Trial 39 finished with value: 2317.898193359375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007736037821441898, 'mc_samples_train': 1, 'prior_scale': 0.012150303233325341, 'q_scale': 0.00023355156477377557, 'obs_scale': 1.3704892915134503, 'batch_size': 64}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:05:40,528] Trial 28 finished with value: 6881.70263671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00043079770241528416, 'mc_samples_train': 1, 'prior_scale': 0.017760483873465176, 'q_scale': 0.0005690864716985643, 'obs_scale': 0.5960392762208313, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:06:00,638] Trial 40 finished with value: 631372.3125 and parameters: {'pretrain_epochs': 5, 'lr': 2.8058268402712556e-05, 'mc_samples_train': 2, 'prior_scale': 0.04533861163761555, 'q_scale': 0.00040784703330132467, 'obs_scale': 1.0315140414821267, 'batch_size': 256}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:09:22,863] Trial 24 finished with value: 3363.364013671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00020784089936046128, 'mc_samples_train': 1, 'prior_scale': 0.02050998174635635, 'q_scale': 0.00014148544304917933, 'obs_scale': 1.004429053278709, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:13:26,049] Trial 41 finished with value: 729.94287109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.000349953513183158, 'mc_samples_train': 1, 'prior_scale': 0.012527228420994466, 'q_scale': 0.00030440208794001676, 'obs_scale': 1.9856568708826312, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:15:52,372] Trial 29 finished with value: 13511.9267578125 and parameters: {'pretrain_epochs': 5, 'lr': 7.261588679867827e-05, 'mc_samples_train': 1, 'prior_scale': 0.034192931955505435, 'q_scale': 0.000383518181805017, 'obs_scale': 1.0326152132412356, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:17:59,959] Trial 25 finished with value: 81325.1796875 and parameters: {'pretrain_epochs': 5, 'lr': 0.000361384064292424, 'mc_samples_train': 1, 'prior_scale': 0.06250540222971072, 'q_scale': 0.0004526070398440934, 'obs_scale': 0.5470120711533071, 'batch_size': 128}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:20:53,795] Trial 42 finished with value: 985.5684814453125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003659724504716335, 'mc_samples_train': 1, 'prior_scale': 0.010036648269580542, 'q_scale': 0.0005823167395014803, 'obs_scale': 1.7421772656444918, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:23:26,406] Trial 30 finished with value: 214068.71875 and parameters: {'pretrain_epochs': 5, 'lr': 4.0371445591997935e-05, 'mc_samples_train': 1, 'prior_scale': 0.013691393617555888, 'q_scale': 0.00013777450908262776, 'obs_scale': 1.6252621426611977, 'batch_size': 256}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:28:38,153] Trial 43 finished with value: 1492.4874267578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00015472507612813454, 'mc_samples_train': 1, 'prior_scale': 0.07666832790534799, 'q_scale': 0.00031196514000577893, 'obs_scale': 1.98641305847789, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:32:07,482] Trial 31 finished with value: 736.4790649414062 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003894044991879751, 'mc_samples_train': 1, 'prior_scale': 0.01353030891895818, 'q_scale': 0.00010008409358998365, 'obs_scale': 1.9957207203174112, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:34:54,097] Trial 44 finished with value: 1106.6483154296875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00024466865976015506, 'mc_samples_train': 1, 'prior_scale': 0.017581346856495525, 'q_scale': 0.00014126243401882358, 'obs_scale': 1.6448960958435905, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:36:00,846] Trial 26 finished with value: 867.1778564453125 and parameters: {'pretrain_epochs': 0, 'lr': 0.000612131580000748, 'mc_samples_train': 2, 'prior_scale': 0.02199866963366996, 'q_scale': 0.0002240033591427662, 'obs_scale': 1.5967477296657937, 'batch_size': 32}. Best is trial 19 with value: 690.365478515625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:39:08,554] Trial 32 finished with value: 800.996337890625 and parameters: {'pretrain_epochs': 5, 'lr': 0.000326839708001541, 'mc_samples_train': 1, 'prior_scale': 0.012905660677751013, 'q_scale': 0.00019119391382860042, 'obs_scale': 1.90985545737988, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:40:19,857] Trial 45 finished with value: 1341.3609619140625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00032562608133613214, 'mc_samples_train': 1, 'prior_scale': 0.014815414106136604, 'q_scale': 0.00046812667831672324, 'obs_scale': 1.4814776598382429, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:43:54,088] Trial 46 finished with value: 5778.1455078125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00044756171259208833, 'mc_samples_train': 1, 'prior_scale': 0.12191994168933055, 'q_scale': 0.009917072934430256, 'obs_scale': 1.7381471529353982, 'batch_size': 128}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:44:15,320] Trial 27 finished with value: 680.919677734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00034268773748172065, 'mc_samples_train': 1, 'prior_scale': 0.13350687499801, 'q_scale': 0.00014022198729040606, 'obs_scale': 1.9712468170042552, 'batch_size': 32}. Best is trial 27 with value: 680.919677734375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:46:34,111] Trial 33 finished with value: 2153.09912109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00020544831132778633, 'mc_samples_train': 1, 'prior_scale': 0.02120658331452482, 'q_scale': 0.00013936544401538933, 'obs_scale': 1.270929739981464, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-22 19:49:21,806] Trial 47 pruned. Trial was pruned at epoch 15.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:54:22,859] Trial 48 finished with value: 205827936.0 and parameters: {'pretrain_epochs': 0, 'lr': 1.0125058472109033e-05, 'mc_samples_train': 1, 'prior_scale': 0.06159890209393115, 'q_scale': 0.0008246276243834558, 'obs_scale': 0.10493102734335331, 'batch_size': 512}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:54:34,434] Trial 34 finished with value: 654602.75 and parameters: {'pretrain_epochs': 0, 'lr': 0.00012521946164260973, 'mc_samples_train': 1, 'prior_scale': 0.012051794065957343, 'q_scale': 0.0002796168896445895, 'obs_scale': 1.6292551147629337, 'batch_size': 512}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 19:55:04,571] Trial 28 finished with value: 8698.59765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001347726731728479, 'mc_samples_train': 1, 'prior_scale': 0.30186663651042894, 'q_scale': 0.00019594652269900464, 'obs_scale': 0.9334482210700186, 'batch_size': 32}. Best is trial 27 with value: 680.919677734375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:02:10,642] Trial 49 finished with value: 3293.40087890625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005731371803020752, 'mc_samples_train': 2, 'prior_scale': 0.3095805198996549, 'q_scale': 0.00019590321361180577, 'obs_scale': 1.2063339076536317, 'batch_size': 64}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:05:49,134] Trial 35 finished with value: 38579.96875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005679353248756998, 'mc_samples_train': 2, 'prior_scale': 0.01735247221022188, 'q_scale': 0.00013953729477277175, 'obs_scale': 1.2107130886509252, 'batch_size': 256}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:07:11,426] Trial 29 finished with value: 1806.1412353515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002855848280483259, 'mc_samples_train': 1, 'prior_scale': 0.11879521903975161, 'q_scale': 0.000383518181805017, 'obs_scale': 1.202433784907586, 'batch_size': 32}. Best is trial 27 with value: 680.919677734375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:10:10,074] Trial 50 finished with value: 4109.27734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00022114591870620205, 'mc_samples_train': 1, 'prior_scale': 0.02882359636973336, 'q_scale': 0.0002498943926852687, 'obs_scale': 0.8750240763456418, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:14:09,063] Trial 36 finished with value: 4226.73046875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008033299203199361, 'mc_samples_train': 1, 'prior_scale': 0.02625194252546978, 'q_scale': 0.00022184963038258764, 'obs_scale': 0.9881913507201647, 'batch_size': 64}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:16:03,980] Trial 30 finished with value: 1896791.25 and parameters: {'pretrain_epochs': 5, 'lr': 9.413733942503548e-05, 'mc_samples_train': 1, 'prior_scale': 0.16618356173953924, 'q_scale': 0.00030383565762676903, 'obs_scale': 0.38486358375352286, 'batch_size': 256}. Best is trial 27 with value: 680.919677734375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:18:01,392] Trial 51 finished with value: 819.7391357421875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003451108476784136, 'mc_samples_train': 1, 'prior_scale': 0.013330351320104935, 'q_scale': 0.00029667197030654966, 'obs_scale': 1.8641794732029495, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:21:15,708] Trial 37 finished with value: 3192569.0 and parameters: {'pretrain_epochs': 0, 'lr': 5.1808411700953774e-05, 'mc_samples_train': 1, 'prior_scale': 0.05517482156228239, 'q_scale': 0.00010150436996174803, 'obs_scale': 0.3290253114763252, 'batch_size': 128}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:25:58,139] Trial 52 finished with value: 816.64990234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004035227861486304, 'mc_samples_train': 1, 'prior_scale': 0.011992400470082954, 'q_scale': 0.0003458283742152302, 'obs_scale': 1.9912974832744732, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:26:20,674] Trial 31 finished with value: 658.057373046875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00037724211667847056, 'mc_samples_train': 1, 'prior_scale': 0.08615632817991781, 'q_scale': 0.00011083344999131202, 'obs_scale': 1.9957207203174112, 'batch_size': 32}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:32:12,087] Trial 53 finished with value: 766.806396484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00044327268713905684, 'mc_samples_train': 1, 'prior_scale': 0.015325754590104058, 'q_scale': 0.0005482741471710519, 'obs_scale': 1.7389289395526306, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:33:50,519] Trial 38 finished with value: 891.9249877929688 and parameters: {'pretrain_epochs': 5, 'lr': 0.00021511909075113173, 'mc_samples_train': 2, 'prior_scale': 0.01727305807347665, 'q_scale': 0.0001777941439844303, 'obs_scale': 1.9911064648055485, 'batch_size': 32}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:36:05,326] Trial 32 finished with value: 890.743896484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006182721622361482, 'mc_samples_train': 1, 'prior_scale': 0.08113763521713255, 'q_scale': 0.00013723994692925727, 'obs_scale': 1.5042717182749339, 'batch_size': 32}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:39:30,622] Trial 54 finished with value: 1550.296630859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00027320998793412357, 'mc_samples_train': 1, 'prior_scale': 0.011487023105323967, 'q_scale': 0.0006918291618565326, 'obs_scale': 1.3431011775320714, 'batch_size': 32}. Best is trial 27 with value: 590.4325561523438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:42:12,650] Trial 39 finished with value: 1760.689208984375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007296627133796101, 'mc_samples_train': 1, 'prior_scale': 0.01170164353463471, 'q_scale': 0.00012870195450164626, 'obs_scale': 1.5411831326512875, 'batch_size': 64}. Best is trial 22 with value: 726.20751953125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:47:10,329] Trial 55 finished with value: 550.9259643554688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006219940986922599, 'mc_samples_train': 1, 'prior_scale': 0.019304840938175787, 'q_scale': 0.00012042546962084434, 'obs_scale': 1.9956938459466813, 'batch_size': 32}. Best is trial 55 with value: 550.9259643554688.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:48:06,996] Trial 33 finished with value: 934.4185180664062 and parameters: {'pretrain_epochs': 5, 'lr': 0.00020044317823543744, 'mc_samples_train': 1, 'prior_scale': 0.1383593126707591, 'q_scale': 0.00014116835889675628, 'obs_scale': 1.9821651880576137, 'batch_size': 32}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:53:41,719] Trial 40 finished with value: 245997.40625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00015501622022815785, 'mc_samples_train': 2, 'prior_scale': 0.1395558122659741, 'q_scale': 0.007017503092058898, 'obs_scale': 0.845134260162153, 'batch_size': 256}. Best is trial 22 with value: 726.20751953125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 20:55:13,629] Trial 56 finished with value: 964.4190063476562 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006197009984473533, 'mc_samples_train': 1, 'prior_scale': 0.018694309285940156, 'q_scale': 0.0001001055306325219, 'obs_scale': 1.4771733729498977, 'batch_size': 32}. Best is trial 55 with value: 550.9259643554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 21:46:55,981] Trial 34 finished with value: 1122208.375 and parameters: {'pretrain_epochs': 0, 'lr': 5.645071308639178e-05, 'mc_samples_train': 1, 'prior_scale': 0.2537858214206979, 'q_scale': 0.0002586124744798167, 'obs_scale': 1.3076415346726225, 'batch_size': 512}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:04:29,749] Trial 41 finished with value: 680.0294189453125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00040451827595905154, 'mc_samples_train': 1, 'prior_scale': 0.015888289321045888, 'q_scale': 0.0001149510996291409, 'obs_scale': 1.9641055674529189, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
[I 2024-05-22 22:04:29,787] Trial 57 finished with value: 1133.2955322265625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008590282959831493, 'mc_samples_train': 1, 'prior_scale': 0.016845855413684382, 'q_scale': 0.00012190285974560626, 'obs_scale': 1.7474768401875425, 'batch_size': 32}. Best is trial 55 with value: 550.9259643554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:09:50,370] Trial 35 finished with value: 37685.30859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00033764632090106005, 'mc_samples_train': 2, 'prior_scale': 0.0881700593887085, 'q_scale': 0.00010339324880286789, 'obs_scale': 1.6328033783551288, 'batch_size': 256}. Best is trial 31 with value: 658.057373046875.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:11:09,538] Trial 58 finished with value: 1220.6507568359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004962228082812997, 'mc_samples_train': 1, 'prior_scale': 0.021007279455667934, 'q_scale': 0.00014987421380106478, 'obs_scale': 1.289639284054054, 'batch_size': 32}. Best is trial 55 with value: 550.9259643554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:13:44,835] Trial 42 finished with value: 727.9373779296875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005214930762188104, 'mc_samples_train': 1, 'prior_scale': 0.015020055919404706, 'q_scale': 0.002519127803750831, 'obs_scale': 1.7436796665361407, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:15:34,060] Trial 59 finished with value: 4306.30517578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007430426655405592, 'mc_samples_train': 1, 'prior_scale': 0.01552910379968333, 'q_scale': 0.00020854998353134956, 'obs_scale': 1.5744896916653908, 'batch_size': 128}. Best is trial 55 with value: 550.9259643554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:19:02,227] Trial 36 finished with value: 4775.17529296875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007701732359305075, 'mc_samples_train': 1, 'prior_scale': 0.06891722085117026, 'q_scale': 0.00018250928399115177, 'obs_scale': 1.0935812533543752, 'batch_size': 64}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:24:17,594] Trial 43 finished with value: 2025.3328857421875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00036634835696837344, 'mc_samples_train': 1, 'prior_scale': 0.022335553045198967, 'q_scale': 0.002722100355528591, 'obs_scale': 1.1153308483703235, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:27:29,145] Trial 37 finished with value: 179911.859375 and parameters: {'pretrain_epochs': 0, 'lr': 0.00045377455163297985, 'mc_samples_train': 1, 'prior_scale': 0.14387266786224442, 'q_scale': 0.00022387715837433864, 'obs_scale': 0.3213143676878045, 'batch_size': 128}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:34:34,655] Trial 44 finished with value: 1040.9639892578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008430387490643767, 'mc_samples_train': 1, 'prior_scale': 0.014601507381045247, 'q_scale': 0.00242554412341212, 'obs_scale': 1.5776475201112252, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:44:27,443] Trial 45 finished with value: 898.1441040039062 and parameters: {'pretrain_epochs': 5, 'lr': 0.00031178766127198064, 'mc_samples_train': 1, 'prior_scale': 0.03368309140709333, 'q_scale': 0.0011106907247158523, 'obs_scale': 1.7246782256092907, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:46:50,917] Trial 38 finished with value: 2335.818115234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001587152838282217, 'mc_samples_train': 2, 'prior_scale': 0.0975710312307657, 'q_scale': 0.009744065344450499, 'obs_scale': 1.651953624625043, 'batch_size': 32}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:49:50,532] Trial 46 finished with value: 176109.34375 and parameters: {'pretrain_epochs': 5, 'lr': 1.6647997355041245e-05, 'mc_samples_train': 1, 'prior_scale': 0.019386548469311815, 'q_scale': 0.009917072934430256, 'obs_scale': 1.4421342009110614, 'batch_size': 128}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:53:45,950] Trial 39 finished with value: 97229.421875 and parameters: {'pretrain_epochs': 0, 'lr': 3.02463835855464e-05, 'mc_samples_train': 1, 'prior_scale': 0.05153005594004817, 'q_scale': 0.000707756895607922, 'obs_scale': 1.2092325444567655, 'batch_size': 64}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 22:56:08,540] Trial 47 finished with value: 33043.61328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005000030063609728, 'mc_samples_train': 1, 'prior_scale': 0.0153504230828757, 'q_scale': 0.0015278949968701198, 'obs_scale': 0.24475714353863257, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:00:58,486] Trial 48 finished with value: 279198.90625 and parameters: {'pretrain_epochs': 0, 'lr': 0.00023514527301492604, 'mc_samples_train': 1, 'prior_scale': 0.07558749672596717, 'q_scale': 0.004455007082221431, 'obs_scale': 1.9987081525642132, 'batch_size': 512}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:03:03,881] Trial 40 finished with value: 64423.1953125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00021962240115490684, 'mc_samples_train': 2, 'prior_scale': 0.11872376976969669, 'q_scale': 0.0010065059072036908, 'obs_scale': 1.4359763305825983, 'batch_size': 256}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:12:29,808] Trial 49 finished with value: 4654.98095703125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00045782231024210635, 'mc_samples_train': 2, 'prior_scale': 0.3034162361807333, 'q_scale': 0.0021812199316917067, 'obs_scale': 1.13048964491048, 'batch_size': 64}. Best is trial 41 with value: 680.0294189453125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:14:11,996] Trial 41 finished with value: 772.0088500976562 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004147682822632012, 'mc_samples_train': 1, 'prior_scale': 0.03550556936671807, 'q_scale': 0.0001250637829753569, 'obs_scale': 1.7760530650067485, 'batch_size': 32}. Best is trial 31 with value: 658.057373046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:22:40,911] Trial 50 finished with value: 885.9912719726562 and parameters: {'pretrain_epochs': 5, 'lr': 0.00032003261420354766, 'mc_samples_train': 1, 'prior_scale': 0.02473178955019059, 'q_scale': 0.0008668929322826986, 'obs_scale': 1.7615159041733282, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:25:50,689] Trial 42 finished with value: 593.6179809570312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007810047860749132, 'mc_samples_train': 1, 'prior_scale': 0.04318519439283112, 'q_scale': 0.00012870414677389127, 'obs_scale': 1.9675337900009708, 'batch_size': 32}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:32:41,964] Trial 51 finished with value: 859.3363037109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005474295640117114, 'mc_samples_train': 1, 'prior_scale': 0.011470381307059721, 'q_scale': 0.00011605023354401883, 'obs_scale': 1.7838149374981098, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:37:27,383] Trial 43 finished with value: 720.563720703125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008056697292903502, 'mc_samples_train': 1, 'prior_scale': 0.025699577311342137, 'q_scale': 0.002006732782072307, 'obs_scale': 1.9861790380217328, 'batch_size': 32}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:41:25,304] Trial 52 finished with value: 1206.8226318359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00042462338510173734, 'mc_samples_train': 1, 'prior_scale': 0.014825839777149567, 'q_scale': 0.0034188829494454036, 'obs_scale': 1.4812875840542081, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:46:24,682] Trial 44 finished with value: 722.9857177734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006478625121376178, 'mc_samples_train': 1, 'prior_scale': 0.07428574458274138, 'q_scale': 0.00012899596823320278, 'obs_scale': 1.686769533427846, 'batch_size': 32}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:49:04,090] Trial 53 finished with value: 1269.81298828125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007023212502522071, 'mc_samples_train': 1, 'prior_scale': 0.01008952168909717, 'q_scale': 0.00017261227333159924, 'obs_scale': 1.3000707628517831, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-05-22 23:52:07,723] Trial 45 pruned. Trial was pruned at epoch 10.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-22 23:58:46,216] Trial 54 finished with value: 841.1301879882812 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005389142331893278, 'mc_samples_train': 1, 'prior_scale': 0.012549141329505303, 'q_scale': 0.0001233911556013389, 'obs_scale': 1.7489597293517558, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:00:36,567] Trial 46 finished with value: 33755564.0 and parameters: {'pretrain_epochs': 5, 'lr': 1.6647997355041245e-05, 'mc_samples_train': 1, 'prior_scale': 0.19245222250425484, 'q_scale': 0.00010273764031960835, 'obs_scale': 0.10383863119825384, 'batch_size': 128}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:08:37,170] Trial 55 finished with value: 1308.8853759765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00036010266508100763, 'mc_samples_train': 1, 'prior_scale': 0.01880161854590529, 'q_scale': 0.00010163835322607116, 'obs_scale': 1.384295109298179, 'batch_size': 32}. Best is trial 41 with value: 680.0294189453125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:12:07,092] Trial 47 finished with value: 843.499755859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005071956098225479, 'mc_samples_train': 1, 'prior_scale': 0.09921952609003644, 'q_scale': 0.00028392569299672714, 'obs_scale': 1.7484088541346527, 'batch_size': 32}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:18:34,580] Trial 56 finished with value: 651.39208984375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009920904418008203, 'mc_samples_train': 1, 'prior_scale': 0.015834431631814645, 'q_scale': 0.0002195319273688266, 'obs_scale': 1.9850125242998247, 'batch_size': 32}. Best is trial 56 with value: 651.39208984375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:21:11,096] Trial 48 finished with value: 356544.5 and parameters: {'pretrain_epochs': 0, 'lr': 0.00031944374687674804, 'mc_samples_train': 1, 'prior_scale': 0.04443717002399295, 'q_scale': 0.003694506284832779, 'obs_scale': 1.4234241618049004, 'batch_size': 512}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:27:27,109] Trial 57 finished with value: 556.8133544921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009267983041934168, 'mc_samples_train': 1, 'prior_scale': 0.030984114521291753, 'q_scale': 0.00024389873385404843, 'obs_scale': 1.9924356424583411, 'batch_size': 32}. Best is trial 57 with value: 556.8133544921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:32:59,850] Trial 49 finished with value: 5316.87548828125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000759517264798783, 'mc_samples_train': 2, 'prior_scale': 0.013123260103604302, 'q_scale': 0.0003628548960640439, 'obs_scale': 1.1226946786306582, 'batch_size': 64}. Best is trial 42 with value: 593.6179809570312.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:34:19,141] Trial 58 finished with value: 839.81591796875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008608728796669692, 'mc_samples_train': 1, 'prior_scale': 0.030468192086969794, 'q_scale': 0.00048799652256171973, 'obs_scale': 1.6161199919786695, 'batch_size': 32}. Best is trial 57 with value: 556.8133544921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:41:20,161] Trial 50 finished with value: 5304.5986328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00024378720151448232, 'mc_samples_train': 1, 'prior_scale': 0.23919557173538825, 'q_scale': 0.0002063663205309124, 'obs_scale': 0.7293822188161447, 'batch_size': 32}. Best is trial 42 with value: 593.6179809570312.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:41:34,217] Trial 59 finished with value: 479.66717529296875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009353211528609264, 'mc_samples_train': 1, 'prior_scale': 0.05416915652084484, 'q_scale': 0.0002524916845030664, 'obs_scale': 1.9887188949483918, 'batch_size': 32}. Best is trial 59 with value: 479.66717529296875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 00:52:23,113] Trial 51 finished with value: 572.227783203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00081867670903763, 'mc_samples_train': 1, 'prior_scale': 0.02627267629622565, 'q_scale': 0.0016889254913482973, 'obs_scale': 1.8647624957571036, 'batch_size': 32}. Best is trial 51 with value: 572.227783203125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:03:26,272] Trial 52 finished with value: 628.3329467773438 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005685515000213217, 'mc_samples_train': 1, 'prior_scale': 0.0293816093816879, 'q_scale': 0.0016693365418859625, 'obs_scale': 1.9910292463505115, 'batch_size': 32}. Best is trial 51 with value: 572.227783203125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:14:33,136] Trial 53 finished with value: 506.33447265625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005894995427734614, 'mc_samples_train': 1, 'prior_scale': 0.03104318658943063, 'q_scale': 0.0014169641144098904, 'obs_scale': 1.9934422652306438, 'batch_size': 32}. Best is trial 53 with value: 506.33447265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:23:13,524] Trial 54 finished with value: 864.670166015625 and parameters: {'pretrain_epochs': 5, 'lr': 0.000596489922045517, 'mc_samples_train': 1, 'prior_scale': 0.02977984540693044, 'q_scale': 0.001390811259393993, 'obs_scale': 1.5505880236737892, 'batch_size': 32}. Best is trial 53 with value: 506.33447265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:32:59,813] Trial 55 finished with value: 697.4493408203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007436459797281506, 'mc_samples_train': 1, 'prior_scale': 0.02327150100095462, 'q_scale': 0.002414394972963518, 'obs_scale': 1.7548409369784226, 'batch_size': 32}. Best is trial 53 with value: 506.33447265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:44:09,242] Trial 56 finished with value: 1410.1312255859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005525278878259838, 'mc_samples_train': 1, 'prior_scale': 0.036293238376466, 'q_scale': 0.001706471075835497, 'obs_scale': 1.3295365154982335, 'batch_size': 32}. Best is trial 53 with value: 506.33447265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 01:55:19,285] Trial 57 finished with value: 488.57672119140625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008467463981896237, 'mc_samples_train': 1, 'prior_scale': 0.017679470674952433, 'q_scale': 0.0012007407924031427, 'obs_scale': 1.9927528153403078, 'batch_size': 32}. Best is trial 57 with value: 488.57672119140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 02:04:44,588] Trial 58 finished with value: 850.5870971679688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007877827882724085, 'mc_samples_train': 1, 'prior_scale': 0.01746513899542512, 'q_scale': 0.0012284860487117909, 'obs_scale': 1.7771063143050858, 'batch_size': 32}. Best is trial 57 with value: 488.57672119140625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-05-23 02:12:32,210] Trial 59 finished with value: 962.2722778320312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009273679197537135, 'mc_samples_train': 1, 'prior_scale': 0.017238705994767664, 'q_scale': 0.003083385037917059, 'obs_scale': 1.479567328209994, 'batch_size': 32}. Best is trial 57 with value: 488.57672119140625.
