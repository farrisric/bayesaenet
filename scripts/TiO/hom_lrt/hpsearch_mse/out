{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 2000, 'max_epochs': 500, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-05-19 15:19:30,473[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-05-19 15:19:30,542[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/hom_lrt_mse.db[0m
[[36m2025-05-19 15:19:47,825[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-05-19 15:19:48,009[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-05-19 15:19:48,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 15:19:48,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-05-19 15:19:48,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 15:19:48,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.10040381100861 prior_scale[0m
[[36m2025-05-19 15:19:49,201[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021873960541613266 q_scale[0m
[[36m2025-05-19 15:19:49,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002306550812550155 obs_scale[0m
[[36m2025-05-19 15:19:49,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-19 15:19:49,612[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-05-19 15:19:49,613[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 15:19:49,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 15:20:01,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 15:20:01,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 15:20:01,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 15:20:01,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 15:20:01,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 15:20:01,442[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 15:20:02,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 15:20:02,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 15:20:02,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 15:20:02,961[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 15:20:06,654[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 •       38.37it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1743.555         
                                                               rmse/train:      
                                                               1811.548         
[[36m2025-05-19 15:40:28,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 15:40:28,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/000[0m
[[36m2025-05-19 15:40:28,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 15:40:28,957[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010045932391231576, lr[0m
[[36m2025-05-19 15:40:29,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-19 15:40:29,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.3455827269243748 prior_scale[0m
[[36m2025-05-19 15:40:29,391[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004826013786176772 q_scale[0m
[[36m2025-05-19 15:40:29,724[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03276542658291345 obs_scale[0m
[[36m2025-05-19 15:40:29,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-19 15:40:29,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-05-19 15:40:29,946[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 15:40:29,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 15:40:37,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 15:40:37,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 15:40:37,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 15:40:37,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 15:40:37,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 15:40:37,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 15:40:37,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 15:40:37,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 15:40:37,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 15:40:45,982[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 15:40:46,474[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 •       14.83it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 121.950
                                                               rmse/train:      
                                                               115.814          
[[36m2025-05-19 16:09:59,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 16:09:59,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/001[0m
[[36m2025-05-19 16:10:00,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 16:10:00,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4150196905720475e-05, lr[0m
[[36m2025-05-19 16:10:00,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-19 16:10:00,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.48103301026688 prior_scale[0m
[[36m2025-05-19 16:10:00,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015545608747938977 q_scale[0m
[[36m2025-05-19 16:10:01,021[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8783158391722686 obs_scale[0m
[[36m2025-05-19 16:10:01,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-19 16:10:01,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-05-19 16:10:01,034[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 16:10:01,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 16:10:07,838[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 16:10:07,843[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 16:10:07,844[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 16:10:07,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 16:10:07,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 16:10:07,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 16:10:07,847[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 16:10:07,847[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 16:10:07,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 16:10:13,945[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 16:10:14,224[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       20.75it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1183.039         
                                                               rmse/train:      
                                                               1131.398         
[[36m2025-05-19 16:37:10,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 16:37:10,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/002[0m
[[36m2025-05-19 16:37:10,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 16:37:10,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9388028480984598e-05, lr[0m
[[36m2025-05-19 16:37:10,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-19 16:37:10,707[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.6549775453786335 prior_scale[0m
[[36m2025-05-19 16:37:10,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.059511772548294796 q_scale[0m
[[36m2025-05-19 16:37:10,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016244403817471303 obs_scale[0m
[[36m2025-05-19 16:37:11,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-19 16:37:11,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-05-19 16:37:11,073[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 16:37:11,073[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 16:37:16,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 16:37:16,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 16:37:16,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 16:37:17,004[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 16:37:17,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 16:37:17,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 16:37:17,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 16:37:17,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 16:37:17,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 16:37:17,373[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 16:37:17,476[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:05 •       33.40it/s v_num: 0.000    
                                      0:00:00                   rmse/val:       
                                                                178.059         
                                                                rmse/train:     
                                                                306.092         
[[36m2025-05-19 18:02:58,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:02:58,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/003[0m
[[36m2025-05-19 18:02:59,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:02:59,449[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001546142648648772, lr[0m
[[36m2025-05-19 18:02:59,500[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 18:02:59,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6427811454849492 prior_scale[0m
[[36m2025-05-19 18:02:59,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009750016190297515 q_scale[0m
[[36m2025-05-19 18:02:59,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0327215724382531 obs_scale[0m
[[36m2025-05-19 18:02:59,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-19 18:02:59,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-05-19 18:02:59,835[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:02:59,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:03:09,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:03:09,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:03:09,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:03:09,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:03:09,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:03:09,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:03:09,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:03:09,457[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:03:09,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:03:16,226[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:03:16,541[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 •       36.17it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 342.489
                                                               rmse/train:      
                                                               294.713          
[[36m2025-05-19 18:12:41,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:12:41,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/004[0m
[[36m2025-05-19 18:12:41,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:12:41,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006671842305866796, lr[0m
[[36m2025-05-19 18:12:41,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-19 18:12:41,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.094980288423564 prior_scale[0m
[[36m2025-05-19 18:12:41,939[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02376251510147171 q_scale[0m
[[36m2025-05-19 18:12:42,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026684237668138052 obs_scale[0m
[[36m2025-05-19 18:12:42,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-19 18:12:42,049[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-05-19 18:12:42,049[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:12:42,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:12:48,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:12:48,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:12:48,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:12:48,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:12:48,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:12:48,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:12:48,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:12:48,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:12:48,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:12:48,168[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:12:48,245[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 81/499 ━━━━━━━━━━━━━━━ 198/198 0:00:06 •       32.95it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1217.198         
                                                               rmse/train:      
                                                               1097.384         
[[36m2025-05-19 18:25:42,404[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 81.
[[36m2025-05-19 18:25:42,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:25:43,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:25:43,743[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.003810848108467e-05, lr[0m
[[36m2025-05-19 18:25:43,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 18:25:43,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.316378855976843 prior_scale[0m
[[36m2025-05-19 18:25:44,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016427412719943545 q_scale[0m
[[36m2025-05-19 18:25:44,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08640088029719115 obs_scale[0m
[[36m2025-05-19 18:25:44,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 18:25:44,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-05-19 18:25:44,111[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:25:44,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:25:50,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:25:50,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:25:50,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:25:50,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:25:50,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:25:50,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:25:50,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:25:50,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:25:50,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:25:50,824[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:25:51,024[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 •       22.53it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 126.606
                                                               rmse/train:      
                                                               186.686          
[[36m2025-05-19 18:38:46,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:38:46,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/006[0m
[[36m2025-05-19 18:38:46,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:38:46,744[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011795146111975982, lr[0m
[[36m2025-05-19 18:38:46,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-19 18:38:46,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.734595987222456 prior_scale[0m
[[36m2025-05-19 18:38:47,035[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006861941183128952 q_scale[0m
[[36m2025-05-19 18:38:47,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.8993334643772415 obs_scale[0m
[[36m2025-05-19 18:38:47,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-19 18:38:47,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-05-19 18:38:47,264[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:38:47,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:38:56,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:38:56,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:38:56,468[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:38:56,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:38:56,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:38:56,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:38:56,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:38:56,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:38:56,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:38:56,511[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:38:56,698[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 300/499 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 •       14.10it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 401.230
                                                               rmse/train:      
                                                               355.228          
[[36m2025-05-19 18:47:12,597[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 300.
[[36m2025-05-19 18:47:12,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:47:13,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:47:13,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018511923116382368, lr[0m
[[36m2025-05-19 18:47:13,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 18:47:13,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.701771566369369 prior_scale[0m
[[36m2025-05-19 18:47:13,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003843021664581486 q_scale[0m
[[36m2025-05-19 18:47:13,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.716679159905746 obs_scale[0m
[[36m2025-05-19 18:47:13,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 18:47:13,867[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-05-19 18:47:13,867[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:47:13,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:47:27,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:47:27,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:47:27,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:47:27,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:47:27,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:47:27,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:47:27,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:47:27,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:47:27,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:47:27,453[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:47:27,598[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 367/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       32.34it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 331.776
                                                               rmse/train:      
                                                               317.056          
[[36m2025-05-19 18:57:44,098[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 367.
[[36m2025-05-19 18:57:44,360[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 18:57:44,795[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 18:57:44,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021819434272647882, lr[0m
[[36m2025-05-19 18:57:45,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 18:57:45,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.26422262434414 prior_scale[0m
[[36m2025-05-19 18:57:45,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004712837715557199 q_scale[0m
[[36m2025-05-19 18:57:45,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.7481178717922905 obs_scale[0m
[[36m2025-05-19 18:57:45,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-19 18:57:45,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-05-19 18:57:45,384[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 18:57:45,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 18:57:52,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 18:57:52,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 18:57:52,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 18:57:52,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 18:57:52,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 18:57:52,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 18:57:52,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 18:57:52,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 18:57:52,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 18:57:54,531[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 18:57:54,973[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 345/499 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 •       26.26it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1199.935         
                                                               rmse/train:      
                                                               993.314          
[[36m2025-05-19 19:04:37,788[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 345.
[[36m2025-05-19 19:04:38,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 19:04:38,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 19:04:38,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.431481131993091e-05, lr[0m
[[36m2025-05-19 19:04:38,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 19:04:39,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0132755975870396 prior_scale[0m
[[36m2025-05-19 19:04:39,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001260198917475352 q_scale[0m
[[36m2025-05-19 19:04:39,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015454185486459525 obs_scale[0m
[[36m2025-05-19 19:04:39,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 19:04:39,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-05-19 19:04:39,463[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 19:04:39,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 19:04:48,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 19:04:48,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 19:04:48,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 19:04:48,072[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 19:04:48,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 19:04:48,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 19:04:48,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 19:04:48,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 19:04:48,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 19:04:48,122[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 19:04:48,346[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       27.07it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 20.981 
                                                               rmse/train:      
                                                               20.249           
[[36m2025-05-19 19:16:47,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 19:16:47,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/010[0m
[[36m2025-05-19 19:16:47,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 19:16:47,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.816070130846141e-05, lr[0m
[[36m2025-05-19 19:16:48,021[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 19:16:48,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0619619070483661 prior_scale[0m
[[36m2025-05-19 19:16:48,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011194175253017673 q_scale[0m
[[36m2025-05-19 19:16:48,122[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015895472762180737 obs_scale[0m
[[36m2025-05-19 19:16:48,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 19:16:48,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-05-19 19:16:48,163[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 19:16:48,163[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 19:16:56,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 19:16:56,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 19:16:56,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 19:16:56,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 19:16:56,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 19:16:56,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 19:16:56,164[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 19:16:56,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 19:16:56,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 19:16:56,219[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 19:16:56,596[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       50.10it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 41.256 
                                                               rmse/train:      
                                                               36.115           
[[36m2025-05-19 19:29:06,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 19:29:06,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/011[0m
[[36m2025-05-19 19:29:06,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 19:29:07,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3313056814979015e-05, lr[0m
[[36m2025-05-19 19:29:07,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 19:29:07,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0336274761153312 prior_scale[0m
[[36m2025-05-19 19:29:07,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012040916068725981 q_scale[0m
[[36m2025-05-19 19:29:07,391[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020466389673667624 obs_scale[0m
[[36m2025-05-19 19:29:07,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 19:29:07,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-05-19 19:29:07,598[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 19:29:07,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 19:29:14,104[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 19:29:14,113[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 19:29:14,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 19:29:14,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 19:29:14,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 19:29:14,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 19:29:14,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 19:29:14,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 19:29:14,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 19:29:14,284[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 19:29:14,703[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:01 •       51.32it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 20.308 
                                                               rmse/train:      
                                                               18.712           
[[36m2025-05-19 19:56:41,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 19:56:41,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/012[0m
[[36m2025-05-19 19:56:41,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 19:56:41,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.370227457124088e-05, lr[0m
[[36m2025-05-19 19:56:41,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 19:56:42,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7149884916460885 prior_scale[0m
[[36m2025-05-19 19:56:42,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011525548279505863 q_scale[0m
[[36m2025-05-19 19:56:42,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011127365489632469 obs_scale[0m
[[36m2025-05-19 19:56:42,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 19:56:42,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-05-19 19:56:42,321[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 19:56:42,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 19:56:48,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 19:56:48,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 19:56:48,808[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 19:56:48,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 19:56:48,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 19:56:48,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 19:56:48,836[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 19:56:48,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 19:56:48,837[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 19:56:49,331[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 19:56:49,694[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:02 •       44.20it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 66.001 
                                                               rmse/train:      
                                                               58.121           
[[36m2025-05-19 20:24:52,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 20:24:52,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/013[0m
[[36m2025-05-19 20:24:53,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 20:24:53,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.653531126105079e-05, lr[0m
[[36m2025-05-19 20:24:53,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 20:24:53,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.030768078033871 prior_scale[0m
[[36m2025-05-19 20:24:53,317[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004129381276126507 q_scale[0m
[[36m2025-05-19 20:24:53,526[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006468067956684026 obs_scale[0m
[[36m2025-05-19 20:24:53,645[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 20:24:53,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-05-19 20:24:53,646[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 20:24:53,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 20:25:00,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 20:25:00,513[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 20:25:00,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 20:25:00,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 20:25:00,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 20:25:00,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 20:25:00,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 20:25:00,517[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 20:25:00,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 20:25:00,744[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 20:25:00,995[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:01 •       52.19it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 25.344 
                                                               rmse/train:      
                                                               24.001           
[[36m2025-05-19 20:52:30,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 20:52:30,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/014[0m
[[36m2025-05-19 20:52:30,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 20:52:30,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.001320564304096e-05, lr[0m
[[36m2025-05-19 20:52:30,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 20:52:30,977[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8903929251777563 prior_scale[0m
[[36m2025-05-19 20:52:31,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035809070187242095 q_scale[0m
[[36m2025-05-19 20:52:31,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006302105125216368 obs_scale[0m
[[36m2025-05-19 20:52:31,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 20:52:31,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-05-19 20:52:31,228[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 20:52:31,228[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 20:52:38,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 20:52:38,120[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 20:52:38,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 20:52:38,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 20:52:38,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 20:52:38,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 20:52:38,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 20:52:38,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 20:52:38,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 20:52:41,535[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 20:52:41,686[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:02 •       38.88it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 215.579
                                                               rmse/train:      
                                                               203.310          
[[36m2025-05-19 21:23:17,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 21:23:17,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/015[0m
[[36m2025-05-19 21:23:18,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 21:23:18,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.22446797581201e-05, lr[0m
[[36m2025-05-19 21:23:18,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 21:23:18,720[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4016045028743804 prior_scale[0m
[[36m2025-05-19 21:23:18,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023497592973673872 q_scale[0m
[[36m2025-05-19 21:23:18,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004576883019588775 obs_scale[0m
[[36m2025-05-19 21:23:18,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 21:23:18,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-05-19 21:23:18,985[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 21:23:18,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 21:23:25,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 21:23:25,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 21:23:25,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 21:23:25,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 21:23:25,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 21:23:25,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 21:23:25,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 21:23:25,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 21:23:25,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 21:23:26,403[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 21:23:26,626[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       42.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 57.253 
                                                               rmse/train:      
                                                               53.771           
[[36m2025-05-19 21:34:55,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 21:34:55,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/016[0m
[[36m2025-05-19 21:34:55,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 21:34:55,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038765931042035386, lr[0m
[[36m2025-05-19 21:34:55,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 21:34:55,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.2557471713427977 prior_scale[0m
[[36m2025-05-19 21:34:55,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009436018632304442 q_scale[0m
[[36m2025-05-19 21:34:55,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033850374133371323 obs_scale[0m
[[36m2025-05-19 21:34:55,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 21:34:55,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-05-19 21:34:55,801[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 21:34:55,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 21:35:02,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 21:35:02,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 21:35:02,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 21:35:02,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 21:35:02,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 21:35:02,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 21:35:02,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 21:35:02,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 21:35:02,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 21:35:02,293[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 21:35:02,595[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       31.03it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 38.779 
                                                               rmse/train:      
                                                               35.914           
[[36m2025-05-19 22:06:33,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 22:06:33,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/017[0m
[[36m2025-05-19 22:06:33,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 22:06:33,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4892850214177034e-05, lr[0m
[[36m2025-05-19 22:06:34,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 22:06:34,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2901828481584094 prior_scale[0m
[[36m2025-05-19 22:06:34,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002216585292567847 q_scale[0m
[[36m2025-05-19 22:06:34,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3709088306769757 obs_scale[0m
[[36m2025-05-19 22:06:34,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 22:06:34,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-05-19 22:06:34,597[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 22:06:34,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 22:06:43,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 22:06:43,082[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 22:06:43,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 22:06:43,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 22:06:43,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 22:06:43,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 22:06:43,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 22:06:43,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 22:06:43,086[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 22:06:43,191[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 22:06:43,470[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       27.87it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.847 
                                                               rmse/train:      
                                                               38.262           
[[36m2025-05-19 22:37:24,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 22:37:24,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/018[0m
[[36m2025-05-19 22:37:24,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 22:37:24,401[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.8167974104891967e-05, lr[0m
[[36m2025-05-19 22:37:24,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 22:37:24,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1650451832717599 prior_scale[0m
[[36m2025-05-19 22:37:24,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007045558933851652 q_scale[0m
[[36m2025-05-19 22:37:24,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006147367556174905 obs_scale[0m
[[36m2025-05-19 22:37:24,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-19 22:37:24,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-05-19 22:37:24,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 22:37:24,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 22:37:31,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 22:37:31,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 22:37:31,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 22:37:31,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 22:37:31,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 22:37:31,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 22:37:31,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 22:37:31,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 22:37:31,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 22:37:33,069[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 22:37:33,438[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 441/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       26.03it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 71.719 
                                                               rmse/train:      
                                                               68.112           
[[36m2025-05-19 22:47:22,150[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 441.
[[36m2025-05-19 22:47:23,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 22:47:23,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 22:47:23,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.250563212805399e-05, lr[0m
[[36m2025-05-19 22:47:23,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 22:47:23,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.644065549927934 prior_scale[0m
[[36m2025-05-19 22:47:23,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018172394673582374 q_scale[0m
[[36m2025-05-19 22:47:23,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025999419863478743 obs_scale[0m
[[36m2025-05-19 22:47:23,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-19 22:47:23,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-05-19 22:47:23,526[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 22:47:23,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 22:47:34,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 22:47:34,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 22:47:34,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 22:47:34,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 22:47:34,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 22:47:34,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 22:47:34,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 22:47:34,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 22:47:34,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 22:47:34,693[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 22:47:35,250[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:09 •       21.55it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 37.514
                                                                rmse/train:     
                                                                36.564          
[[36m2025-05-19 23:42:04,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-19 23:42:04,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/020[0m
[[36m2025-05-19 23:42:05,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-19 23:42:05,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.997581777245899e-05, lr[0m
[[36m2025-05-19 23:42:05,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-19 23:42:05,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0644734008641272 prior_scale[0m
[[36m2025-05-19 23:42:05,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004096316450018883 q_scale[0m
[[36m2025-05-19 23:42:05,528[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008557555819215616 obs_scale[0m
[[36m2025-05-19 23:42:05,610[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-19 23:42:05,610[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-05-19 23:42:05,611[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-19 23:42:05,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-19 23:42:13,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-19 23:42:13,821[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-19 23:42:13,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-19 23:42:13,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-19 23:42:13,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-19 23:42:13,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-19 23:42:13,837[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-19 23:42:13,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-19 23:42:13,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-19 23:42:14,048[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-19 23:42:14,630[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:01 •       57.60it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 23.493 
                                                               rmse/train:      
                                                               20.799           
[[36m2025-05-20 00:10:49,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 00:10:49,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/021[0m
[[36m2025-05-20 00:10:49,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 00:10:49,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.7113830197423015e-05, lr[0m
[[36m2025-05-20 00:10:49,799[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-20 00:10:49,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0465807235352955 prior_scale[0m
[[36m2025-05-20 00:10:50,028[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016947777711543875 q_scale[0m
[[36m2025-05-20 00:10:50,089[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009071294324339235 obs_scale[0m
[[36m2025-05-20 00:10:50,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 00:10:50,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-05-20 00:10:50,237[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 00:10:50,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 00:10:56,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 00:10:56,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 00:10:56,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 00:10:56,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 00:10:56,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 00:10:56,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 00:10:56,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 00:10:56,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 00:10:56,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 00:10:58,112[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 00:10:58,720[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       32.79it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 29.909 
                                                               rmse/train:      
                                                               25.445           
[[36m2025-05-20 00:41:39,252[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 00:41:39,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/022[0m
[[36m2025-05-20 00:41:39,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 00:41:39,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.4517059853669515e-05, lr[0m
[[36m2025-05-20 00:41:39,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-20 00:41:39,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4767738573592597 prior_scale[0m
[[36m2025-05-20 00:41:39,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043221335433494434 q_scale[0m
[[36m2025-05-20 00:41:39,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010469514679526358 obs_scale[0m
[[36m2025-05-20 00:41:40,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 00:41:40,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-05-20 00:41:40,047[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 00:41:40,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 00:41:46,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 00:41:46,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 00:41:46,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 00:41:46,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 00:41:46,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 00:41:46,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 00:41:46,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 00:41:46,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 00:41:46,957[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 00:41:47,628[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 00:41:48,138[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 377/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:01 •       54.14it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 71.138 
                                                               rmse/train:      
                                                               64.204           
[[36m2025-05-20 01:04:23,037[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 377.
[[36m2025-05-20 01:04:23,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 01:04:24,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 01:04:24,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.262597078465666e-05, lr[0m
[[36m2025-05-20 01:04:24,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-20 01:04:24,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.105400690588794 prior_scale[0m
[[36m2025-05-20 01:04:24,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017793870578244336 q_scale[0m
[[36m2025-05-20 01:04:24,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001195041342384119 obs_scale[0m
[[36m2025-05-20 01:04:24,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 01:04:24,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-05-20 01:04:24,948[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 01:04:24,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 01:04:36,195[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 01:04:36,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 01:04:36,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 01:04:36,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 01:04:36,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 01:04:36,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 01:04:36,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 01:04:36,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 01:04:36,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 01:04:43,515[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 01:04:44,161[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:02 •       48.94it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 94.023 
                                                               rmse/train:      
                                                               83.185           
[[36m2025-05-20 01:40:29,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 01:40:29,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/024[0m
[[36m2025-05-20 01:40:30,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 01:40:30,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.889886364210567e-05, lr[0m
[[36m2025-05-20 01:40:30,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-20 01:40:30,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2245074196659953 prior_scale[0m
[[36m2025-05-20 01:40:30,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010451070279537009 q_scale[0m
[[36m2025-05-20 01:40:30,645[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002737996184659327 obs_scale[0m
[[36m2025-05-20 01:40:30,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-20 01:40:30,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-05-20 01:40:30,811[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 01:40:30,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 01:40:42,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 01:40:42,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 01:40:42,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 01:40:42,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 01:40:42,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 01:40:42,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 01:40:42,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 01:40:42,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 01:40:42,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 01:40:46,842[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 01:40:47,344[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 25/25 0:00:00 •       26.72it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 100.199
                                                               rmse/train:      
                                                               94.170           
[[36m2025-05-20 01:56:36,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 01:56:36,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/025[0m
[[36m2025-05-20 01:56:37,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 01:56:37,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013610767856721577, lr[0m
[[36m2025-05-20 01:56:38,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 01:56:38,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.442645089697962 prior_scale[0m
[[36m2025-05-20 01:56:38,281[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032188525231225643 q_scale[0m
[[36m2025-05-20 01:56:38,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01136408694314958 obs_scale[0m
[[36m2025-05-20 01:56:38,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 01:56:38,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-05-20 01:56:38,604[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 01:56:38,604[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 01:56:49,926[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 01:56:49,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 01:56:49,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 01:56:49,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 01:56:49,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 01:56:49,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 01:56:49,992[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 01:56:49,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 01:56:49,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 01:57:00,682[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 01:57:01,144[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       27.70it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 22.154 
                                                               rmse/train:      
                                                               18.821           
[[36m2025-05-20 02:48:09,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 02:48:09,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/026[0m
[[36m2025-05-20 02:48:10,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 02:48:10,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002825868922803633, lr[0m
[[36m2025-05-20 02:48:10,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 02:48:10,703[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.8244346225388877 prior_scale[0m
[[36m2025-05-20 02:48:10,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003379299551310577 q_scale[0m
[[36m2025-05-20 02:48:10,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009835990138759155 obs_scale[0m
[[36m2025-05-20 02:48:11,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 02:48:11,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-05-20 02:48:11,025[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 02:48:11,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 02:48:18,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 02:48:18,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 02:48:18,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 02:48:18,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 02:48:18,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 02:48:18,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 02:48:18,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 02:48:18,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 02:48:18,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 02:48:27,130[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 02:48:27,471[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 100/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:11 •        8.57it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 186.516
                                                               rmse/train:      
                                                               173.414          
[[36m2025-05-20 02:59:53,475[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 100.
[[36m2025-05-20 02:59:53,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 02:59:54,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 02:59:54,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012638172566946902, lr[0m
[[36m2025-05-20 02:59:54,620[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 02:59:54,674[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3956793251990156 prior_scale[0m
[[36m2025-05-20 02:59:54,730[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006429555743052847 q_scale[0m
[[36m2025-05-20 02:59:54,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07627304276050186 obs_scale[0m
[[36m2025-05-20 02:59:54,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 02:59:54,873[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-05-20 02:59:54,874[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 02:59:54,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 03:00:01,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 03:00:01,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 03:00:01,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 03:00:01,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 03:00:01,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 03:00:01,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 03:00:01,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 03:00:01,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 03:00:01,498[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 03:00:01,548[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 03:00:01,965[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       31.39it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 27.075 
                                                               rmse/train:      
                                                               23.070           
[[36m2025-05-20 03:47:17,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 03:47:17,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/028[0m
[[36m2025-05-20 03:47:18,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 03:47:18,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041773806426149057, lr[0m
[[36m2025-05-20 03:47:18,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 03:47:18,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9911068200044502 prior_scale[0m
[[36m2025-05-20 03:47:18,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002427898874521128 q_scale[0m
[[36m2025-05-20 03:47:18,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016533330833168607 obs_scale[0m
[[36m2025-05-20 03:47:19,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 03:47:19,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-05-20 03:47:19,004[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 03:47:19,004[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 03:47:30,206[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 03:47:30,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 03:47:30,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 03:47:30,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 03:47:30,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 03:47:30,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 03:47:30,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 03:47:30,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 03:47:30,252[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 03:47:41,379[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 03:47:42,244[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:09 •       10.61it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 25.696 
                                                               rmse/train:      
                                                               22.206           
[[36m2025-05-20 04:39:17,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 04:39:17,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/029[0m
[[36m2025-05-20 04:39:18,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 04:39:18,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008795166160409569, lr[0m
[[36m2025-05-20 04:39:18,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 04:39:18,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5670646955483223 prior_scale[0m
[[36m2025-05-20 04:39:19,127[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00027868338623627923 q_scale[0m
[[36m2025-05-20 04:39:19,289[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005048425865740138 obs_scale[0m
[[36m2025-05-20 04:39:19,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 04:39:19,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-05-20 04:39:19,427[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 04:39:19,427[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 04:39:26,129[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 04:39:26,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 04:39:26,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 04:39:26,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 04:39:26,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 04:39:26,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 04:39:26,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 04:39:26,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 04:39:26,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 04:39:26,228[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 04:39:26,519[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       17.41it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 20.372 
                                                               rmse/train:      
                                                               18.114           
[[36m2025-05-20 05:11:00,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 05:11:00,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/030[0m
[[36m2025-05-20 05:11:00,822[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 05:11:01,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.914086674474999e-05, lr[0m
[[36m2025-05-20 05:11:01,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-20 05:11:01,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1467726405297494 prior_scale[0m
[[36m2025-05-20 05:11:01,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015000646392824825 q_scale[0m
[[36m2025-05-20 05:11:01,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032056087908981863 obs_scale[0m
[[36m2025-05-20 05:11:01,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 05:11:01,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-05-20 05:11:01,948[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 05:11:01,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 05:11:09,847[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 05:11:09,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 05:11:09,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 05:11:09,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 05:11:09,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 05:11:09,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 05:11:09,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 05:11:09,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 05:11:09,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 05:11:19,944[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 05:11:20,267[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:01 •       58.00it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 19.617 
                                                               rmse/train:      
                                                               18.114           
[[36m2025-05-20 05:43:28,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 05:43:28,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/031[0m
[[36m2025-05-20 05:43:30,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 05:43:30,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.941251297831662e-05, lr[0m
[[36m2025-05-20 05:43:30,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 05:43:30,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1896099196019947 prior_scale[0m
[[36m2025-05-20 05:43:30,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005355738040699326 q_scale[0m
[[36m2025-05-20 05:43:30,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040327362327173663 obs_scale[0m
[[36m2025-05-20 05:43:30,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 05:43:30,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-05-20 05:43:30,964[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 05:43:30,964[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 05:43:37,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 05:43:37,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 05:43:37,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 05:43:37,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 05:43:37,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 05:43:37,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 05:43:37,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 05:43:37,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 05:43:37,194[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 05:43:45,567[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 05:43:47,026[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 •       17.06it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 15.577 
                                                               rmse/train:      
                                                               14.756           
[[36m2025-05-20 06:35:22,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 06:35:22,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/032[0m
[[36m2025-05-20 06:35:22,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 06:35:22,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.011704030282528e-05, lr[0m
[[36m2025-05-20 06:35:22,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 06:35:23,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2163191107223672 prior_scale[0m
[[36m2025-05-20 06:35:23,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016817910644971825 q_scale[0m
[[36m2025-05-20 06:35:23,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003269828822088494 obs_scale[0m
[[36m2025-05-20 06:35:23,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 06:35:23,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-05-20 06:35:23,729[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 06:35:23,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 06:35:32,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 06:35:32,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 06:35:32,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 06:35:32,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 06:35:32,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 06:35:32,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 06:35:32,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 06:35:32,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 06:35:32,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 06:35:42,901[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 06:35:43,344[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       30.73it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 28.081 
                                                               rmse/train:      
                                                               23.953           
[[36m2025-05-20 07:31:15,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 07:31:15,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/033[0m
[[36m2025-05-20 07:31:15,523[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 07:31:15,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011412102333817467, lr[0m
[[36m2025-05-20 07:31:15,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 07:31:15,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8569757103393927 prior_scale[0m
[[36m2025-05-20 07:31:15,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000552082274032325 q_scale[0m
[[36m2025-05-20 07:31:15,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017089364062394647 obs_scale[0m
[[36m2025-05-20 07:31:15,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 07:31:15,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-05-20 07:31:15,677[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 07:31:15,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 07:31:22,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 07:31:22,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 07:31:22,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 07:31:22,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 07:31:22,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 07:31:22,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 07:31:22,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 07:31:22,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 07:31:22,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 07:31:36,271[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 07:31:36,609[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 248/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 •       28.21it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 106.604
                                                               rmse/train:      
                                                               97.848           
[[36m2025-05-20 07:46:47,168[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 248.
[[36m2025-05-20 07:46:48,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 07:46:48,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 07:46:48,406[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001521357045563839, lr[0m
[[36m2025-05-20 07:46:48,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 07:46:48,886[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.181306427997601 prior_scale[0m
[[36m2025-05-20 07:46:49,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001168637188741035 q_scale[0m
[[36m2025-05-20 07:46:49,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017198287150168884 obs_scale[0m
[[36m2025-05-20 07:46:49,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 07:46:49,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-05-20 07:46:49,471[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 07:46:49,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 07:46:56,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 07:46:56,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 07:46:56,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 07:46:56,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 07:46:56,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 07:46:56,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 07:46:56,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 07:46:56,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 07:46:56,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 07:47:07,572[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 07:47:07,800[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 •       28.32it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 21.676 
                                                               rmse/train:      
                                                               20.788           
[[36m2025-05-20 08:38:01,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 08:38:01,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/035[0m
[[36m2025-05-20 08:38:02,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 08:38:02,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.317867868581776e-05, lr[0m
[[36m2025-05-20 08:38:02,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 08:38:02,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.021997134941305 prior_scale[0m
[[36m2025-05-20 08:38:02,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001171552817622904 q_scale[0m
[[36m2025-05-20 08:38:02,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07336377031864849 obs_scale[0m
[[36m2025-05-20 08:38:03,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 08:38:03,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-05-20 08:38:03,049[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 08:38:03,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 08:38:10,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 08:38:10,186[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 08:38:10,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 08:38:10,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 08:38:10,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 08:38:10,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 08:38:10,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 08:38:10,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 08:38:10,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 08:38:23,807[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 08:38:24,467[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 146/499 ━━━━━━━━━━━━━━━ 198/198 0:00:06 •       32.30it/s v_num: 0.000    
                                      0:00:00                   rmse/val:       
                                                                1364.914        
                                                                rmse/train:     
                                                                1210.949        
[[36m2025-05-20 09:08:21,707[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 146.
[[36m2025-05-20 09:08:22,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 09:08:22,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 09:08:22,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017662064542995105, lr[0m
[[36m2025-05-20 09:08:22,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 09:08:22,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1640588407675216 prior_scale[0m
[[36m2025-05-20 09:08:22,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018108570036927223 q_scale[0m
[[36m2025-05-20 09:08:22,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24002500540769467 obs_scale[0m
[[36m2025-05-20 09:08:23,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-20 09:08:23,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-05-20 09:08:23,119[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 09:08:23,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 09:08:30,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 09:08:30,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 09:08:30,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 09:08:30,702[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 09:08:30,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 09:08:30,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 09:08:30,704[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 09:08:30,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 09:08:30,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 09:08:39,069[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 09:08:39,350[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 •       18.17it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 18.863 
                                                               rmse/train:      
                                                               19.202           
[[36m2025-05-20 09:58:14,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 09:58:14,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/037[0m
[[36m2025-05-20 09:58:14,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 09:58:14,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018084282212162882, lr[0m
[[36m2025-05-20 09:58:14,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 09:58:14,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.5172676897502932 prior_scale[0m
[[36m2025-05-20 09:58:14,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00715479893464565 q_scale[0m
[[36m2025-05-20 09:58:14,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4921413941691813 obs_scale[0m
[[36m2025-05-20 09:58:14,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-20 09:58:14,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-05-20 09:58:14,961[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 09:58:14,961[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 09:58:23,186[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 09:58:23,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 09:58:23,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 09:58:23,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 09:58:23,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 09:58:23,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 09:58:23,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 09:58:23,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 09:58:23,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 09:58:31,716[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 09:58:31,832[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 116/499 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 •       18.19it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 477.491
                                                               rmse/train:      
                                                               463.071          
[[36m2025-05-20 10:02:00,868[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 116.
[[36m2025-05-20 10:02:01,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 10:02:02,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 10:02:02,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028236179214231806, lr[0m
[[36m2025-05-20 10:02:02,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 10:02:03,051[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2178184534716836 prior_scale[0m
[[36m2025-05-20 10:02:03,105[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016129534092611 q_scale[0m
[[36m2025-05-20 10:02:03,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8479907862276201 obs_scale[0m
[[36m2025-05-20 10:02:03,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 10:02:03,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-05-20 10:02:03,181[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 10:02:03,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 10:02:10,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 10:02:10,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 10:02:10,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 10:02:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 10:02:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 10:02:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 10:02:10,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 10:02:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 10:02:10,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 10:02:10,946[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 10:02:11,169[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       17.74it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 18.645 
                                                               rmse/train:      
                                                               21.809           
[[36m2025-05-20 10:33:01,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 10:33:02,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/039[0m
[[36m2025-05-20 10:33:03,295[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 10:33:03,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026711232479663784, lr[0m
[[36m2025-05-20 10:33:03,688[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 10:33:03,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.641495795809893 prior_scale[0m
[[36m2025-05-20 10:33:04,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002108224207197285 q_scale[0m
[[36m2025-05-20 10:33:04,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.387424791498 obs_scale[0m
[[36m2025-05-20 10:33:04,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 10:33:04,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-05-20 10:33:04,894[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 10:33:04,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 10:33:12,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 10:33:12,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 10:33:12,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 10:33:12,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 10:33:12,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 10:33:12,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 10:33:12,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 10:33:12,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 10:33:12,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 10:33:24,354[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 10:33:24,835[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 •       27.61it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 36.759 
                                                               rmse/train:      
                                                               31.910           
[[36m2025-05-20 11:01:49,428[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 11:01:49,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/040[0m
[[36m2025-05-20 11:01:50,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 11:01:50,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038797403686860395, lr[0m
[[36m2025-05-20 11:01:50,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 11:01:51,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1877751793985916 prior_scale[0m
[[36m2025-05-20 11:01:51,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013396755630776327 q_scale[0m
[[36m2025-05-20 11:01:51,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19257258277246928 obs_scale[0m
[[36m2025-05-20 11:01:51,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 11:01:51,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-05-20 11:01:51,759[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 11:01:51,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 11:02:06,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 11:02:06,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 11:02:06,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 11:02:06,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 11:02:06,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 11:02:06,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 11:02:06,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 11:02:06,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 11:02:06,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 11:02:08,887[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 11:02:09,320[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 •       14.74it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 24.282 
                                                               rmse/train:      
                                                               19.410           
[[36m2025-05-20 11:32:09,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 11:32:09,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/041[0m
[[36m2025-05-20 11:32:10,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 11:32:10,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015757272045576075, lr[0m
[[36m2025-05-20 11:32:10,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 11:32:11,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.324106744946416 prior_scale[0m
[[36m2025-05-20 11:32:11,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00323178057923976 q_scale[0m
[[36m2025-05-20 11:32:11,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.192978986733068 obs_scale[0m
[[36m2025-05-20 11:32:11,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 11:32:11,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-05-20 11:32:11,385[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 11:32:11,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 11:32:19,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 11:32:19,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 11:32:19,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 11:32:19,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 11:32:19,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 11:32:19,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 11:32:19,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 11:32:19,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 11:32:19,755[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 11:32:19,994[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 11:32:20,199[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 82/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •        23.06it/s v_num: 0.000     
                                    0:00:00                    rmse/val: 97.441 
                                                               rmse/train:      
                                                               99.895           
[[36m2025-05-20 11:37:18,074[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 82.
[[36m2025-05-20 11:37:18,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 11:37:18,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 11:37:18,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023339572844812223, lr[0m
[[36m2025-05-20 11:37:18,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 11:37:18,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1350303510716058 prior_scale[0m
[[36m2025-05-20 11:37:19,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009258609606646315 q_scale[0m
[[36m2025-05-20 11:37:19,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0087613887729026 obs_scale[0m
[[36m2025-05-20 11:37:19,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 11:37:19,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-05-20 11:37:19,266[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 11:37:19,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 11:37:25,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 11:37:25,697[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 11:37:25,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 11:37:25,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 11:37:25,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 11:37:25,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 11:37:25,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 11:37:25,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 11:37:25,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 11:37:25,981[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 11:37:26,400[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:07 •        6.28it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 16.728 
                                                               rmse/train:      
                                                               14.608           
[[36m2025-05-20 12:07:43,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 12:07:43,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/043[0m
[[36m2025-05-20 12:07:44,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 12:07:44,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022900030986314343, lr[0m
[[36m2025-05-20 12:07:44,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 12:07:44,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1259292008855806 prior_scale[0m
[[36m2025-05-20 12:07:45,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006128267771669666 q_scale[0m
[[36m2025-05-20 12:07:45,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2585103580845565 obs_scale[0m
[[36m2025-05-20 12:07:45,618[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 12:07:45,620[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-05-20 12:07:45,623[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 12:07:45,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 12:07:53,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 12:07:53,568[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 12:07:53,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 12:07:53,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 12:07:53,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 12:07:53,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 12:07:53,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 12:07:53,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 12:07:53,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 12:07:54,486[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 12:07:54,737[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       17.89it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 21.406 
                                                               rmse/train:      
                                                               25.781           
[[36m2025-05-20 12:33:33,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 12:33:33,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/044[0m
[[36m2025-05-20 12:33:33,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 12:33:33,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005101019069929286, lr[0m
[[36m2025-05-20 12:33:33,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 12:33:33,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.638123085435614 prior_scale[0m
[[36m2025-05-20 12:33:33,674[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010504324026288593 q_scale[0m
[[36m2025-05-20 12:33:33,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2302980012007463 obs_scale[0m
[[36m2025-05-20 12:33:33,777[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 12:33:33,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-05-20 12:33:33,779[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 12:33:33,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 12:33:41,716[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 12:33:41,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 12:33:41,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 12:33:41,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 12:33:41,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 12:33:41,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 12:33:41,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 12:33:41,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 12:33:41,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 12:33:43,767[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 12:33:44,074[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 43/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 •        25.29it/s v_num: 0.000     
                                    0:00:00                    rmse/val:        
                                                               2326.769         
                                                               rmse/train:      
                                                               2160.303         
[[36m2025-05-20 12:35:50,150[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 43.
[[36m2025-05-20 12:35:50,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 12:35:51,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 12:35:51,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024668843381260813, lr[0m
[[36m2025-05-20 12:35:51,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 12:35:51,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6937368280043685 prior_scale[0m
[[36m2025-05-20 12:35:52,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05087554260971675 q_scale[0m
[[36m2025-05-20 12:35:52,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.588110587536637 obs_scale[0m
[[36m2025-05-20 12:35:52,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 12:35:52,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-05-20 12:35:52,208[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 12:35:52,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 12:35:58,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 12:35:58,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 12:35:58,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 12:35:58,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 12:35:58,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 12:35:58,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 12:35:58,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 12:35:58,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 12:35:58,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 12:35:58,560[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 12:35:58,703[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 76/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •        22.28it/s v_num: 0.000     
                                    0:00:00                    rmse/val: 504.594
                                                               rmse/train:      
                                                               592.678          
[[36m2025-05-20 12:39:49,813[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 76.
[[36m2025-05-20 12:39:49,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 12:39:50,150[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 12:39:50,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020958029437457814, lr[0m
[[36m2025-05-20 12:39:50,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 12:39:51,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.534069856661655 prior_scale[0m
[[36m2025-05-20 12:39:51,459[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025407875860157417 q_scale[0m
[[36m2025-05-20 12:39:51,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9173463478065038 obs_scale[0m
[[36m2025-05-20 12:39:51,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 12:39:51,783[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-05-20 12:39:51,783[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 12:39:51,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 12:39:58,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 12:39:58,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 12:39:58,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 12:39:58,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 12:39:58,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 12:39:58,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 12:39:58,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 12:39:58,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 12:39:58,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 12:39:58,901[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 12:39:59,062[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 109/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 •       31.75it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 76.075 
                                                               rmse/train:      
                                                               79.801           
[[36m2025-05-20 12:45:21,607[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 109.
[[36m2025-05-20 12:45:21,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 12:45:22,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 12:45:22,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003328731605432384, lr[0m
[[36m2025-05-20 12:45:22,477[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 12:45:22,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3203506929875568 prior_scale[0m
[[36m2025-05-20 12:45:22,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006265798586389031 q_scale[0m
[[36m2025-05-20 12:45:23,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17719897322110015 obs_scale[0m
[[36m2025-05-20 12:45:23,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 12:45:23,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-05-20 12:45:23,933[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 12:45:23,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 12:45:30,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 12:45:30,854[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 12:45:30,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 12:45:30,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 12:45:30,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 12:45:30,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 12:45:30,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 12:45:30,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 12:45:30,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 12:45:31,006[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 12:45:31,165[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 335/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       16.40it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.753 
                                                               rmse/train:      
                                                               45.166           
[[36m2025-05-20 13:05:31,289[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 335.
[[36m2025-05-20 13:05:31,537[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 13:05:32,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 13:05:32,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005885666050209538, lr[0m
[[36m2025-05-20 13:05:32,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 13:05:32,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7814268074045188 prior_scale[0m
[[36m2025-05-20 13:05:33,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008267535274569326 q_scale[0m
[[36m2025-05-20 13:05:33,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5189057417747952 obs_scale[0m
[[36m2025-05-20 13:05:33,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 13:05:33,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-05-20 13:05:33,572[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 13:05:33,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 13:05:41,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 13:05:41,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 13:05:41,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 13:05:41,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 13:05:41,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 13:05:41,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 13:05:41,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 13:05:41,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 13:05:41,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 13:05:41,323[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 13:05:41,417[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       22.17it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 26.106 
                                                               rmse/train:      
                                                               21.340           
[[36m2025-05-20 13:33:17,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 13:33:17,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/049[0m
[[36m2025-05-20 13:33:18,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 13:33:18,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003127076920176439, lr[0m
[[36m2025-05-20 13:33:18,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 13:33:18,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0018251583154814 prior_scale[0m
[[36m2025-05-20 13:33:18,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004778017829916769 q_scale[0m
[[36m2025-05-20 13:33:18,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8669415176062734 obs_scale[0m
[[36m2025-05-20 13:33:18,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-20 13:33:18,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-05-20 13:33:18,471[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 13:33:18,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 13:33:25,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 13:33:25,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 13:33:25,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 13:33:25,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 13:33:25,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 13:33:25,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 13:33:25,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 13:33:25,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 13:33:25,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 13:33:27,528[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 13:33:27,708[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 60/499 ━━━━━━━━━━━━━━━━ 12/12 0:00:01 •        10.56it/s v_num: 0.000     
                                    0:00:00                    rmse/val: 124.737
                                                               rmse/train:      
                                                               119.328          
[[36m2025-05-20 13:35:42,468[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 60.
[[36m2025-05-20 13:35:42,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 13:35:42,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 13:35:42,861[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019719209564955114, lr[0m
[[36m2025-05-20 13:35:43,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 13:35:43,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1556172425754192 prior_scale[0m
[[36m2025-05-20 13:35:43,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016492041388603352 q_scale[0m
[[36m2025-05-20 13:35:43,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2565130613919206 obs_scale[0m
[[36m2025-05-20 13:35:43,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-20 13:35:43,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-05-20 13:35:43,368[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 13:35:43,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 13:35:51,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 13:35:51,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 13:35:51,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 13:35:51,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 13:35:51,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 13:35:51,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 13:35:51,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 13:35:51,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 13:35:51,097[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 13:35:51,152[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 13:35:51,364[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 •       16.63it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 36.473 
                                                               rmse/train:      
                                                               28.862           
[[36m2025-05-20 14:04:47,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 14:04:47,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/051[0m
[[36m2025-05-20 14:04:48,191[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 14:04:48,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010982493191800038, lr[0m
[[36m2025-05-20 14:04:48,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 14:04:48,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1030254558251493 prior_scale[0m
[[36m2025-05-20 14:04:48,670[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0034616247324774528 q_scale[0m
[[36m2025-05-20 14:04:48,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.132876877605438 obs_scale[0m
[[36m2025-05-20 14:04:48,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 14:04:48,876[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-05-20 14:04:48,877[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 14:04:48,877[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 14:04:55,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 14:04:55,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 14:04:55,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 14:04:55,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 14:04:55,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 14:04:55,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 14:04:55,732[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 14:04:55,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 14:04:55,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 14:04:56,835[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 14:04:57,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:19 •       10.35it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 18.404
                                                                rmse/train:     
                                                                18.363          
[[36m2025-05-20 15:42:38,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 15:42:38,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/052[0m
[[36m2025-05-20 15:42:39,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 15:42:39,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010510773930658169, lr[0m
[[36m2025-05-20 15:42:39,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 15:42:39,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.366165038810785 prior_scale[0m
[[36m2025-05-20 15:42:40,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033733276295111114 q_scale[0m
[[36m2025-05-20 15:42:40,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.017101528220944 obs_scale[0m
[[36m2025-05-20 15:42:40,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 15:42:40,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-05-20 15:42:40,539[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 15:42:40,539[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 15:42:49,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 15:42:49,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 15:42:49,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 15:42:49,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 15:42:49,901[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 15:42:49,901[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 15:42:49,902[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 15:42:49,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 15:42:49,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 15:42:49,952[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 15:42:50,243[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 346/499 ━━━━━━━━━━━━━━━ 198/198 0:00:06 •       28.60it/s v_num: 0.000    
                                      0:00:00                   rmse/val:       
                                                                230.706         
                                                                rmse/train:     
                                                                193.488         
[[36m2025-05-20 16:44:14,571[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 346.
[[36m2025-05-20 16:44:14,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 16:44:17,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 16:44:17,900[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015468073318119637, lr[0m
[[36m2025-05-20 16:44:18,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 16:44:18,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1188985385734282 prior_scale[0m
[[36m2025-05-20 16:44:18,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00151940199026503 q_scale[0m
[[36m2025-05-20 16:44:18,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4005907895730916 obs_scale[0m
[[36m2025-05-20 16:44:19,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 16:44:19,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-05-20 16:44:19,108[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 16:44:19,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 16:44:25,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 16:44:25,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 16:44:25,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 16:44:25,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 16:44:25,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 16:44:25,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 16:44:25,604[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 16:44:25,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 16:44:25,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 16:44:25,647[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 16:44:25,816[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:07 •       27.58it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 12.772
                                                                rmse/train:     
                                                                17.119          
[[36m2025-05-20 18:07:32,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 18:07:32,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/054[0m
[[36m2025-05-20 18:07:33,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 18:07:33,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016968228154898345, lr[0m
[[36m2025-05-20 18:07:33,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 18:07:33,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3059317474789898 prior_scale[0m
[[36m2025-05-20 18:07:33,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014293757002125965 q_scale[0m
[[36m2025-05-20 18:07:33,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.634973757185219 obs_scale[0m
[[36m2025-05-20 18:07:33,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 18:07:33,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-05-20 18:07:33,711[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 18:07:33,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 18:07:40,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 18:07:40,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 18:07:40,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 18:07:40,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 18:07:40,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 18:07:40,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 18:07:40,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 18:07:40,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 18:07:40,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 18:07:46,225[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 18:07:46,547[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:05 •       36.05it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 14.488
                                                                rmse/train:     
                                                                14.412          
[[36m2025-05-20 19:26:42,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 19:26:42,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/055[0m
[[36m2025-05-20 19:26:43,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 19:26:43,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014634677105441126, lr[0m
[[36m2025-05-20 19:26:44,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 19:26:44,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3029748991030856 prior_scale[0m
[[36m2025-05-20 19:26:44,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000989769573241862 q_scale[0m
[[36m2025-05-20 19:26:44,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.9458155547268157 obs_scale[0m
[[36m2025-05-20 19:26:44,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 19:26:44,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-05-20 19:26:44,468[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 19:26:44,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 19:26:50,716[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 19:26:50,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 19:26:50,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 19:26:50,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 19:26:50,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 19:26:50,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 19:26:50,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 19:26:50,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 19:26:50,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 19:26:58,329[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 19:26:58,549[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:05 •       36.82it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 21.679
                                                                rmse/train:     
                                                                29.600          
[[36m2025-05-20 20:47:16,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 20:47:17,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/056[0m
[[36m2025-05-20 20:47:17,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 20:47:17,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.74513783816056e-05, lr[0m
[[36m2025-05-20 20:47:17,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 20:47:17,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3755532454653012 prior_scale[0m
[[36m2025-05-20 20:47:17,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005188808414556879 q_scale[0m
[[36m2025-05-20 20:47:18,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.628310456554278 obs_scale[0m
[[36m2025-05-20 20:47:18,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 20:47:18,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-05-20 20:47:18,102[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 20:47:18,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 20:47:28,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 20:47:28,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 20:47:28,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 20:47:28,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 20:47:28,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 20:47:28,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 20:47:28,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 20:47:28,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 20:47:28,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 20:47:34,846[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 20:47:35,120[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:05 •       36.66it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 16.059
                                                                rmse/train:     
                                                                15.479          
[[36m2025-05-20 22:04:45,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 22:04:45,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/057[0m
[[36m2025-05-20 22:04:46,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 22:04:46,150[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.078299047490653e-05, lr[0m
[[36m2025-05-20 22:04:46,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 22:04:46,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0680857488251299 prior_scale[0m
[[36m2025-05-20 22:04:46,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013361363910908868 q_scale[0m
[[36m2025-05-20 22:04:46,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11837132275991237 obs_scale[0m
[[36m2025-05-20 22:04:46,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 22:04:46,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-05-20 22:04:46,761[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 22:04:46,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 22:04:52,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 22:04:53,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 22:04:53,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 22:04:53,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 22:04:53,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 22:04:53,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 22:04:53,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 22:04:53,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 22:04:53,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 22:04:59,470[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 22:04:59,658[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:05 •       36.36it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 16.954
                                                                rmse/train:     
                                                                17.172          
[[36m2025-05-20 23:27:25,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-20 23:27:25,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/058[0m
[[36m2025-05-20 23:27:26,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-20 23:27:26,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012854385974754148, lr[0m
[[36m2025-05-20 23:27:26,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-20 23:27:26,625[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5104914800451048 prior_scale[0m
[[36m2025-05-20 23:27:26,688[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007767133069857264 q_scale[0m
[[36m2025-05-20 23:27:26,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.476999342923903 obs_scale[0m
[[36m2025-05-20 23:27:26,959[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-20 23:27:26,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-05-20 23:27:26,960[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-20 23:27:26,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-20 23:27:36,023[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-20 23:27:36,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-20 23:27:36,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-20 23:27:36,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-20 23:27:36,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-20 23:27:36,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-20 23:27:36,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-20 23:27:36,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-20 23:27:36,091[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-20 23:27:40,805[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-20 23:27:41,111[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 499/499 ━━━━━━━━━━━━━━━ 198/198 0:00:08 •       24.58it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 23.820
                                                                rmse/train:     
                                                                22.819          
[[36m2025-05-21 00:44:10,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-21 00:44:10,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_lrt_hps_mse/runs/2025-05-19_15-19-29/059[0m
[[36m2025-05-21 00:44:10,993[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
