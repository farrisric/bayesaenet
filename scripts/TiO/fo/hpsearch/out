{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-24 16:30:24,966[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-24 16:30:24,968[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/fo_20perc.db[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-24 16:30:25,410[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-24 16:30:25,413[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/fo_100perc.db[0m
[[36m2025-02-24 16:30:25,874[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-24 16:30:25,906[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-24 16:30:25,959[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:26,000[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-02-24 16:30:26,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:30:26,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-02-24 16:30:26,044[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-02-24 16:30:26,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:30:26,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-24 16:30:26,061[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:26,061[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2025-02-24 16:30:26,071[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-24 16:30:26,075[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-24 16:30:26,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:26,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-02-24 16:30:26,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:30:26,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-02-24 16:30:26,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-02-24 16:30:26,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:30:26,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-24 16:30:26,233[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:26,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:35,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:35,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:30:37,383[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:37,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:37,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:37,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:37,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:37,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:37,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:37,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:37,391[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:37,392[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:37,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:37,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:37,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:37,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:37,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:37,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:37,674[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:37,741[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:37,805[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2025-02-24 16:30:37,877[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 13.98it/s v_num: 0.000      
                                                              rmse/val: 4214.726
                                                              rmse/train:       
                                                              4291.915          
[[36m2025-02-24 16:30:49,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:30:49,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/000[0m
[[36m2025-02-24 16:30:49,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:49,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-02-24 16:30:49,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:30:49,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374377640063412 prior_scale[0m
[[36m2025-02-24 16:30:49,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030269344709026166 q_scale[0m
[[36m2025-02-24 16:30:49,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:30:49,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-24 16:30:49,293[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:49,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:58,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:30:58,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:58,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:58,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:58,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:58,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:58,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:58,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:58,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:58,885[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:58,933[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.40it/s v_num: 0.000      
                                                              rmse/val: 4336.963
                                                              rmse/train:       
                                                              4434.997          
[[36m2025-02-24 16:31:12,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:12,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/001[0m
[[36m2025-02-24 16:31:12,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:12,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-02-24 16:31:12,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:31:12,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012778268753495938 prior_scale[0m
[[36m2025-02-24 16:31:12,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.540207249341968 q_scale[0m
[[36m2025-02-24 16:31:12,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:31:12,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-24 16:31:12,366[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:12,366[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:21,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:21,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:21,763[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:21,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:21,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:21,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:21,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:21,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:21,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:21,800[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:21,809[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 14.77it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3630.491         
                                                               rmse/train:      
                                                               3837.216         
[[36m2025-02-24 16:31:22,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:22,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/000[0m
[[36m2025-02-24 16:31:22,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:22,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-02-24 16:31:22,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:31:22,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374377640063412 prior_scale[0m
[[36m2025-02-24 16:31:22,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030269344709026166 q_scale[0m
[[36m2025-02-24 16:31:22,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:31:22,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-24 16:31:22,832[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:22,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:33,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:33,087[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:33,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:33,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:33,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:33,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:33,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:33,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:33,093[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:33,126[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:33,135[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 19.73it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2893.570         
                                                               rmse/train:      
                                                               4237.446         
[[36m2025-02-24 16:31:35,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:35,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/002[0m
[[36m2025-02-24 16:31:35,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:35,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-02-24 16:31:35,595[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:31:35,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002699606552195955 prior_scale[0m
[[36m2025-02-24 16:31:35,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06562115716452717 q_scale[0m
[[36m2025-02-24 16:31:35,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:31:35,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-24 16:31:35,631[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:35,631[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:44,892[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:44,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:44,898[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:44,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:44,901[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:44,901[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:44,902[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:44,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:44,903[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:44,917[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:44,925[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 11.67it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3235.902         
                                                               rmse/train:      
                                                               3336.530         
[[36m2025-02-24 16:32:06,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:06,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/003[0m
[[36m2025-02-24 16:32:07,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:07,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-02-24 16:32:07,127[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:07,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10583829396911469 prior_scale[0m
[[36m2025-02-24 16:32:07,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023905570899706415 q_scale[0m
[[36m2025-02-24 16:32:07,172[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:07,172[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-24 16:32:07,172[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:07,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:16,460[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:16,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:16,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:16,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:16,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:16,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:16,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:16,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:16,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:16,486[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:16,669[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 22.21it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4052.925         
                                                               rmse/train:      
                                                               4143.995         
[[36m2025-02-24 16:32:29,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:29,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/004[0m
[[36m2025-02-24 16:32:29,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:29,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-02-24 16:32:29,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:29,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001047833275436284 prior_scale[0m
[[36m2025-02-24 16:32:29,959[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02949625201538112 q_scale[0m
[[36m2025-02-24 16:32:29,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:29,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-24 16:32:29,972[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:29,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:02 • 0:00:00 4.81it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4295.527         
                                                               rmse/train:      
                                                               4365.647         
[[36m2025-02-24 16:32:31,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:31,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/001[0m
[[36m2025-02-24 16:32:31,652[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:31,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-02-24 16:32:31,707[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:31,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012778268753495938 prior_scale[0m
[[36m2025-02-24 16:32:31,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.540207249341968 q_scale[0m
[[36m2025-02-24 16:32:31,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:31,751[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-24 16:32:31,751[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:31,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:39,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:39,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:39,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:39,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:39,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:39,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:39,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:39,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:39,243[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:39,279[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:39,311[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:41,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:41,320[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:41,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:41,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:41,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:41,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:41,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:41,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:41,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:41,359[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:41,381[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/19 ━━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 19.58it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4141.398         
                                                               rmse/train:      
                                                               4220.461         
[[36m2025-02-24 16:32:42,672[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 4.
[[36m2025-02-24 16:32:42,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:42,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:42,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-02-24 16:32:42,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:42,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038638969563953266 prior_scale[0m
[[36m2025-02-24 16:32:42,822[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033827492632411567 q_scale[0m
[[36m2025-02-24 16:32:42,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:42,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-24 16:32:42,835[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:42,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:52,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:52,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:52,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:52,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:52,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:52,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:52,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:52,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:52,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:52,232[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:52,240[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 22.30it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4079.106         
                                                               rmse/train:      
                                                               4180.053         
[[36m2025-02-24 16:33:06,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:33:06,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/006[0m
[[36m2025-02-24 16:33:06,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:33:06,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-02-24 16:33:06,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:33:06,201[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020959477484878194 prior_scale[0m
[[36m2025-02-24 16:33:06,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008257988273685458 q_scale[0m
[[36m2025-02-24 16:33:06,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:33:06,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-24 16:33:06,224[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:33:06,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:33:15,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:33:15,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:33:15,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:33:15,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:33:15,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:33:15,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:33:15,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:33:15,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:33:15,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:33:15,313[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:33:15,321[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 22.36it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4334.705         
                                                               rmse/train:      
                                                               4018.962         
[[36m2025-02-24 16:33:38,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:33:38,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/002[0m
[[36m2025-02-24 16:33:38,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:33:38,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-02-24 16:33:38,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:33:38,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002699606552195955 prior_scale[0m
[[36m2025-02-24 16:33:38,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06562115716452717 q_scale[0m
[[36m2025-02-24 16:33:38,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:33:38,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-24 16:33:38,829[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:33:38,829[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:33:48,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:33:48,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:33:48,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:33:48,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:33:48,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:33:48,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:33:48,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:33:48,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:33:48,068[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:33:48,102[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:33:48,115[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 28.17it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3479.218         
                                                               rmse/train:      
                                                               3572.078         
[[36m2025-02-24 16:33:48,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:33:48,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/007[0m
[[36m2025-02-24 16:33:48,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:33:48,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-02-24 16:33:49,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:33:49,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07537199486913888 prior_scale[0m
[[36m2025-02-24 16:33:49,040[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0666791815288874 q_scale[0m
[[36m2025-02-24 16:33:49,056[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:33:49,056[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-24 16:33:49,056[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:33:49,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:33:58,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:33:58,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:33:58,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:33:58,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:33:58,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:33:58,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:33:58,339[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:33:58,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:33:58,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:33:58,371[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:33:58,382[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 11.85it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3840.450         
                                                               rmse/train:      
                                                               3985.998         
[[36m2025-02-24 16:34:19,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:34:19,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/008[0m
[[36m2025-02-24 16:34:19,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:34:19,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-02-24 16:34:19,737[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:34:19,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.714967484470097 prior_scale[0m
[[36m2025-02-24 16:34:19,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00834519932080496 q_scale[0m
[[36m2025-02-24 16:34:19,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:34:19,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-24 16:34:19,771[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:34:19,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:34:28,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:34:28,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:34:28,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:34:28,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:34:28,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:34:28,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:34:28,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:34:28,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:34:28,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:34:28,973[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:34:28,983[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 22.12it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4925.230         
                                                               rmse/train:      
                                                               4971.172         
[[36m2025-02-24 16:34:40,289[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2025-02-24 16:34:40,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:34:40,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:34:40,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-02-24 16:34:40,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:34:40,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01116798829495977 prior_scale[0m
[[36m2025-02-24 16:34:40,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013611901663306908 q_scale[0m
[[36m2025-02-24 16:34:40,452[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:34:40,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-24 16:34:40,453[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:34:40,453[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:34:49,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:34:49,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:34:49,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:34:49,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:34:49,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:34:49,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:34:49,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:34:49,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:34:49,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:34:49,502[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:34:49,584[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:04 • 0:00:00 12.05it/s v_num: 0.000     
                                                               rmse/val: 114.985
                                                               rmse/train:      
                                                               84.378           
[[36m2025-02-24 16:35:23,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:35:23,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/003[0m
[[36m2025-02-24 16:35:23,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:35:23,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-02-24 16:35:23,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:35:23,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10583829396911469 prior_scale[0m
[[36m2025-02-24 16:35:23,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023905570899706415 q_scale[0m
[[36m2025-02-24 16:35:23,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:35:23,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-24 16:35:23,280[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:35:23,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:35:32,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:35:32,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:35:32,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:35:32,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:35:32,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:35:32,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:35:32,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:35:32,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:35:32,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:35:32,647[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:35:32,785[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 16.28it/s v_num: 0.000     
                                                               rmse/val: 66.961 
                                                               rmse/train:      
                                                               65.137           
[[36m2025-02-24 16:35:48,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:35:48,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/010[0m
[[36m2025-02-24 16:35:48,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:35:48,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-02-24 16:35:48,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:35:48,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015791568646716513 prior_scale[0m
[[36m2025-02-24 16:35:48,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013400032806480455 q_scale[0m
[[36m2025-02-24 16:35:48,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:35:48,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-24 16:35:48,440[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:35:48,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:35:57,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:35:57,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:35:57,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:35:57,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:35:57,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:35:57,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:35:57,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:35:57,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:35:57,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:35:57,448[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:35:57,457[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 22.71it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4072.012         
                                                               rmse/train:      
                                                               4149.354         
[[36m2025-02-24 16:36:27,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:36:27,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/004[0m
[[36m2025-02-24 16:36:27,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:36:27,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-02-24 16:36:27,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:36:27,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001047833275436284 prior_scale[0m
[[36m2025-02-24 16:36:27,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02949625201538112 q_scale[0m
[[36m2025-02-24 16:36:27,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:36:27,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-24 16:36:27,540[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:36:27,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:36:36,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:36:36,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:36:36,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:36:36,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:36:36,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:36:36,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:36:36,875[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:36:36,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:36:36,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:36:36,913[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:36:36,923[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 16.24it/s v_num: 0.000     
                                                               rmse/val: 57.122 
                                                               rmse/train:      
                                                               54.412           
[[36m2025-02-24 16:36:55,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:36:55,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/011[0m
[[36m2025-02-24 16:36:55,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:36:55,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-02-24 16:36:55,372[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:36:55,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01578701912640358 prior_scale[0m
[[36m2025-02-24 16:36:55,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010569299297450266 q_scale[0m
[[36m2025-02-24 16:36:55,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:36:55,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-24 16:36:55,415[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:36:55,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:37:04,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:37:04,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:37:04,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:37:04,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:37:04,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:37:04,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:37:04,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:37:04,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:37:04,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:37:04,637[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:37:04,786[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 21.88it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4086.422         
                                                               rmse/train:      
                                                               4150.201         
[[36m2025-02-24 16:37:35,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:37:35,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/005[0m
[[36m2025-02-24 16:37:35,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:37:35,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-02-24 16:37:35,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:37:35,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038638969563953266 prior_scale[0m
[[36m2025-02-24 16:37:35,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033827492632411567 q_scale[0m
[[36m2025-02-24 16:37:35,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:37:35,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-24 16:37:35,353[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:37:35,353[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:37:44,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:37:44,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:37:44,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:37:44,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:37:44,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:37:44,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:37:44,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:37:44,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:37:44,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:37:44,790[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:37:44,799[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 13.92it/s v_num: 0.000     
                                                               rmse/val: 104.738
                                                               rmse/train:      
                                                               92.158           
[[36m2025-02-24 16:38:09,844[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:38:09,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/012[0m
[[36m2025-02-24 16:38:09,968[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:38:10,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009998183169689775, lr[0m
[[36m2025-02-24 16:38:10,023[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:38:10,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01064012896031672 prior_scale[0m
[[36m2025-02-24 16:38:10,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010211784008112604 q_scale[0m
[[36m2025-02-24 16:38:10,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:38:10,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-24 16:38:10,076[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:38:10,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:38:19,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:38:19,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:38:19,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:38:19,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:38:19,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:38:19,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:38:19,509[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:38:19,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:38:19,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:38:19,543[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:38:19,552[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.15it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3707.630         
                                                               rmse/train:      
                                                               3787.328         
[[36m2025-02-24 16:38:47,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:38:47,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/006[0m
[[36m2025-02-24 16:38:47,612[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:38:47,643[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-02-24 16:38:47,658[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:38:47,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020959477484878194 prior_scale[0m
[[36m2025-02-24 16:38:47,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008257988273685458 q_scale[0m
[[36m2025-02-24 16:38:47,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:38:47,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-24 16:38:47,704[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:38:47,704[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:38:56,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:38:56,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:38:56,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:38:56,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:38:56,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:38:56,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:38:56,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:38:56,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:38:56,999[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:38:57,039[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:38:57,051[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.69it/s v_num: 0.000     
                                                               rmse/val: 63.411 
                                                               rmse/train:      
                                                               44.702           
[[36m2025-02-24 16:38:58,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:38:58,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/013[0m
[[36m2025-02-24 16:38:58,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:38:58,239[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009813379195690634, lr[0m
[[36m2025-02-24 16:38:58,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:38:58,280[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03462087235603707 prior_scale[0m
[[36m2025-02-24 16:38:58,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004237992367412906 q_scale[0m
[[36m2025-02-24 16:38:58,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:38:58,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-24 16:38:58,323[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:38:58,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:39:07,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:39:07,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:39:07,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:39:07,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:39:07,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:39:07,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:39:07,939[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:39:07,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:39:07,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:39:07,965[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:39:07,980[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.16it/s v_num: 0.000     
                                                               rmse/val: 97.237 
                                                               rmse/train:      
                                                               54.107           
[[36m2025-02-24 16:39:45,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:39:45,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/014[0m
[[36m2025-02-24 16:39:45,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:39:45,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000993342265262209, lr[0m
[[36m2025-02-24 16:39:45,295[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:39:45,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03417847592213208 prior_scale[0m
[[36m2025-02-24 16:39:45,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005371630331658818 q_scale[0m
[[36m2025-02-24 16:39:45,363[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:39:45,363[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-24 16:39:45,363[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:39:45,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:39:55,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:39:55,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:39:55,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:39:55,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:39:55,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:39:55,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:39:55,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:39:55,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:39:55,028[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:39:55,062[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:39:55,094[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.23it/s v_num: 0.000     
                                                               rmse/val: 122.637
                                                               rmse/train:      
                                                               80.853           
[[36m2025-02-24 16:40:33,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:40:33,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/015[0m
[[36m2025-02-24 16:40:33,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:40:33,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000948739319244003, lr[0m
[[36m2025-02-24 16:40:33,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:40:33,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04757309843878119 prior_scale[0m
[[36m2025-02-24 16:40:34,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005478446090810961 q_scale[0m
[[36m2025-02-24 16:40:34,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:40:34,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-24 16:40:34,027[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:40:34,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:40:43,388[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:40:43,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:40:43,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:40:43,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:40:43,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:40:43,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:40:43,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:40:43,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:40:43,402[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:40:43,418[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:40:43,429[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.31it/s v_num: 0.000     
                                                               rmse/val: 77.885 
                                                               rmse/train:      
                                                               80.349           
[[36m2025-02-24 16:41:22,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:41:22,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/016[0m
[[36m2025-02-24 16:41:22,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:41:22,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005082091555483537, lr[0m
[[36m2025-02-24 16:41:22,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:41:22,615[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04022669862928931 prior_scale[0m
[[36m2025-02-24 16:41:22,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006411550999815748 q_scale[0m
[[36m2025-02-24 16:41:22,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:41:22,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-24 16:41:22,664[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:41:22,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:41:31,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:41:31,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:41:31,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:41:31,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:41:31,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:41:32,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:41:32,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:41:32,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:41:32,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:41:32,031[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:41:32,223[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:07 •       24.92it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1848.304         
                                                               rmse/train:      
                                                               1875.966         
[[36m2025-02-24 16:41:50,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:41:50,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/007[0m
[[36m2025-02-24 16:41:50,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:41:50,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-02-24 16:41:50,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:41:50,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07537199486913888 prior_scale[0m
[[36m2025-02-24 16:41:50,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0666791815288874 q_scale[0m
[[36m2025-02-24 16:41:50,688[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:41:50,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-24 16:41:50,689[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:41:50,690[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:42:00,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:42:00,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:42:00,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:42:00,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:42:00,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:42:00,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:42:00,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:42:00,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:42:00,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:42:00,385[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:42:00,394[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.11it/s v_num: 0.000     
                                                               rmse/val: 84.351 
                                                               rmse/train:      
                                                               68.622           
[[36m2025-02-24 16:42:12,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:42:12,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/017[0m
[[36m2025-02-24 16:42:13,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:42:13,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001350612004156431, lr[0m
[[36m2025-02-24 16:42:13,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:42:13,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32195184848174246 prior_scale[0m
[[36m2025-02-24 16:42:13,362[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00162577924453938 q_scale[0m
[[36m2025-02-24 16:42:13,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:42:13,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-24 16:42:13,381[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:42:13,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:42:23,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:42:23,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:42:23,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:42:23,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:42:23,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:42:23,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:42:23,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:42:23,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:42:23,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:42:23,126[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:42:23,135[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.12it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2451.976         
                                                               rmse/train:      
                                                               2609.455         
[[36m2025-02-24 16:43:02,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:43:02,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/018[0m
[[36m2025-02-24 16:43:02,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:43:02,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005632197917412741, lr[0m
[[36m2025-02-24 16:43:02,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:43:02,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06188833349524017 prior_scale[0m
[[36m2025-02-24 16:43:02,867[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002942702531995975 q_scale[0m
[[36m2025-02-24 16:43:02,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:43:02,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-24 16:43:02,886[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:43:02,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:43:12,170[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:43:12,178[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:43:12,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:43:12,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:43:12,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:43:12,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:43:12,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:43:12,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:43:12,183[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:43:12,222[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:43:12,235[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:04 • 0:00:00 11.82it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1974.164         
                                                               rmse/train:      
                                                               2111.061         
[[36m2025-02-24 16:43:50,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:43:50,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/008[0m
[[36m2025-02-24 16:43:50,630[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:43:50,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-02-24 16:43:50,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:43:50,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.714967484470097 prior_scale[0m
[[36m2025-02-24 16:43:50,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00834519932080496 q_scale[0m
[[36m2025-02-24 16:43:50,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:43:50,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-24 16:43:50,816[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:43:50,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.08it/s v_num: 0.000     
                                                               rmse/val: 88.889 
                                                               rmse/train:      
                                                               62.496           
[[36m2025-02-24 16:43:56,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:43:56,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/019[0m
[[36m2025-02-24 16:43:56,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:43:56,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006574375848469725, lr[0m
[[36m2025-02-24 16:43:56,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:43:56,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.562522491504443 prior_scale[0m
[[36m2025-02-24 16:43:56,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005383502861555352 q_scale[0m
[[36m2025-02-24 16:43:56,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:43:56,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-24 16:43:56,597[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:43:56,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:44:00,359[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:44:00,366[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:44:00,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:44:00,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:44:00,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:44:00,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:44:00,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:44:00,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:44:00,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:44:00,409[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:44:00,420[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:44:05,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:44:06,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:44:06,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:44:06,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:44:06,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:44:06,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:44:06,178[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:44:06,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:44:06,179[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:44:06,211[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:44:06,273[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.39it/s v_num: 0.000      
                                                              rmse/val: 4143.877
                                                              rmse/train:       
                                                              4155.646          
[[36m2025-02-24 16:44:28,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:44:28,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/020[0m
[[36m2025-02-24 16:44:28,499[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:44:28,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009674822215525922, lr[0m
[[36m2025-02-24 16:44:28,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:44:28,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03236196956216834 prior_scale[0m
[[36m2025-02-24 16:44:28,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004420637115621802 q_scale[0m
[[36m2025-02-24 16:44:28,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:44:28,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-24 16:44:28,636[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:44:28,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:44:38,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:44:38,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:44:38,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:44:38,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:44:38,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:44:38,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:44:38,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:44:38,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:44:38,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:44:39,978[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:44:40,311[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.01it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3394.655         
                                                               rmse/train:      
                                                               3489.448         
[[36m2025-02-24 16:45:13,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:45:13,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/009[0m
[[36m2025-02-24 16:45:13,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:45:13,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-02-24 16:45:13,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:45:13,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01116798829495977 prior_scale[0m
[[36m2025-02-24 16:45:13,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013611901663306908 q_scale[0m
[[36m2025-02-24 16:45:13,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:45:13,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-24 16:45:13,539[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:45:13,539[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:45:23,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:45:23,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:45:23,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:45:23,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:45:23,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:45:23,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:45:23,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:45:23,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:45:23,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:45:23,168[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:45:23,269[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.30it/s v_num: 0.000     
                                                               rmse/val: 104.182
                                                               rmse/train:      
                                                               68.310           
[[36m2025-02-24 16:45:24,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:45:24,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/021[0m
[[36m2025-02-24 16:45:24,767[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:45:24,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007743097196559441, lr[0m
[[36m2025-02-24 16:45:24,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:45:24,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03150770600840728 prior_scale[0m
[[36m2025-02-24 16:45:24,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013629141180540472 q_scale[0m
[[36m2025-02-24 16:45:24,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:45:24,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-24 16:45:24,889[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:45:24,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:45:34,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:45:34,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:45:34,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:45:34,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:45:34,567[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:45:34,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:45:34,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:45:34,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:45:34,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:45:34,588[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:45:34,598[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.53it/s v_num: 0.000     
                                                               rmse/val: 76.653 
                                                               rmse/train:      
                                                               54.330           
[[36m2025-02-24 16:46:11,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:46:11,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/022[0m
[[36m2025-02-24 16:46:11,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:46:11,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003786342127922616, lr[0m
[[36m2025-02-24 16:46:11,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:46:11,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.055317605061792445 prior_scale[0m
[[36m2025-02-24 16:46:11,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001507869429877801 q_scale[0m
[[36m2025-02-24 16:46:11,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:46:11,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-24 16:46:11,850[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:46:11,850[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:46:21,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:46:21,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:46:21,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:46:21,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:46:21,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:46:21,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:46:21,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:46:21,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:46:21,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:46:21,076[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:46:21,088[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.69it/s v_num: 0.000     
                                                               rmse/val: 150.938
                                                               rmse/train:      
                                                               161.422          
[[36m2025-02-24 16:47:02,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:47:02,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/023[0m
[[36m2025-02-24 16:47:02,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:47:02,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007125597761136394, lr[0m
[[36m2025-02-24 16:47:02,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:47:02,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006209310061318424 prior_scale[0m
[[36m2025-02-24 16:47:02,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014017326931421701 q_scale[0m
[[36m2025-02-24 16:47:02,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:47:02,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-24 16:47:02,880[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:47:02,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:47:12,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:47:12,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:47:12,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:47:12,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:47:12,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:47:12,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:47:12,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:47:12,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:47:12,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:47:12,249[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:47:12,273[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 8.41it/s v_num: 0.000      
                                                              rmse/val: 3203.242
                                                              rmse/train:       
                                                              3308.916          
[[36m2025-02-24 16:47:28,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:47:28,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/024[0m
[[36m2025-02-24 16:47:28,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:47:28,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004377467467829548, lr[0m
[[36m2025-02-24 16:47:28,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:47:28,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02288161600526003 prior_scale[0m
[[36m2025-02-24 16:47:28,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000342001263210907 q_scale[0m
[[36m2025-02-24 16:47:28,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:47:28,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-24 16:47:28,520[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:47:28,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:47:38,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:47:38,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:47:38,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:47:38,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:47:38,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:47:38,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:47:38,122[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:47:38,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:47:38,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:47:38,157[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:47:38,165[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.61it/s v_num: 0.000     
                                                               rmse/val: 122.389
                                                               rmse/train:      
                                                               128.410          
[[36m2025-02-24 16:48:17,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:48:17,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/025[0m
[[36m2025-02-24 16:48:17,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:48:17,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017593822992170268, lr[0m
[[36m2025-02-24 16:48:17,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:48:17,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15888778059582906 prior_scale[0m
[[36m2025-02-24 16:48:17,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002468621810993818 q_scale[0m
[[36m2025-02-24 16:48:17,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:48:17,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-24 16:48:17,501[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:48:17,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:48:26,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:48:26,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:48:26,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:48:26,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:48:26,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:48:26,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:48:26,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:48:26,886[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:48:26,887[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:48:26,901[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:48:26,910[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.94it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1943.268         
                                                               rmse/train:      
                                                               2082.088         
[[36m2025-02-24 16:49:04,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:49:04,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/026[0m
[[36m2025-02-24 16:49:04,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:49:04,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000778472802681413, lr[0m
[[36m2025-02-24 16:49:04,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:49:04,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.022634886982972866 prior_scale[0m
[[36m2025-02-24 16:49:04,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001004025177131389 q_scale[0m
[[36m2025-02-24 16:49:04,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:49:04,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-24 16:49:04,860[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:49:04,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:49:14,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:49:14,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:49:14,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:49:14,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:49:14,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:49:14,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:49:14,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:49:14,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:49:14,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:49:14,191[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:49:14,559[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.66it/s v_num: 0.000     
                                                               rmse/val: 99.768 
                                                               rmse/train:      
                                                               57.583           
[[36m2025-02-24 16:49:53,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:49:53,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/027[0m
[[36m2025-02-24 16:49:53,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:49:53,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003708248657038377, lr[0m
[[36m2025-02-24 16:49:53,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:49:53,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005987275126147801 prior_scale[0m
[[36m2025-02-24 16:49:53,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024217422139077454 q_scale[0m
[[36m2025-02-24 16:49:53,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:49:53,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-24 16:49:53,879[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:49:53,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:50:03,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:50:03,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:50:03,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:50:03,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:50:03,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:50:03,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:50:03,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:50:03,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:50:03,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:50:03,390[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:50:03,399[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:13 •       14.41it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 33.742 
                                                               rmse/train:      
                                                               26.556           
[[36m2025-02-24 16:50:40,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:50:40,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/010[0m
[[36m2025-02-24 16:50:40,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:50:40,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-02-24 16:50:40,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:50:40,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015791568646716513 prior_scale[0m
[[36m2025-02-24 16:50:40,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013400032806480455 q_scale[0m
[[36m2025-02-24 16:50:40,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:50:40,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-24 16:50:40,765[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:50:40,766[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.81it/s v_num: 0.000     
                                                               rmse/val: 559.408
                                                               rmse/train:      
                                                               705.997          
[[36m2025-02-24 16:50:42,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:50:42,103[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/028[0m
[[36m2025-02-24 16:50:42,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:50:42,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021497093006200005, lr[0m
[[36m2025-02-24 16:50:42,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:50:42,306[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2180582445508034 prior_scale[0m
[[36m2025-02-24 16:50:42,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006171832259851186 q_scale[0m
[[36m2025-02-24 16:50:42,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:50:42,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-24 16:50:42,342[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:50:42,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:50:50,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:50:50,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:50:50,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:50:50,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:50:50,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:50:50,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:50:50,122[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:50:50,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:50:50,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:50:50,157[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:50:50,165[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:50:51,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:50:51,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:50:51,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:50:51,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:50:51,576[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:50:51,576[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:50:51,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:50:51,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:50:51,578[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:50:51,613[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:50:51,635[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 7.55it/s v_num: 0.000      
                                                              rmse/val: 3478.393
                                                              rmse/train:       
                                                              3590.551          
[[36m2025-02-24 16:51:08,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:51:08,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/029[0m
[[36m2025-02-24 16:51:08,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:51:08,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.432377867102485e-05, lr[0m
[[36m2025-02-24 16:51:08,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:51:08,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07857858776141072 prior_scale[0m
[[36m2025-02-24 16:51:08,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01640672639104651 q_scale[0m
[[36m2025-02-24 16:51:08,913[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:51:08,913[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-24 16:51:08,913[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:51:08,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:51:18,542[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:51:18,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:51:18,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:51:18,551[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:51:18,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:51:18,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:51:18,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:51:18,553[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:51:18,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:51:18,567[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:51:18,576[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 6/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.16it/s v_num: 0.000       
                                                             rmse/val: 4143.756 
                                                             rmse/train:        
                                                             4233.214           
[[36m2025-02-24 16:51:23,449[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 6.
[[36m2025-02-24 16:51:23,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:51:23,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:51:23,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008347156871973041, lr[0m
[[36m2025-02-24 16:51:23,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:51:23,649[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04374071253578515 prior_scale[0m
[[36m2025-02-24 16:51:23,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004508934743020513 q_scale[0m
[[36m2025-02-24 16:51:23,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:51:23,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-24 16:51:23,680[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:51:23,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:51:32,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:51:32,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:51:32,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:51:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:51:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:51:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:51:32,919[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:51:32,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:51:32,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:51:32,934[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:51:32,943[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.05it/s v_num: 0.000     
                                                               rmse/val: 67.330 
                                                               rmse/train:      
                                                               50.624           
[[36m2025-02-24 16:52:12,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:52:12,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/031[0m
[[36m2025-02-24 16:52:13,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:52:13,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000775512645784766, lr[0m
[[36m2025-02-24 16:52:13,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:52:13,121[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04059316282401631 prior_scale[0m
[[36m2025-02-24 16:52:13,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023079812577530453 q_scale[0m
[[36m2025-02-24 16:52:13,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:52:13,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-24 16:52:13,160[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:52:13,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:52:22,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:52:22,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:52:22,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:52:22,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:52:22,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:52:22,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:52:22,478[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:52:22,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:52:22,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:52:22,521[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:52:22,534[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.26it/s v_num: 0.000     
                                                               rmse/val: 94.666 
                                                               rmse/train:      
                                                               70.282           
[[36m2025-02-24 16:53:01,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:53:01,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/032[0m
[[36m2025-02-24 16:53:01,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:53:01,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006804238848424044, lr[0m
[[36m2025-02-24 16:53:01,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:53:01,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.024278988745211245 prior_scale[0m
[[36m2025-02-24 16:53:01,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000736436212010933 q_scale[0m
[[36m2025-02-24 16:53:01,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:53:01,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-24 16:53:01,630[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:53:01,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:53:10,887[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:53:10,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:53:10,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:53:10,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:53:10,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:53:10,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:53:10,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:53:10,898[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:53:10,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:53:10,915[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:53:10,929[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.11it/s v_num: 0.000     
                                                               rmse/val: 78.404 
                                                               rmse/train:      
                                                               61.241           
[[36m2025-02-24 16:53:51,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:53:51,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/033[0m
[[36m2025-02-24 16:53:51,189[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:53:51,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004897796375031308, lr[0m
[[36m2025-02-24 16:53:51,239[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:53:51,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1155845475783687 prior_scale[0m
[[36m2025-02-24 16:53:51,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026442223564081156 q_scale[0m
[[36m2025-02-24 16:53:51,291[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:53:51,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-24 16:53:51,292[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:53:51,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:54:00,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:54:00,755[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:54:00,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:54:00,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:54:00,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:54:00,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:54:00,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:54:00,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:54:00,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:54:00,798[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:54:00,808[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 8.00it/s v_num: 0.000      
                                                              rmse/val: 3601.296
                                                              rmse/train:       
                                                              3708.055          
[[36m2025-02-24 16:54:17,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:54:17,643[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/034[0m
[[36m2025-02-24 16:54:17,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:54:17,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037617391924871403, lr[0m
[[36m2025-02-24 16:54:17,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:54:17,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05883704849475808 prior_scale[0m
[[36m2025-02-24 16:54:17,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8713279764354432 q_scale[0m
[[36m2025-02-24 16:54:17,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:54:17,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-24 16:54:17,890[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:54:17,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:54:27,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:54:27,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:54:27,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:54:27,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:54:27,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:54:27,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:54:27,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:54:27,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:54:27,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:54:27,282[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:54:27,303[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 6/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.24it/s v_num: 0.000     
                                                               rmse/val:        
                                                               5896.039         
                                                               rmse/train:      
                                                               4223.155         
[[36m2025-02-24 16:54:41,084[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 6.
[[36m2025-02-24 16:54:41,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:54:41,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:54:41,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000607008776649612, lr[0m
[[36m2025-02-24 16:54:41,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:54:41,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10060077655666898 prior_scale[0m
[[36m2025-02-24 16:54:41,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022391690342702332 q_scale[0m
[[36m2025-02-24 16:54:41,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:54:41,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-24 16:54:41,312[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:54:41,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:54:50,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:54:50,831[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:54:50,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:54:50,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:54:50,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:54:50,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:54:50,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:54:50,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:54:50,836[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:54:50,850[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:54:50,860[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 7.75it/s v_num: 0.000      
                                                              rmse/val: 3914.380
                                                              rmse/train:       
                                                              4012.133          
[[36m2025-02-24 16:54:59,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:54:59,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/036[0m
[[36m2025-02-24 16:54:59,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:54:59,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008092239092387384, lr[0m
[[36m2025-02-24 16:54:59,317[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:54:59,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0075106744285885875 prior_scale[0m
[[36m2025-02-24 16:54:59,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21193361588766488 q_scale[0m
[[36m2025-02-24 16:54:59,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:54:59,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-24 16:54:59,379[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:54:59,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:55:08,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:55:08,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:55:08,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:55:08,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:55:08,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:55:08,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:55:08,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:55:08,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:55:08,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:55:08,783[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:55:08,791[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.28it/s v_num: 0.000     
                                                               rmse/val: 420.163
                                                               rmse/train:      
                                                               284.657          
[[36m2025-02-24 16:55:45,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:55:45,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/037[0m
[[36m2025-02-24 16:55:45,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:55:45,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6429465259517205e-05, lr[0m
[[36m2025-02-24 16:55:45,796[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:55:45,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15632015523338957 prior_scale[0m
[[36m2025-02-24 16:55:45,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010379133942359465 q_scale[0m
[[36m2025-02-24 16:55:45,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:55:45,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-24 16:55:45,849[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:55:45,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:55:55,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:55:55,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:55:55,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:55:55,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:55:55,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:55:55,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:55:55,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:55:55,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:55:55,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:55:55,230[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:55:55,239[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       15.69it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 57.098 
                                                               rmse/train:      
                                                               43.939           
[[36m2025-02-24 16:56:05,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:56:05,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/011[0m
[[36m2025-02-24 16:56:06,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:56:06,044[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-02-24 16:56:06,056[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:56:06,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01578701912640358 prior_scale[0m
[[36m2025-02-24 16:56:06,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010569299297450266 q_scale[0m
[[36m2025-02-24 16:56:06,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:56:06,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-24 16:56:06,104[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:56:06,104[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:56:15,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:56:15,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:56:15,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:56:15,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:56:15,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:56:15,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:56:15,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:56:15,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:56:15,366[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:56:15,398[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:56:15,409[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:00 • 0:00:00 25.86it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3830.158         
                                                               rmse/train:      
                                                               3934.135         
[[36m2025-02-24 16:56:16,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:56:16,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/038[0m
[[36m2025-02-24 16:56:16,905[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:56:16,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0774254950974043e-05, lr[0m
[[36m2025-02-24 16:56:16,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:56:17,000[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04833802569046193 prior_scale[0m
[[36m2025-02-24 16:56:17,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00413733566583495 q_scale[0m
[[36m2025-02-24 16:56:17,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:56:17,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-24 16:56:17,047[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:56:17,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:56:26,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:56:26,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:56:26,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:56:26,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:56:26,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:56:26,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:56:26,353[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:56:26,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:56:26,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:56:26,392[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:56:26,425[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 7/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.59it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4147.723         
                                                               rmse/train:      
                                                               4252.897         
[[36m2025-02-24 16:56:41,757[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 7.
[[36m2025-02-24 16:56:41,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:56:41,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:56:41,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046320482838322957, lr[0m
[[36m2025-02-24 16:56:41,907[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:56:41,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023768200547248104 prior_scale[0m
[[36m2025-02-24 16:56:41,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047988390298866346 q_scale[0m
[[36m2025-02-24 16:56:41,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:56:41,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-24 16:56:41,964[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:56:41,964[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:56:51,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:56:51,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:56:51,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:56:51,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:56:51,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:56:51,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:56:51,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:56:51,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:56:51,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:56:51,885[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:56:51,893[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 15.81it/s v_num: 0.000      
                                                              rmse/val: 3535.463
                                                              rmse/train:       
                                                              3624.512          
[[36m2025-02-24 16:57:01,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:57:01,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/040[0m
[[36m2025-02-24 16:57:02,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:57:02,049[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009129174942486608, lr[0m
[[36m2025-02-24 16:57:02,066[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:57:02,089[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03303462275860387 prior_scale[0m
[[36m2025-02-24 16:57:02,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045841765775860374 q_scale[0m
[[36m2025-02-24 16:57:02,130[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:57:02,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-24 16:57:02,131[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:57:02,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:57:11,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:57:11,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:57:11,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:57:11,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:57:11,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:57:11,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:57:11,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:57:11,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:57:11,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:57:11,428[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:57:11,437[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.66it/s v_num: 0.000     
                                                               rmse/val: 127.211
                                                               rmse/train:      
                                                               66.343           
[[36m2025-02-24 16:57:49,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:57:49,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/041[0m
[[36m2025-02-24 16:57:49,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:57:49,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009691463861919047, lr[0m
[[36m2025-02-24 16:57:49,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:57:49,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016700353156951207 prior_scale[0m
[[36m2025-02-24 16:57:49,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018565455630260784 q_scale[0m
[[36m2025-02-24 16:57:49,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:57:49,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-24 16:57:49,900[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:57:49,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:57:59,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:57:59,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:57:59,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:57:59,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:57:59,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:57:59,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:57:59,491[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:57:59,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:57:59,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:57:59,524[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:57:59,543[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.02it/s v_num: 0.000     
                                                               rmse/val: 61.777 
                                                               rmse/train:      
                                                               45.901           
[[36m2025-02-24 16:58:35,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:58:35,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/042[0m
[[36m2025-02-24 16:58:35,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:58:35,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006104799687456833, lr[0m
[[36m2025-02-24 16:58:35,306[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:58:35,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0939675991605891 prior_scale[0m
[[36m2025-02-24 16:58:35,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00058966571608454 q_scale[0m
[[36m2025-02-24 16:58:35,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:58:35,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-24 16:58:35,354[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:58:35,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:58:44,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:58:44,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:58:44,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:58:44,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:58:44,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:58:44,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:58:44,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:58:44,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:58:44,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:58:44,579[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:58:44,590[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.21it/s v_num: 0.000     
                                                               rmse/val: 75.577 
                                                               rmse/train:      
                                                               58.047           
[[36m2025-02-24 16:59:23,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:59:23,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/043[0m
[[36m2025-02-24 16:59:23,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:59:23,746[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007919370154360854, lr[0m
[[36m2025-02-24 16:59:23,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:59:23,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.030991503194794913 prior_scale[0m
[[36m2025-02-24 16:59:23,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022032660462482086 q_scale[0m
[[36m2025-02-24 16:59:23,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:59:23,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-24 16:59:23,819[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:59:23,819[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:59:33,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:59:33,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:59:33,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:59:33,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:59:33,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:59:33,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:59:33,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:59:33,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:59:33,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:59:33,247[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:59:33,271[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.82it/s v_num: 0.000     
                                                               rmse/val: 108.278
                                                               rmse/train:      
                                                               70.832           
[[36m2025-02-24 17:00:09,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:00:09,886[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/044[0m
[[36m2025-02-24 17:00:10,022[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:00:10,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005824325059967519, lr[0m
[[36m2025-02-24 17:00:10,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:00:10,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07172891491207671 prior_scale[0m
[[36m2025-02-24 17:00:10,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000987826984116259 q_scale[0m
[[36m2025-02-24 17:00:10,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 17:00:10,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-24 17:00:10,141[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:00:10,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:00:19,661[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:00:19,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:00:19,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:00:19,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:00:19,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:00:19,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:00:19,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:00:19,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:00:19,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:00:19,688[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:00:19,696[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 10.45it/s v_num: 0.000     
                                                               rmse/val: 405.253
                                                               rmse/train:      
                                                               336.709          
[[36m2025-02-24 17:00:43,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:00:43,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/045[0m
[[36m2025-02-24 17:00:43,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:00:43,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031148414780247724, lr[0m
[[36m2025-02-24 17:00:43,616[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:00:43,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04224380282874942 prior_scale[0m
[[36m2025-02-24 17:00:43,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035137193151403334 q_scale[0m
[[36m2025-02-24 17:00:43,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:00:43,690[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-24 17:00:43,690[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:00:43,691[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:00:53,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:00:53,021[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:00:53,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:00:53,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:00:53,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:00:53,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:00:53,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:00:53,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:00:53,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:00:53,060[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:00:53,074[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:13 •       15.20it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 55.199 
                                                               rmse/train:      
                                                               45.487           
[[36m2025-02-24 17:01:16,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:01:16,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/012[0m
[[36m2025-02-24 17:01:16,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:01:16,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015991366116446953, lr[0m
[[36m2025-02-24 17:01:16,645[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:01:16,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023551654708581973 prior_scale[0m
[[36m2025-02-24 17:01:16,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010194432109815798 q_scale[0m
[[36m2025-02-24 17:01:16,697[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:01:16,697[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-24 17:01:16,698[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:01:16,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:01:26,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:01:26,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:01:26,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:01:26,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:01:26,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:01:26,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:01:26,129[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:01:26,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:01:26,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:01:26,161[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:01:26,301[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 25.30it/s v_num: 0.000     
                                                               rmse/val: 90.872 
                                                               rmse/train:      
                                                               57.064           
[[36m2025-02-24 17:01:31,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:01:31,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/046[0m
[[36m2025-02-24 17:01:32,085[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:01:32,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009781738011541141, lr[0m
[[36m2025-02-24 17:01:32,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:01:32,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017550439370320955 prior_scale[0m
[[36m2025-02-24 17:01:32,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001619891078163313 q_scale[0m
[[36m2025-02-24 17:01:32,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:01:32,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-24 17:01:32,229[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:01:32,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:01:41,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:01:41,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:01:41,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:01:41,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:01:41,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:01:41,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:01:41,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:01:41,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:01:41,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:01:41,639[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:01:41,660[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.93it/s v_num: 0.000     
                                                               rmse/val: 67.787 
                                                               rmse/train:      
                                                               38.604           
[[36m2025-02-24 17:02:18,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:02:18,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/047[0m
[[36m2025-02-24 17:02:18,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:02:18,645[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.1808411700953774e-05, lr[0m
[[36m2025-02-24 17:02:18,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:02:18,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008876003580946194 prior_scale[0m
[[36m2025-02-24 17:02:18,720[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016973428070037386 q_scale[0m
[[36m2025-02-24 17:02:18,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 17:02:18,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-24 17:02:18,740[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:02:18,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:02:28,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:02:28,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:02:28,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:02:28,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:02:28,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:02:28,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:02:28,246[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:02:28,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:02:28,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:02:28,286[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:02:28,786[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.14it/s v_num: 0.000      
                                                              rmse/val: 4105.711
                                                              rmse/train:       
                                                              4204.119          
[[36m2025-02-24 17:02:42,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:02:42,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/048[0m
[[36m2025-02-24 17:02:42,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:02:42,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007873965500460281, lr[0m
[[36m2025-02-24 17:02:42,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:02:42,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0182224486616023 prior_scale[0m
[[36m2025-02-24 17:02:42,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015635062812306252 q_scale[0m
[[36m2025-02-24 17:02:42,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:02:42,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-24 17:02:42,695[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:02:42,696[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:02:52,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:02:52,074[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:02:52,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:02:52,076[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:02:52,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:02:52,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:02:52,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:02:52,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:02:52,080[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:02:52,095[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:02:52,106[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.54it/s v_num: 0.000     
                                                               rmse/val: 43.449 
                                                               rmse/train:      
                                                               43.513           
[[36m2025-02-24 17:03:29,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:03:29,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/049[0m
[[36m2025-02-24 17:03:29,800[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:03:29,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004226936666484588, lr[0m
[[36m2025-02-24 17:03:29,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:03:29,865[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012151975919083978 prior_scale[0m
[[36m2025-02-24 17:03:29,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.013144470438999153 q_scale[0m
[[36m2025-02-24 17:03:29,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 17:03:29,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-24 17:03:29,898[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:03:29,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:03:38,968[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:03:38,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:03:38,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:03:38,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:03:38,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:03:38,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:03:38,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:03:38,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:03:38,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:03:39,011[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:03:39,068[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 11.48it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2217.652         
                                                               rmse/train:      
                                                               2340.342         
[[36m2025-02-24 17:04:00,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:04:00,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/050[0m
[[36m2025-02-24 17:04:00,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:04:00,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009482434335817354, lr[0m
[[36m2025-02-24 17:04:00,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:04:00,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03133377678532152 prior_scale[0m
[[36m2025-02-24 17:04:00,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006824097246447805 q_scale[0m
[[36m2025-02-24 17:04:00,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:04:00,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-24 17:04:00,400[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:04:00,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:04:09,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:04:09,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:04:09,537[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:04:09,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:04:09,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:04:09,540[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:04:09,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:04:09,540[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:04:09,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:04:09,555[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:04:09,564[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.36it/s v_num: 0.000     
                                                               rmse/val: 60.593 
                                                               rmse/train:      
                                                               52.408           
[[36m2025-02-24 17:04:15,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:04:15,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/013[0m
[[36m2025-02-24 17:04:16,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:04:16,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013257409719258245, lr[0m
[[36m2025-02-24 17:04:16,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:04:16,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03461234960695386 prior_scale[0m
[[36m2025-02-24 17:04:16,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042354345526637144 q_scale[0m
[[36m2025-02-24 17:04:16,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:04:16,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-24 17:04:16,241[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:04:16,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:04:25,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:04:25,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:04:25,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:04:25,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:04:25,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:04:25,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:04:25,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:04:25,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:04:25,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:04:25,530[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:04:25,649[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.85it/s v_num: 0.000     
                                                               rmse/val: 99.260 
                                                               rmse/train:      
                                                               56.840           
[[36m2025-02-24 17:04:42,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:04:42,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/051[0m
[[36m2025-02-24 17:04:43,050[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:04:43,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008608671748388018, lr[0m
[[36m2025-02-24 17:04:43,126[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:04:43,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0278647376009903 prior_scale[0m
[[36m2025-02-24 17:04:43,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000347369178303397 q_scale[0m
[[36m2025-02-24 17:04:43,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:04:43,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-24 17:04:43,196[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:04:43,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:04:52,281[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:04:52,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:04:52,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:04:52,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:04:52,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:04:52,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:04:52,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:04:52,291[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:04:52,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:04:52,377[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:04:52,385[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.89it/s v_num: 0.000     
                                                               rmse/val: 116.682
                                                               rmse/train:      
                                                               60.574           
[[36m2025-02-24 17:05:26,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:05:26,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/052[0m
[[36m2025-02-24 17:05:26,708[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:05:26,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006775415450880807, lr[0m
[[36m2025-02-24 17:05:26,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:05:26,799[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.018777319860926664 prior_scale[0m
[[36m2025-02-24 17:05:26,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007315498418777774 q_scale[0m
[[36m2025-02-24 17:05:26,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:05:26,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-24 17:05:26,852[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:05:26,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:05:35,892[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:05:35,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:05:35,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:05:35,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:05:35,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:05:35,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:05:35,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:05:35,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:05:35,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:05:35,919[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:05:35,944[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.02it/s v_num: 0.000     
                                                               rmse/val: 76.770 
                                                               rmse/train:      
                                                               62.162           
[[36m2025-02-24 17:06:09,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:06:09,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/053[0m
[[36m2025-02-24 17:06:09,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:06:09,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005270049230390942, lr[0m
[[36m2025-02-24 17:06:09,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:06:09,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.013484640148584826 prior_scale[0m
[[36m2025-02-24 17:06:09,808[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012983649112572094 q_scale[0m
[[36m2025-02-24 17:06:09,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:06:09,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-24 17:06:09,824[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:06:09,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:06:18,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:06:18,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:06:18,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:06:18,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:06:18,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:06:18,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:06:18,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:06:18,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:06:18,793[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:06:18,841[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:06:18,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.28it/s v_num: 0.000     
                                                               rmse/val: 55.397 
                                                               rmse/train:      
                                                               52.203           
[[36m2025-02-24 17:07:04,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:07:04,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/014[0m
[[36m2025-02-24 17:07:04,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:07:04,958[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015189044974620586, lr[0m
[[36m2025-02-24 17:07:04,975[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:07:04,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03417847592213208 prior_scale[0m
[[36m2025-02-24 17:07:05,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005113084326933055 q_scale[0m
[[36m2025-02-24 17:07:05,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:07:05,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-24 17:07:05,037[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:07:05,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:07:14,309[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:07:14,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:07:14,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:07:14,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:07:14,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:07:14,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:07:14,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:07:14,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:07:14,320[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:07:14,364[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:07:14,375[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 15.41it/s v_num: 0.000     
                                                               rmse/val: 40.293 
                                                               rmse/train:      
                                                               41.285           
[[36m2025-02-24 17:07:19,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:07:19,407[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/054[0m
[[36m2025-02-24 17:07:19,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:07:19,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009806708740653322, lr[0m
[[36m2025-02-24 17:07:19,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:07:19,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036913256485267935 prior_scale[0m
[[36m2025-02-24 17:07:19,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012527526668498944 q_scale[0m
[[36m2025-02-24 17:07:19,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:07:19,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-24 17:07:19,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:07:19,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:07:28,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:07:28,613[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:07:28,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:07:28,615[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:07:28,615[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:07:28,616[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:07:28,616[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:07:28,616[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:07:28,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:07:28,663[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:07:28,689[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.85it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2483.031         
                                                               rmse/train:      
                                                               2586.841         
[[36m2025-02-24 17:08:08,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:08:08,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/055[0m
[[36m2025-02-24 17:08:08,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:08:08,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006706160260172728, lr[0m
[[36m2025-02-24 17:08:08,455[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:08:08,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.046273074623980094 prior_scale[0m
[[36m2025-02-24 17:08:08,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00185892206781537 q_scale[0m
[[36m2025-02-24 17:08:08,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:08:08,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-24 17:08:08,505[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:08:08,505[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:08:17,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:08:17,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:08:17,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:08:17,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:08:17,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:08:17,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:08:17,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:08:17,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:08:17,495[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:08:17,510[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:08:17,588[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 13.84it/s v_num: 0.000     
                                                               rmse/val: 77.253 
                                                               rmse/train:      
                                                               59.058           
[[36m2025-02-24 17:08:51,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:08:51,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/056[0m
[[36m2025-02-24 17:08:51,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:08:51,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005531698886003352, lr[0m
[[36m2025-02-24 17:08:51,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:08:51,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014112612497003464 prior_scale[0m
[[36m2025-02-24 17:08:51,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05320235517324705 q_scale[0m
[[36m2025-02-24 17:08:51,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:08:51,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-24 17:08:51,301[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:08:51,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:09:00,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:09:00,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:09:00,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:09:00,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:09:00,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:09:00,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:09:00,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:09:00,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:09:00,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:09:00,305[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:09:00,358[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:00 • 0:00:00 25.76it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3544.967         
                                                               rmse/train:      
                                                               3602.301         
[[36m2025-02-24 17:09:20,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:09:20,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/057[0m
[[36m2025-02-24 17:09:20,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:09:20,443[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008517250477451783, lr[0m
[[36m2025-02-24 17:09:20,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:09:20,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06494034100378222 prior_scale[0m
[[36m2025-02-24 17:09:20,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031733990387606767 q_scale[0m
[[36m2025-02-24 17:09:20,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:09:20,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-24 17:09:20,510[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:09:20,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:09:29,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:09:29,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:09:29,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:09:29,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:09:29,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:09:29,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:09:29,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:09:29,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:09:29,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:09:29,501[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:09:29,510[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.20it/s v_num: 0.000     
                                                               rmse/val: 48.832 
                                                               rmse/train:      
                                                               47.161           
[[36m2025-02-24 17:09:56,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:09:56,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/015[0m
[[36m2025-02-24 17:09:56,464[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:09:56,507[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007375947662957758, lr[0m
[[36m2025-02-24 17:09:56,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:09:56,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04682731583684367 prior_scale[0m
[[36m2025-02-24 17:09:56,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006635200583129311 q_scale[0m
[[36m2025-02-24 17:09:56,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:09:56,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-24 17:09:56,586[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:09:56,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.22it/s v_num: 0.000     
                                                               rmse/val: 99.461 
                                                               rmse/train:      
                                                               67.772           
[[36m2025-02-24 17:10:03,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:10:03,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/058[0m
[[36m2025-02-24 17:10:04,050[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:10:04,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008128662342401826, lr[0m
[[36m2025-02-24 17:10:04,096[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:10:04,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07201780620192742 prior_scale[0m
[[36m2025-02-24 17:10:04,130[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004043860747595835 q_scale[0m
[[36m2025-02-24 17:10:04,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:10:04,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-24 17:10:04,145[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:10:04,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:10:05,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:10:05,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:10:05,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:10:05,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:10:05,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:10:05,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:10:05,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:10:05,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:10:05,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:10:05,899[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:10:05,947[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:10:13,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:10:13,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:10:13,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:10:13,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:10:13,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:10:13,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:10:13,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:10:13,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:10:13,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:10:13,180[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:10:13,187[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.00it/s v_num: 0.000     
                                                               rmse/val: 102.379
                                                               rmse/train:      
                                                               67.971           
[[36m2025-02-24 17:10:46,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:10:46,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-02-24_16-30-24/059[0m
[[36m2025-02-24 17:10:46,948[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.59it/s v_num: 0.000     
                                                               rmse/val: 52.168 
                                                               rmse/train:      
                                                               42.900           
[[36m2025-02-24 17:12:53,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:12:53,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/016[0m
[[36m2025-02-24 17:12:53,459[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:12:53,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008857057187524028, lr[0m
[[36m2025-02-24 17:12:53,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:12:53,523[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005572134247816106 prior_scale[0m
[[36m2025-02-24 17:12:53,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015837714312822743 q_scale[0m
[[36m2025-02-24 17:12:53,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 17:12:53,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-24 17:12:53,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:12:53,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:13:03,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:13:03,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:13:03,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:13:03,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:13:03,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:13:03,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:13:03,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:13:03,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:13:03,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:13:03,222[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:13:03,232[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 8.26it/s v_num: 0.000     
                                                               rmse/val: 90.137 
                                                               rmse/train:      
                                                               75.438           
[[36m2025-02-24 17:14:14,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:14:14,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/017[0m
[[36m2025-02-24 17:14:14,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:14:14,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009158499664787932, lr[0m
[[36m2025-02-24 17:14:14,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:14:14,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31873226199384586 prior_scale[0m
[[36m2025-02-24 17:14:14,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026981562100785334 q_scale[0m
[[36m2025-02-24 17:14:14,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 17:14:14,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-24 17:14:14,265[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:14:14,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:14:24,428[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:14:24,434[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:14:24,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:14:24,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:14:24,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:14:24,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:14:24,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:14:24,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:14:24,439[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:14:24,543[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:14:24,568[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:02 • 0:00:00 5.12it/s v_num: 0.000     
                                                               rmse/val: 119.916
                                                               rmse/train:      
                                                               114.309          
[[36m2025-02-24 17:15:20,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:15:20,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/018[0m
[[36m2025-02-24 17:15:20,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:15:20,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004974897803992315, lr[0m
[[36m2025-02-24 17:15:20,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:15:20,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007133078560557303 prior_scale[0m
[[36m2025-02-24 17:15:20,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012151921954315257 q_scale[0m
[[36m2025-02-24 17:15:20,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:15:20,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-24 17:15:20,357[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:15:20,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:15:30,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:15:30,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:15:30,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:15:30,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:15:30,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:15:30,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:15:30,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:15:30,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:15:30,221[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:15:30,252[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:15:30,266[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       16.46it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 28.442 
                                                               rmse/train:      
                                                               26.784           
[[36m2025-02-24 17:20:27,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:20:27,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/019[0m
[[36m2025-02-24 17:20:27,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:20:27,527[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004972303740230067, lr[0m
[[36m2025-02-24 17:20:27,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:20:27,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05683649955159428 prior_scale[0m
[[36m2025-02-24 17:20:27,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002493671225705809 q_scale[0m
[[36m2025-02-24 17:20:27,582[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:20:27,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-24 17:20:27,583[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:20:27,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:20:36,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:20:36,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:20:36,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:20:36,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:20:36,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:20:36,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:20:36,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:20:36,763[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:20:36,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:20:36,794[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:20:36,801[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.42it/s v_num: 0.000     
                                                               rmse/val: 48.149 
                                                               rmse/train:      
                                                               42.349           
[[36m2025-02-24 17:23:12,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:23:12,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/020[0m
[[36m2025-02-24 17:23:12,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:23:13,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004830116927473398, lr[0m
[[36m2025-02-24 17:23:13,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:23:13,040[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06006153051586785 prior_scale[0m
[[36m2025-02-24 17:23:13,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000261586980086613 q_scale[0m
[[36m2025-02-24 17:23:13,077[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:23:13,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-24 17:23:13,078[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:23:13,078[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:23:22,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:23:22,392[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:23:22,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:23:22,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:23:22,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:23:22,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:23:22,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:23:22,396[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:23:22,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:23:22,441[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:23:22,455[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.63it/s v_num: 0.000     
                                                               rmse/val: 52.050 
                                                               rmse/train:      
                                                               39.544           
[[36m2025-02-24 17:25:58,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:25:58,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/021[0m
[[36m2025-02-24 17:25:58,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:25:58,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005377740280800115, lr[0m
[[36m2025-02-24 17:25:58,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:25:58,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05105843166597698 prior_scale[0m
[[36m2025-02-24 17:25:58,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029912684398653944 q_scale[0m
[[36m2025-02-24 17:25:58,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:25:58,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-24 17:25:58,329[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:25:58,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:26:07,545[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:26:07,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:26:07,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:26:07,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:26:07,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:26:07,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:26:07,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:26:07,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:26:07,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:26:07,601[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:26:07,613[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.64it/s v_num: 0.000     
                                                               rmse/val: 52.077 
                                                               rmse/train:      
                                                               43.634           
[[36m2025-02-24 17:28:43,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:28:43,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/022[0m
[[36m2025-02-24 17:28:43,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:28:43,913[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006762758852258772, lr[0m
[[36m2025-02-24 17:28:43,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:28:43,953[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.046934091497090095 prior_scale[0m
[[36m2025-02-24 17:28:44,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002533974916926274 q_scale[0m
[[36m2025-02-24 17:28:44,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:28:44,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-24 17:28:44,040[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:28:44,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:28:53,206[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:28:53,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:28:53,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:28:53,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:28:53,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:28:53,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:28:53,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:28:53,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:28:53,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:28:53,256[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:28:53,268[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.01it/s v_num: 0.000     
                                                               rmse/val: 52.407 
                                                               rmse/train:      
                                                               43.870           
[[36m2025-02-24 17:31:41,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:31:41,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/023[0m
[[36m2025-02-24 17:31:41,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:31:41,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003728926253884459, lr[0m
[[36m2025-02-24 17:31:41,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:31:41,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17962616168149295 prior_scale[0m
[[36m2025-02-24 17:31:41,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006723353115962035 q_scale[0m
[[36m2025-02-24 17:31:41,886[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:31:41,886[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-24 17:31:41,887[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:31:41,887[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:31:51,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:31:51,386[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:31:51,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:31:51,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:31:51,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:31:51,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:31:51,390[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:31:51,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:31:51,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:31:51,427[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:31:51,459[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.45it/s v_num: 0.000     
                                                               rmse/val: 54.094 
                                                               rmse/train:      
                                                               45.832           
[[36m2025-02-24 17:34:29,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:34:29,468[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-24_16-30-24/024[0m
[[36m2025-02-24 17:34:29,566[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:34:29,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035130721966574813, lr[0m
[[36m2025-02-24 17:34:29,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:34:29,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.40432221386901723 prior_scale[0m
[[36m2025-02-24 17:34:29,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007388845588571457 q_scale[0m
[[36m2025-02-24 17:34:29,670[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:34:29,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-24 17:34:29,671[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:34:29,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
[[36m2025-02-24 17:38:53,585[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 27, in __init__
    self.load_db()
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 44, in load_db
    self.list_structures_energy, self.list_structures_forces, self.list_removed, self.max_nnb, self.tin = read_list_structures(self.tin)
                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/prepare_batches.py", line 15, in read_list_structures
    list_structures_energy, list_removed, max_nnb, tin = read_train(tin)
                                                         ^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/read_trainset.py", line 104, in read_train
    with open (trainfile, "r") as tf:
         ^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: '/work/g15farris/database/TiO/data.train.ascii'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 46, in train
    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.datamodule)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'bnn_aenet.datamodule.aenet_datamodule.AenetDataModule':
OSError(5, 'Input/output error')
full_key: datamodule
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-25 10:43:49,132[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-25 10:43:49,133[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/fo_100perc.db[0m
[[36m2025-02-25 10:43:51,179[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-25 10:43:51,188[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-25 10:43:51,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 10:43:51,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003427185058354017, lr[0m
[[36m2025-02-25 10:43:51,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 10:43:51,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4807864763603264 prior_scale[0m
[[36m2025-02-25 10:43:51,437[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007598072483725891 q_scale[0m
[[36m2025-02-25 10:43:51,455[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 10:43:51,455[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-25 10:43:51,456[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 10:43:51,456[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
[[36m2025-02-25 10:57:00,689[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 27, in __init__
    self.load_db()
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 44, in load_db
    self.list_structures_energy, self.list_structures_forces, self.list_removed, self.max_nnb, self.tin = read_list_structures(self.tin)
                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/prepare_batches.py", line 15, in read_list_structures
    list_structures_energy, list_removed, max_nnb, tin = read_train(tin)
                                                         ^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/read_trainset.py", line 104, in read_train
    with open (trainfile, "r") as tf:
         ^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: '/work/g15farris/database/TiO/data.train.ascii'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 46, in train
    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.datamodule)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'bnn_aenet.datamodule.aenet_datamodule.AenetDataModule':
OSError(5, 'Input/output error')
full_key: datamodule
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-25 11:01:19,895[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-25 11:01:19,900[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/fo_100perc.db[0m
[[36m2025-02-25 11:01:20,441[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-25 11:01:20,446[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-25 11:01:20,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:01:20,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003427185058354017, lr[0m
[[36m2025-02-25 11:01:20,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:01:20,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4807864763603264 prior_scale[0m
[[36m2025-02-25 11:01:20,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007598072483725891 q_scale[0m
[[36m2025-02-25 11:01:20,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:01:20,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-25 11:01:20,642[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:01:20,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:01:30,326[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:01:32,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:01:32,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:01:32,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:01:32,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:01:32,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:01:32,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:01:32,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:01:32,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:01:32,354[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:01:32,516[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 12.80it/s v_num: 0.000     
                                                               rmse/val: 49.600 
                                                               rmse/train:      
                                                               40.107           
[[36m2025-02-25 11:04:17,130[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2025-02-25 11:04:17,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:04:17,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:04:17,625[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00039451456352014266, lr[0m
[[36m2025-02-25 11:04:17,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:04:17,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15579590651811182 prior_scale[0m
[[36m2025-02-25 11:04:17,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007697277673579377 q_scale[0m
[[36m2025-02-25 11:04:17,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:04:17,720[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-25 11:04:17,721[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:04:17,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:04:27,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:04:27,221[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:04:27,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:04:27,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:04:27,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:04:27,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:04:27,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:04:27,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:04:27,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:04:27,294[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:04:27,325[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.91it/s v_num: 0.000     
                                                               rmse/val: 50.197 
                                                               rmse/train:      
                                                               34.162           
[[36m2025-02-25 11:07:22,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:07:22,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/028[0m
[[36m2025-02-25 11:07:22,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:07:22,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007269248594832969, lr[0m
[[36m2025-02-25 11:07:22,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:07:22,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.25803201983845575 prior_scale[0m
[[36m2025-02-25 11:07:22,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001340252675660988 q_scale[0m
[[36m2025-02-25 11:07:22,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:07:22,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-25 11:07:22,804[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:07:22,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:07:32,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:07:32,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:07:32,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:07:32,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:07:32,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:07:32,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:07:32,377[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:07:32,377[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:07:32,379[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:07:32,601[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:07:32,626[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 12.99it/s v_num: 0.000     
                                                               rmse/val: 53.901 
                                                               rmse/train:      
                                                               43.926           
[[36m2025-02-25 11:10:30,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:10:30,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/029[0m
[[36m2025-02-25 11:10:30,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:10:31,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000237679721845533, lr[0m
[[36m2025-02-25 11:10:31,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:10:31,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09057090300643525 prior_scale[0m
[[36m2025-02-25 11:10:31,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004492611808782323 q_scale[0m
[[36m2025-02-25 11:10:31,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:10:31,117[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-25 11:10:31,118[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:10:31,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:10:40,575[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:10:40,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:10:40,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:10:40,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:10:40,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:10:40,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:10:40,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:10:40,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:10:40,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:10:40,646[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:10:40,655[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 12.91it/s v_num: 0.000     
                                                               rmse/val: 61.852 
                                                               rmse/train:      
                                                               50.937           
[[36m2025-02-25 11:13:36,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:13:36,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/030[0m
[[36m2025-02-25 11:13:36,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:13:36,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000993640067505852, lr[0m
[[36m2025-02-25 11:13:36,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:13:36,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18162169046510418 prior_scale[0m
[[36m2025-02-25 11:13:36,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006034408509941582 q_scale[0m
[[36m2025-02-25 11:13:36,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:13:36,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-25 11:13:36,987[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:13:36,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:13:46,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:13:46,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:13:46,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:13:46,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:13:46,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:13:46,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:13:46,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:13:46,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:13:46,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:13:46,715[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:13:46,723[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 8.53it/s v_num: 0.000     
                                                               rmse/val: 64.974 
                                                               rmse/train:      
                                                               59.594           
[[36m2025-02-25 11:14:57,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:14:57,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/031[0m
[[36m2025-02-25 11:14:57,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:14:57,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009865246002035441, lr[0m
[[36m2025-02-25 11:14:57,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:14:57,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.38966438292874317 prior_scale[0m
[[36m2025-02-25 11:14:57,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015885105792392447 q_scale[0m
[[36m2025-02-25 11:14:57,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:14:57,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-25 11:14:57,501[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:14:57,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:15:06,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:15:06,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:15:06,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:15:06,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:15:06,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:15:06,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:15:06,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:15:06,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:15:06,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:15:07,177[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:15:07,273[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 10/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.92it/s v_num: 0.000     
                                                               rmse/val: 941.813
                                                               rmse/train:      
                                                               1016.332         
[[36m2025-02-25 11:15:47,940[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 10.
[[36m2025-02-25 11:15:47,945[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:15:48,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:15:48,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000707590049834826, lr[0m
[[36m2025-02-25 11:15:48,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:15:48,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19908330830829532 prior_scale[0m
[[36m2025-02-25 11:15:48,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005764471187015978 q_scale[0m
[[36m2025-02-25 11:15:48,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:15:48,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-25 11:15:48,233[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:15:48,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:15:58,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:15:58,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:15:58,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:15:58,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:15:58,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:15:58,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:15:58,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:15:58,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:15:58,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:15:58,069[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:15:58,176[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.98it/s v_num: 0.000     
                                                               rmse/val: 47.639 
                                                               rmse/train:      
                                                               46.480           
[[36m2025-02-25 11:17:11,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:17:11,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/033[0m
[[36m2025-02-25 11:17:11,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:17:11,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006632740253598452, lr[0m
[[36m2025-02-25 11:17:11,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:17:11,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15976219024803112 prior_scale[0m
[[36m2025-02-25 11:17:11,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006411550999815748 q_scale[0m
[[36m2025-02-25 11:17:11,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:17:11,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-25 11:17:11,283[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:17:11,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:17:20,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:17:20,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:17:20,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:17:20,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:17:20,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:17:20,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:17:20,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:17:20,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:17:20,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:17:20,955[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:17:20,966[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 8.36it/s v_num: 0.000     
                                                               rmse/val: 60.015 
                                                               rmse/train:      
                                                               58.212           
[[36m2025-02-25 11:18:32,886[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:18:32,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/034[0m
[[36m2025-02-25 11:18:33,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:18:33,105[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007512572629138248, lr[0m
[[36m2025-02-25 11:18:33,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:18:33,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1899127532734213 prior_scale[0m
[[36m2025-02-25 11:18:33,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020332984919444776 q_scale[0m
[[36m2025-02-25 11:18:33,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:18:33,191[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-25 11:18:33,191[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:18:33,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:18:42,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:18:42,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:18:42,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:18:42,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:18:42,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:18:42,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:18:42,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:18:42,581[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:18:42,582[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:18:42,613[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:18:42,622[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.91it/s v_num: 0.000     
                                                               rmse/val: 67.812 
                                                               rmse/train:      
                                                               63.484           
[[36m2025-02-25 11:19:54,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:19:54,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/035[0m
[[36m2025-02-25 11:19:54,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:19:54,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004140870018774387, lr[0m
[[36m2025-02-25 11:19:54,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:19:54,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2119922193196194 prior_scale[0m
[[36m2025-02-25 11:19:55,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020006514159703653 q_scale[0m
[[36m2025-02-25 11:19:55,023[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:19:55,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-25 11:19:55,024[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:19:55,024[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:20:04,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:20:04,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:20:04,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:20:04,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:20:04,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:20:04,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:20:04,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:20:04,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:20:04,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:20:04,691[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:20:04,718[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.94it/s v_num: 0.000     
                                                               rmse/val: 119.189
                                                               rmse/train:      
                                                               128.936          
[[36m2025-02-25 11:21:17,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:21:17,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/036[0m
[[36m2025-02-25 11:21:17,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:21:17,516[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009846890224531311, lr[0m
[[36m2025-02-25 11:21:17,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:21:17,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7746726721833557 prior_scale[0m
[[36m2025-02-25 11:21:17,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005089358866182199 q_scale[0m
[[36m2025-02-25 11:21:17,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:21:17,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-25 11:21:17,612[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:21:17,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:21:27,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:21:27,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:21:27,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:21:27,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:21:27,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:21:27,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:21:27,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:21:27,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:21:27,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:21:27,192[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:21:27,230[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 8.53it/s v_num: 0.000     
                                                               rmse/val: 72.062 
                                                               rmse/train:      
                                                               71.781           
[[36m2025-02-25 11:22:36,663[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2025-02-25 11:22:36,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:22:36,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:22:36,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021124113595566394, lr[0m
[[36m2025-02-25 11:22:36,808[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:22:36,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11963542302456126 prior_scale[0m
[[36m2025-02-25 11:22:36,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010925563268652616 q_scale[0m
[[36m2025-02-25 11:22:36,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:22:36,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-25 11:22:36,857[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:22:36,857[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:22:46,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:22:46,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:22:46,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:22:46,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:22:46,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:22:46,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:22:46,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:22:46,279[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:22:46,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:22:46,335[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:22:46,343[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 15.25it/s v_num: 0.000     
                                                               rmse/val: 337.415
                                                               rmse/train:      
                                                               354.208          
[[36m2025-02-25 11:23:28,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:23:28,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/038[0m
[[36m2025-02-25 11:23:28,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:23:28,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.565192656041682e-05, lr[0m
[[36m2025-02-25 11:23:28,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:23:28,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.537137378930078 prior_scale[0m
[[36m2025-02-25 11:23:28,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002221812437584267 q_scale[0m
[[36m2025-02-25 11:23:28,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:23:28,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-25 11:23:28,915[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:23:28,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:23:38,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:23:38,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:23:38,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:23:38,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:23:38,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:23:38,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:23:38,516[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:23:38,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:23:38,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:23:38,531[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:23:38,539[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.86it/s v_num: 0.000     
                                                               rmse/val: 703.596
                                                               rmse/train:      
                                                               744.886          
[[36m2025-02-25 11:24:51,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:24:51,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/039[0m
[[36m2025-02-25 11:24:51,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:24:51,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006429333294557271, lr[0m
[[36m2025-02-25 11:24:51,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:24:51,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20507833378967316 prior_scale[0m
[[36m2025-02-25 11:24:51,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003683288891358153 q_scale[0m
[[36m2025-02-25 11:24:51,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 11:24:51,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-25 11:24:51,915[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:24:51,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:25:02,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:25:02,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:25:02,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:25:02,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:25:02,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:25:02,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:25:02,061[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:25:02,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:25:02,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:25:02,094[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:25:02,110[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 9.34it/s v_num: 0.000     
                                                               rmse/val: 204.476
                                                               rmse/train:      
                                                               227.792          
[[36m2025-02-25 11:25:34,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:25:34,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/040[0m
[[36m2025-02-25 11:25:34,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:25:34,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003558250160840399, lr[0m
[[36m2025-02-25 11:25:35,063[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:25:35,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26818240855726705 prior_scale[0m
[[36m2025-02-25 11:25:35,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7539083463430221 q_scale[0m
[[36m2025-02-25 11:25:35,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:25:35,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-25 11:25:35,177[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:25:35,177[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:25:44,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:25:44,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:25:44,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:25:44,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:25:44,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:25:44,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:25:44,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:25:44,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:25:44,829[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:25:44,842[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:25:44,868[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 6/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 8.54it/s v_num: 0.000      
                                                              rmse/val: 4188.052
                                                              rmse/train:       
                                                              3540.998          
[[36m2025-02-25 11:26:10,243[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 6.
[[36m2025-02-25 11:26:10,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:26:10,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:26:10,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.865200524077346e-05, lr[0m
[[36m2025-02-25 11:26:10,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:26:10,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9703569177034177 prior_scale[0m
[[36m2025-02-25 11:26:10,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033562917349588117 q_scale[0m
[[36m2025-02-25 11:26:10,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:26:10,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-25 11:26:10,440[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:26:10,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:26:19,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:26:19,957[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:26:19,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:26:19,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:26:19,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:26:19,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:26:19,961[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:26:19,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:26:19,962[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:26:19,992[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:26:20,000[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 15.15it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4530.891         
                                                               rmse/train:      
                                                               4647.476         
[[36m2025-02-25 11:27:00,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:27:00,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/042[0m
[[36m2025-02-25 11:27:00,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:27:00,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007166712240888227, lr[0m
[[36m2025-02-25 11:27:00,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:27:00,857[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10811061887086142 prior_scale[0m
[[36m2025-02-25 11:27:00,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007264166220322228 q_scale[0m
[[36m2025-02-25 11:27:00,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:27:00,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-25 11:27:00,904[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:27:00,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:27:10,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:27:10,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:27:10,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:27:10,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:27:10,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:27:10,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:27:10,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:27:10,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:27:10,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:27:10,550[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:27:10,559[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.96it/s v_num: 0.000     
                                                               rmse/val: 75.544 
                                                               rmse/train:      
                                                               75.320           
[[36m2025-02-25 11:28:25,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:28:25,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/043[0m
[[36m2025-02-25 11:28:25,189[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:28:25,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007698300883305607, lr[0m
[[36m2025-02-25 11:28:25,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:28:25,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18169081359952768 prior_scale[0m
[[36m2025-02-25 11:28:25,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020482240667682217 q_scale[0m
[[36m2025-02-25 11:28:25,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 11:28:25,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-25 11:28:25,290[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:28:25,290[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:28:35,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:28:35,407[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:28:35,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:28:35,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:28:35,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:28:35,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:28:35,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:28:35,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:28:35,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:28:35,455[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:28:35,577[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:02 • 0:00:00 4.91it/s v_num: 0.000     
                                                               rmse/val: 185.686
                                                               rmse/train:      
                                                               196.195          
[[36m2025-02-25 11:29:32,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:29:32,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/044[0m
[[36m2025-02-25 11:29:32,248[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:29:32,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005843513618671082, lr[0m
[[36m2025-02-25 11:29:32,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:29:32,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0798175204721811 prior_scale[0m
[[36m2025-02-25 11:29:32,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009607600842833615 q_scale[0m
[[36m2025-02-25 11:29:32,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:29:32,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-25 11:29:32,370[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:29:32,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:29:42,028[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:29:42,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:29:42,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:29:42,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:29:42,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:29:42,038[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:29:42,039[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:29:42,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:29:42,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:29:42,070[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:29:42,548[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.92it/s v_num: 0.000     
                                                               rmse/val: 73.796 
                                                               rmse/train:      
                                                               71.885           
[[36m2025-02-25 11:30:58,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:30:58,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/045[0m
[[36m2025-02-25 11:30:58,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:30:58,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0597177679192552e-05, lr[0m
[[36m2025-02-25 11:30:58,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:30:58,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1273161139377335 prior_scale[0m
[[36m2025-02-25 11:30:58,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005152825742333252 q_scale[0m
[[36m2025-02-25 11:30:58,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:30:58,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-25 11:30:58,482[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:30:58,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:31:08,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:31:08,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:31:08,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:31:08,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:31:08,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:31:08,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:31:08,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:31:08,169[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:31:08,170[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:31:08,202[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:31:08,215[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:03 • 0:00:00 7.94it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4006.637         
                                                               rmse/train:      
                                                               4071.834         
[[36m2025-02-25 11:32:22,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:32:22,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/046[0m
[[36m2025-02-25 11:32:22,230[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:32:22,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007923762666056606, lr[0m
[[36m2025-02-25 11:32:22,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:32:22,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5227344109654916 prior_scale[0m
[[36m2025-02-25 11:32:22,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016892743184552565 q_scale[0m
[[36m2025-02-25 11:32:22,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:32:22,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-25 11:32:22,332[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:32:22,332[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:32:31,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:32:32,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:32:32,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:32:32,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:32:32,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:32:32,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:32:32,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:32:32,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:32:32,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:32:32,101[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:32:32,109[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 8.53it/s v_num: 0.000     
                                                               rmse/val: 77.020 
                                                               rmse/train:      
                                                               65.167           
[[36m2025-02-25 11:33:45,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:33:45,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/047[0m
[[36m2025-02-25 11:33:45,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:33:45,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042229950729932386, lr[0m
[[36m2025-02-25 11:33:45,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:33:45,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3109180975949119 prior_scale[0m
[[36m2025-02-25 11:33:45,452[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020316039936646373 q_scale[0m
[[36m2025-02-25 11:33:45,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:33:45,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-25 11:33:45,475[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:33:45,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:33:54,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:33:54,781[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:33:54,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:33:54,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:33:54,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:33:54,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:33:54,785[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:33:54,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:33:54,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:33:54,828[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:33:54,839[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.11it/s v_num: 0.000     
                                                               rmse/val: 47.604 
                                                               rmse/train:      
                                                               40.341           
[[36m2025-02-25 11:34:55,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:34:55,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/048[0m
[[36m2025-02-25 11:34:55,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:34:55,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004345818546382463, lr[0m
[[36m2025-02-25 11:34:55,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:34:55,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3469893715151292 prior_scale[0m
[[36m2025-02-25 11:34:55,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020302145800764421 q_scale[0m
[[36m2025-02-25 11:34:55,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:34:55,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-25 11:34:55,852[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:34:55,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:35:05,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:35:05,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:35:05,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:35:05,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:35:05,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:35:05,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:35:05,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:35:05,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:35:05,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:35:05,378[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:35:05,386[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.17it/s v_num: 0.000     
                                                               rmse/val: 38.459 
                                                               rmse/train:      
                                                               35.508           
[[36m2025-02-25 11:36:07,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:36:07,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/049[0m
[[36m2025-02-25 11:36:07,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:36:07,784[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011488334419451255, lr[0m
[[36m2025-02-25 11:36:07,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:36:07,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.345294463046589 prior_scale[0m
[[36m2025-02-25 11:36:07,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001651786393791005 q_scale[0m
[[36m2025-02-25 11:36:07,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:36:07,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-25 11:36:07,847[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:36:07,847[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:36:17,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:36:17,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:36:17,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:36:17,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:36:17,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:36:17,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:36:17,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:36:17,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:36:17,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:36:17,329[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:36:17,356[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.69it/s v_num: 0.000     
                                                               rmse/val: 255.701
                                                               rmse/train:      
                                                               260.769          
[[36m2025-02-25 11:37:19,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:37:19,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/050[0m
[[36m2025-02-25 11:37:19,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:37:19,615[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031340311191667343, lr[0m
[[36m2025-02-25 11:37:19,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:37:19,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6228420672843981 prior_scale[0m
[[36m2025-02-25 11:37:19,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001589093331924912 q_scale[0m
[[36m2025-02-25 11:37:19,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:37:19,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-25 11:37:19,696[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:37:19,696[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:37:29,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:37:29,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:37:29,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:37:29,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:37:29,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:37:29,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:37:29,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:37:29,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:37:29,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:37:29,201[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:37:29,209[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.30it/s v_num: 0.000     
                                                               rmse/val: 216.397
                                                               rmse/train:      
                                                               219.152          
[[36m2025-02-25 11:38:28,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:38:28,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/051[0m
[[36m2025-02-25 11:38:28,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:38:28,724[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019579788640749392, lr[0m
[[36m2025-02-25 11:38:28,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:38:28,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41937985309561415 prior_scale[0m
[[36m2025-02-25 11:38:28,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.173448068722513 q_scale[0m
[[36m2025-02-25 11:38:28,861[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:38:28,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-25 11:38:28,862[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:38:28,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:38:38,543[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:38:38,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:38:38,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:38:38,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:38:38,553[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:38:38,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:38:38,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:38:38,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:38:38,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:38:38,588[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:38:38,611[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.24it/s v_num: 0.000     
                                                               rmse/val: 435.054
                                                               rmse/train:      
                                                               577.498          
[[36m2025-02-25 11:39:41,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:39:41,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/052[0m
[[36m2025-02-25 11:39:41,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:39:41,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004415040442157595, lr[0m
[[36m2025-02-25 11:39:41,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:39:41,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2629309848428353 prior_scale[0m
[[36m2025-02-25 11:39:41,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041961345355145155 q_scale[0m
[[36m2025-02-25 11:39:41,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:39:41,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-25 11:39:41,983[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:39:41,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:39:51,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:39:51,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:39:51,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:39:51,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:39:51,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:39:51,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:39:51,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:39:51,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:39:51,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:39:51,461[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:39:51,484[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.22it/s v_num: 0.000     
                                                               rmse/val: 44.044 
                                                               rmse/train:      
                                                               39.630           
[[36m2025-02-25 11:40:51,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:40:51,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/053[0m
[[36m2025-02-25 11:40:51,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:40:51,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042906495334352, lr[0m
[[36m2025-02-25 11:40:51,807[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:40:51,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26903246477311676 prior_scale[0m
[[36m2025-02-25 11:40:51,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045466560919731416 q_scale[0m
[[36m2025-02-25 11:40:51,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:40:51,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-25 11:40:51,860[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:40:51,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:41:01,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:41:01,290[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:41:01,291[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:41:01,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:41:01,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:41:01,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:41:01,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:41:01,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:41:01,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:41:01,329[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:41:01,434[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.91it/s v_num: 0.000     
                                                               rmse/val: 38.247 
                                                               rmse/train:      
                                                               37.305           
[[36m2025-02-25 11:42:03,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:42:03,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/054[0m
[[36m2025-02-25 11:42:03,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:42:03,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.7819216257911568e-05, lr[0m
[[36m2025-02-25 11:42:03,568[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:42:03,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30029660067751923 prior_scale[0m
[[36m2025-02-25 11:42:03,610[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004340505291163494 q_scale[0m
[[36m2025-02-25 11:42:03,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:42:03,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-25 11:42:03,629[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:42:03,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:42:13,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:42:13,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:42:13,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:42:13,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:42:13,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:42:13,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:42:13,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:42:13,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:42:13,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:42:13,105[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:42:13,137[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.18it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3302.081         
                                                               rmse/train:      
                                                               3373.425         
[[36m2025-02-25 11:43:15,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:43:15,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/055[0m
[[36m2025-02-25 11:43:15,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:43:15,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004401865471378798, lr[0m
[[36m2025-02-25 11:43:15,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:43:15,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3476208999233071 prior_scale[0m
[[36m2025-02-25 11:43:15,998[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019988444444786404 q_scale[0m
[[36m2025-02-25 11:43:16,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:43:16,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-25 11:43:16,018[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:43:16,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:43:25,582[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:43:25,588[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:43:25,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:43:25,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:43:25,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:43:25,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:43:25,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:43:25,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:43:25,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:43:25,625[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:43:25,634[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.10it/s v_num: 0.000     
                                                               rmse/val: 59.014 
                                                               rmse/train:      
                                                               43.011           
[[36m2025-02-25 11:44:26,963[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:44:26,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/056[0m
[[36m2025-02-25 11:44:27,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:44:27,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029204624161600955, lr[0m
[[36m2025-02-25 11:44:27,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:44:27,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23677774028871276 prior_scale[0m
[[36m2025-02-25 11:44:27,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031744462625672313 q_scale[0m
[[36m2025-02-25 11:44:27,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:44:27,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-25 11:44:27,369[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:44:27,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:44:36,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:44:36,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:44:36,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:44:36,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:44:36,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:44:36,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:44:36,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:44:36,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:44:36,821[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:44:36,853[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:44:36,864[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 21.56it/s v_num: 0.000     
                                                               rmse/val: 43.107 
                                                               rmse/train:      
                                                               43.380           
[[36m2025-02-25 11:45:35,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:45:35,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/057[0m
[[36m2025-02-25 11:45:35,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:45:35,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005855412624750563, lr[0m
[[36m2025-02-25 11:45:36,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:45:36,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6806591464622032 prior_scale[0m
[[36m2025-02-25 11:45:36,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011120146196902444 q_scale[0m
[[36m2025-02-25 11:45:36,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:45:36,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-25 11:45:36,102[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:45:36,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:45:45,647[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:45:45,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:45:45,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:45:45,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:45:45,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:45:45,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:45:45,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:45:45,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:45:45,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:45:45,690[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:45:45,699[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.18it/s v_num: 0.000     
                                                               rmse/val: 76.136 
                                                               rmse/train:      
                                                               65.026           
[[36m2025-02-25 11:46:47,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:46:47,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/058[0m
[[36m2025-02-25 11:46:47,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:46:47,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002434295028300879, lr[0m
[[36m2025-02-25 11:46:47,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:46:47,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016984720600350866 prior_scale[0m
[[36m2025-02-25 11:46:47,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046886314266276623 q_scale[0m
[[36m2025-02-25 11:46:47,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:46:47,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-25 11:46:47,474[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:46:47,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:46:56,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:46:56,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:46:56,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:46:56,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:46:56,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:46:56,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:46:56,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:46:56,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:46:56,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:46:56,972[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:46:57,008[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.16it/s v_num: 0.000     
                                                               rmse/val: 211.301
                                                               rmse/train:      
                                                               217.351          
[[36m2025-02-25 11:47:59,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:47:59,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/059[0m
[[36m2025-02-25 11:47:59,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:47:59,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005050920866805903, lr[0m
[[36m2025-02-25 11:47:59,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:47:59,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.984136249859589 prior_scale[0m
[[36m2025-02-25 11:47:59,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020012711097405623 q_scale[0m
[[36m2025-02-25 11:47:59,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:47:59,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 060 __________________[0m
[[36m2025-02-25 11:47:59,648[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:47:59,648[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:48:09,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:48:09,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:48:09,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:48:09,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:48:09,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:48:09,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:48:09,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:48:09,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:48:09,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:48:09,184[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:48:09,194[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.16it/s v_num: 0.000     
                                                               rmse/val: 61.277 
                                                               rmse/train:      
                                                               54.267           
[[36m2025-02-25 11:49:10,798[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:49:10,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/060[0m
[[36m2025-02-25 11:49:10,940[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:49:10,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042064242427777116, lr[0m
[[36m2025-02-25 11:49:11,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:49:11,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.42429041542371104 prior_scale[0m
[[36m2025-02-25 11:49:11,052[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037544282581996913 q_scale[0m
[[36m2025-02-25 11:49:11,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:49:11,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 061 __________________[0m
[[36m2025-02-25 11:49:11,075[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:49:11,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:49:20,584[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:49:20,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:49:20,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:49:20,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:49:20,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:49:20,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:49:20,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:49:20,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:49:20,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:49:20,628[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:49:20,659[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.84it/s v_num: 0.000     
                                                               rmse/val: 40.973 
                                                               rmse/train:      
                                                               36.738           
[[36m2025-02-25 11:50:22,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:50:22,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/061[0m
[[36m2025-02-25 11:50:22,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:50:22,590[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008525853226589846, lr[0m
[[36m2025-02-25 11:50:22,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:50:22,625[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4200343655508948 prior_scale[0m
[[36m2025-02-25 11:50:22,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003258338691878481 q_scale[0m
[[36m2025-02-25 11:50:22,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:50:22,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 062 __________________[0m
[[36m2025-02-25 11:50:22,665[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:50:22,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:50:32,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:50:32,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:50:32,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:50:32,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:50:32,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:50:32,099[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:50:32,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:50:32,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:50:32,101[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:50:32,134[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:50:32,181[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.10it/s v_num: 0.000     
                                                               rmse/val: 51.668 
                                                               rmse/train:      
                                                               47.140           
[[36m2025-02-25 11:51:33,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:51:33,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/062[0m
[[36m2025-02-25 11:51:33,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:51:33,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000828305174633999, lr[0m
[[36m2025-02-25 11:51:33,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:51:33,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.45731897792546594 prior_scale[0m
[[36m2025-02-25 11:51:33,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031329968600381523 q_scale[0m
[[36m2025-02-25 11:51:33,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:51:33,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 063 __________________[0m
[[36m2025-02-25 11:51:33,799[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:51:33,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:51:43,228[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:51:43,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:51:43,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:51:43,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:51:43,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:51:43,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:51:43,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:51:43,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:51:43,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:51:43,272[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:51:43,280[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.87it/s v_num: 0.000     
                                                               rmse/val: 49.914 
                                                               rmse/train:      
                                                               42.589           
[[36m2025-02-25 11:52:48,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:52:48,183[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/063[0m
[[36m2025-02-25 11:52:48,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:52:48,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000828338962983645, lr[0m
[[36m2025-02-25 11:52:48,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:52:48,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.43539777599704316 prior_scale[0m
[[36m2025-02-25 11:52:48,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032126721922987056 q_scale[0m
[[36m2025-02-25 11:52:48,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:52:48,643[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 064 __________________[0m
[[36m2025-02-25 11:52:48,643[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:52:48,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:52:58,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:52:58,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:52:58,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:52:58,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:52:58,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:52:58,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:52:58,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:52:58,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:52:58,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:52:58,226[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:52:58,269[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.99it/s v_num: 0.000     
                                                               rmse/val: 71.289 
                                                               rmse/train:      
                                                               61.182           
[[36m2025-02-25 11:53:59,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:53:59,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/064[0m
[[36m2025-02-25 11:54:00,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:54:00,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008625586872377582, lr[0m
[[36m2025-02-25 11:54:00,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:54:00,404[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.45592830440283033 prior_scale[0m
[[36m2025-02-25 11:54:00,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035545170788409033 q_scale[0m
[[36m2025-02-25 11:54:00,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:54:00,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 065 __________________[0m
[[36m2025-02-25 11:54:00,451[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:54:00,452[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:54:09,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:54:09,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:54:09,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:54:09,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:54:09,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:54:09,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:54:09,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:54:09,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:54:09,992[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:54:10,031[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:54:10,039[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.98it/s v_num: 0.000     
                                                               rmse/val: 62.200 
                                                               rmse/train:      
                                                               52.255           
[[36m2025-02-25 11:55:11,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:55:11,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/065[0m
[[36m2025-02-25 11:55:11,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:55:11,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006112237319911698, lr[0m
[[36m2025-02-25 11:55:11,969[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:55:11,987[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5891810938269604 prior_scale[0m
[[36m2025-02-25 11:55:12,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014517811596752146 q_scale[0m
[[36m2025-02-25 11:55:12,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:55:12,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 066 __________________[0m
[[36m2025-02-25 11:55:12,025[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:55:12,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:55:21,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:55:21,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:55:21,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:55:21,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:55:21,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:55:21,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:55:21,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:55:21,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:55:21,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:55:21,524[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:55:21,539[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.13it/s v_num: 0.000     
                                                               rmse/val: 45.959 
                                                               rmse/train:      
                                                               41.837           
[[36m2025-02-25 11:56:22,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:56:22,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/066[0m
[[36m2025-02-25 11:56:23,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:56:23,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005285911799052368, lr[0m
[[36m2025-02-25 11:56:23,117[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:56:23,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8308280396805242 prior_scale[0m
[[36m2025-02-25 11:56:23,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012652152149947418 q_scale[0m
[[36m2025-02-25 11:56:23,189[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:56:23,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 067 __________________[0m
[[36m2025-02-25 11:56:23,190[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:56:23,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:56:32,631[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:56:32,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:56:32,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:56:32,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:56:32,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:56:32,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:56:32,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:56:32,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:56:32,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:56:32,676[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:56:32,719[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 21.78it/s v_num: 0.000     
                                                               rmse/val: 97.821 
                                                               rmse/train:      
                                                               82.835           
[[36m2025-02-25 11:57:33,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:57:33,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/067[0m
[[36m2025-02-25 11:57:33,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:57:33,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033063076252161144, lr[0m
[[36m2025-02-25 11:57:33,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:57:33,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5934945618870623 prior_scale[0m
[[36m2025-02-25 11:57:33,965[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024897639277775036 q_scale[0m
[[36m2025-02-25 11:57:33,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 11:57:33,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 068 __________________[0m
[[36m2025-02-25 11:57:33,981[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:57:33,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:57:43,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:57:43,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:57:43,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:57:43,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:57:43,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:57:43,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:57:43,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:57:43,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:57:43,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:57:43,387[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:57:43,395[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.11it/s v_num: 0.000     
                                                               rmse/val: 164.572
                                                               rmse/train:      
                                                               151.473          
[[36m2025-02-25 11:58:43,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:58:43,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/068[0m
[[36m2025-02-25 11:58:43,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:58:44,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005973016848938724, lr[0m
[[36m2025-02-25 11:58:44,064[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:58:44,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3633523536214609 prior_scale[0m
[[36m2025-02-25 11:58:44,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049562987903705266 q_scale[0m
[[36m2025-02-25 11:58:44,115[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:58:44,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 069 __________________[0m
[[36m2025-02-25 11:58:44,116[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:58:44,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:58:53,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:58:53,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:58:53,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:58:53,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:58:53,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:58:53,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:58:53,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:58:53,457[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:58:53,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:58:53,499[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:58:53,842[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:07 •       26.62it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 73.796 
                                                               rmse/train:      
                                                               82.181           
[[36m2025-02-25 12:01:02,401[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 13.
[[36m2025-02-25 12:01:02,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:01:02,527[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:01:02,566[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006252172607954191, lr[0m
[[36m2025-02-25 12:01:02,582[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:01:02,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7174751637194189 prior_scale[0m
[[36m2025-02-25 12:01:02,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025743181244390395 q_scale[0m
[[36m2025-02-25 12:01:02,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:01:02,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 070 __________________[0m
[[36m2025-02-25 12:01:02,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:01:02,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:01:12,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:01:12,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:01:12,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:01:12,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:01:12,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:01:12,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:01:12,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:01:12,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:01:12,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:01:12,257[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:01:12,265[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.92it/s v_num: 0.000     
                                                               rmse/val: 51.729 
                                                               rmse/train:      
                                                               43.317           
[[36m2025-02-25 12:02:13,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:02:13,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/070[0m
[[36m2025-02-25 12:02:13,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:02:13,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048526859158756557, lr[0m
[[36m2025-02-25 12:02:13,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:02:13,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4150833904182122 prior_scale[0m
[[36m2025-02-25 12:02:13,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016589719111487726 q_scale[0m
[[36m2025-02-25 12:02:13,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:02:13,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 071 __________________[0m
[[36m2025-02-25 12:02:13,810[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:02:13,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:02:23,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:02:23,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:02:23,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:02:23,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:02:23,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:02:23,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:02:23,249[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:02:23,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:02:23,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:02:23,283[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:02:23,292[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.04it/s v_num: 0.000     
                                                               rmse/val: 50.502 
                                                               rmse/train:      
                                                               47.454           
[[36m2025-02-25 12:03:23,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:03:23,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/071[0m
[[36m2025-02-25 12:03:23,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:03:24,035[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008876081127301351, lr[0m
[[36m2025-02-25 12:03:24,064[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:03:24,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5875697158757496 prior_scale[0m
[[36m2025-02-25 12:03:24,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015194341295380036 q_scale[0m
[[36m2025-02-25 12:03:24,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:03:24,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 072 __________________[0m
[[36m2025-02-25 12:03:24,146[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:03:24,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:03:33,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:03:33,755[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:03:33,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:03:33,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:03:33,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:03:33,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:03:33,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:03:33,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:03:33,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:03:33,803[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:03:33,814[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.72it/s v_num: 0.000     
                                                               rmse/val: 75.448 
                                                               rmse/train:      
                                                               65.052           
[[36m2025-02-25 12:04:41,773[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:04:41,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/072[0m
[[36m2025-02-25 12:04:41,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:04:41,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047270214510780357, lr[0m
[[36m2025-02-25 12:04:41,939[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:04:41,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4711664976135989 prior_scale[0m
[[36m2025-02-25 12:04:41,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011114607227305491 q_scale[0m
[[36m2025-02-25 12:04:42,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:04:42,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 073 __________________[0m
[[36m2025-02-25 12:04:42,016[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:04:42,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:04:51,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:04:51,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:04:51,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:04:51,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:04:51,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:04:51,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:04:51,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:04:51,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:04:51,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:04:51,674[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:04:51,682[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.25it/s v_num: 0.000     
                                                               rmse/val: 53.493 
                                                               rmse/train:      
                                                               48.896           
[[36m2025-02-25 12:05:56,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:05:56,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/073[0m
[[36m2025-02-25 12:05:56,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:05:56,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005331312938533932, lr[0m
[[36m2025-02-25 12:05:56,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:05:56,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4122540069620023 prior_scale[0m
[[36m2025-02-25 12:05:56,434[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010829144241898896 q_scale[0m
[[36m2025-02-25 12:05:56,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:05:56,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 074 __________________[0m
[[36m2025-02-25 12:05:56,452[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:05:56,452[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:06:05,978[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:06:05,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:06:05,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:06:05,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:06:05,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:06:05,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:06:05,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:06:05,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:06:05,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:06:06,236[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:06:06,319[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.71it/s v_num: 0.000     
                                                               rmse/val: 46.899 
                                                               rmse/train:      
                                                               42.326           
[[36m2025-02-25 12:07:09,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:07:09,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/074[0m
[[36m2025-02-25 12:07:09,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:07:09,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004995304774666142, lr[0m
[[36m2025-02-25 12:07:09,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:07:09,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.795689869081228 prior_scale[0m
[[36m2025-02-25 12:07:09,795[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010445721253381038 q_scale[0m
[[36m2025-02-25 12:07:09,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:07:09,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 075 __________________[0m
[[36m2025-02-25 12:07:09,811[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:07:09,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:07:19,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:07:19,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:07:19,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:07:19,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:07:19,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:07:19,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:07:19,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:07:19,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:07:19,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:07:19,352[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:07:19,392[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.10it/s v_num: 0.000     
                                                               rmse/val: 58.856 
                                                               rmse/train:      
                                                               56.379           
[[36m2025-02-25 12:08:21,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:08:21,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/075[0m
[[36m2025-02-25 12:08:22,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:08:22,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003823370559303089, lr[0m
[[36m2025-02-25 12:08:22,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:08:22,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5117485322314641 prior_scale[0m
[[36m2025-02-25 12:08:22,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013018434246189276 q_scale[0m
[[36m2025-02-25 12:08:22,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:08:22,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 076 __________________[0m
[[36m2025-02-25 12:08:22,324[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:08:22,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:08:32,039[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:08:32,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:08:32,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:08:32,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:08:32,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:08:32,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:08:32,050[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:08:32,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:08:32,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:08:32,287[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:08:32,295[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.31it/s v_num: 0.000     
                                                               rmse/val: 124.662
                                                               rmse/train:      
                                                               121.563          
[[36m2025-02-25 12:09:33,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:09:33,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/076[0m
[[36m2025-02-25 12:09:33,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:09:34,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006863653041571739, lr[0m
[[36m2025-02-25 12:09:34,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:09:34,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.022210741007635718 prior_scale[0m
[[36m2025-02-25 12:09:34,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019379397773894462 q_scale[0m
[[36m2025-02-25 12:09:34,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 12:09:34,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 077 __________________[0m
[[36m2025-02-25 12:09:34,139[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:09:34,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:09:44,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:09:44,846[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:09:44,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:09:44,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:09:44,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:09:44,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:09:44,850[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:09:44,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:09:44,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:09:44,948[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:09:45,093[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 8.35it/s v_num: 0.000     
                                                               rmse/val: 228.283
                                                               rmse/train:      
                                                               231.159          
[[36m2025-02-25 12:10:21,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:10:21,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/077[0m
[[36m2025-02-25 12:10:21,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:10:21,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00027871747058348857, lr[0m
[[36m2025-02-25 12:10:21,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:10:21,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1470954668574702 prior_scale[0m
[[36m2025-02-25 12:10:21,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010248725737167054 q_scale[0m
[[36m2025-02-25 12:10:21,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:10:21,394[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 078 __________________[0m
[[36m2025-02-25 12:10:21,394[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:10:21,394[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:10:31,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:10:31,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:10:31,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:10:31,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:10:31,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:10:31,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:10:31,086[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:10:31,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:10:31,087[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:10:31,102[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:10:31,112[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.88it/s v_num: 0.000     
                                                               rmse/val: 57.489 
                                                               rmse/train:      
                                                               55.857           
[[36m2025-02-25 12:11:37,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:11:37,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/078[0m
[[36m2025-02-25 12:11:37,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:11:37,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000558208560445388, lr[0m
[[36m2025-02-25 12:11:37,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:11:37,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3604405748832786 prior_scale[0m
[[36m2025-02-25 12:11:37,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015778961819060464 q_scale[0m
[[36m2025-02-25 12:11:37,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:11:37,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 079 __________________[0m
[[36m2025-02-25 12:11:37,715[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:11:37,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:11:47,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:11:47,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:11:47,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:11:47,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:11:47,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:11:47,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:11:47,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:11:47,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:11:47,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:11:47,313[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:11:47,323[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:07 •       24.78it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 42.977 
                                                               rmse/train:      
                                                               32.337           
[[36m2025-02-25 12:15:00,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:15:00,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/079[0m
[[36m2025-02-25 12:15:00,391[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:15:00,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.262319774636383e-05, lr[0m
[[36m2025-02-25 12:15:00,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:15:00,464[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22269041155597363 prior_scale[0m
[[36m2025-02-25 12:15:00,484[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001369324697416132 q_scale[0m
[[36m2025-02-25 12:15:00,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:15:00,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 080 __________________[0m
[[36m2025-02-25 12:15:00,502[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:15:00,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:15:10,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:15:10,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:15:10,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:15:10,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:15:10,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:15:10,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:15:10,024[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:15:10,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:15:10,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:15:10,112[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:15:10,154[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.85it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3141.167         
                                                               rmse/train:      
                                                               3249.833         
[[36m2025-02-25 12:16:16,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:16:16,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/080[0m
[[36m2025-02-25 12:16:16,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:16:17,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045857377848814823, lr[0m
[[36m2025-02-25 12:16:17,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:16:17,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.864313418195456 prior_scale[0m
[[36m2025-02-25 12:16:17,126[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.30115943002231466 q_scale[0m
[[36m2025-02-25 12:16:17,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:16:17,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 081 __________________[0m
[[36m2025-02-25 12:16:17,147[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:16:17,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:16:26,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:16:26,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:16:26,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:16:26,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:16:26,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:16:26,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:16:26,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:16:26,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:16:26,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:16:26,891[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:16:26,899[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/19 ━━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.87it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1725.276         
                                                               rmse/train:      
                                                               2431.604         
[[36m2025-02-25 12:16:42,052[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 4.
[[36m2025-02-25 12:16:42,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:16:42,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:16:42,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003829778896247256, lr[0m
[[36m2025-02-25 12:16:42,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:16:42,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6332190546279312 prior_scale[0m
[[36m2025-02-25 12:16:42,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002343444113726463 q_scale[0m
[[36m2025-02-25 12:16:42,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:16:42,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 082 __________________[0m
[[36m2025-02-25 12:16:42,453[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:16:42,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:16:51,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:16:51,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:16:51,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:16:51,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:16:51,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:16:51,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:16:51,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:16:51,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:16:51,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:16:51,945[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:16:51,997[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 17.96it/s v_num: 0.000     
                                                               rmse/val: 85.840 
                                                               rmse/train:      
                                                               80.386           
[[36m2025-02-25 12:18:01,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:18:01,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/082[0m
[[36m2025-02-25 12:18:01,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:18:01,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006608128069247574, lr[0m
[[36m2025-02-25 12:18:01,824[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:18:01,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.38949436381657987 prior_scale[0m
[[36m2025-02-25 12:18:01,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000299012503184217 q_scale[0m
[[36m2025-02-25 12:18:01,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:18:01,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 083 __________________[0m
[[36m2025-02-25 12:18:01,889[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:18:01,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:18:11,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:18:11,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:18:11,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:18:11,644[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:18:11,644[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:18:11,645[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:18:11,645[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:18:11,646[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:18:11,647[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:18:11,785[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:18:11,926[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.44it/s v_num: 0.000     
                                                               rmse/val: 378.146
                                                               rmse/train:      
                                                               338.923          
[[36m2025-02-25 12:19:17,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:19:17,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/083[0m
[[36m2025-02-25 12:19:17,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:19:17,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007645073006572579, lr[0m
[[36m2025-02-25 12:19:17,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:19:17,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.49248348564067973 prior_scale[0m
[[36m2025-02-25 12:19:17,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005629564538373742 q_scale[0m
[[36m2025-02-25 12:19:17,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:19:17,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 084 __________________[0m
[[36m2025-02-25 12:19:17,869[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:19:17,869[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:19:27,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:19:27,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:19:27,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:19:27,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:19:27,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:19:27,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:19:27,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:19:27,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:19:27,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:19:27,555[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:19:27,622[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.84it/s v_num: 0.000     
                                                               rmse/val: 52.311 
                                                               rmse/train:      
                                                               47.078           
[[36m2025-02-25 12:20:32,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:20:32,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/084[0m
[[36m2025-02-25 12:20:32,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:20:32,987[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005456430183642379, lr[0m
[[36m2025-02-25 12:20:33,006[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:20:33,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.501881809856386 prior_scale[0m
[[36m2025-02-25 12:20:33,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008635667470808006 q_scale[0m
[[36m2025-02-25 12:20:33,064[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:20:33,065[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 085 __________________[0m
[[36m2025-02-25 12:20:33,065[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:20:33,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:20:42,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:20:42,775[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:20:42,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:20:42,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:20:42,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:20:42,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:20:42,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:20:42,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:20:42,780[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:20:42,819[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:20:42,877[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.90it/s v_num: 0.000     
                                                               rmse/val: 57.258 
                                                               rmse/train:      
                                                               50.773           
[[36m2025-02-25 12:21:48,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:21:48,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/085[0m
[[36m2025-02-25 12:21:48,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:21:48,939[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007137023787486322, lr[0m
[[36m2025-02-25 12:21:48,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:21:48,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29216851944644845 prior_scale[0m
[[36m2025-02-25 12:21:49,000[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000169705334269115 q_scale[0m
[[36m2025-02-25 12:21:49,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:21:49,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 086 __________________[0m
[[36m2025-02-25 12:21:49,018[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:21:49,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:21:58,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:21:58,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:21:58,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:21:58,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:21:58,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:21:58,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:21:58,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:21:58,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:21:58,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:21:58,708[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:21:58,737[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.92it/s v_num: 0.000     
                                                               rmse/val: 784.916
                                                               rmse/train:      
                                                               728.576          
[[36m2025-02-25 12:23:05,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:23:05,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_100perc/runs/2025-02-25_11-01-19/086[0m
[[36m2025-02-25 12:23:05,364[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 87[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-04-29 16:16:21,988[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-04-29 16:16:21,990[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/fo_20perc.db[0m
[[36m2025-04-29 16:16:24,856[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-04-29 16:16:24,907[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-04-29 16:16:25,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:16:25,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000321294138520261, lr[0m
[[36m2025-04-29 16:16:25,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:16:25,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05517709283305456 prior_scale[0m
[[36m2025-04-29 16:16:25,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002729593825231425 q_scale[0m
[[36m2025-04-29 16:16:25,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-04-29 16:16:25,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 060 __________________[0m
[[36m2025-04-29 16:16:25,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:16:25,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:16:34,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:16:46,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:16:46,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:16:46,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:16:46,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:16:46,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:16:47,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:16:47,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:16:47,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:16:47,475[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:16:49,133[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 12.08it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2788.118         
                                                               rmse/train:      
                                                               2896.961         
[[36m2025-04-29 16:17:18,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:17:18,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/060[0m
[[36m2025-04-29 16:17:18,343[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:17:18,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008849390854871424, lr[0m
[[36m2025-04-29 16:17:18,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:17:18,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03694603814763513 prior_scale[0m
[[36m2025-04-29 16:17:18,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019440927823755153 q_scale[0m
[[36m2025-04-29 16:17:18,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:17:18,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 061 __________________[0m
[[36m2025-04-29 16:17:18,585[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:17:18,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:17:27,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:17:27,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:17:27,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:17:27,892[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:17:27,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:17:27,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:17:27,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:17:27,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:17:27,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:17:27,942[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:17:28,105[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.82it/s v_num: 0.000     
                                                               rmse/val: 77.047 
                                                               rmse/train:      
                                                               64.133           
[[36m2025-04-29 16:18:03,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:18:03,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/061[0m
[[36m2025-04-29 16:18:03,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:18:03,550[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007147819869252515, lr[0m
[[36m2025-04-29 16:18:03,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:18:03,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.037314781548842366 prior_scale[0m
[[36m2025-04-29 16:18:03,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006008553643026683 q_scale[0m
[[36m2025-04-29 16:18:03,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:18:03,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 062 __________________[0m
[[36m2025-04-29 16:18:03,741[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:18:03,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:18:12,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:18:12,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:18:12,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:18:12,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:18:12,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:18:12,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:18:12,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:18:12,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:18:12,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:18:12,794[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:18:12,926[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.70it/s v_num: 0.000     
                                                               rmse/val: 76.405 
                                                               rmse/train:      
                                                               58.631           
[[36m2025-04-29 16:18:47,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:18:47,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/062[0m
[[36m2025-04-29 16:18:47,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:18:47,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008326094498922375, lr[0m
[[36m2025-04-29 16:18:47,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:18:47,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08570822282818988 prior_scale[0m
[[36m2025-04-29 16:18:47,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008873026835516475 q_scale[0m
[[36m2025-04-29 16:18:47,549[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:18:47,549[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 063 __________________[0m
[[36m2025-04-29 16:18:47,549[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:18:47,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:18:56,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:18:56,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:18:56,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:18:56,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:18:56,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:18:56,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:18:56,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:18:56,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:18:56,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:18:56,647[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:18:56,819[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.73it/s v_num: 0.000     
                                                               rmse/val: 88.407 
                                                               rmse/train:      
                                                               54.978           
[[36m2025-04-29 16:19:31,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:19:31,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/063[0m
[[36m2025-04-29 16:19:31,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:19:31,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006119467732209221, lr[0m
[[36m2025-04-29 16:19:31,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:19:31,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12936655939402944 prior_scale[0m
[[36m2025-04-29 16:19:31,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000873268675221586 q_scale[0m
[[36m2025-04-29 16:19:31,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:19:31,953[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 064 __________________[0m
[[36m2025-04-29 16:19:31,953[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:19:31,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:19:40,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:19:40,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:19:40,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:19:40,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:19:40,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:19:40,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:19:40,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:19:40,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:19:40,961[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:19:41,021[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:19:41,277[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.69it/s v_num: 0.000     
                                                               rmse/val: 76.025 
                                                               rmse/train:      
                                                               59.474           
[[36m2025-04-29 16:20:16,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:20:16,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/064[0m
[[36m2025-04-29 16:20:16,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:20:16,919[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005000849151866124, lr[0m
[[36m2025-04-29 16:20:16,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:20:16,969[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08760412341134641 prior_scale[0m
[[36m2025-04-29 16:20:16,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0034749293755917143 q_scale[0m
[[36m2025-04-29 16:20:17,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:20:17,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 065 __________________[0m
[[36m2025-04-29 16:20:17,027[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:20:17,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:20:25,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:20:25,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:20:25,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:20:25,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:20:25,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:20:25,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:20:25,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:20:25,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:20:25,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:20:25,968[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:20:26,246[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.72it/s v_num: 0.000     
                                                               rmse/val: 108.914
                                                               rmse/train:      
                                                               82.255           
[[36m2025-04-29 16:21:00,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:21:00,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/065[0m
[[36m2025-04-29 16:21:00,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:21:00,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007166557140818262, lr[0m
[[36m2025-04-29 16:21:00,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:21:00,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.027246659620479823 prior_scale[0m
[[36m2025-04-29 16:21:00,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013142105093650023 q_scale[0m
[[36m2025-04-29 16:21:00,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-04-29 16:21:00,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 066 __________________[0m
[[36m2025-04-29 16:21:00,628[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:21:00,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:21:09,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:21:09,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:21:09,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:21:09,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:21:09,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:21:09,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:21:09,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:21:09,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:21:09,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:21:09,671[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:21:09,963[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 16.38it/s v_num: 0.000     
                                                               rmse/val: 125.077
                                                               rmse/train:      
                                                               61.976           
[[36m2025-04-29 16:22:08,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:22:08,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/066[0m
[[36m2025-04-29 16:22:08,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:22:08,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008572901913113138, lr[0m
[[36m2025-04-29 16:22:08,992[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:22:09,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19584374197081483 prior_scale[0m
[[36m2025-04-29 16:22:09,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006410695788706826 q_scale[0m
[[36m2025-04-29 16:22:09,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:22:09,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 067 __________________[0m
[[36m2025-04-29 16:22:09,160[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:22:09,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:22:18,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:22:18,106[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:22:18,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:22:18,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:22:18,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:22:18,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:22:18,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:22:18,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:22:18,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:22:18,167[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:22:18,453[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.72it/s v_num: 0.000     
                                                               rmse/val: 71.529 
                                                               rmse/train:      
                                                               52.299           
[[36m2025-04-29 16:22:52,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:22:52,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/067[0m
[[36m2025-04-29 16:22:52,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:22:53,003[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008742932071905694, lr[0m
[[36m2025-04-29 16:22:53,050[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:22:53,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3079302854554135 prior_scale[0m
[[36m2025-04-29 16:22:53,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005389987565127144 q_scale[0m
[[36m2025-04-29 16:22:53,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-04-29 16:22:53,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 068 __________________[0m
[[36m2025-04-29 16:22:53,149[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:22:53,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:23:02,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:23:02,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:23:02,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:23:02,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:23:02,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:23:02,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:23:02,187[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:23:02,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:23:02,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:23:02,231[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:23:02,503[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 8.72it/s v_num: 0.000      
                                                              rmse/val: 1300.782
                                                              rmse/train:       
                                                              1451.904          
[[36m2025-04-29 16:23:18,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:23:18,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/068[0m
[[36m2025-04-29 16:23:19,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:23:19,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013590268931152027, lr[0m
[[36m2025-04-29 16:23:19,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:23:19,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21540262417680206 prior_scale[0m
[[36m2025-04-29 16:23:19,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023364723443759468 q_scale[0m
[[36m2025-04-29 16:23:19,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-04-29 16:23:19,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 069 __________________[0m
[[36m2025-04-29 16:23:19,151[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:23:19,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:23:28,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:23:28,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:23:28,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:23:28,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:23:28,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:23:28,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:23:28,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:23:28,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:23:28,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:23:28,343[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:23:28,545[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.56it/s v_num: 0.000      
                                                              rmse/val: 3979.118
                                                              rmse/train:       
                                                              4081.310          
[[36m2025-04-29 16:23:42,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:23:42,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/069[0m
[[36m2025-04-29 16:23:42,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:23:42,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041831003743710173, lr[0m
[[36m2025-04-29 16:23:42,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:23:42,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.51557206296688 prior_scale[0m
[[36m2025-04-29 16:23:43,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006868886321226492 q_scale[0m
[[36m2025-04-29 16:23:43,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:23:43,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 070 __________________[0m
[[36m2025-04-29 16:23:43,026[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:23:43,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:23:51,907[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:23:51,914[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:23:51,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:23:51,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:23:51,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:23:51,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:23:51,919[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:23:51,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:23:51,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:23:51,959[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:23:52,223[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 798.558
                                                               rmse/train:      
                                                               883.716          
[[36m2025-04-29 16:24:26,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:24:26,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/070[0m
[[36m2025-04-29 16:24:27,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:24:27,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007598803135213259, lr[0m
[[36m2025-04-29 16:24:27,170[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:24:27,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05587427943302682 prior_scale[0m
[[36m2025-04-29 16:24:27,209[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012367752755936612 q_scale[0m
[[36m2025-04-29 16:24:27,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:24:27,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 071 __________________[0m
[[36m2025-04-29 16:24:27,224[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:24:27,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:24:36,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:24:36,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:24:36,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:24:36,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:24:36,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:24:36,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:24:36,228[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:24:36,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:24:36,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:24:36,272[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:24:36,550[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.73it/s v_num: 0.000     
                                                               rmse/val: 85.047 
                                                               rmse/train:      
                                                               65.273           
[[36m2025-04-29 16:25:11,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:25:11,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/071[0m
[[36m2025-04-29 16:25:11,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:25:11,248[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009908923659889205, lr[0m
[[36m2025-04-29 16:25:11,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:25:11,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04770334728668845 prior_scale[0m
[[36m2025-04-29 16:25:11,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004250836899623507 q_scale[0m
[[36m2025-04-29 16:25:11,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:25:11,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 072 __________________[0m
[[36m2025-04-29 16:25:11,347[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:25:11,347[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:25:20,254[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:25:20,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:25:20,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:25:20,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:25:20,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:25:20,264[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:25:20,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:25:20,264[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:25:20,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:25:20,310[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:25:20,565[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.68it/s v_num: 0.000     
                                                               rmse/val: 79.647 
                                                               rmse/train:      
                                                               64.739           
[[36m2025-04-29 16:25:55,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:25:55,194[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/072[0m
[[36m2025-04-29 16:25:55,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:25:55,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008666444036343495, lr[0m
[[36m2025-04-29 16:25:55,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:25:55,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17728356102350445 prior_scale[0m
[[36m2025-04-29 16:25:55,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040588704557028546 q_scale[0m
[[36m2025-04-29 16:25:55,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:25:55,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 073 __________________[0m
[[36m2025-04-29 16:25:55,556[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:25:55,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:26:04,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:26:04,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:26:04,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:26:04,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:26:04,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:26:04,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:26:04,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:26:04,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:26:04,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:26:04,592[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:26:04,800[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.67it/s v_num: 0.000     
                                                               rmse/val: 108.697
                                                               rmse/train:      
                                                               65.589           
[[36m2025-04-29 16:26:40,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:26:40,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/073[0m
[[36m2025-04-29 16:26:40,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:26:40,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006268834401261908, lr[0m
[[36m2025-04-29 16:26:40,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:26:40,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16992771954803002 prior_scale[0m
[[36m2025-04-29 16:26:40,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045301817861435623 q_scale[0m
[[36m2025-04-29 16:26:40,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:26:40,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 074 __________________[0m
[[36m2025-04-29 16:26:40,735[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:26:40,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:26:50,005[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:26:50,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:26:50,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:26:50,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:26:50,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:26:50,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:26:50,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:26:50,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:26:50,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:26:50,070[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:26:50,226[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.59it/s v_num: 0.000     
                                                               rmse/val: 95.389 
                                                               rmse/train:      
                                                               83.323           
[[36m2025-04-29 16:27:25,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:27:25,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/074[0m
[[36m2025-04-29 16:27:25,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:27:25,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009976572661968591, lr[0m
[[36m2025-04-29 16:27:25,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:27:25,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11548887979401883 prior_scale[0m
[[36m2025-04-29 16:27:25,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008031677542519279 q_scale[0m
[[36m2025-04-29 16:27:25,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:27:25,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 075 __________________[0m
[[36m2025-04-29 16:27:25,722[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:27:25,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:27:34,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:27:34,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:27:34,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:27:34,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:27:34,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:27:34,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:27:34,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:27:34,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:27:34,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:27:34,721[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:27:34,923[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.53it/s v_num: 0.000     
                                                               rmse/val: 84.453 
                                                               rmse/train:      
                                                               66.869           
[[36m2025-04-29 16:28:09,162[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:28:09,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/075[0m
[[36m2025-04-29 16:28:09,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:28:09,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000995662664412563, lr[0m
[[36m2025-04-29 16:28:09,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-04-29 16:28:09,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32082707364860497 prior_scale[0m
[[36m2025-04-29 16:28:09,401[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018694137272742782 q_scale[0m
[[36m2025-04-29 16:28:09,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:28:09,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 076 __________________[0m
[[36m2025-04-29 16:28:09,419[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:28:09,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:28:18,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:28:18,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:28:18,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:28:18,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:28:18,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:28:18,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:28:18,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:28:18,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:28:18,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:28:18,386[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:28:18,546[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:00 • 0:00:00 27.29it/s v_num: 0.000     
                                                               rmse/val: 81.221 
                                                               rmse/train:      
                                                               51.085           
[[36m2025-04-29 16:28:39,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:28:39,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/076[0m
[[36m2025-04-29 16:28:39,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:28:39,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.102064254293686e-05, lr[0m
[[36m2025-04-29 16:28:40,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:28:40,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2592839373434493 prior_scale[0m
[[36m2025-04-29 16:28:40,085[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008489184487304948 q_scale[0m
[[36m2025-04-29 16:28:40,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:28:40,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 077 __________________[0m
[[36m2025-04-29 16:28:40,121[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:28:40,121[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:28:49,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:28:49,105[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:28:49,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:28:49,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:28:49,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:28:49,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:28:49,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:28:49,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:28:49,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:28:49,142[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:28:49,317[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4214.420         
                                                               rmse/train:      
                                                               4322.292         
[[36m2025-04-29 16:29:24,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:29:24,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/077[0m
[[36m2025-04-29 16:29:24,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:29:24,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006928481809461501, lr[0m
[[36m2025-04-29 16:29:24,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:29:24,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12374177189395613 prior_scale[0m
[[36m2025-04-29 16:29:24,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004164295233245191 q_scale[0m
[[36m2025-04-29 16:29:24,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:29:24,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 078 __________________[0m
[[36m2025-04-29 16:29:24,898[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:29:24,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:29:33,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:29:33,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:29:33,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:29:33,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:29:33,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:29:33,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:29:33,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:29:33,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:29:33,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:29:33,916[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:29:34,150[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.51it/s v_num: 0.000     
                                                               rmse/val: 51.475 
                                                               rmse/train:      
                                                               44.456           
[[36m2025-04-29 16:30:09,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:30:09,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/078[0m
[[36m2025-04-29 16:30:09,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:30:09,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005494052645056185, lr[0m
[[36m2025-04-29 16:30:09,783[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:30:09,838[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19058382424391404 prior_scale[0m
[[36m2025-04-29 16:30:09,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007389382612010596 q_scale[0m
[[36m2025-04-29 16:30:09,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:30:09,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 079 __________________[0m
[[36m2025-04-29 16:30:09,992[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:30:09,992[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:30:18,906[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:30:18,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:30:18,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:30:18,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:30:18,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:30:18,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:30:18,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:30:18,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:30:18,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:30:18,970[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:30:19,159[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.65it/s v_num: 0.000     
                                                               rmse/val: 131.362
                                                               rmse/train:      
                                                               118.323          
[[36m2025-04-29 16:30:52,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:30:52,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/079[0m
[[36m2025-04-29 16:30:53,086[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:30:53,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008451044423006672, lr[0m
[[36m2025-04-29 16:30:53,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:30:53,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10774981530178412 prior_scale[0m
[[36m2025-04-29 16:30:53,350[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002674304390849248 q_scale[0m
[[36m2025-04-29 16:30:53,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:30:53,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 080 __________________[0m
[[36m2025-04-29 16:30:53,414[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:30:53,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:31:02,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:31:02,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:31:02,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:31:02,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:31:02,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:31:02,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:31:02,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:31:02,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:31:02,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:31:02,405[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:31:02,686[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.71it/s v_num: 0.000     
                                                               rmse/val: 90.375 
                                                               rmse/train:      
                                                               71.803           
[[36m2025-04-29 16:31:36,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:31:36,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/080[0m
[[36m2025-04-29 16:31:36,853[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:31:36,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000884082970383745, lr[0m
[[36m2025-04-29 16:31:36,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:31:36,956[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0846057490180087 prior_scale[0m
[[36m2025-04-29 16:31:36,970[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006096299443764606 q_scale[0m
[[36m2025-04-29 16:31:37,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:31:37,014[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 081 __________________[0m
[[36m2025-04-29 16:31:37,014[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:31:37,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:31:45,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:31:45,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:31:45,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:31:45,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:31:45,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:31:45,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:31:45,986[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:31:45,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:31:45,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:31:46,038[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:31:46,150[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.55it/s v_num: 0.000     
                                                               rmse/val: 89.558 
                                                               rmse/train:      
                                                               58.592           
[[36m2025-04-29 16:32:19,502[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:32:19,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/081[0m
[[36m2025-04-29 16:32:19,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:32:19,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008938112288733105, lr[0m
[[36m2025-04-29 16:32:19,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:32:19,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08586244547682277 prior_scale[0m
[[36m2025-04-29 16:32:19,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009677910581766383 q_scale[0m
[[36m2025-04-29 16:32:19,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:32:19,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 082 __________________[0m
[[36m2025-04-29 16:32:19,829[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:32:19,829[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:32:28,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:32:28,812[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:32:28,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:32:28,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:32:28,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:32:28,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:32:28,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:32:28,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:32:28,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:32:28,851[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:32:28,954[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.67it/s v_num: 0.000     
                                                               rmse/val: 67.658 
                                                               rmse/train:      
                                                               46.668           
[[36m2025-04-29 16:33:03,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:33:03,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/082[0m
[[36m2025-04-29 16:33:03,686[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:33:03,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000767365766370981, lr[0m
[[36m2025-04-29 16:33:03,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:33:03,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4343776327295782 prior_scale[0m
[[36m2025-04-29 16:33:03,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009908563016703855 q_scale[0m
[[36m2025-04-29 16:33:03,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:33:03,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 083 __________________[0m
[[36m2025-04-29 16:33:03,852[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:33:03,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:33:12,850[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:33:12,857[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:33:12,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:33:12,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:33:12,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:33:12,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:33:12,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:33:12,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:33:12,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:33:12,910[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:33:13,138[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.63it/s v_num: 0.000     
                                                               rmse/val: 80.394 
                                                               rmse/train:      
                                                               66.149           
[[36m2025-04-29 16:33:47,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:33:47,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/083[0m
[[36m2025-04-29 16:33:47,122[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:33:47,157[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000725039738452886, lr[0m
[[36m2025-04-29 16:33:47,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:33:47,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8383171762160949 prior_scale[0m
[[36m2025-04-29 16:33:47,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009556324240249662 q_scale[0m
[[36m2025-04-29 16:33:47,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:33:47,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 084 __________________[0m
[[36m2025-04-29 16:33:47,279[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:33:47,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:33:56,257[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:33:56,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:33:56,264[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:33:56,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:33:56,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:33:56,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:33:56,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:33:56,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:33:56,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:33:56,299[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:33:56,401[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.61it/s v_num: 0.000     
                                                               rmse/val: 114.228
                                                               rmse/train:      
                                                               100.060          
[[36m2025-04-29 16:34:30,774[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:34:30,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/084[0m
[[36m2025-04-29 16:34:30,925[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:34:31,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006236972994789613, lr[0m
[[36m2025-04-29 16:34:31,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:34:31,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41937985309561415 prior_scale[0m
[[36m2025-04-29 16:34:31,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005635773163578988 q_scale[0m
[[36m2025-04-29 16:34:31,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-04-29 16:34:31,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 085 __________________[0m
[[36m2025-04-29 16:34:31,226[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:34:31,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:34:40,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:34:40,305[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:34:40,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:34:40,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:34:40,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:34:40,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:34:40,310[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:34:40,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:34:40,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:34:40,351[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:34:40,554[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 8.65it/s v_num: 0.000      
                                                              rmse/val: 1541.729
                                                              rmse/train:       
                                                              1637.315          
[[36m2025-04-29 16:34:57,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:34:57,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/085[0m
[[36m2025-04-29 16:34:57,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:34:57,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008526704695232297, lr[0m
[[36m2025-04-29 16:34:57,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:34:57,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14580529596315478 prior_scale[0m
[[36m2025-04-29 16:34:57,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010291310945908258 q_scale[0m
[[36m2025-04-29 16:34:57,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:34:57,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 086 __________________[0m
[[36m2025-04-29 16:34:57,504[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:34:57,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:35:06,470[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:35:06,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:35:06,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:35:06,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:35:06,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:35:06,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:35:06,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:35:06,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:35:06,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:35:06,496[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:35:06,656[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.64it/s v_num: 0.000     
                                                               rmse/val: 110.656
                                                               rmse/train:      
                                                               68.880           
[[36m2025-04-29 16:35:41,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:35:41,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/086[0m
[[36m2025-04-29 16:35:41,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:35:41,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000755862917300843, lr[0m
[[36m2025-04-29 16:35:41,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:35:41,568[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.46718022725002645 prior_scale[0m
[[36m2025-04-29 16:35:41,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016652125441241165 q_scale[0m
[[36m2025-04-29 16:35:41,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-04-29 16:35:41,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 087 __________________[0m
[[36m2025-04-29 16:35:41,650[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:35:41,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:35:50,914[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:35:50,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:35:50,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:35:50,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:35:50,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:35:50,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:35:50,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:35:50,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:35:50,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:35:50,971[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:35:51,177[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.57it/s v_num: 0.000      
                                                              rmse/val: 2918.055
                                                              rmse/train:       
                                                              2955.820          
[[36m2025-04-29 16:36:04,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:36:04,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/087[0m
[[36m2025-04-29 16:36:05,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:36:05,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.356426390557434e-05, lr[0m
[[36m2025-04-29 16:36:05,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-04-29 16:36:05,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6957819754052135 prior_scale[0m
[[36m2025-04-29 16:36:05,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003417908197896149 q_scale[0m
[[36m2025-04-29 16:36:05,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-04-29 16:36:05,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 088 __________________[0m
[[36m2025-04-29 16:36:05,374[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:36:05,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:36:14,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:36:14,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:36:14,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:36:14,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:36:14,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:36:14,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:36:14,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:36:14,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:36:14,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:36:14,351[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:36:14,565[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 22.67it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2167.863         
                                                               rmse/train:      
                                                               2212.674         
[[36m2025-04-29 16:36:28,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:36:28,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/088[0m
[[36m2025-04-29 16:36:28,370[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:36:28,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002361494050001949, lr[0m
[[36m2025-04-29 16:36:28,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:36:28,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08592702011371281 prior_scale[0m
[[36m2025-04-29 16:36:28,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006415770731033501 q_scale[0m
[[36m2025-04-29 16:36:28,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:36:28,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 089 __________________[0m
[[36m2025-04-29 16:36:28,607[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:36:28,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:36:37,580[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:36:37,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:36:37,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:36:37,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:36:37,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:36:37,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:36:37,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:36:37,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:36:37,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:36:37,646[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:36:37,693[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 319.339
                                                               rmse/train:      
                                                               374.674          
[[36m2025-04-29 16:37:12,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:37:12,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/089[0m
[[36m2025-04-29 16:37:12,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:37:12,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004552461059635254, lr[0m
[[36m2025-04-29 16:37:12,649[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:37:12,730[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24870363279318985 prior_scale[0m
[[36m2025-04-29 16:37:12,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0028437539887052918 q_scale[0m
[[36m2025-04-29 16:37:12,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-04-29 16:37:12,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 090 __________________[0m
[[36m2025-04-29 16:37:12,843[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:37:12,843[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:37:21,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:37:21,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:37:21,772[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:37:21,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:37:21,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:37:21,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:37:21,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:37:21,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:37:21,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:37:21,826[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:37:22,080[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 16.37it/s v_num: 0.000     
                                                               rmse/val: 83.078 
                                                               rmse/train:      
                                                               50.875           
[[36m2025-04-29 16:38:22,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:38:22,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/090[0m
[[36m2025-04-29 16:38:22,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:38:22,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008804235113703822, lr[0m
[[36m2025-04-29 16:38:22,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:38:22,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3820088860319297 prior_scale[0m
[[36m2025-04-29 16:38:22,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004819052810952975 q_scale[0m
[[36m2025-04-29 16:38:22,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:38:22,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 091 __________________[0m
[[36m2025-04-29 16:38:22,433[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:38:22,433[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:38:31,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:38:31,418[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:38:31,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:38:31,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:38:31,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:38:31,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:38:31,422[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:38:31,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:38:31,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:38:31,471[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:38:31,604[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.55it/s v_num: 0.000     
                                                               rmse/val: 76.594 
                                                               rmse/train:      
                                                               72.475           
[[36m2025-04-29 16:39:05,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:39:05,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/091[0m
[[36m2025-04-29 16:39:06,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:39:06,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008989978448735005, lr[0m
[[36m2025-04-29 16:39:06,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:39:06,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05242431702686154 prior_scale[0m
[[36m2025-04-29 16:39:06,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1821322766525705 q_scale[0m
[[36m2025-04-29 16:39:06,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:39:06,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 092 __________________[0m
[[36m2025-04-29 16:39:06,357[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:39:06,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:39:15,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:39:15,350[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:39:15,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:39:15,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:39:15,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:39:15,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:39:15,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:39:15,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:39:15,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:39:15,401[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:39:15,584[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 9/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.67it/s v_num: 0.000     
                                                               rmse/val: 610.175
                                                               rmse/train:      
                                                               995.559          
[[36m2025-04-29 16:39:32,978[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 9.
[[36m2025-04-29 16:39:33,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:39:33,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:39:33,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006661378777081805, lr[0m
[[36m2025-04-29 16:39:33,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:39:33,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07148416014951761 prior_scale[0m
[[36m2025-04-29 16:39:33,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165632331454393 q_scale[0m
[[36m2025-04-29 16:39:33,703[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:39:33,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 093 __________________[0m
[[36m2025-04-29 16:39:33,704[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:39:33,704[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:39:42,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:39:42,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:39:42,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:39:42,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:39:42,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:39:42,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:39:42,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:39:42,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:39:42,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:39:42,705[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:39:43,008[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.55it/s v_num: 0.000     
                                                               rmse/val: 101.927
                                                               rmse/train:      
                                                               64.350           
[[36m2025-04-29 16:40:17,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:40:17,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/093[0m
[[36m2025-04-29 16:40:17,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:40:17,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000575694908451725, lr[0m
[[36m2025-04-29 16:40:17,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:40:17,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09964371621686118 prior_scale[0m
[[36m2025-04-29 16:40:17,867[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003753731523139581 q_scale[0m
[[36m2025-04-29 16:40:17,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:40:17,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 094 __________________[0m
[[36m2025-04-29 16:40:17,899[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:40:17,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:40:26,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:40:26,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:40:26,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:40:26,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:40:26,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:40:26,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:40:26,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:40:26,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:40:26,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:40:26,911[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:40:27,112[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 76.665 
                                                               rmse/train:      
                                                               60.272           
[[36m2025-04-29 16:41:03,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:41:03,076[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/094[0m
[[36m2025-04-29 16:41:03,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:41:03,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000773835099444639, lr[0m
[[36m2025-04-29 16:41:03,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:41:03,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.045881141365481215 prior_scale[0m
[[36m2025-04-29 16:41:03,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005204463334099387 q_scale[0m
[[36m2025-04-29 16:41:03,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:41:03,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 095 __________________[0m
[[36m2025-04-29 16:41:03,346[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:41:03,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:41:12,274[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:41:12,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:41:12,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:41:12,282[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:41:12,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:41:12,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:41:12,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:41:12,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:41:12,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:41:12,328[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:41:12,531[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.68it/s v_num: 0.000     
                                                               rmse/val: 76.330 
                                                               rmse/train:      
                                                               67.293           
[[36m2025-04-29 16:41:46,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:41:46,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/095[0m
[[36m2025-04-29 16:41:47,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:41:47,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009234786825551796, lr[0m
[[36m2025-04-29 16:41:47,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:41:47,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1830400089979241 prior_scale[0m
[[36m2025-04-29 16:41:47,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002917239205507117 q_scale[0m
[[36m2025-04-29 16:41:47,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:41:47,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 096 __________________[0m
[[36m2025-04-29 16:41:47,305[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:41:47,305[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:41:56,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:41:56,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:41:56,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:41:56,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:41:56,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:41:56,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:41:56,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:41:56,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:41:56,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:41:56,288[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:41:56,529[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.56it/s v_num: 0.000     
                                                               rmse/val: 86.568 
                                                               rmse/train:      
                                                               52.053           
[[36m2025-04-29 16:42:30,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:42:30,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/096[0m
[[36m2025-04-29 16:42:30,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:42:30,855[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009053515058980799, lr[0m
[[36m2025-04-29 16:42:30,893[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:42:30,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17859526101527923 prior_scale[0m
[[36m2025-04-29 16:42:30,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012123702475577388 q_scale[0m
[[36m2025-04-29 16:42:31,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:42:31,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 097 __________________[0m
[[36m2025-04-29 16:42:31,020[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:42:31,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:42:40,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:42:40,007[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:42:40,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:42:40,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:42:40,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:42:40,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:42:40,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:42:40,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:42:40,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:42:40,072[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:42:40,333[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 80.272 
                                                               rmse/train:      
                                                               53.706           
[[36m2025-04-29 16:43:14,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:43:14,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/097[0m
[[36m2025-04-29 16:43:14,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:43:14,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005146034430871437, lr[0m
[[36m2025-04-29 16:43:14,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:43:14,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18900334730773416 prior_scale[0m
[[36m2025-04-29 16:43:14,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011380213548990678 q_scale[0m
[[36m2025-04-29 16:43:14,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:43:14,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 098 __________________[0m
[[36m2025-04-29 16:43:14,657[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:43:14,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:43:23,620[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:43:23,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:43:23,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:43:23,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:43:23,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:43:23,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:43:23,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:43:23,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:43:23,631[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:43:23,678[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:43:23,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.61it/s v_num: 0.000     
                                                               rmse/val: 143.832
                                                               rmse/train:      
                                                               129.596          
[[36m2025-04-29 16:43:57,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:43:57,963[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/098[0m
[[36m2025-04-29 16:43:58,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:43:58,289[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008093909988017736, lr[0m
[[36m2025-04-29 16:43:58,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:43:58,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2665114826421801 prior_scale[0m
[[36m2025-04-29 16:43:58,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021215120899473745 q_scale[0m
[[36m2025-04-29 16:43:58,568[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:43:58,568[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 099 __________________[0m
[[36m2025-04-29 16:43:58,569[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:43:58,569[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:44:07,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:44:07,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:44:07,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:44:07,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:44:07,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:44:07,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:44:07,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:44:07,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:44:07,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:44:07,602[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:44:07,795[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 48.692 
                                                               rmse/train:      
                                                               48.584           
[[36m2025-04-29 16:44:42,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:44:42,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/099[0m
[[36m2025-04-29 16:44:42,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:44:42,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.222891785364368e-05, lr[0m
[[36m2025-04-29 16:44:42,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:44:42,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3660799099718286 prior_scale[0m
[[36m2025-04-29 16:44:42,391[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014470230233792498 q_scale[0m
[[36m2025-04-29 16:44:42,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:44:42,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 100 __________________[0m
[[36m2025-04-29 16:44:42,440[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:44:42,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:44:51,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:44:51,394[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:44:51,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:44:51,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:44:51,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:44:51,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:44:51,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:44:51,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:44:51,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:44:51,444[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:44:51,643[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.61it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3996.107         
                                                               rmse/train:      
                                                               4103.805         
[[36m2025-04-29 16:45:25,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:45:25,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/100[0m
[[36m2025-04-29 16:45:25,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:45:25,977[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008138524538808853, lr[0m
[[36m2025-04-29 16:45:26,006[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:45:26,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26305679956720235 prior_scale[0m
[[36m2025-04-29 16:45:26,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021691713333335167 q_scale[0m
[[36m2025-04-29 16:45:26,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:45:26,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 101 __________________[0m
[[36m2025-04-29 16:45:26,134[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:45:26,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:45:35,087[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:45:35,093[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:45:35,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:45:35,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:45:35,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:45:35,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:45:35,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:45:35,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:45:35,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:45:35,143[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:45:35,289[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 103.140
                                                               rmse/train:      
                                                               70.839           
[[36m2025-04-29 16:46:08,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:46:08,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/101[0m
[[36m2025-04-29 16:46:08,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:46:08,965[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007436979481430882, lr[0m
[[36m2025-04-29 16:46:09,022[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:46:09,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2891648527851588 prior_scale[0m
[[36m2025-04-29 16:46:09,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002015034439206207 q_scale[0m
[[36m2025-04-29 16:46:09,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:46:09,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 102 __________________[0m
[[36m2025-04-29 16:46:09,155[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:46:09,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:46:18,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:46:18,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:46:18,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:46:18,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:46:18,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:46:18,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:46:18,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:46:18,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:46:18,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:46:18,186[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:46:18,369[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.65it/s v_num: 0.000     
                                                               rmse/val: 119.226
                                                               rmse/train:      
                                                               66.616           
[[36m2025-04-29 16:46:52,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:46:52,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/102[0m
[[36m2025-04-29 16:46:52,855[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:46:52,882[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006425139746480691, lr[0m
[[36m2025-04-29 16:46:52,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:46:52,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1872810085686905 prior_scale[0m
[[36m2025-04-29 16:46:52,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019614447358452274 q_scale[0m
[[36m2025-04-29 16:46:52,969[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:46:52,969[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 103 __________________[0m
[[36m2025-04-29 16:46:52,970[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:46:52,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:47:01,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:47:01,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:47:01,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:47:01,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:47:01,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:47:01,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:47:01,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:47:01,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:47:01,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:47:01,946[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:47:02,087[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 99.422 
                                                               rmse/train:      
                                                               72.020           
[[36m2025-04-29 16:47:36,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:47:36,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/103[0m
[[36m2025-04-29 16:47:36,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:47:36,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007346615912082988, lr[0m
[[36m2025-04-29 16:47:36,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:47:36,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2906448648896502 prior_scale[0m
[[36m2025-04-29 16:47:36,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000292707466773095 q_scale[0m
[[36m2025-04-29 16:47:36,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:47:36,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 104 __________________[0m
[[36m2025-04-29 16:47:36,949[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:47:36,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:47:45,896[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:47:45,903[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:47:45,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:47:45,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:47:45,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:47:45,906[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:47:45,906[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:47:45,906[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:47:45,907[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:47:45,953[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:47:46,078[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.67it/s v_num: 0.000     
                                                               rmse/val: 101.645
                                                               rmse/train:      
                                                               66.025           
[[36m2025-04-29 16:48:20,906[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:48:20,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/104[0m
[[36m2025-04-29 16:48:21,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:48:21,086[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009170929129696647, lr[0m
[[36m2025-04-29 16:48:21,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:48:21,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22580304088551809 prior_scale[0m
[[36m2025-04-29 16:48:21,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013138556939607695 q_scale[0m
[[36m2025-04-29 16:48:21,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:48:21,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 105 __________________[0m
[[36m2025-04-29 16:48:21,253[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:48:21,254[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:48:30,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:48:30,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:48:30,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:48:30,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:48:30,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:48:30,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:48:30,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:48:30,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:48:30,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:48:30,288[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:48:30,356[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 100.328
                                                               rmse/train:      
                                                               69.256           
[[36m2025-04-29 16:49:04,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:49:04,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/105[0m
[[36m2025-04-29 16:49:04,979[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:49:05,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006868468226688608, lr[0m
[[36m2025-04-29 16:49:05,068[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:49:05,135[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3638503100512091 prior_scale[0m
[[36m2025-04-29 16:49:05,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026028990933077846 q_scale[0m
[[36m2025-04-29 16:49:05,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:49:05,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 106 __________________[0m
[[36m2025-04-29 16:49:05,235[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:49:05,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:49:14,197[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:49:14,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:49:14,204[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:49:14,206[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:49:14,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:49:14,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:49:14,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:49:14,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:49:14,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:49:14,244[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:49:14,331[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.58it/s v_num: 0.000     
                                                               rmse/val: 90.774 
                                                               rmse/train:      
                                                               83.365           
[[36m2025-04-29 16:49:48,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:49:48,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/106[0m
[[36m2025-04-29 16:49:48,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:49:49,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008089343898122368, lr[0m
[[36m2025-04-29 16:49:49,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-04-29 16:49:49,115[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14390209170353113 prior_scale[0m
[[36m2025-04-29 16:49:49,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011255046967326028 q_scale[0m
[[36m2025-04-29 16:49:49,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-04-29 16:49:49,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 107 __________________[0m
[[36m2025-04-29 16:49:49,182[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:49:49,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:49:58,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:49:58,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:49:58,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:49:58,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:49:58,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:49:58,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:49:58,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:49:58,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:49:58,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:49:58,203[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:49:58,319[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 14.75it/s v_num: 0.000      
                                                              rmse/val: 1829.636
                                                              rmse/train:       
                                                              1952.482          
[[36m2025-04-29 16:50:10,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:50:10,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/107[0m
[[36m2025-04-29 16:50:10,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:50:10,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005643934463473842, lr[0m
[[36m2025-04-29 16:50:10,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:50:10,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16705362931305617 prior_scale[0m
[[36m2025-04-29 16:50:10,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016709024425665345 q_scale[0m
[[36m2025-04-29 16:50:10,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:50:10,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 108 __________________[0m
[[36m2025-04-29 16:50:10,543[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:50:10,543[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:50:19,512[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:50:19,519[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:50:19,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:50:19,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:50:19,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:50:19,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:50:19,523[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:50:19,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:50:19,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:50:19,556[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:50:19,673[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.57it/s v_num: 0.000     
                                                               rmse/val: 135.189
                                                               rmse/train:      
                                                               101.460          
[[36m2025-04-29 16:50:54,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:50:54,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/108[0m
[[36m2025-04-29 16:50:54,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:50:54,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009118411105816951, lr[0m
[[36m2025-04-29 16:50:54,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:50:54,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5810872551535202 prior_scale[0m
[[36m2025-04-29 16:50:54,527[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010340672793305362 q_scale[0m
[[36m2025-04-29 16:50:54,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-04-29 16:50:54,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 109 __________________[0m
[[36m2025-04-29 16:50:54,559[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:50:54,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:51:03,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:51:03,491[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:51:03,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:51:03,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:51:03,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:51:03,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:51:03,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:51:03,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:51:03,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:51:03,532[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:51:03,617[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 12.06it/s v_num: 0.000     
                                                               rmse/val: 147.998
                                                               rmse/train:      
                                                               120.572          
[[36m2025-04-29 16:51:25,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:51:25,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/109[0m
[[36m2025-04-29 16:51:25,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:51:25,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007334106533567376, lr[0m
[[36m2025-04-29 16:51:25,334[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:51:25,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19991898191834712 prior_scale[0m
[[36m2025-04-29 16:51:25,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024617097705536374 q_scale[0m
[[36m2025-04-29 16:51:25,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:51:25,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 110 __________________[0m
[[36m2025-04-29 16:51:25,538[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:51:25,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:51:34,509[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:51:34,515[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:51:34,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:51:34,517[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:51:34,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:51:34,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:51:34,519[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:51:34,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:51:34,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:51:34,567[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:51:34,759[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.57it/s v_num: 0.000     
                                                               rmse/val: 91.239 
                                                               rmse/train:      
                                                               65.675           
[[36m2025-04-29 16:52:08,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:52:08,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/110[0m
[[36m2025-04-29 16:52:09,133[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:52:09,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008020631053582455, lr[0m
[[36m2025-04-29 16:52:09,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:52:09,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.25230889790963446 prior_scale[0m
[[36m2025-04-29 16:52:09,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019536910216660268 q_scale[0m
[[36m2025-04-29 16:52:09,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:52:09,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 111 __________________[0m
[[36m2025-04-29 16:52:09,377[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:52:09,377[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:52:18,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:52:18,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:52:18,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:52:18,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:52:18,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:52:18,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:52:18,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:52:18,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:52:18,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:52:18,375[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:52:18,585[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 92.353 
                                                               rmse/train:      
                                                               54.926           
[[36m2025-04-29 16:52:52,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:52:52,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/111[0m
[[36m2025-04-29 16:52:52,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:52:52,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009004285895117579, lr[0m
[[36m2025-04-29 16:52:52,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:52:52,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1338151648862832 prior_scale[0m
[[36m2025-04-29 16:52:52,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002941253876609506 q_scale[0m
[[36m2025-04-29 16:52:52,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:52:52,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 112 __________________[0m
[[36m2025-04-29 16:52:52,810[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:52:52,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:53:01,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:53:01,766[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:53:01,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:53:01,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:53:01,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:53:01,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:53:01,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:53:01,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:53:01,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:53:01,807[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:53:01,960[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.67it/s v_num: 0.000     
                                                               rmse/val: 87.759 
                                                               rmse/train:      
                                                               58.764           
[[36m2025-04-29 16:53:36,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:53:36,161[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/112[0m
[[36m2025-04-29 16:53:36,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:53:36,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006395725383371067, lr[0m
[[36m2025-04-29 16:53:36,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:53:36,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24235361540689906 prior_scale[0m
[[36m2025-04-29 16:53:36,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018495231743684512 q_scale[0m
[[36m2025-04-29 16:53:36,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:53:36,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 113 __________________[0m
[[36m2025-04-29 16:53:36,538[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:53:36,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:53:45,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:53:45,445[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:53:45,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:53:45,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:53:45,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:53:45,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:53:45,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:53:45,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:53:45,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:53:45,507[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:53:45,664[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.58it/s v_num: 0.000     
                                                               rmse/val: 108.083
                                                               rmse/train:      
                                                               78.065           
[[36m2025-04-29 16:54:20,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:54:20,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/113[0m
[[36m2025-04-29 16:54:20,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:54:20,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008076723091725019, lr[0m
[[36m2025-04-29 16:54:20,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:54:20,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4390156631064091 prior_scale[0m
[[36m2025-04-29 16:54:20,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00036954509836188476 q_scale[0m
[[36m2025-04-29 16:54:20,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:54:20,499[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 114 __________________[0m
[[36m2025-04-29 16:54:20,499[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:54:20,499[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:54:29,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:54:29,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:54:29,458[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:54:29,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:54:29,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:54:29,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:54:29,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:54:29,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:54:29,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:54:29,522[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:54:29,719[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 76.348 
                                                               rmse/train:      
                                                               55.919           
[[36m2025-04-29 16:55:03,565[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:55:03,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/114[0m
[[36m2025-04-29 16:55:03,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:55:03,751[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008286843910701744, lr[0m
[[36m2025-04-29 16:55:03,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:55:03,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27758629041782007 prior_scale[0m
[[36m2025-04-29 16:55:03,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003661215278504638 q_scale[0m
[[36m2025-04-29 16:55:03,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-04-29 16:55:03,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 115 __________________[0m
[[36m2025-04-29 16:55:03,835[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:55:03,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:55:12,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:55:12,986[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:55:12,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:55:12,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:55:12,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:55:12,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:55:12,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:55:12,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:55:12,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:55:13,033[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:55:13,184[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.54it/s v_num: 0.000      
                                                              rmse/val: 3430.185
                                                              rmse/train:       
                                                              3519.166          
[[36m2025-04-29 16:55:26,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:55:26,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/115[0m
[[36m2025-04-29 16:55:26,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:55:26,706[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000922580857092428, lr[0m
[[36m2025-04-29 16:55:26,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:55:26,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23092671235231627 prior_scale[0m
[[36m2025-04-29 16:55:26,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014601198787178831 q_scale[0m
[[36m2025-04-29 16:55:26,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:55:26,873[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 116 __________________[0m
[[36m2025-04-29 16:55:26,873[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:55:26,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:55:35,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:55:35,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:55:35,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:55:35,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:55:35,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:55:35,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:55:35,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:55:35,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:55:35,875[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:55:35,889[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:55:36,131[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 79.181 
                                                               rmse/train:      
                                                               52.545           
[[36m2025-04-29 16:56:10,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:56:10,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/116[0m
[[36m2025-04-29 16:56:10,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:56:10,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5055855934557481e-05, lr[0m
[[36m2025-04-29 16:56:10,434[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:56:10,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17487967745670888 prior_scale[0m
[[36m2025-04-29 16:56:10,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014893775566915084 q_scale[0m
[[36m2025-04-29 16:56:10,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-04-29 16:56:10,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 117 __________________[0m
[[36m2025-04-29 16:56:10,609[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:56:10,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:56:19,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:56:19,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:56:19,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:56:19,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:56:19,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:56:19,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:56:19,584[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:56:19,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:56:19,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:56:19,628[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:56:19,771[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 16.25it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4110.408         
                                                               rmse/train:      
                                                               4216.202         
[[36m2025-04-29 16:57:19,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:57:19,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/117[0m
[[36m2025-04-29 16:57:19,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:57:19,194[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009301705755781016, lr[0m
[[36m2025-04-29 16:57:19,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:57:19,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2235592139890673 prior_scale[0m
[[36m2025-04-29 16:57:19,343[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003027792899656357 q_scale[0m
[[36m2025-04-29 16:57:19,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:57:19,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 118 __________________[0m
[[36m2025-04-29 16:57:19,361[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:57:19,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:57:28,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:57:28,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:57:28,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:57:28,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:57:28,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:57:28,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:57:28,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:57:28,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:57:28,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:57:28,385[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:57:28,497[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.60it/s v_num: 0.000     
                                                               rmse/val: 80.750 
                                                               rmse/train:      
                                                               49.491           
[[36m2025-04-29 16:58:03,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:58:03,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/118[0m
[[36m2025-04-29 16:58:03,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-04-29 16:58:03,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009991793914550906, lr[0m
[[36m2025-04-29 16:58:03,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-04-29 16:58:03,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2178553563233182 prior_scale[0m
[[36m2025-04-29 16:58:03,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003138109309342773 q_scale[0m
[[36m2025-04-29 16:58:03,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-04-29 16:58:03,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 119 __________________[0m
[[36m2025-04-29 16:58:03,902[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-04-29 16:58:03,902[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-04-29 16:58:12,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-04-29 16:58:12,907[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-04-29 16:58:12,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-04-29 16:58:12,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-04-29 16:58:12,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-04-29 16:58:12,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-04-29 16:58:12,910[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-04-29 16:58:12,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-04-29 16:58:12,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-04-29 16:58:12,954[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-04-29 16:58:13,025[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.62it/s v_num: 0.000     
                                                               rmse/val: 76.022 
                                                               rmse/train:      
                                                               49.595           
[[36m2025-04-29 16:58:47,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-04-29 16:58:47,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/fo_hps_20perc/runs/2025-04-29_16-16-21/119[0m
[[36m2025-04-29 16:58:47,493[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 120[0m
