{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-24 16:30:10,531[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-24 16:30:10,533[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/lrt_20perc.db[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-24 16:30:10,535[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-24 16:30:10,555[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/lrt_100perc.db[0m
[[36m2025-02-24 16:30:18,288[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-24 16:30:18,293[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-24 16:30:18,455[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-24 16:30:18,456[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-24 16:30:18,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:18,595[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:18,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-02-24 16:30:18,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-02-24 16:30:18,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:30:18,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:30:18,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-02-24 16:30:18,697[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-02-24 16:30:18,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-02-24 16:30:18,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-02-24 16:30:18,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:30:18,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-24 16:30:18,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:30:18,735[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:18,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-24 16:30:18,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2025-02-24 16:30:18,736[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:18,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:29,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:29,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:30:30,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:30,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:30,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:30,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:30,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:30,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:30,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:30,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:30,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:30,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:31,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:31,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:31,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:31,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:31,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:31,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:32,162[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:32,177[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:32,422[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2025-02-24 16:30:32,430[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 14.51it/s v_num: 0.000      
                                                              rmse/val: 4940.205
                                                              rmse/train:       
                                                              4892.529          
[[36m2025-02-24 16:30:46,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:30:46,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/000[0m
[[36m2025-02-24 16:30:46,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:30:46,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-02-24 16:30:46,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:30:46,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374377640063412 prior_scale[0m
[[36m2025-02-24 16:30:46,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030269344709026166 q_scale[0m
[[36m2025-02-24 16:30:46,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:30:46,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-24 16:30:46,250[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:30:46,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:30:56,393[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:30:56,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:30:56,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:30:56,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:30:56,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:30:56,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:30:56,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:30:56,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:30:56,406[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:30:56,426[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:30:56,531[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.53it/s v_num: 0.000      
                                                              rmse/val: 4165.868
                                                              rmse/train:       
                                                              4264.896          
[[36m2025-02-24 16:31:09,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:09,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/001[0m
[[36m2025-02-24 16:31:09,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:09,390[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-02-24 16:31:09,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:31:09,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012778268753495938 prior_scale[0m
[[36m2025-02-24 16:31:09,445[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.540207249341968 q_scale[0m
[[36m2025-02-24 16:31:09,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:31:09,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-24 16:31:09,457[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:09,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.84it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3746.373         
                                                               rmse/train:      
                                                               3709.080         
[[36m2025-02-24 16:31:10,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:10,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/000[0m
[[36m2025-02-24 16:31:10,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:10,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-02-24 16:31:10,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:31:10,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374377640063412 prior_scale[0m
[[36m2025-02-24 16:31:10,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030269344709026166 q_scale[0m
[[36m2025-02-24 16:31:10,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:31:10,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-24 16:31:10,867[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:10,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:19,159[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:19,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:19,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:19,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:19,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:19,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:19,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:19,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:19,183[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:19,217[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:19,233[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:21,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:21,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:21,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:21,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:21,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:21,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:21,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:21,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:21,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:21,675[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:21,684[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 18.00it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2813.940         
                                                               rmse/train:      
                                                               4205.828         
[[36m2025-02-24 16:31:34,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:31:34,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/002[0m
[[36m2025-02-24 16:31:34,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:31:34,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-02-24 16:31:34,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:31:34,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002699606552195955 prior_scale[0m
[[36m2025-02-24 16:31:34,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06562115716452717 q_scale[0m
[[36m2025-02-24 16:31:34,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:31:34,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-24 16:31:34,283[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:31:34,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:31:44,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:31:44,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:31:44,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:31:44,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:31:44,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:31:44,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:31:44,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:31:44,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:31:44,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:31:44,287[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:31:44,297[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 11.65it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3187.905         
                                                               rmse/train:      
                                                               3295.642         
[[36m2025-02-24 16:32:08,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:08,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/003[0m
[[36m2025-02-24 16:32:08,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:08,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-02-24 16:32:08,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:08,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10583829396911469 prior_scale[0m
[[36m2025-02-24 16:32:08,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023905570899706415 q_scale[0m
[[36m2025-02-24 16:32:08,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:08,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-24 16:32:08,634[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:08,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.39it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4322.533         
                                                               rmse/train:      
                                                               4399.819         
[[36m2025-02-24 16:32:09,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:09,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/001[0m
[[36m2025-02-24 16:32:09,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:09,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-02-24 16:32:09,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:09,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012778268753495938 prior_scale[0m
[[36m2025-02-24 16:32:09,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.540207249341968 q_scale[0m
[[36m2025-02-24 16:32:09,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:09,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-24 16:32:09,520[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:09,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:18,846[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:18,858[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:18,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:18,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:18,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:18,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:18,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:18,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:18,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:18,886[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:18,895[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:19,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:19,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:19,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:19,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:19,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:19,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:19,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:19,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:19,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:19,695[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:19,707[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 17.93it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4119.133         
                                                               rmse/train:      
                                                               4203.242         
[[36m2025-02-24 16:32:33,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:33,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/004[0m
[[36m2025-02-24 16:32:33,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:33,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-02-24 16:32:33,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:33,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001047833275436284 prior_scale[0m
[[36m2025-02-24 16:32:33,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02949625201538112 q_scale[0m
[[36m2025-02-24 16:32:33,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:33,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-24 16:32:33,431[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:33,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:43,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:43,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:43,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:43,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:43,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:43,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:43,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:43,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:43,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:43,471[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:43,480[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 3/19 ━━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 17.82it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4119.403         
                                                               rmse/train:      
                                                               4219.628         
[[36m2025-02-24 16:32:46,463[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 3.
[[36m2025-02-24 16:32:46,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:32:46,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:32:46,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-02-24 16:32:46,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:32:46,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038638969563953266 prior_scale[0m
[[36m2025-02-24 16:32:46,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033827492632411567 q_scale[0m
[[36m2025-02-24 16:32:46,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:32:46,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-24 16:32:46,711[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:32:46,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:32:57,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:32:57,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:32:57,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:32:57,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:32:57,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:32:57,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:32:57,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:32:57,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:32:57,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:32:57,403[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:32:57,734[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 18.70it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4080.768         
                                                               rmse/train:      
                                                               4182.205         
[[36m2025-02-24 16:33:13,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:33:13,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/006[0m
[[36m2025-02-24 16:33:13,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:33:13,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-02-24 16:33:13,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:33:13,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020959477484878194 prior_scale[0m
[[36m2025-02-24 16:33:13,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008257988273685458 q_scale[0m
[[36m2025-02-24 16:33:13,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:33:13,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-24 16:33:13,541[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:33:13,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 22.36it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4516.116         
                                                               rmse/train:      
                                                               4040.240         
[[36m2025-02-24 16:33:14,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:33:14,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/002[0m
[[36m2025-02-24 16:33:14,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:33:14,784[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-02-24 16:33:14,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:33:14,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002699606552195955 prior_scale[0m
[[36m2025-02-24 16:33:14,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06562115716452717 q_scale[0m
[[36m2025-02-24 16:33:14,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:33:14,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-24 16:33:14,823[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:33:14,823[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:33:23,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:33:23,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:33:23,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:33:23,821[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:33:23,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:33:23,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:33:23,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:33:23,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:33:23,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:33:23,846[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:33:23,904[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:33:24,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:33:24,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:33:24,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:33:24,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:33:24,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:33:24,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:33:24,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:33:24,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:33:24,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:33:24,717[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:33:24,785[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 22.95it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3480.464         
                                                               rmse/train:      
                                                               3572.372         
[[36m2025-02-24 16:34:07,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:34:07,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/007[0m
[[36m2025-02-24 16:34:07,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:34:07,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-02-24 16:34:07,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:34:07,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07537199486913888 prior_scale[0m
[[36m2025-02-24 16:34:07,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0666791815288874 q_scale[0m
[[36m2025-02-24 16:34:07,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:34:07,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-24 16:34:07,225[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:34:07,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:34:16,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:34:16,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:34:16,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:34:16,908[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:34:16,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:34:16,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:34:16,910[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:34:16,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:34:16,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:34:16,944[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:34:16,969[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 10.14it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4033.020         
                                                               rmse/train:      
                                                               4028.809         
[[36m2025-02-24 16:34:39,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:34:39,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/008[0m
[[36m2025-02-24 16:34:39,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:34:40,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-02-24 16:34:40,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:34:40,068[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.714967484470097 prior_scale[0m
[[36m2025-02-24 16:34:40,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00834519932080496 q_scale[0m
[[36m2025-02-24 16:34:40,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:34:40,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-24 16:34:40,099[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:34:40,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:34:50,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:34:50,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:34:50,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:34:50,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:34:50,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:34:50,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:34:50,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:34:50,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:34:50,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:34:50,069[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:34:50,079[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 12.59it/s v_num: 0.000     
                                                               rmse/val: 98.784 
                                                               rmse/train:      
                                                               79.878           
[[36m2025-02-24 16:34:58,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:34:58,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/003[0m
[[36m2025-02-24 16:34:58,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:34:58,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-02-24 16:34:58,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:34:58,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10583829396911469 prior_scale[0m
[[36m2025-02-24 16:34:58,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023905570899706415 q_scale[0m
[[36m2025-02-24 16:34:58,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:34:58,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-24 16:34:58,574[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:34:58,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 20.38it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2988.345         
                                                               rmse/train:      
                                                               3095.374         
[[36m2025-02-24 16:35:03,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:35:03,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/009[0m
[[36m2025-02-24 16:35:03,599[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:35:03,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-02-24 16:35:03,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:35:03,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01116798829495977 prior_scale[0m
[[36m2025-02-24 16:35:03,686[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013611901663306908 q_scale[0m
[[36m2025-02-24 16:35:03,702[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:35:03,702[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-24 16:35:03,703[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:35:03,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:35:08,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:35:08,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:35:08,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:35:08,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:35:08,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:35:08,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:35:08,565[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:35:08,565[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:35:08,566[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:35:08,604[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:35:08,610[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:35:13,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:35:13,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:35:13,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:35:13,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:35:13,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:35:13,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:35:13,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:35:13,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:35:13,636[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:35:13,650[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:35:13,659[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.90it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4026.050         
                                                               rmse/train:      
                                                               4105.703         
[[36m2025-02-24 16:36:04,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:36:04,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/004[0m
[[36m2025-02-24 16:36:04,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:36:04,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-02-24 16:36:04,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:36:04,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001047833275436284 prior_scale[0m
[[36m2025-02-24 16:36:04,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02949625201538112 q_scale[0m
[[36m2025-02-24 16:36:04,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:36:04,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-24 16:36:04,692[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:36:04,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:36:14,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:36:14,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:36:14,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:36:14,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:36:14,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:36:14,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:36:14,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:36:14,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:36:14,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:36:14,778[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:36:14,872[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:03 • 0:00:00 13.24it/s v_num: 0.000     
                                                               rmse/val: 64.540 
                                                               rmse/train:      
                                                               64.108           
[[36m2025-02-24 16:36:25,440[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:36:25,442[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/010[0m
[[36m2025-02-24 16:36:25,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:36:25,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-02-24 16:36:25,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:36:25,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015791568646716513 prior_scale[0m
[[36m2025-02-24 16:36:25,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013400032806480455 q_scale[0m
[[36m2025-02-24 16:36:25,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:36:25,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-24 16:36:25,661[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:36:25,661[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:36:35,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:36:35,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:36:35,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:36:35,531[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:36:35,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:36:35,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:36:35,533[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:36:35,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:36:35,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:36:35,568[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:36:35,578[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.70it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4098.552         
                                                               rmse/train:      
                                                               4145.828         
[[36m2025-02-24 16:37:10,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:37:10,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/005[0m
[[36m2025-02-24 16:37:10,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:37:10,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-02-24 16:37:10,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:37:10,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038638969563953266 prior_scale[0m
[[36m2025-02-24 16:37:10,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033827492632411567 q_scale[0m
[[36m2025-02-24 16:37:10,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:37:10,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-24 16:37:10,429[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:37:10,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:37:20,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:37:20,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:37:20,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:37:20,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:37:20,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:37:20,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:37:20,353[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:37:20,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:37:20,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:37:20,399[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:37:20,424[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:02 • 0:00:00 14.78it/s v_num: 0.000     
                                                               rmse/val: 42.628 
                                                               rmse/train:      
                                                               54.773           
[[36m2025-02-24 16:37:46,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:37:46,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/011[0m
[[36m2025-02-24 16:37:46,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:37:46,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-02-24 16:37:46,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:37:46,496[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01578701912640358 prior_scale[0m
[[36m2025-02-24 16:37:46,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010569299297450266 q_scale[0m
[[36m2025-02-24 16:37:46,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:37:46,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-24 16:37:46,531[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:37:46,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:37:56,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:37:56,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:37:56,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:37:56,048[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:37:56,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:37:56,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:37:56,050[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:37:56,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:37:56,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:37:56,084[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:37:56,094[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 21.78it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3708.182         
                                                               rmse/train:      
                                                               3786.406         
[[36m2025-02-24 16:38:16,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:38:16,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/006[0m
[[36m2025-02-24 16:38:16,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:38:16,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-02-24 16:38:16,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:38:16,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020959477484878194 prior_scale[0m
[[36m2025-02-24 16:38:16,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008257988273685458 q_scale[0m
[[36m2025-02-24 16:38:16,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:38:16,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-24 16:38:16,217[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:38:16,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:38:26,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:38:26,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:38:26,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:38:26,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:38:26,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:38:26,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:38:26,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:38:26,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:38:26,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:38:26,047[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:38:26,304[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:03 • 0:00:00 12.99it/s v_num: 0.000     
                                                               rmse/val: 112.694
                                                               rmse/train:      
                                                               93.842           
[[36m2025-02-24 16:39:08,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:39:08,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/012[0m
[[36m2025-02-24 16:39:08,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:39:09,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009998183169689775, lr[0m
[[36m2025-02-24 16:39:09,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:39:09,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01064012896031672 prior_scale[0m
[[36m2025-02-24 16:39:09,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010211784008112604 q_scale[0m
[[36m2025-02-24 16:39:09,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:39:09,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-24 16:39:09,258[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:39:09,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:39:19,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:39:19,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:39:19,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:39:19,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:39:19,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:39:19,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:39:19,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:39:19,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:39:19,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:39:19,166[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:39:19,219[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 10.77it/s v_num: 0.000     
                                                               rmse/val: 46.247 
                                                               rmse/train:      
                                                               39.380           
[[36m2025-02-24 16:39:59,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:39:59,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/013[0m
[[36m2025-02-24 16:39:59,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:39:59,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009813379195690634, lr[0m
[[36m2025-02-24 16:39:59,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:39:59,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03462087235603707 prior_scale[0m
[[36m2025-02-24 16:39:59,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004237992367412906 q_scale[0m
[[36m2025-02-24 16:39:59,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:39:59,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-24 16:39:59,711[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:39:59,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:40:09,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:40:09,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:40:09,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:40:09,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:40:09,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:40:09,501[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:40:09,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:40:09,502[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:40:09,503[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:40:09,519[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:40:09,530[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.44it/s v_num: 0.000     
                                                               rmse/val: 91.692 
                                                               rmse/train:      
                                                               55.910           
[[36m2025-02-24 16:40:49,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:40:49,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/014[0m
[[36m2025-02-24 16:40:49,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:40:49,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009889182716204107, lr[0m
[[36m2025-02-24 16:40:49,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:40:49,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04295889441861082 prior_scale[0m
[[36m2025-02-24 16:40:49,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005750345772627247 q_scale[0m
[[36m2025-02-24 16:40:49,530[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:40:49,530[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-24 16:40:49,530[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:40:49,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:40:59,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:40:59,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:40:59,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:40:59,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:40:59,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:40:59,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:40:59,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:40:59,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:40:59,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:40:59,262[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:40:59,271[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:07 •       25.78it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1848.343         
                                                               rmse/train:      
                                                               1875.872         
[[36m2025-02-24 16:41:20,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:41:20,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/007[0m
[[36m2025-02-24 16:41:20,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:41:20,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-02-24 16:41:20,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:41:20,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07537199486913888 prior_scale[0m
[[36m2025-02-24 16:41:20,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0666791815288874 q_scale[0m
[[36m2025-02-24 16:41:20,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:41:20,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-24 16:41:20,194[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:41:20,194[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:41:30,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:41:30,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:41:30,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:41:30,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:41:30,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:41:30,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:41:30,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:41:30,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:41:30,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:41:30,762[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:41:30,770[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.01it/s v_num: 0.000     
                                                               rmse/val: 75.905 
                                                               rmse/train:      
                                                               57.759           
[[36m2025-02-24 16:41:38,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:41:38,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/015[0m
[[36m2025-02-24 16:41:38,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:41:38,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009485885170359142, lr[0m
[[36m2025-02-24 16:41:38,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:41:38,244[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.050760342213256066 prior_scale[0m
[[36m2025-02-24 16:41:38,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005478446090810961 q_scale[0m
[[36m2025-02-24 16:41:38,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:41:38,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-24 16:41:38,275[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:41:38,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:41:48,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:41:48,033[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:41:48,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:41:48,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:41:48,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:41:48,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:41:48,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:41:48,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:41:48,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:41:48,053[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:41:48,063[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 10.91it/s v_num: 0.000     
                                                               rmse/val: 71.695 
                                                               rmse/train:      
                                                               49.157           
[[36m2025-02-24 16:42:30,548[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:42:30,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/016[0m
[[36m2025-02-24 16:42:30,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:42:30,687[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005082091555483537, lr[0m
[[36m2025-02-24 16:42:30,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:42:30,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.36097912828529327 prior_scale[0m
[[36m2025-02-24 16:42:30,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006411550999815748 q_scale[0m
[[36m2025-02-24 16:42:30,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:42:30,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-24 16:42:30,749[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:42:30,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:42:40,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:42:40,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:42:40,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:42:40,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:42:40,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:42:40,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:42:40,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:42:40,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:42:40,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:42:40,784[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:42:40,795[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 49/49 0:00:04 • 0:00:00 9.85it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1812.756         
                                                               rmse/train:      
                                                               1935.619         
[[36m2025-02-24 16:43:20,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:43:20,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/008[0m
[[36m2025-02-24 16:43:20,496[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:43:20,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-02-24 16:43:20,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:43:20,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.714967484470097 prior_scale[0m
[[36m2025-02-24 16:43:20,581[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00834519932080496 q_scale[0m
[[36m2025-02-24 16:43:20,595[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 16:43:20,596[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-24 16:43:20,596[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:43:20,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 10.87it/s v_num: 0.000     
                                                               rmse/val: 153.091
                                                               rmse/train:      
                                                               107.718          
[[36m2025-02-24 16:43:25,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:43:25,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/017[0m
[[36m2025-02-24 16:43:26,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:43:27,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001350612004156431, lr[0m
[[36m2025-02-24 16:43:27,149[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:43:27,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04479669818096754 prior_scale[0m
[[36m2025-02-24 16:43:27,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00162577924453938 q_scale[0m
[[36m2025-02-24 16:43:27,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:43:27,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-24 16:43:27,235[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:43:27,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:43:30,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:43:30,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:43:30,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:43:30,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:43:30,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:43:30,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:43:30,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:43:30,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:43:30,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:43:30,960[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:43:31,253[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:43:37,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:43:37,162[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:43:37,162[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:43:37,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:43:37,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:43:37,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:43:37,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:43:37,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:43:37,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:43:37,181[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:43:37,188[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.21it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3011.352         
                                                               rmse/train:      
                                                               3104.061         
[[36m2025-02-24 16:44:29,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:44:29,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/018[0m
[[36m2025-02-24 16:44:30,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:44:30,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005632231128261526, lr[0m
[[36m2025-02-24 16:44:30,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:44:30,087[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03718801483781791 prior_scale[0m
[[36m2025-02-24 16:44:30,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002942702531995975 q_scale[0m
[[36m2025-02-24 16:44:30,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:44:30,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-24 16:44:30,139[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:44:30,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:44:39,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:44:39,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:44:39,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:44:39,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:44:39,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:44:39,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:44:39,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:44:39,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:44:39,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:44:40,007[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:44:40,016[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 18.92it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2200.884         
                                                               rmse/train:      
                                                               2229.142         
[[36m2025-02-24 16:44:43,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:44:43,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/009[0m
[[36m2025-02-24 16:44:43,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:44:43,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-02-24 16:44:43,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:44:43,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01116798829495977 prior_scale[0m
[[36m2025-02-24 16:44:43,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013611901663306908 q_scale[0m
[[36m2025-02-24 16:44:43,643[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:44:43,643[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-24 16:44:43,643[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:44:43,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:44:53,712[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:44:53,740[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:44:53,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:44:53,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:44:53,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:44:53,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:44:53,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:44:53,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:44:53,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:44:57,334[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:44:57,348[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.29it/s v_num: 0.000     
                                                               rmse/val: 82.352 
                                                               rmse/train:      
                                                               64.303           
[[36m2025-02-24 16:45:25,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:45:25,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/019[0m
[[36m2025-02-24 16:45:25,620[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:45:25,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006574375848469725, lr[0m
[[36m2025-02-24 16:45:25,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:45:25,706[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0688834918800732 prior_scale[0m
[[36m2025-02-24 16:45:25,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005383502861555352 q_scale[0m
[[36m2025-02-24 16:45:25,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:45:25,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-24 16:45:25,748[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:45:25,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:45:35,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:45:35,978[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:45:35,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:45:35,981[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:45:35,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:45:35,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:45:35,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:45:35,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:45:35,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:45:36,002[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:45:36,039[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.65it/s v_num: 0.000      
                                                              rmse/val: 3845.774
                                                              rmse/train:       
                                                              3940.096          
[[36m2025-02-24 16:45:50,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:45:50,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/020[0m
[[36m2025-02-24 16:45:50,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:45:50,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009674822215525922, lr[0m
[[36m2025-02-24 16:45:50,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:45:50,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.028447825080262935 prior_scale[0m
[[36m2025-02-24 16:45:50,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004765721941975227 q_scale[0m
[[36m2025-02-24 16:45:50,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:45:50,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-24 16:45:50,935[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:45:50,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:46:00,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:46:00,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:46:00,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:46:00,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:46:00,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:46:00,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:46:00,632[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:46:00,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:46:00,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:46:00,669[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:46:00,693[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 10.33it/s v_num: 0.000     
                                                               rmse/val: 104.815
                                                               rmse/train:      
                                                               57.093           
[[36m2025-02-24 16:46:47,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:46:47,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/021[0m
[[36m2025-02-24 16:46:48,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:46:48,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038903540548520176, lr[0m
[[36m2025-02-24 16:46:48,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:46:48,121[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.025097966623569633 prior_scale[0m
[[36m2025-02-24 16:46:48,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033550995264756994 q_scale[0m
[[36m2025-02-24 16:46:48,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:46:48,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-24 16:46:48,161[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:46:48,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:46:58,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:46:58,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:46:58,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:46:58,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:46:58,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:46:58,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:46:58,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:46:58,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:46:58,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:46:58,285[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:46:58,319[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 10.38it/s v_num: 0.000     
                                                               rmse/val: 172.826
                                                               rmse/train:      
                                                               177.430          
[[36m2025-02-24 16:47:37,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:47:37,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/022[0m
[[36m2025-02-24 16:47:37,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:47:37,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007535961514594533, lr[0m
[[36m2025-02-24 16:47:37,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:47:37,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.026883396378969467 prior_scale[0m
[[36m2025-02-24 16:47:37,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012581973353670143 q_scale[0m
[[36m2025-02-24 16:47:38,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:47:38,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-24 16:47:38,010[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:47:38,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:47:47,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:47:47,790[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:47:47,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:47:47,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:47:47,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:47:47,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:47:47,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:47:47,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:47:47,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:47:47,830[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:47:47,853[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.31it/s v_num: 0.000     
                                                               rmse/val: 85.635 
                                                               rmse/train:      
                                                               69.238           
[[36m2025-02-24 16:48:28,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:48:28,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/023[0m
[[36m2025-02-24 16:48:29,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:48:29,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003558250160840399, lr[0m
[[36m2025-02-24 16:48:29,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:48:29,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006209310061318424 prior_scale[0m
[[36m2025-02-24 16:48:29,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003801340996352811 q_scale[0m
[[36m2025-02-24 16:48:29,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:48:29,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-24 16:48:29,209[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:48:29,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:48:39,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:48:39,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:48:39,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:48:39,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:48:39,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:48:39,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:48:39,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:48:39,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:48:39,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:48:39,769[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:48:39,782[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 7.35it/s v_num: 0.000      
                                                              rmse/val: 3855.129
                                                              rmse/train:       
                                                              3961.600          
[[36m2025-02-24 16:48:57,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:48:57,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/024[0m
[[36m2025-02-24 16:48:57,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:48:57,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001918736794283924, lr[0m
[[36m2025-02-24 16:48:57,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:48:57,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16500300882824115 prior_scale[0m
[[36m2025-02-24 16:48:57,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001767415258466624 q_scale[0m
[[36m2025-02-24 16:48:57,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:48:57,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-24 16:48:57,264[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:48:57,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:49:07,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:49:07,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:49:07,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:49:07,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:49:07,498[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:49:07,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:49:07,500[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:49:07,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:49:07,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:49:07,539[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:49:07,549[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.70it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1688.142         
                                                               rmse/train:      
                                                               1823.316         
[[36m2025-02-24 16:49:48,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:49:48,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/025[0m
[[36m2025-02-24 16:49:48,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:49:48,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008219238268640003, lr[0m
[[36m2025-02-24 16:49:48,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:49:48,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0701219661498586 prior_scale[0m
[[36m2025-02-24 16:49:48,824[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022317390945526404 q_scale[0m
[[36m2025-02-24 16:49:48,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:49:48,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-24 16:49:48,840[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:49:48,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:49:58,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:49:58,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:49:58,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:49:58,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:49:58,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:49:58,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:49:58,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:49:58,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:49:58,906[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:49:58,922[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:49:58,951[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 14.24it/s v_num: 0.000     
                                                               rmse/val: 81.771 
                                                               rmse/train:      
                                                               54.451           
[[36m2025-02-24 16:50:37,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:50:37,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/026[0m
[[36m2025-02-24 16:50:37,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:50:37,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004385283241074326, lr[0m
[[36m2025-02-24 16:50:38,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:50:38,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3101187669774712 prior_scale[0m
[[36m2025-02-24 16:50:38,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021254299046878652 q_scale[0m
[[36m2025-02-24 16:50:38,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:50:38,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-24 16:50:38,062[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:50:38,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       15.89it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 42.221 
                                                               rmse/train:      
                                                               33.189           
[[36m2025-02-24 16:50:43,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:50:43,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/010[0m
[[36m2025-02-24 16:50:43,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:50:43,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-02-24 16:50:43,957[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:50:43,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015791568646716513 prior_scale[0m
[[36m2025-02-24 16:50:43,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013400032806480455 q_scale[0m
[[36m2025-02-24 16:50:43,998[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:50:43,998[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-24 16:50:43,998[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:50:43,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:50:47,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:50:47,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:50:47,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:50:47,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:50:47,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:50:47,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:50:47,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:50:47,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:50:47,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:50:47,676[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:50:47,684[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:50:53,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:50:53,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:50:53,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:50:53,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:50:53,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:50:53,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:50:53,784[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:50:53,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:50:53,785[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:50:53,821[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:50:53,831[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.00it/s v_num: 0.000     
                                                               rmse/val: 208.518
                                                               rmse/train:      
                                                               159.864          
[[36m2025-02-24 16:51:29,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:51:29,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/027[0m
[[36m2025-02-24 16:51:29,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:51:29,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000724443730204724, lr[0m
[[36m2025-02-24 16:51:29,343[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:51:29,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5368203639253165 prior_scale[0m
[[36m2025-02-24 16:51:29,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009958342281810118 q_scale[0m
[[36m2025-02-24 16:51:29,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:51:29,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-24 16:51:29,427[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:51:29,427[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:51:39,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:51:39,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:51:39,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:51:39,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:51:39,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:51:39,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:51:39,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:51:39,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:51:39,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:51:39,606[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:51:39,615[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.32it/s v_num: 0.000     
                                                               rmse/val: 116.708
                                                               rmse/train:      
                                                               54.710           
[[36m2025-02-24 16:52:20,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:52:20,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/028[0m
[[36m2025-02-24 16:52:20,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:52:20,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006881081423441657, lr[0m
[[36m2025-02-24 16:52:20,896[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:52:20,920[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6670023417651386 prior_scale[0m
[[36m2025-02-24 16:52:20,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008731294528918791 q_scale[0m
[[36m2025-02-24 16:52:20,975[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:52:20,975[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-24 16:52:20,975[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:52:20,976[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:52:31,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:52:31,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:52:31,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:52:31,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:52:31,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:52:31,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:52:31,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:52:31,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:52:31,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:52:31,171[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:52:31,202[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 8.26it/s v_num: 0.000      
                                                              rmse/val: 329.657 
                                                              rmse/train:       
                                                              367.671           
[[36m2025-02-24 16:52:48,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:52:48,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/029[0m
[[36m2025-02-24 16:52:48,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:52:48,454[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.432377867102485e-05, lr[0m
[[36m2025-02-24 16:52:48,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:52:48,493[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3977129712664468 prior_scale[0m
[[36m2025-02-24 16:52:48,515[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9098338000810426 q_scale[0m
[[36m2025-02-24 16:52:48,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:52:48,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-24 16:52:48,536[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:52:48,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:52:59,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:52:59,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:52:59,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:52:59,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:52:59,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:52:59,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:52:59,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:52:59,094[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:52:59,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:52:59,109[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:52:59,123[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 3/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 4.85it/s v_num: 0.000       
                                                             rmse/val: 8306.673 
                                                             rmse/train:        
                                                             4621.233           
[[36m2025-02-24 16:53:01,651[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 3.
[[36m2025-02-24 16:53:01,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:53:01,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:53:01,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007504380924840447, lr[0m
[[36m2025-02-24 16:53:01,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:53:01,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07302603787832612 prior_scale[0m
[[36m2025-02-24 16:53:01,835[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019768362488607863 q_scale[0m
[[36m2025-02-24 16:53:01,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:53:01,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-24 16:53:01,852[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:53:01,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:53:11,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:53:11,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:53:11,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:53:11,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:53:11,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:53:11,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:53:11,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:53:11,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:53:11,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:53:11,574[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:53:11,582[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.42it/s v_num: 0.000     
                                                               rmse/val: 82.074 
                                                               rmse/train:      
                                                               46.978           
[[36m2025-02-24 16:53:49,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:53:49,029[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/031[0m
[[36m2025-02-24 16:53:49,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:53:49,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007487513495989997, lr[0m
[[36m2025-02-24 16:53:49,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:53:49,202[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1958565775631171 prior_scale[0m
[[36m2025-02-24 16:53:49,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020168380272309736 q_scale[0m
[[36m2025-02-24 16:53:49,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:53:49,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-24 16:53:49,235[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:53:49,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:53:59,091[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:53:59,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:53:59,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:53:59,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:53:59,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:53:59,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:53:59,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:53:59,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:53:59,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:53:59,135[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:53:59,142[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.55it/s v_num: 0.000     
                                                               rmse/val: 76.211 
                                                               rmse/train:      
                                                               48.078           
[[36m2025-02-24 16:54:39,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:54:39,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/032[0m
[[36m2025-02-24 16:54:39,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:54:39,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006344273141515181, lr[0m
[[36m2025-02-24 16:54:39,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:54:39,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23774077646075986 prior_scale[0m
[[36m2025-02-24 16:54:39,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002869432117032144 q_scale[0m
[[36m2025-02-24 16:54:39,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:54:39,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-24 16:54:39,477[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:54:39,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:54:49,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:54:49,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:54:49,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:54:49,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:54:49,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:54:49,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:54:49,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:54:49,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:54:49,491[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:54:49,507[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:54:49,529[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.65it/s v_num: 0.000     
                                                               rmse/val: 90.988 
                                                               rmse/train:      
                                                               63.300           
[[36m2025-02-24 16:55:30,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:55:30,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/033[0m
[[36m2025-02-24 16:55:30,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:55:30,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046322689176454547, lr[0m
[[36m2025-02-24 16:55:30,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:55:30,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14366689658702228 prior_scale[0m
[[36m2025-02-24 16:55:30,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020489167173149444 q_scale[0m
[[36m2025-02-24 16:55:30,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:55:30,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-24 16:55:30,584[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:55:30,584[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:55:40,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:55:40,618[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:55:40,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:55:40,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:55:40,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:55:40,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:55:40,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:55:40,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:55:40,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:55:40,662[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:55:40,671[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:13 •       15.07it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 50.838 
                                                               rmse/train:      
                                                               40.043           
[[36m2025-02-24 16:55:48,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:55:48,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/011[0m
[[36m2025-02-24 16:55:48,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:55:48,615[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-02-24 16:55:48,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:55:48,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01578701912640358 prior_scale[0m
[[36m2025-02-24 16:55:48,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010569299297450266 q_scale[0m
[[36m2025-02-24 16:55:48,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 16:55:48,690[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-24 16:55:48,690[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:55:48,690[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 9.99it/s v_num: 0.000      
                                                              rmse/val: 3349.793
                                                              rmse/train:       
                                                              3455.838          
[[36m2025-02-24 16:55:56,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:55:56,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/034[0m
[[36m2025-02-24 16:55:56,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:55:56,289[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003543464729623235, lr[0m
[[36m2025-02-24 16:55:56,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:55:56,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19797991285980732 prior_scale[0m
[[36m2025-02-24 16:55:56,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009701445897562239 q_scale[0m
[[36m2025-02-24 16:55:56,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:55:56,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-24 16:55:56,356[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:55:56,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:55:58,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:55:58,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:55:58,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:55:58,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:55:58,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:55:58,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:55:58,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:55:58,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:55:58,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:55:58,332[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:55:58,372[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:56:05,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:56:05,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:56:05,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:56:05,892[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:56:05,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:56:05,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:56:05,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:56:05,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:56:05,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:56:05,909[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:56:05,922[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:02 • 0:00:00 9.64it/s v_num: 0.000     
                                                               rmse/val: 232.488
                                                               rmse/train:      
                                                               181.254          
[[36m2025-02-24 16:56:45,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:56:45,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/035[0m
[[36m2025-02-24 16:56:45,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:56:45,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007432127200109299, lr[0m
[[36m2025-02-24 16:56:45,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:56:45,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9136614367319559 prior_scale[0m
[[36m2025-02-24 16:56:45,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002498921993623579 q_scale[0m
[[36m2025-02-24 16:56:45,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 16:56:45,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-24 16:56:45,737[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:56:45,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:56:55,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:56:55,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:56:55,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:56:55,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:56:55,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:56:55,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:56:55,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:56:55,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:56:55,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:56:55,796[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:56:55,824[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 8.84it/s v_num: 0.000      
                                                              rmse/val: 1299.485
                                                              rmse/train:       
                                                              1385.736          
[[36m2025-02-24 16:57:04,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:57:04,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/036[0m
[[36m2025-02-24 16:57:04,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:57:04,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005472156220426618, lr[0m
[[36m2025-02-24 16:57:04,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:57:04,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08979092874053499 prior_scale[0m
[[36m2025-02-24 16:57:04,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21193361588766488 q_scale[0m
[[36m2025-02-24 16:57:04,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:57:04,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-24 16:57:04,498[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:57:04,498[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:57:14,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:57:14,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:57:14,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:57:14,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:57:14,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:57:14,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:57:14,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:57:14,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:57:14,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:57:14,695[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:57:14,734[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 5/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.99it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3347.850         
                                                               rmse/train:      
                                                               3860.760         
[[36m2025-02-24 16:57:26,661[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 5.
[[36m2025-02-24 16:57:26,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:57:26,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:57:26,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6429465259517205e-05, lr[0m
[[36m2025-02-24 16:57:26,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:57:26,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5006907864002006 prior_scale[0m
[[36m2025-02-24 16:57:26,853[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017377672968208042 q_scale[0m
[[36m2025-02-24 16:57:26,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:57:26,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-24 16:57:26,871[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:57:26,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:57:37,128[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:57:37,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:57:37,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:57:37,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:57:37,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:57:37,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:57:37,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:57:37,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:57:37,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:57:37,160[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:57:37,170[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 9/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:00 • 0:00:00 22.58it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3165.974         
                                                               rmse/train:      
                                                               3346.453         
[[36m2025-02-24 16:57:48,900[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 9.
[[36m2025-02-24 16:57:48,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:57:48,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:57:49,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0774254950974043e-05, lr[0m
[[36m2025-02-24 16:57:49,033[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:57:49,051[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.25930765018610186 prior_scale[0m
[[36m2025-02-24 16:57:49,069[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005341226886060583 q_scale[0m
[[36m2025-02-24 16:57:49,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:57:49,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-24 16:57:49,084[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:57:49,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:57:58,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:57:58,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:57:58,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:57:58,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:57:58,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:57:58,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:57:58,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:57:58,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:57:58,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:57:58,956[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:57:58,965[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 7/19 ━━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.98it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3977.317         
                                                               rmse/train:      
                                                               4096.697         
[[36m2025-02-24 16:58:15,491[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 7.
[[36m2025-02-24 16:58:15,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:58:15,572[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:58:15,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020652522290167825, lr[0m
[[36m2025-02-24 16:58:15,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 16:58:15,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12901340461166597 prior_scale[0m
[[36m2025-02-24 16:58:15,652[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001975015724074028 q_scale[0m
[[36m2025-02-24 16:58:15,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 16:58:15,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-24 16:58:15,667[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:58:15,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:58:25,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:58:25,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:58:25,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:58:25,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:58:25,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:58:25,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:58:25,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:58:25,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:58:25,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:58:25,619[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:58:25,629[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 5/5 0:00:00 • 0:00:00 15.98it/s v_num: 0.000      
                                                              rmse/val: 3835.782
                                                              rmse/train:       
                                                              3933.489          
[[36m2025-02-24 16:58:35,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:58:35,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/040[0m
[[36m2025-02-24 16:58:35,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:58:35,824[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008001623841521837, lr[0m
[[36m2025-02-24 16:58:35,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:58:35,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06455459535288349 prior_scale[0m
[[36m2025-02-24 16:58:35,895[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024170895358512567 q_scale[0m
[[36m2025-02-24 16:58:35,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:58:35,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-24 16:58:35,915[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:58:35,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:58:45,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:58:45,790[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:58:45,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:58:45,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:58:45,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:58:45,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:58:45,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:58:45,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:58:45,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:58:45,811[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:58:45,821[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.51it/s v_num: 0.000     
                                                               rmse/val: 94.981 
                                                               rmse/train:      
                                                               65.457           
[[36m2025-02-24 16:59:27,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 16:59:27,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/041[0m
[[36m2025-02-24 16:59:27,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 16:59:27,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008067100945477406, lr[0m
[[36m2025-02-24 16:59:27,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 16:59:27,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05615254688031494 prior_scale[0m
[[36m2025-02-24 16:59:27,454[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018565455630260784 q_scale[0m
[[36m2025-02-24 16:59:27,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 16:59:27,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-24 16:59:27,474[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 16:59:27,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 16:59:37,919[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 16:59:37,926[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 16:59:37,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 16:59:37,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 16:59:37,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 16:59:37,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 16:59:37,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 16:59:37,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 16:59:37,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 16:59:37,963[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 16:59:37,974[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 11.92it/s v_num: 0.000     
                                                               rmse/val: 73.336 
                                                               rmse/train:      
                                                               47.737           
[[36m2025-02-24 17:00:19,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:00:19,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/042[0m
[[36m2025-02-24 17:00:19,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:00:19,886[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005820610644418714, lr[0m
[[36m2025-02-24 17:00:19,904[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:00:19,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1077996955687841 prior_scale[0m
[[36m2025-02-24 17:00:19,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015351435165738284 q_scale[0m
[[36m2025-02-24 17:00:19,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:00:19,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-24 17:00:19,973[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:00:19,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:00:30,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:00:30,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:00:30,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:00:30,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:00:30,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:00:30,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:00:30,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:00:30,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:00:30,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:00:30,253[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:00:30,262[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       15.37it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 53.335 
                                                               rmse/train:      
                                                               45.763           
[[36m2025-02-24 17:00:53,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:00:53,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/012[0m
[[36m2025-02-24 17:00:53,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:00:53,317[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015991366116446953, lr[0m
[[36m2025-02-24 17:00:53,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:00:53,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023551654708581973 prior_scale[0m
[[36m2025-02-24 17:00:53,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010194432109815798 q_scale[0m
[[36m2025-02-24 17:00:53,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:00:53,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-24 17:00:53,473[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:00:53,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:01:03,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:01:03,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:01:03,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:01:03,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:01:03,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:01:03,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:01:03,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:01:03,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:01:03,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:01:03,267[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:01:03,275[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.44it/s v_num: 0.000     
                                                               rmse/val: 113.332
                                                               rmse/train:      
                                                               96.502           
[[36m2025-02-24 17:01:10,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:01:10,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/043[0m
[[36m2025-02-24 17:01:10,962[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:01:11,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004124831321621341, lr[0m
[[36m2025-02-24 17:01:11,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:01:11,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.051388910072198576 prior_scale[0m
[[36m2025-02-24 17:01:11,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000625714390067751 q_scale[0m
[[36m2025-02-24 17:01:11,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:01:11,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-24 17:01:11,077[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:01:11,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:01:20,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:01:20,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:01:20,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:01:20,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:01:20,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:01:20,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:01:20,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:01:20,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:01:20,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:01:20,759[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:01:20,768[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 20/20 0:00:01 • 0:00:00 12.17it/s v_num: 0.000     
                                                               rmse/val: 115.363
                                                               rmse/train:      
                                                               119.939          
[[36m2025-02-24 17:02:02,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:02:02,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/044[0m
[[36m2025-02-24 17:02:02,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:02:02,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003089199434659764, lr[0m
[[36m2025-02-24 17:02:02,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:02:02,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.494804586529123 prior_scale[0m
[[36m2025-02-24 17:02:02,480[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003314861886201554 q_scale[0m
[[36m2025-02-24 17:02:02,495[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-24 17:02:02,496[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-24 17:02:02,496[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:02:02,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:02:12,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:02:12,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:02:12,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:02:12,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:02:12,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:02:12,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:02:12,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:02:12,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:02:12,491[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:02:12,507[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:02:12,533[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 10/10 0:00:00 • 0:00:00 11.23it/s v_num: 0.000     
                                                               rmse/val: 538.535
                                                               rmse/train:      
                                                               582.105          
[[36m2025-02-24 17:02:37,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:02:37,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/045[0m
[[36m2025-02-24 17:02:37,518[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:02:37,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008365809969780687, lr[0m
[[36m2025-02-24 17:02:37,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:02:37,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10598115165911277 prior_scale[0m
[[36m2025-02-24 17:02:37,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014655866571127322 q_scale[0m
[[36m2025-02-24 17:02:37,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:02:37,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-24 17:02:37,685[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:02:37,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:02:47,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:02:47,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:02:47,842[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:02:47,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:02:47,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:02:47,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:02:47,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:02:47,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:02:47,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:02:48,073[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:02:48,085[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 22.94it/s v_num: 0.000     
                                                               rmse/val: 71.378 
                                                               rmse/train:      
                                                               44.167           
[[36m2025-02-24 17:03:31,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:03:31,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/046[0m
[[36m2025-02-24 17:03:31,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:03:31,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004901582158569339, lr[0m
[[36m2025-02-24 17:03:31,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:03:31,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18434016661664662 prior_scale[0m
[[36m2025-02-24 17:03:31,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011360614395175576 q_scale[0m
[[36m2025-02-24 17:03:31,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:03:31,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-24 17:03:31,377[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:03:31,377[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:03:41,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:03:41,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:03:41,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:03:41,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:03:41,030[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:03:41,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:03:41,031[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:03:41,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:03:41,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:03:41,046[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:03:41,057[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.92it/s v_num: 0.000     
                                                               rmse/val: 56.778 
                                                               rmse/train:      
                                                               50.611           
[[36m2025-02-24 17:03:42,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:03:42,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/013[0m
[[36m2025-02-24 17:03:42,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:03:42,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009801615183585152, lr[0m
[[36m2025-02-24 17:03:42,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:03:42,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03777462213368495 prior_scale[0m
[[36m2025-02-24 17:03:42,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042903850239015034 q_scale[0m
[[36m2025-02-24 17:03:42,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:03:42,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-24 17:03:42,865[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:03:42,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:03:52,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:03:52,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:03:52,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:03:52,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:03:52,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:03:52,531[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:03:52,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:03:52,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:03:52,533[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:03:52,563[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:03:52,571[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 22.07it/s v_num: 0.000     
                                                               rmse/val: 46.667 
                                                               rmse/train:      
                                                               43.173           
[[36m2025-02-24 17:04:26,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:04:26,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/047[0m
[[36m2025-02-24 17:04:26,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:04:26,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004933632794909617, lr[0m
[[36m2025-02-24 17:04:26,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:04:27,021[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.020405542491552745 prior_scale[0m
[[36m2025-02-24 17:04:27,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011047000076727068 q_scale[0m
[[36m2025-02-24 17:04:27,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:04:27,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-24 17:04:27,060[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:04:27,061[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:04:37,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:04:37,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:04:37,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:04:37,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:04:37,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:04:37,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:04:37,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:04:37,029[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:04:37,030[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:04:37,062[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:04:37,089[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 22.96it/s v_num: 0.000     
                                                               rmse/val: 63.803 
                                                               rmse/train:      
                                                               38.095           
[[36m2025-02-24 17:05:21,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:05:21,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/048[0m
[[36m2025-02-24 17:05:21,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:05:22,028[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002318423262287637, lr[0m
[[36m2025-02-24 17:05:22,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:05:22,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11607667945247209 prior_scale[0m
[[36m2025-02-24 17:05:22,079[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014434003992706498 q_scale[0m
[[36m2025-02-24 17:05:22,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:05:22,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-24 17:05:22,102[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:05:22,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:05:31,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:05:31,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:05:31,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:05:31,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:05:31,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:05:31,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:05:31,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:05:31,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:05:31,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:05:31,750[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:05:31,759[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 25.86it/s v_num: 0.000     
                                                               rmse/val: 107.573
                                                               rmse/train:      
                                                               98.098           
[[36m2025-02-24 17:06:12,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:06:12,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/049[0m
[[36m2025-02-24 17:06:12,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:06:12,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008871351483351918, lr[0m
[[36m2025-02-24 17:06:12,976[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:06:12,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16041163498374023 prior_scale[0m
[[36m2025-02-24 17:06:13,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011172652931689133 q_scale[0m
[[36m2025-02-24 17:06:13,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:06:13,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-24 17:06:13,035[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:06:13,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:06:22,986[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:06:22,994[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:06:22,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:06:22,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:06:22,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:06:22,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:06:22,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:06:22,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:06:23,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:06:23,035[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:06:23,044[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 23.60it/s v_num: 0.000     
                                                               rmse/val: 98.241 
                                                               rmse/train:      
                                                               49.837           
[[36m2025-02-24 17:07:06,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:07:06,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/050[0m
[[36m2025-02-24 17:07:06,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:07:06,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006650259307840426, lr[0m
[[36m2025-02-24 17:07:06,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:07:06,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20613605240220698 prior_scale[0m
[[36m2025-02-24 17:07:06,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010186339574177252 q_scale[0m
[[36m2025-02-24 17:07:06,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:07:06,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-24 17:07:06,702[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:07:06,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:07:17,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:07:17,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:07:17,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:07:17,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:07:17,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:07:17,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:07:17,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:07:17,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:07:17,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:07:17,231[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:07:17,262[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 25.36it/s v_num: 0.000     
                                                               rmse/val: 76.549 
                                                               rmse/train:      
                                                               51.306           
[[36m2025-02-24 17:07:58,574[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:07:58,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/051[0m
[[36m2025-02-24 17:07:58,674[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:07:58,706[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006123224953559687, lr[0m
[[36m2025-02-24 17:07:58,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:07:58,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09503694997607778 prior_scale[0m
[[36m2025-02-24 17:07:58,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010626733881971644 q_scale[0m
[[36m2025-02-24 17:07:58,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:07:58,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-24 17:07:58,770[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:07:58,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:08:08,639[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:08:08,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:08:08,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:08:08,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:08:08,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:08:08,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:08:08,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:08:08,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:08:08,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:08:08,686[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:08:09,034[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 27.12it/s v_num: 0.000     
                                                               rmse/val: 71.932 
                                                               rmse/train:      
                                                               47.998           
[[36m2025-02-24 17:08:48,172[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:08:48,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/052[0m
[[36m2025-02-24 17:08:48,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:08:48,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005770641519746715, lr[0m
[[36m2025-02-24 17:08:48,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:08:48,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.054916448893760926 prior_scale[0m
[[36m2025-02-24 17:08:48,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004395781220958909 q_scale[0m
[[36m2025-02-24 17:08:48,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:08:48,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-24 17:08:48,385[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:08:48,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       15.66it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 39.302 
                                                               rmse/train:      
                                                               29.918           
[[36m2025-02-24 17:08:48,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:08:48,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/014[0m
[[36m2025-02-24 17:08:48,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:08:48,911[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009933433836908847, lr[0m
[[36m2025-02-24 17:08:48,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:08:48,940[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04295889441861082 prior_scale[0m
[[36m2025-02-24 17:08:48,957[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005371630331658818 q_scale[0m
[[36m2025-02-24 17:08:48,970[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:08:48,970[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-24 17:08:48,971[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:08:48,971[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:08:58,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:08:58,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:08:58,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:08:58,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:08:58,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:08:58,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:08:58,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:08:58,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:08:58,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:08:58,155[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:08:58,168[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:08:58,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:08:58,503[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:08:58,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:08:58,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:08:58,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:08:58,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:08:58,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:08:58,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:08:58,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:08:58,538[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:08:58,546[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 25.88it/s v_num: 0.000     
                                                               rmse/val: 73.661 
                                                               rmse/train:      
                                                               42.455           
[[36m2025-02-24 17:09:37,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:09:37,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/053[0m
[[36m2025-02-24 17:09:37,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:09:37,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003097749945698196, lr[0m
[[36m2025-02-24 17:09:37,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:09:37,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3063189159865552 prior_scale[0m
[[36m2025-02-24 17:09:37,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028785875540367 q_scale[0m
[[36m2025-02-24 17:09:37,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:09:37,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-24 17:09:37,900[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:09:37,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:09:47,576[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:09:47,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:09:47,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:09:47,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:09:47,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:09:47,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:09:47,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:09:47,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:09:47,588[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:09:47,617[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:09:47,625[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 22.58it/s v_num: 0.000     
                                                               rmse/val: 70.351 
                                                               rmse/train:      
                                                               50.355           
[[36m2025-02-24 17:10:27,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:10:27,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/054[0m
[[36m2025-02-24 17:10:27,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:10:27,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015253671276923227, lr[0m
[[36m2025-02-24 17:10:27,979[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:10:27,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09415310255835511 prior_scale[0m
[[36m2025-02-24 17:10:28,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010622638533885774 q_scale[0m
[[36m2025-02-24 17:10:28,035[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:10:28,036[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-24 17:10:28,036[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:10:28,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:10:37,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:10:37,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:10:37,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:10:37,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:10:37,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:10:37,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:10:37,691[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:10:37,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:10:37,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:10:37,707[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:10:37,816[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 24.25it/s v_num: 0.000     
                                                               rmse/val: 291.592
                                                               rmse/train:      
                                                               262.981          
[[36m2025-02-24 17:11:16,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:11:16,892[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/055[0m
[[36m2025-02-24 17:11:17,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:11:17,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006234503695443075, lr[0m
[[36m2025-02-24 17:11:17,051[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:11:17,069[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5746791270552903 prior_scale[0m
[[36m2025-02-24 17:11:17,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007515326369669672 q_scale[0m
[[36m2025-02-24 17:11:17,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:11:17,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-24 17:11:17,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:11:17,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:11:26,740[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:11:26,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:11:26,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:11:26,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:11:26,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:11:26,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:11:26,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:11:26,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:11:26,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:11:26,785[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:11:26,832[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 26.73it/s v_num: 0.000     
                                                               rmse/val: 79.377 
                                                               rmse/train:      
                                                               46.987           
[[36m2025-02-24 17:12:06,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:12:06,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/056[0m
[[36m2025-02-24 17:12:06,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:12:06,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006331440189537419, lr[0m
[[36m2025-02-24 17:12:06,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:12:06,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6055709728691586 prior_scale[0m
[[36m2025-02-24 17:12:06,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007833907890241141 q_scale[0m
[[36m2025-02-24 17:12:06,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:12:06,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-24 17:12:06,463[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:12:06,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:12:16,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:12:16,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:12:16,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:12:16,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:12:16,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:12:16,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:12:16,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:12:16,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:12:16,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:12:16,066[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:12:16,074[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 27.55it/s v_num: 0.000     
                                                               rmse/val: 90.925 
                                                               rmse/train:      
                                                               51.436           
[[36m2025-02-24 17:12:53,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:12:53,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/057[0m
[[36m2025-02-24 17:12:54,133[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:12:54,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004713186781202526, lr[0m
[[36m2025-02-24 17:12:54,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:12:54,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8397504651877787 prior_scale[0m
[[36m2025-02-24 17:12:54,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016519937294930918 q_scale[0m
[[36m2025-02-24 17:12:54,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:12:54,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-24 17:12:54,263[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:12:54,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:13:03,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:13:03,837[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:13:03,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:13:03,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:13:03,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:13:03,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:13:03,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:13:03,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:13:03,842[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:13:03,873[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:13:03,883[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 24.18it/s v_num: 0.000     
                                                               rmse/val: 62.651 
                                                               rmse/train:      
                                                               55.896           
[[36m2025-02-24 17:13:46,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:13:46,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/058[0m
[[36m2025-02-24 17:13:46,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:13:46,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.518736571418839e-05, lr[0m
[[36m2025-02-24 17:13:46,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-24 17:13:46,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5893824062185491 prior_scale[0m
[[36m2025-02-24 17:13:46,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004160694286668926 q_scale[0m
[[36m2025-02-24 17:13:46,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:13:46,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-24 17:13:46,586[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:13:46,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       16.13it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 52.327 
                                                               rmse/train:      
                                                               32.529           
[[36m2025-02-24 17:13:50,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:13:50,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/015[0m
[[36m2025-02-24 17:13:50,170[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:13:50,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009418616963254316, lr[0m
[[36m2025-02-24 17:13:50,218[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:13:50,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0057475489968997415 prior_scale[0m
[[36m2025-02-24 17:13:50,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005478446090810961 q_scale[0m
[[36m2025-02-24 17:13:50,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:13:50,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-24 17:13:50,269[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:13:50,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 141 [7765, 3499, 2329, 2573, 821]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:13:56,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:13:56,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:13:56,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:13:56,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:13:56,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:13:56,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:13:56,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:13:56,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:13:56,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:13:56,169[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:13:56,180[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:13:59,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:13:59,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:13:59,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:13:59,835[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:13:59,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:13:59,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:13:59,837[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:13:59,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:13:59,838[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:13:59,870[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:14:01,013[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 40/40 0:00:01 • 0:00:00 21.37it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1402.053         
                                                               rmse/train:      
                                                               1536.889         
[[36m2025-02-24 17:14:38,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:14:38,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_20perc/runs/2025-02-24_16-30-10/059[0m
[[36m2025-02-24 17:14:38,248[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       16.11it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 62.748 
                                                               rmse/train:      
                                                               32.517           
[[36m2025-02-24 17:18:54,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:18:54,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/016[0m
[[36m2025-02-24 17:18:54,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:18:54,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048726994464372547, lr[0m
[[36m2025-02-24 17:18:54,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:18:54,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03298570457662521 prior_scale[0m
[[36m2025-02-24 17:18:54,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013121308489553924 q_scale[0m
[[36m2025-02-24 17:18:54,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-24 17:18:54,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-24 17:18:54,879[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:18:54,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:19:04,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:19:04,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:19:04,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:19:04,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:19:04,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:19:04,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:19:04,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:19:04,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:19:04,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:19:04,783[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:19:04,951[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 10.02it/s v_num: 0.000     
                                                               rmse/val: 86.072 
                                                               rmse/train:      
                                                               84.137           
[[36m2025-02-24 17:20:04,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:20:04,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/017[0m
[[36m2025-02-24 17:20:04,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:20:04,961[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048212758884668886, lr[0m
[[36m2025-02-24 17:20:04,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:20:04,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27634381419905757 prior_scale[0m
[[36m2025-02-24 17:20:05,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002885851817360491 q_scale[0m
[[36m2025-02-24 17:20:05,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-24 17:20:05,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-24 17:20:05,015[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:20:05,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:20:15,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:20:15,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:20:15,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:20:15,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:20:15,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:20:15,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:20:15,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:20:15,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:20:15,740[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:20:15,772[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:20:15,782[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.50it/s v_num: 0.000     
                                                               rmse/val: 338.348
                                                               rmse/train:      
                                                               367.308          
[[36m2025-02-24 17:21:02,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:21:02,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/018[0m
[[36m2025-02-24 17:21:02,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:21:02,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012544540249913088, lr[0m
[[36m2025-02-24 17:21:02,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:21:02,529[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007133078560557303 prior_scale[0m
[[36m2025-02-24 17:21:02,544[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001932611973562815 q_scale[0m
[[36m2025-02-24 17:21:02,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-24 17:21:02,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-24 17:21:02,556[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:21:02,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:21:12,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:21:12,197[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:21:12,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:21:12,200[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:21:12,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:21:12,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:21:12,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:21:12,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:21:12,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:21:12,218[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:21:12,229[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 14.14it/s v_num: 0.000     
                                                               rmse/val: 34.316 
                                                               rmse/train:      
                                                               33.721           
[[36m2025-02-24 17:23:49,906[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:23:49,908[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/019[0m
[[36m2025-02-24 17:23:50,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:23:50,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032043021391109096, lr[0m
[[36m2025-02-24 17:23:50,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:23:50,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05538828055465327 prior_scale[0m
[[36m2025-02-24 17:23:50,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024331562128032956 q_scale[0m
[[36m2025-02-24 17:23:50,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:23:50,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-24 17:23:50,123[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:23:50,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:23:59,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:23:59,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:23:59,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:23:59,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:23:59,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:23:59,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:23:59,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:23:59,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:23:59,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:23:59,735[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:23:59,751[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:12 •       15.59it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.249 
                                                               rmse/train:      
                                                               33.244           
[[36m2025-02-24 17:28:51,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:28:51,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/020[0m
[[36m2025-02-24 17:28:51,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:28:51,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002844592019038099, lr[0m
[[36m2025-02-24 17:28:51,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:28:51,690[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.060077948867644476 prior_scale[0m
[[36m2025-02-24 17:28:51,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002925940795318177 q_scale[0m
[[36m2025-02-24 17:28:51,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:28:51,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-24 17:28:51,736[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:28:51,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-24 17:29:01,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-24 17:29:01,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-24 17:29:01,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-24 17:29:01,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-24 17:29:01,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-24 17:29:01,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-24 17:29:01,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-24 17:29:01,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-24 17:29:01,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-24 17:29:01,385[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-24 17:29:01,394[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:15 •       12.60it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 50.082 
                                                               rmse/train:      
                                                               37.747           
[[36m2025-02-24 17:34:08,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-24 17:34:08,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-24_16-30-10/021[0m
[[36m2025-02-24 17:34:08,390[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-24 17:34:08,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005377740280800115, lr[0m
[[36m2025-02-24 17:34:08,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-24 17:34:08,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.025721840905250332 prior_scale[0m
[[36m2025-02-24 17:34:08,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002788619313409219 q_scale[0m
[[36m2025-02-24 17:34:08,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-24 17:34:08,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-24 17:34:08,521[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-24 17:34:08,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
[[36m2025-02-24 17:38:28,014[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 27, in __init__
    self.load_db()
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet_datamodule.py", line 44, in load_db
    self.list_structures_energy, self.list_structures_forces, self.list_removed, self.max_nnb, self.tin = read_list_structures(self.tin)
                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/prepare_batches.py", line 15, in read_list_structures
    list_structures_energy, list_removed, max_nnb, tin = read_train(tin)
                                                         ^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/datamodule/aenet/read_trainset.py", line 104, in read_train
    with open (trainfile, "r") as tf:
         ^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: '/work/g15farris/database/TiO/data.train.ascii'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 46, in train
    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.datamodule)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'bnn_aenet.datamodule.aenet_datamodule.AenetDataModule':
OSError(5, 'Input/output error')
full_key: datamodule
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-25 10:43:49,106[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-25 10:43:49,107[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/lrt_100perc.db[0m
[[36m2025-02-25 10:43:51,181[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-25 10:43:51,187[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-25 10:43:51,273[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 10:43:51,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006509790984463777, lr[0m
[[36m2025-02-25 10:43:51,328[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 10:43:51,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04658057864895187 prior_scale[0m
[[36m2025-02-25 10:43:51,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002632382905467797 q_scale[0m
[[36m2025-02-25 10:43:51,394[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 10:43:51,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-25 10:43:51,395[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 10:43:51,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-25 11:00:37,092[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-25 11:00:37,093[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/lrt_100perc.db[0m
[[36m2025-02-25 11:00:42,871[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-25 11:00:42,904[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-25 11:00:43,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:00:43,063[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006509790984463777, lr[0m
[[36m2025-02-25 11:00:43,081[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:00:43,105[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04658057864895187 prior_scale[0m
[[36m2025-02-25 11:00:43,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002632382905467797 q_scale[0m
[[36m2025-02-25 11:00:43,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:00:43,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-25 11:00:43,148[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:00:43,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:00:55,180[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:01:16,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:01:16,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:01:16,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:01:16,565[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:01:16,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:01:16,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:01:16,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:01:16,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:01:17,098[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:01:21,240[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.44it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.092 
                                                               rmse/train:      
                                                               37.334           
[[36m2025-02-25 11:05:54,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:05:54,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/024[0m
[[36m2025-02-25 11:05:54,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:05:55,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006829298328061672, lr[0m
[[36m2025-02-25 11:05:55,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:05:55,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03324722460692267 prior_scale[0m
[[36m2025-02-25 11:05:55,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034558961381588423 q_scale[0m
[[36m2025-02-25 11:05:55,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:05:55,406[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-25 11:05:55,406[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:05:55,407[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:06:04,645[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:06:04,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:06:04,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:06:04,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:06:04,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:06:04,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:06:04,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:06:04,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:06:04,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:06:05,038[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:06:05,051[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.16it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.517 
                                                               rmse/train:      
                                                               39.492           
[[36m2025-02-25 11:10:21,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:10:21,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/025[0m
[[36m2025-02-25 11:10:21,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:10:21,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006238411395857852, lr[0m
[[36m2025-02-25 11:10:21,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:10:21,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18847537475897708 prior_scale[0m
[[36m2025-02-25 11:10:21,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0059812201173843095 q_scale[0m
[[36m2025-02-25 11:10:21,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:10:21,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-25 11:10:21,689[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:10:21,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:10:30,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:10:30,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:10:30,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:10:30,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:10:30,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:10:30,843[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:10:30,844[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:10:30,844[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:10:30,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:10:30,884[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:10:30,897[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.31it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 27.386 
                                                               rmse/train:      
                                                               24.426           
[[36m2025-02-25 11:14:47,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:14:47,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/026[0m
[[36m2025-02-25 11:14:47,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:14:47,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006983210809334892, lr[0m
[[36m2025-02-25 11:14:47,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:14:47,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07072483341252464 prior_scale[0m
[[36m2025-02-25 11:14:47,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011472396045626744 q_scale[0m
[[36m2025-02-25 11:14:47,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:14:47,243[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-25 11:14:47,243[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:14:47,243[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:14:56,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:14:56,246[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:14:56,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:14:56,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:14:56,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:14:56,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:14:56,249[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:14:56,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:14:56,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:14:56,291[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:14:56,316[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.12it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 43.556 
                                                               rmse/train:      
                                                               34.988           
[[36m2025-02-25 11:19:11,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:19:11,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/027[0m
[[36m2025-02-25 11:19:11,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:19:11,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003728086209673569, lr[0m
[[36m2025-02-25 11:19:11,874[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:19:11,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4102783837375459 prior_scale[0m
[[36m2025-02-25 11:19:11,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003379845080952342 q_scale[0m
[[36m2025-02-25 11:19:11,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:19:11,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-25 11:19:11,937[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:19:11,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:19:21,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:19:21,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:19:21,048[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:19:21,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:19:21,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:19:21,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:19:21,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:19:21,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:19:21,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:19:21,138[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:19:21,269[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.14it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.209 
                                                               rmse/train:      
                                                               40.329           
[[36m2025-02-25 11:23:39,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:23:39,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/028[0m
[[36m2025-02-25 11:23:39,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:23:39,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020597547065149416, lr[0m
[[36m2025-02-25 11:23:39,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:23:39,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021794603752404315 prior_scale[0m
[[36m2025-02-25 11:23:39,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019803364724850774 q_scale[0m
[[36m2025-02-25 11:23:39,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:23:39,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-25 11:23:39,300[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:23:39,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:23:48,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:23:48,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:23:48,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:23:48,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:23:48,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:23:48,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:23:48,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:23:48,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:23:48,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:23:48,462[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:23:48,470[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.94it/s v_num: 0.000     
                                                               rmse/val: 65.121 
                                                               rmse/train:      
                                                               55.199           
[[36m2025-02-25 11:26:06,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:26:06,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/029[0m
[[36m2025-02-25 11:26:06,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:26:06,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040552576010057743, lr[0m
[[36m2025-02-25 11:26:06,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:26:06,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11011957907017718 prior_scale[0m
[[36m2025-02-25 11:26:06,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006899810583390177 q_scale[0m
[[36m2025-02-25 11:26:06,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 11:26:06,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-25 11:26:06,692[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:26:06,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:26:16,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:26:16,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:26:16,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:26:16,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:26:16,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:26:16,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:26:16,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:26:16,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:26:16,406[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:26:16,442[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:26:16,567[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.31it/s v_num: 0.000     
                                                               rmse/val: 978.849
                                                               rmse/train:      
                                                               1112.073         
[[36m2025-02-25 11:26:57,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:26:57,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/030[0m
[[36m2025-02-25 11:26:57,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:26:57,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007214176960215279, lr[0m
[[36m2025-02-25 11:26:57,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:26:57,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.051047223149922265 prior_scale[0m
[[36m2025-02-25 11:26:57,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7616145805338517 q_scale[0m
[[36m2025-02-25 11:26:57,351[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:26:57,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-25 11:26:57,352[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:26:57,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:27:06,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:27:06,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:27:06,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:27:06,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:27:06,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:27:06,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:27:06,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:27:06,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:27:06,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:27:06,687[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:27:06,789[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 7/19 ━━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 11.32it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3592.795         
                                                               rmse/train:      
                                                               3889.191         
[[36m2025-02-25 11:27:28,160[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 7.
[[36m2025-02-25 11:27:28,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:27:28,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:27:28,566[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010682995798866446, lr[0m
[[36m2025-02-25 11:27:28,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:27:28,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.025831207105731828 prior_scale[0m
[[36m2025-02-25 11:27:28,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002352154084601003 q_scale[0m
[[36m2025-02-25 11:27:28,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:27:28,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-25 11:27:28,649[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:27:28,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:27:37,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:27:37,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:27:37,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:27:37,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:27:37,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:27:37,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:27:37,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:27:37,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:27:37,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:27:38,018[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:27:38,050[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:02 • 0:00:00 11.30it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3038.176         
                                                               rmse/train:      
                                                               3131.273         
[[36m2025-02-25 11:28:31,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:28:31,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/032[0m
[[36m2025-02-25 11:28:31,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:28:31,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003684161850187871, lr[0m
[[36m2025-02-25 11:28:31,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:28:31,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.37378992749314094 prior_scale[0m
[[36m2025-02-25 11:28:31,406[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003212726526118929 q_scale[0m
[[36m2025-02-25 11:28:31,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:28:31,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-25 11:28:31,423[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:28:31,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:28:40,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:28:40,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:28:40,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:28:40,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:28:40,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:28:40,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:28:40,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:28:40,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:28:40,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:28:40,603[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:28:40,629[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.07it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 27.506 
                                                               rmse/train:      
                                                               21.790           
[[36m2025-02-25 11:33:01,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:33:01,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/033[0m
[[36m2025-02-25 11:33:01,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:33:01,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037904252978057163, lr[0m
[[36m2025-02-25 11:33:01,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:33:01,796[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8631445024831159 prior_scale[0m
[[36m2025-02-25 11:33:01,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002258825207351197 q_scale[0m
[[36m2025-02-25 11:33:01,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:33:01,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-25 11:33:01,838[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:33:01,838[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:33:10,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:33:10,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:33:10,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:33:10,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:33:10,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:33:10,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:33:10,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:33:10,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:33:10,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:33:11,001[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:33:11,012[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.07it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.607 
                                                               rmse/train:      
                                                               44.246           
[[36m2025-02-25 11:37:28,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:37:28,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/034[0m
[[36m2025-02-25 11:37:28,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:37:28,244[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007245914220860388, lr[0m
[[36m2025-02-25 11:37:28,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:37:28,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3805723370060441 prior_scale[0m
[[36m2025-02-25 11:37:28,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009485522113989473 q_scale[0m
[[36m2025-02-25 11:37:28,302[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:37:28,302[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-25 11:37:28,302[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:37:28,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:37:37,309[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:37:37,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:37:37,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:37:37,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:37:37,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:37:37,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:37:37,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:37:37,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:37:37,320[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:37:37,405[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:37:37,418[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.26it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 33.776 
                                                               rmse/train:      
                                                               29.020           
[[36m2025-02-25 11:41:53,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:41:53,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/035[0m
[[36m2025-02-25 11:41:53,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:41:53,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007286170843324783, lr[0m
[[36m2025-02-25 11:41:53,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:41:53,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2974764122719904 prior_scale[0m
[[36m2025-02-25 11:41:53,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011561199955338337 q_scale[0m
[[36m2025-02-25 11:41:53,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:41:53,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-25 11:41:53,365[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:41:53,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:42:02,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:42:02,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:42:02,502[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:42:02,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:42:02,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:42:02,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:42:02,505[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:42:02,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:42:02,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:42:02,562[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:42:02,577[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.12it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.087 
                                                               rmse/train:      
                                                               38.483           
[[36m2025-02-25 11:46:18,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:46:18,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/036[0m
[[36m2025-02-25 11:46:18,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:46:18,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005243619617447778, lr[0m
[[36m2025-02-25 11:46:18,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:46:18,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4928283400121777 prior_scale[0m
[[36m2025-02-25 11:46:18,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00117112249392426 q_scale[0m
[[36m2025-02-25 11:46:18,934[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 11:46:18,934[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-25 11:46:18,935[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:46:18,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:46:28,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:46:28,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:46:28,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:46:28,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:46:28,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:46:28,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:46:28,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:46:28,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:46:28,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:46:28,721[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:46:28,732[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.26it/s v_num: 0.000     
                                                               rmse/val: 224.847
                                                               rmse/train:      
                                                               255.367          
[[36m2025-02-25 11:47:09,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:47:09,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/037[0m
[[36m2025-02-25 11:47:09,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:47:09,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008043638118363524, lr[0m
[[36m2025-02-25 11:47:09,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:47:09,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2325528110186277 prior_scale[0m
[[36m2025-02-25 11:47:09,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3011197994172172 q_scale[0m
[[36m2025-02-25 11:47:09,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:47:09,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-25 11:47:09,321[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:47:09,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:47:18,393[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:47:18,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:47:18,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:47:18,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:47:18,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:47:18,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:47:18,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:47:18,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:47:18,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:47:18,417[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:47:18,427[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 7/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:05 •        33.91it/s v_num: 0.000     
                                    0:00:00                    rmse/val: 214.398
                                                               rmse/train:      
                                                               235.516          
[[36m2025-02-25 11:48:17,881[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 7.
[[36m2025-02-25 11:48:17,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:48:17,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:48:18,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000560203106547756, lr[0m
[[36m2025-02-25 11:48:18,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:48:18,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3660045282784296 prior_scale[0m
[[36m2025-02-25 11:48:18,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005211051528825213 q_scale[0m
[[36m2025-02-25 11:48:18,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:48:18,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-25 11:48:18,073[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:48:18,073[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:48:27,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:48:27,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:48:27,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:48:27,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:48:27,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:48:27,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:48:27,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:48:27,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:48:27,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:48:27,250[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:48:27,274[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:10 •       18.01it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 30.804 
                                                               rmse/train:      
                                                               23.340           
[[36m2025-02-25 11:52:45,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:52:45,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/039[0m
[[36m2025-02-25 11:52:45,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:52:45,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021805449229521945, lr[0m
[[36m2025-02-25 11:52:45,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:52:45,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15995278997044418 prior_scale[0m
[[36m2025-02-25 11:52:45,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01323191568429593 q_scale[0m
[[36m2025-02-25 11:52:45,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:52:45,754[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-25 11:52:45,754[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:52:45,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:52:54,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:52:54,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:52:54,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:52:54,844[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:52:54,844[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:52:54,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:52:54,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:52:54,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:52:54,846[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:52:54,889[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:52:54,916[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 10/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:05 •       33.56it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 66.635 
                                                               rmse/train:      
                                                               63.580           
[[36m2025-02-25 11:54:16,799[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 10.
[[36m2025-02-25 11:54:16,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:54:16,962[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:54:17,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0294620903386365e-05, lr[0m
[[36m2025-02-25 11:54:17,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:54:17,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5903418491155675 prior_scale[0m
[[36m2025-02-25 11:54:17,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0035117890454306813 q_scale[0m
[[36m2025-02-25 11:54:17,112[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 11:54:17,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-25 11:54:17,113[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:54:17,113[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:54:26,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:54:26,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:54:26,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:54:26,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:54:26,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:54:26,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:54:26,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:54:26,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:54:26,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:54:26,265[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:54:26,304[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.62it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3242.557         
                                                               rmse/train:      
                                                               3352.165         
[[36m2025-02-25 11:56:46,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:56:46,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/041[0m
[[36m2025-02-25 11:56:46,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:56:46,845[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.075611820416461e-05, lr[0m
[[36m2025-02-25 11:56:46,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 11:56:46,874[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1243042312330324 prior_scale[0m
[[36m2025-02-25 11:56:46,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008839908430144221 q_scale[0m
[[36m2025-02-25 11:56:46,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-25 11:56:46,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-25 11:56:46,903[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:56:46,903[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:56:56,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:56:56,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:56:56,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:56:56,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:56:56,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:56:56,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:56:56,121[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:56:56,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:56:56,122[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:56:56,163[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:56:56,240[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 21.06it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4030.513         
                                                               rmse/train:      
                                                               4099.245         
[[36m2025-02-25 11:57:28,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 11:57:28,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/042[0m
[[36m2025-02-25 11:57:28,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 11:57:28,390[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007615317917538199, lr[0m
[[36m2025-02-25 11:57:28,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 11:57:28,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2997290524017179 prior_scale[0m
[[36m2025-02-25 11:57:28,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004382195401082087 q_scale[0m
[[36m2025-02-25 11:57:28,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 11:57:28,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-25 11:57:28,474[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 11:57:28,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 11:57:37,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 11:57:37,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 11:57:37,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 11:57:37,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 11:57:37,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 11:57:37,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 11:57:37,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 11:57:37,574[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 11:57:37,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 11:57:37,591[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 11:57:37,798[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.97it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 38.640 
                                                               rmse/train:      
                                                               34.995           
[[36m2025-02-25 12:01:56,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:01:56,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/043[0m
[[36m2025-02-25 12:01:56,230[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:01:56,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007940523052301803, lr[0m
[[36m2025-02-25 12:01:56,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:01:56,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29819852329246094 prior_scale[0m
[[36m2025-02-25 12:01:56,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018337796577275539 q_scale[0m
[[36m2025-02-25 12:01:56,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:01:56,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-25 12:01:56,386[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:01:56,386[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:02:05,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:02:05,568[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:02:05,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:02:05,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:02:05,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:02:05,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:02:05,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:02:05,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:02:05,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:02:05,615[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:02:05,632[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.92it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 31.515 
                                                               rmse/train:      
                                                               33.388           
[[36m2025-02-25 12:06:25,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:06:25,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/044[0m
[[36m2025-02-25 12:06:25,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:06:25,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004346673644455997, lr[0m
[[36m2025-02-25 12:06:25,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:06:25,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9744952982848707 prior_scale[0m
[[36m2025-02-25 12:06:25,351[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017000949050492947 q_scale[0m
[[36m2025-02-25 12:06:25,370[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:06:25,370[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-25 12:06:25,371[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:06:25,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:06:34,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:06:34,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:06:34,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:06:34,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:06:34,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:06:34,567[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:06:34,567[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:06:34,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:06:34,568[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:06:34,610[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:06:34,621[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.98it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 90.854 
                                                               rmse/train:      
                                                               79.984           
[[36m2025-02-25 12:10:53,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:10:53,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/045[0m
[[36m2025-02-25 12:10:53,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:10:53,314[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005547915996773387, lr[0m
[[36m2025-02-25 12:10:53,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:10:53,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6039419025768079 prior_scale[0m
[[36m2025-02-25 12:10:53,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006966133059950005 q_scale[0m
[[36m2025-02-25 12:10:53,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:10:53,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-25 12:10:53,396[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:10:53,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:11:02,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:11:02,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:11:02,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:11:02,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:11:02,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:11:02,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:11:02,512[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:11:02,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:11:02,513[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:11:02,550[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:11:02,596[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.94it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 30.844 
                                                               rmse/train:      
                                                               27.421           
[[36m2025-02-25 12:15:22,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:15:22,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/046[0m
[[36m2025-02-25 12:15:23,086[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:15:23,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.1375879420384186e-05, lr[0m
[[36m2025-02-25 12:15:23,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:15:23,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3621742694732916 prior_scale[0m
[[36m2025-02-25 12:15:23,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004621627756722631 q_scale[0m
[[36m2025-02-25 12:15:23,210[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:15:23,210[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-25 12:15:23,210[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:15:23,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:15:32,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:15:32,443[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:15:32,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:15:32,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:15:32,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:15:32,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:15:32,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:15:32,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:15:32,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:15:32,526[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:15:32,537[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.34it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2598.175         
                                                               rmse/train:      
                                                               2661.667         
[[36m2025-02-25 12:16:54,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:16:54,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/047[0m
[[36m2025-02-25 12:16:54,526[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:16:54,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008384052381899798, lr[0m
[[36m2025-02-25 12:16:54,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:16:54,616[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08542144783764337 prior_scale[0m
[[36m2025-02-25 12:16:54,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016146632654310278 q_scale[0m
[[36m2025-02-25 12:16:54,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:16:54,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-25 12:16:54,660[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:16:54,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:17:03,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:17:03,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:17:03,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:17:03,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:17:03,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:17:03,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:17:03,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:17:03,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:17:03,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:17:03,867[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:17:04,072[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:05 •       33.71it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 50.186 
                                                               rmse/train:      
                                                               35.760           
[[36m2025-02-25 12:19:35,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:19:35,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/048[0m
[[36m2025-02-25 12:19:35,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:19:35,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006330373057854226, lr[0m
[[36m2025-02-25 12:19:35,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:19:35,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18036732081542833 prior_scale[0m
[[36m2025-02-25 12:19:35,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000887761860037635 q_scale[0m
[[36m2025-02-25 12:19:35,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:19:35,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-25 12:19:35,633[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:19:35,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:19:44,709[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:19:44,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:19:44,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:19:44,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:19:44,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:19:44,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:19:44,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:19:44,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:19:44,719[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:19:44,774[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:19:44,789[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.95it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 43.444 
                                                               rmse/train:      
                                                               38.448           
[[36m2025-02-25 12:24:04,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:24:04,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/049[0m
[[36m2025-02-25 12:24:04,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:24:04,317[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006290102057144817, lr[0m
[[36m2025-02-25 12:24:04,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:24:04,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.193010925093162 prior_scale[0m
[[36m2025-02-25 12:24:04,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029634572562788025 q_scale[0m
[[36m2025-02-25 12:24:04,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:24:04,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-25 12:24:04,398[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:24:04,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:24:13,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:24:13,512[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:24:13,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:24:13,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:24:13,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:24:13,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:24:13,515[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:24:13,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:24:13,516[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:24:13,561[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:24:13,695[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.74it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 39.358 
                                                               rmse/train:      
                                                               31.869           
[[36m2025-02-25 12:28:34,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:28:34,842[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/050[0m
[[36m2025-02-25 12:28:34,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:28:35,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008769255259426099, lr[0m
[[36m2025-02-25 12:28:35,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:28:35,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08932033956168513 prior_scale[0m
[[36m2025-02-25 12:28:35,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021640621136322986 q_scale[0m
[[36m2025-02-25 12:28:35,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-25 12:28:35,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-25 12:28:35,094[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:28:35,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:28:45,030[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:28:45,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:28:45,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:28:45,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:28:45,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:28:45,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:28:45,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:28:45,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:28:45,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:28:45,097[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:28:45,175[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.20it/s v_num: 0.000     
                                                               rmse/val: 173.716
                                                               rmse/train:      
                                                               170.017          
[[36m2025-02-25 12:29:26,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:29:26,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/051[0m
[[36m2025-02-25 12:29:27,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:29:27,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.585553704010568e-05, lr[0m
[[36m2025-02-25 12:29:27,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:29:27,115[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1552775640762928 prior_scale[0m
[[36m2025-02-25 12:29:27,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009611441399406295 q_scale[0m
[[36m2025-02-25 12:29:27,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-25 12:29:27,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-25 12:29:27,171[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:29:27,172[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:29:36,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:29:36,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:29:36,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:29:36,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:29:36,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:29:36,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:29:36,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:29:36,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:29:36,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:29:36,429[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:29:36,469[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.37it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1869.631         
                                                               rmse/train:      
                                                               2000.493         
[[36m2025-02-25 12:30:57,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:30:57,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/052[0m
[[36m2025-02-25 12:30:57,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:30:57,799[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006149970689040431, lr[0m
[[36m2025-02-25 12:30:57,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:30:57,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26512852618136656 prior_scale[0m
[[36m2025-02-25 12:30:57,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000577010115338762 q_scale[0m
[[36m2025-02-25 12:30:57,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:30:57,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-25 12:30:57,903[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:30:57,903[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:31:06,967[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:31:06,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:31:06,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:31:06,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:31:06,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:31:06,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:31:06,976[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:31:06,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:31:06,977[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:31:07,034[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:31:07,088[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.89it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 36.083 
                                                               rmse/train:      
                                                               30.930           
[[36m2025-02-25 12:35:30,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:35:30,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/053[0m
[[36m2025-02-25 12:35:30,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:35:30,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005881574450522152, lr[0m
[[36m2025-02-25 12:35:30,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:35:30,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2591948435707256 prior_scale[0m
[[36m2025-02-25 12:35:30,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000636963617578096 q_scale[0m
[[36m2025-02-25 12:35:30,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:35:30,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-25 12:35:30,752[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:35:30,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:35:39,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:35:39,823[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:35:39,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:35:39,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:35:39,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:35:39,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:35:39,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:35:39,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:35:39,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:35:39,874[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:35:39,924[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.81it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 60.580 
                                                               rmse/train:      
                                                               55.363           
[[36m2025-02-25 12:39:59,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:39:59,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/054[0m
[[36m2025-02-25 12:39:59,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:39:59,708[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046920795808497797, lr[0m
[[36m2025-02-25 12:39:59,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:39:59,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24889977469572572 prior_scale[0m
[[36m2025-02-25 12:39:59,767[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006548994792766683 q_scale[0m
[[36m2025-02-25 12:39:59,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:39:59,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-25 12:39:59,787[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:39:59,787[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:40:08,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:40:08,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:40:08,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:40:08,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:40:08,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:40:08,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:40:08,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:40:08,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:40:08,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:40:09,003[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:40:09,013[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 35.475 
                                                               rmse/train:      
                                                               30.466           
[[36m2025-02-25 12:44:29,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:44:29,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/055[0m
[[36m2025-02-25 12:44:29,681[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:44:29,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000479176835878153, lr[0m
[[36m2025-02-25 12:44:29,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:44:29,749[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2164729112422234 prior_scale[0m
[[36m2025-02-25 12:44:29,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016255787458547795 q_scale[0m
[[36m2025-02-25 12:44:29,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:44:29,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-25 12:44:29,786[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:44:29,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:44:38,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:44:38,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:44:38,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:44:38,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:44:38,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:44:38,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:44:38,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:44:38,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:44:38,892[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:44:38,955[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:44:39,100[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.85it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 39.377 
                                                               rmse/train:      
                                                               34.615           
[[36m2025-02-25 12:48:59,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:48:59,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/056[0m
[[36m2025-02-25 12:48:59,337[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:48:59,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004504664236057951, lr[0m
[[36m2025-02-25 12:48:59,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:48:59,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12649218439890125 prior_scale[0m
[[36m2025-02-25 12:48:59,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07105722818981272 q_scale[0m
[[36m2025-02-25 12:48:59,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:48:59,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-25 12:48:59,559[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:48:59,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:49:08,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:49:08,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:49:08,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:49:08,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:49:08,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:49:08,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:49:08,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:49:08,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:49:08,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:49:08,784[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:49:10,212[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •        17.84it/s v_num: 0.000     
                                    0:00:00                    rmse/val: 179.491
                                                               rmse/train:      
                                                               155.986          
[[36m2025-02-25 12:50:15,631[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 4.
[[36m2025-02-25 12:50:16,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:50:16,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:50:16,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009953935228166127, lr[0m
[[36m2025-02-25 12:50:16,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:50:16,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5217392174673524 prior_scale[0m
[[36m2025-02-25 12:50:16,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005408946508854562 q_scale[0m
[[36m2025-02-25 12:50:16,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:50:16,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-25 12:50:16,295[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:50:16,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:50:25,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:50:25,422[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:50:25,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:50:25,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:50:25,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:50:25,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:50:25,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:50:25,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:50:25,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:50:25,478[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:50:26,963[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:11 •       17.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 29.572 
                                                               rmse/train:      
                                                               29.695           
[[36m2025-02-25 12:54:48,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:54:48,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/058[0m
[[36m2025-02-25 12:54:49,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:54:49,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033056606661663573, lr[0m
[[36m2025-02-25 12:54:49,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 12:54:49,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014818536151051014 prior_scale[0m
[[36m2025-02-25 12:54:49,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037168343417977735 q_scale[0m
[[36m2025-02-25 12:54:49,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-25 12:54:49,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-25 12:54:49,336[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:54:49,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:54:58,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:54:58,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:54:58,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:54:58,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:54:58,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:54:58,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:54:58,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:54:58,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:54:58,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:54:58,536[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:54:59,784[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 198/198 0:00:06 •       33.06it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               2751.579         
                                                               rmse/train:      
                                                               2797.429         
[[36m2025-02-25 12:57:37,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 12:57:37,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/059[0m
[[36m2025-02-25 12:57:37,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 12:57:37,362[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002482679089394269, lr[0m
[[36m2025-02-25 12:57:37,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 12:57:37,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16140767274576168 prior_scale[0m
[[36m2025-02-25 12:57:37,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014998028529645947 q_scale[0m
[[36m2025-02-25 12:57:37,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 12:57:37,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 060 __________________[0m
[[36m2025-02-25 12:57:37,435[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 12:57:37,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 12:57:46,543[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 12:57:46,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 12:57:46,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 12:57:46,551[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 12:57:46,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 12:57:46,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 12:57:46,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 12:57:46,553[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 12:57:46,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 12:57:46,595[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 12:57:47,307[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 16.47it/s v_num: 0.000     
                                                               rmse/val: 41.174 
                                                               rmse/train:      
                                                               36.770           
[[36m2025-02-25 13:00:11,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:00:11,906[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/060[0m
[[36m2025-02-25 13:00:12,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:00:12,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002516412831975507, lr[0m
[[36m2025-02-25 13:00:12,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:00:12,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2904095841242468 prior_scale[0m
[[36m2025-02-25 13:00:12,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014341769538948682 q_scale[0m
[[36m2025-02-25 13:00:12,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:00:12,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 061 __________________[0m
[[36m2025-02-25 13:00:12,162[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:00:12,162[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:00:21,309[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:00:21,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:00:21,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:00:21,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:00:21,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:00:21,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:00:21,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:00:21,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:00:21,320[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:00:21,374[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:00:22,181[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.63it/s v_num: 0.000     
                                                               rmse/val: 44.530 
                                                               rmse/train:      
                                                               36.507           
[[36m2025-02-25 13:02:45,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:02:45,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/061[0m
[[36m2025-02-25 13:02:45,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:02:45,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014612039095042477, lr[0m
[[36m2025-02-25 13:02:45,281[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:02:45,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17364561913386883 prior_scale[0m
[[36m2025-02-25 13:02:45,314[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002484450015659679 q_scale[0m
[[36m2025-02-25 13:02:45,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:02:45,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 062 __________________[0m
[[36m2025-02-25 13:02:45,327[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:02:45,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:02:54,411[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:02:54,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:02:54,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:02:54,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:02:54,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:02:54,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:02:54,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:02:54,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:02:54,422[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:02:54,477[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:02:58,159[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.54it/s v_num: 0.000     
                                                               rmse/val: 45.171 
                                                               rmse/train:      
                                                               41.572           
[[36m2025-02-25 13:05:18,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:05:18,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/062[0m
[[36m2025-02-25 13:05:18,940[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:05:18,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006112237319911698, lr[0m
[[36m2025-02-25 13:05:18,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:05:19,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22656050867842187 prior_scale[0m
[[36m2025-02-25 13:05:19,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000444594528183239 q_scale[0m
[[36m2025-02-25 13:05:19,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:05:19,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 063 __________________[0m
[[36m2025-02-25 13:05:19,110[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:05:19,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:05:28,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:05:28,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:05:28,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:05:28,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:05:28,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:05:28,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:05:28,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:05:28,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:05:28,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:05:28,358[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:05:29,800[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.57it/s v_num: 0.000     
                                                               rmse/val: 44.475 
                                                               rmse/train:      
                                                               41.865           
[[36m2025-02-25 13:07:52,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:07:52,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/063[0m
[[36m2025-02-25 13:07:52,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:07:52,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005329084989890526, lr[0m
[[36m2025-02-25 13:07:52,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:07:52,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2212667333874839 prior_scale[0m
[[36m2025-02-25 13:07:52,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000725736714091057 q_scale[0m
[[36m2025-02-25 13:07:52,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:07:52,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 064 __________________[0m
[[36m2025-02-25 13:07:52,724[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:07:52,724[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:08:01,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:08:01,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:08:01,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:08:01,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:08:01,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:08:01,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:08:01,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:08:01,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:08:01,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:08:01,960[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:08:03,053[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 16.44it/s v_num: 0.000     
                                                               rmse/val: 45.720 
                                                               rmse/train:      
                                                               37.691           
[[36m2025-02-25 13:10:25,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:10:25,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/064[0m
[[36m2025-02-25 13:10:25,770[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:10:25,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005617342933955713, lr[0m
[[36m2025-02-25 13:10:25,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:10:25,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1446985960420336 prior_scale[0m
[[36m2025-02-25 13:10:25,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007371684349194762 q_scale[0m
[[36m2025-02-25 13:10:25,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:10:25,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 065 __________________[0m
[[36m2025-02-25 13:10:25,945[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:10:25,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:10:35,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:10:35,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:10:35,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:10:35,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:10:35,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:10:35,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:10:35,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:10:35,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:10:35,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:10:35,256[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:10:35,755[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.60it/s v_num: 0.000     
                                                               rmse/val: 37.051 
                                                               rmse/train:      
                                                               32.651           
[[36m2025-02-25 13:12:56,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:12:56,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/065[0m
[[36m2025-02-25 13:12:56,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:12:56,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031266853636797304, lr[0m
[[36m2025-02-25 13:12:56,454[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:12:56,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10319184201525437 prior_scale[0m
[[36m2025-02-25 13:12:56,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007439341763389912 q_scale[0m
[[36m2025-02-25 13:12:56,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:12:56,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 066 __________________[0m
[[36m2025-02-25 13:12:56,501[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:12:56,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:13:05,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:13:05,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:13:05,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:13:05,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:13:05,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:13:05,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:13:05,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:13:05,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:13:05,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:13:05,636[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:13:05,939[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 16.50it/s v_num: 0.000     
                                                               rmse/val: 53.950 
                                                               rmse/train:      
                                                               44.749           
[[36m2025-02-25 13:15:26,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:15:26,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/066[0m
[[36m2025-02-25 13:15:26,919[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:15:26,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032233941289796955, lr[0m
[[36m2025-02-25 13:15:26,962[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:15:26,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10327493848803794 prior_scale[0m
[[36m2025-02-25 13:15:26,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045368614665782187 q_scale[0m
[[36m2025-02-25 13:15:27,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:15:27,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 067 __________________[0m
[[36m2025-02-25 13:15:27,012[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:15:27,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:15:36,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:15:36,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:15:36,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:15:36,072[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:15:36,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:15:36,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:15:36,074[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:15:36,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:15:36,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:15:36,125[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:15:36,135[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.52it/s v_num: 0.000     
                                                               rmse/val: 53.437 
                                                               rmse/train:      
                                                               44.456           
[[36m2025-02-25 13:17:57,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:17:57,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/067[0m
[[36m2025-02-25 13:17:57,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:17:57,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023116626974829078, lr[0m
[[36m2025-02-25 13:17:57,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:17:57,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10684746225783721 prior_scale[0m
[[36m2025-02-25 13:17:57,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007301264915899488 q_scale[0m
[[36m2025-02-25 13:17:57,561[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:17:57,561[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 068 __________________[0m
[[36m2025-02-25 13:17:57,561[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:17:57,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:18:06,716[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:18:06,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:18:06,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:18:06,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:18:06,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:18:06,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:18:06,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:18:06,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:18:06,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:18:06,776[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:18:06,796[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.56it/s v_num: 0.000     
                                                               rmse/val: 51.144 
                                                               rmse/train:      
                                                               45.146           
[[36m2025-02-25 13:20:30,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:20:30,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/068[0m
[[36m2025-02-25 13:20:30,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:20:30,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020338036945597227, lr[0m
[[36m2025-02-25 13:20:30,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:20:30,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06696831950609647 prior_scale[0m
[[36m2025-02-25 13:20:30,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041367237001281213 q_scale[0m
[[36m2025-02-25 13:20:30,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:20:30,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 069 __________________[0m
[[36m2025-02-25 13:20:30,212[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:20:30,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:20:39,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:20:39,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:20:39,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:20:39,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:20:39,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:20:39,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:20:39,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:20:39,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:20:39,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:20:39,338[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:20:39,346[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 16.49it/s v_num: 0.000     
                                                               rmse/val: 57.221 
                                                               rmse/train:      
                                                               48.814           
[[36m2025-02-25 13:23:05,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:23:05,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/069[0m
[[36m2025-02-25 13:23:05,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:23:05,202[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00030574145799197605, lr[0m
[[36m2025-02-25 13:23:05,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:23:05,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09807914386623252 prior_scale[0m
[[36m2025-02-25 13:23:05,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004380723830388925 q_scale[0m
[[36m2025-02-25 13:23:05,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:23:05,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 070 __________________[0m
[[36m2025-02-25 13:23:05,286[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:23:05,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:23:14,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:23:14,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:23:14,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:23:14,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:23:14,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:23:14,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:23:14,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:23:14,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:23:14,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:23:14,533[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:23:14,540[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 11/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.58it/s v_num: 0.000     
                                                               rmse/val: 55.189 
                                                               rmse/train:      
                                                               48.312           
[[36m2025-02-25 13:24:38,732[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 11.
[[36m2025-02-25 13:24:39,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:24:39,115[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:24:39,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025636487944607095, lr[0m
[[36m2025-02-25 13:24:39,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:24:39,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12778168109400143 prior_scale[0m
[[36m2025-02-25 13:24:39,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012256660654409398 q_scale[0m
[[36m2025-02-25 13:24:39,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:24:39,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 071 __________________[0m
[[36m2025-02-25 13:24:39,238[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:24:39,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:24:48,406[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:24:48,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:24:48,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:24:48,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:24:48,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:24:48,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:24:48,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:24:48,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:24:48,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:24:48,469[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:24:48,487[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 16.41it/s v_num: 0.000     
                                                               rmse/val: 55.065 
                                                               rmse/train:      
                                                               47.652           
[[36m2025-02-25 13:27:10,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:27:10,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/071[0m
[[36m2025-02-25 13:27:10,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:27:10,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034253305734575966, lr[0m
[[36m2025-02-25 13:27:10,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:27:10,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11057058360008695 prior_scale[0m
[[36m2025-02-25 13:27:10,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013526611362317908 q_scale[0m
[[36m2025-02-25 13:27:10,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:27:10,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 072 __________________[0m
[[36m2025-02-25 13:27:10,997[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:27:10,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:27:20,180[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:27:20,186[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:27:20,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:27:20,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:27:20,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:27:20,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:27:20,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:27:20,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:27:20,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:27:20,239[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:27:20,330[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:05 • 0:00:00 16.60it/s v_num: 0.000     
                                                               rmse/val: 50.089 
                                                               rmse/train:      
                                                               38.438           
[[36m2025-02-25 13:29:40,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:29:40,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/072[0m
[[36m2025-02-25 13:29:40,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:29:40,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017999357876446857, lr[0m
[[36m2025-02-25 13:29:40,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:29:40,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12011638078136157 prior_scale[0m
[[36m2025-02-25 13:29:40,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011881019455953559 q_scale[0m
[[36m2025-02-25 13:29:40,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:29:40,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 073 __________________[0m
[[36m2025-02-25 13:29:40,918[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:29:40,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:29:50,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:29:50,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:29:50,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:29:50,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:29:50,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:29:50,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:29:50,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:29:50,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:29:50,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:29:50,203[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:29:50,324[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.65it/s v_num: 0.000     
                                                               rmse/val: 60.065 
                                                               rmse/train:      
                                                               51.222           
[[36m2025-02-25 13:32:19,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:32:19,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/073[0m
[[36m2025-02-25 13:32:19,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:32:19,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003371727945055252, lr[0m
[[36m2025-02-25 13:32:19,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:32:19,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0813305980279409 prior_scale[0m
[[36m2025-02-25 13:32:19,459[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020285551884818566 q_scale[0m
[[36m2025-02-25 13:32:19,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:32:19,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 074 __________________[0m
[[36m2025-02-25 13:32:19,477[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:32:19,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:32:28,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:32:28,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:32:28,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:32:29,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:32:29,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:32:29,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:32:29,004[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:32:29,004[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:32:29,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:32:29,057[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:32:29,280[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.19it/s v_num: 0.000     
                                                               rmse/val: 52.184 
                                                               rmse/train:      
                                                               46.807           
[[36m2025-02-25 13:35:23,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:35:23,822[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/074[0m
[[36m2025-02-25 13:35:23,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:35:23,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003982713597966943, lr[0m
[[36m2025-02-25 13:35:24,014[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:35:24,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0690103031092565 prior_scale[0m
[[36m2025-02-25 13:35:24,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020159662491373343 q_scale[0m
[[36m2025-02-25 13:35:24,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:35:24,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 075 __________________[0m
[[36m2025-02-25 13:35:24,071[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:35:24,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:35:33,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:35:33,621[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:35:33,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:35:33,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:35:33,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:35:33,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:35:33,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:35:33,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:35:33,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:35:33,683[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:35:34,287[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.75it/s v_num: 0.000     
                                                               rmse/val: 56.828 
                                                               rmse/train:      
                                                               47.820           
[[36m2025-02-25 13:38:21,498[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:38:21,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/075[0m
[[36m2025-02-25 13:38:21,674[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:38:21,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003492419081791508, lr[0m
[[36m2025-02-25 13:38:21,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:38:21,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1419650934730244 prior_scale[0m
[[36m2025-02-25 13:38:21,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013555260976025975 q_scale[0m
[[36m2025-02-25 13:38:21,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:38:21,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 076 __________________[0m
[[36m2025-02-25 13:38:21,807[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:38:21,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:38:31,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:38:31,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:38:31,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:38:31,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:38:31,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:38:31,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:38:31,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:38:31,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:38:31,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:38:31,482[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:38:31,865[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.19it/s v_num: 0.000     
                                                               rmse/val: 38.833 
                                                               rmse/train:      
                                                               34.656           
[[36m2025-02-25 13:41:18,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:41:18,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/076[0m
[[36m2025-02-25 13:41:18,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:41:18,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003427187858186089, lr[0m
[[36m2025-02-25 13:41:18,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:41:18,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14147699282096687 prior_scale[0m
[[36m2025-02-25 13:41:18,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001349612689423686 q_scale[0m
[[36m2025-02-25 13:41:18,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:41:18,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 077 __________________[0m
[[36m2025-02-25 13:41:18,636[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:41:18,636[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:41:28,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:41:28,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:41:28,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:41:28,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:41:28,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:41:28,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:41:28,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:41:28,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:41:28,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:41:28,292[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:41:28,889[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:06 • 0:00:00 14.21it/s v_num: 0.000     
                                                               rmse/val: 45.606 
                                                               rmse/train:      
                                                               40.065           
[[36m2025-02-25 13:44:15,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:44:15,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/077[0m
[[36m2025-02-25 13:44:16,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:44:16,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035515811832816205, lr[0m
[[36m2025-02-25 13:44:16,117[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-25 13:44:16,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08298310373108063 prior_scale[0m
[[36m2025-02-25 13:44:16,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017007457743319746 q_scale[0m
[[36m2025-02-25 13:44:16,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:44:16,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 078 __________________[0m
[[36m2025-02-25 13:44:16,183[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:44:16,183[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:44:25,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:44:25,701[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:44:25,702[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:44:25,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:44:25,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:44:25,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:44:25,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:44:25,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:44:25,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:44:25,757[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:44:26,367[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:07 • 0:00:00 13.90it/s v_num: 0.000     
                                                               rmse/val: 60.739 
                                                               rmse/train:      
                                                               49.833           
[[36m2025-02-25 13:47:16,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:47:16,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/078[0m
[[36m2025-02-25 13:47:17,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:47:17,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000290829664453999, lr[0m
[[36m2025-02-25 13:47:17,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 13:47:17,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14076790324402377 prior_scale[0m
[[36m2025-02-25 13:47:17,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000258743398460186 q_scale[0m
[[36m2025-02-25 13:47:17,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:47:17,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 079 __________________[0m
[[36m2025-02-25 13:47:17,665[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:47:17,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:47:27,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:47:27,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:47:27,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:47:27,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:47:27,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:47:27,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:47:27,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:47:27,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:47:27,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:47:27,477[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:47:40,353[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 • 0:00:00 26.16it/s v_num: 0.000     
                                                               rmse/val: 47.493 
                                                               rmse/train:      
                                                               41.951           
[[36m2025-02-25 13:49:17,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:49:17,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/079[0m
[[36m2025-02-25 13:49:17,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:49:17,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041434390682968005, lr[0m
[[36m2025-02-25 13:49:17,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 13:49:17,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1427423132374321 prior_scale[0m
[[36m2025-02-25 13:49:17,500[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002489919576897951 q_scale[0m
[[36m2025-02-25 13:49:17,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:49:17,513[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 080 __________________[0m
[[36m2025-02-25 13:49:17,513[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:49:17,513[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:49:27,114[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:49:27,120[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:49:27,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:49:27,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:49:27,124[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:49:27,124[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:49:27,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:49:27,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:49:27,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:49:27,188[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:49:28,679[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 • 0:00:00 27.27it/s v_num: 0.000     
                                                               rmse/val: 50.488 
                                                               rmse/train:      
                                                               37.889           
[[36m2025-02-25 13:51:05,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:51:05,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/080[0m
[[36m2025-02-25 13:51:05,516[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:51:05,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028049313586589366, lr[0m
[[36m2025-02-25 13:51:05,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 13:51:05,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.042923249866200816 prior_scale[0m
[[36m2025-02-25 13:51:05,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002857122359359686 q_scale[0m
[[36m2025-02-25 13:51:05,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:51:05,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 081 __________________[0m
[[36m2025-02-25 13:51:05,699[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:51:05,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:51:15,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:51:15,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:51:15,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:51:15,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:51:15,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:51:15,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:51:15,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:51:15,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:51:15,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:51:15,377[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:51:17,799[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 • 0:00:00 26.73it/s v_num: 0.000     
                                                               rmse/val: 52.768 
                                                               rmse/train:      
                                                               45.937           
[[36m2025-02-25 13:52:54,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:52:54,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/081[0m
[[36m2025-02-25 13:52:54,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:52:54,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005343251405187812, lr[0m
[[36m2025-02-25 13:52:54,951[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 13:52:54,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21251938015643568 prior_scale[0m
[[36m2025-02-25 13:52:54,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021907339916724436 q_scale[0m
[[36m2025-02-25 13:52:55,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:52:55,007[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 082 __________________[0m
[[36m2025-02-25 13:52:55,008[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:52:55,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:53:04,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:53:04,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:53:04,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:53:04,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:53:04,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:53:04,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:53:04,632[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:53:04,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:53:04,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:53:04,673[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:53:05,441[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 • 0:00:00 26.69it/s v_num: 0.000     
                                                               rmse/val: 39.710 
                                                               rmse/train:      
                                                               31.749           
[[36m2025-02-25 13:54:43,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:54:43,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/082[0m
[[36m2025-02-25 13:54:44,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-25 13:54:44,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004733634912280229, lr[0m
[[36m2025-02-25 13:54:44,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-25 13:54:44,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20910268495933063 prior_scale[0m
[[36m2025-02-25 13:54:44,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002134022862276677 q_scale[0m
[[36m2025-02-25 13:54:44,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-25 13:54:44,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 083 __________________[0m
[[36m2025-02-25 13:54:44,187[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-25 13:54:44,187[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-25 13:54:53,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-25 13:54:53,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-25 13:54:53,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-25 13:54:53,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-25 13:54:53,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-25 13:54:53,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-25 13:54:53,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-25 13:54:53,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-25 13:54:53,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-25 13:54:53,839[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-25 13:54:54,235[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 99/99 0:00:03 • 0:00:00 26.11it/s v_num: 0.000     
                                                               rmse/val: 38.545 
                                                               rmse/train:      
                                                               33.216           
[[36m2025-02-25 13:56:30,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-25 13:56:30,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/lrt_hps_100perc/runs/2025-02-25_11-00-37/083[0m
[[36m2025-02-25 13:56:30,526[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 84[0m
