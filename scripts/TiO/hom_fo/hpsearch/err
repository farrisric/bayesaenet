/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2025-05-09 16:38:47,611] A new study created in RDB with name: hom_fo_100perc_big
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (49) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-09 17:26:21,826] Trial 0 finished with value: 663413440.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.4156772025296228e-05, 'mc_samples_train': 1, 'prior_scale': 0.22702608040701588, 'q_scale': 0.13179630432958683, 'obs_scale': 0.0012313185468743894, 'batch_size': 128}. Best is trial 0 with value: 663413440.0.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-09 18:43:39,418] Trial 1 finished with value: 81355.53125 and parameters: {'pretrain_epochs': 0, 'lr': 0.00010045932391231576, 'mc_samples_train': 2, 'prior_scale': 0.012904829303853454, 'q_scale': 0.017570525244134657, 'obs_scale': 0.010288040405240286, 'batch_size': 128}. Best is trial 1 with value: 81355.53125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-09 20:22:43,870] Trial 2 finished with value: 62.74943542480469 and parameters: {'pretrain_epochs': 0, 'lr': 1.4150196905720475e-05, 'mc_samples_train': 2, 'prior_scale': 0.08997760513084464, 'q_scale': 0.0038798086852341396, 'obs_scale': 0.14286326515987452, 'batch_size': 128}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 00:55:13,974] Trial 3 finished with value: 3456227.75 and parameters: {'pretrain_epochs': 0, 'lr': 1.9388028480984598e-05, 'mc_samples_train': 2, 'prior_scale': 0.004532901866195528, 'q_scale': 0.5005765657505178, 'obs_scale': 0.005868985298319507, 'batch_size': 32}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 01:18:21,640] Trial 4 finished with value: 70023.75 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001546142648648772, 'mc_samples_train': 1, 'prior_scale': 0.04833917568085432, 'q_scale': 0.0020829257190366937, 'obs_scale': 0.010277023093936914, 'batch_size': 512}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 05:11:23,457] Trial 5 finished with value: 81648.4296875 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006671842305866796, 'mc_samples_train': 2, 'prior_scale': 0.7523246408184491, 'q_scale': 0.14718262393979, 'obs_scale': 0.001383578612730786, 'batch_size': 32}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
[I 2025-05-10 05:12:43,193] Trial 6 pruned. Trial was pruned at epoch 70.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 05:48:54,906] Trial 7 finished with value: 830.5249633789062 and parameters: {'pretrain_epochs': 0, 'lr': 0.00011795146111975982, 'mc_samples_train': 2, 'prior_scale': 0.020449350394769326, 'q_scale': 0.028092862158076635, 'obs_scale': 0.470752138441911, 'batch_size': 512}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 06:21:19,617] Trial 8 finished with value: 138.93426513671875 and parameters: {'pretrain_epochs': 0, 'lr': 0.00018511923116382368, 'mc_samples_train': 1, 'prior_scale': 0.0507257930731161, 'q_scale': 0.012968719897940156, 'obs_scale': 0.6393152366775274, 'batch_size': 256}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 06:45:58,926] Trial 9 finished with value: 688.1807250976562 and parameters: {'pretrain_epochs': 0, 'lr': 0.00021819434272647882, 'mc_samples_train': 1, 'prior_scale': 0.24581113447438505, 'q_scale': 0.0170232827909058, 'obs_scale': 0.730039111673774, 'batch_size': 512}. Best is trial 2 with value: 62.74943542480469.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 07:59:06,242] Trial 10 finished with value: -123.30404663085938 and parameters: {'pretrain_epochs': 0, 'lr': 1.1267228743583923e-05, 'mc_samples_train': 2, 'prior_scale': 0.1438501886620343, 'q_scale': 0.0001361190166330691, 'obs_scale': 0.12508757174951737, 'batch_size': 128}. Best is trial 10 with value: -123.30404663085938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 09:14:40,233] Trial 11 finished with value: -138.06358337402344 and parameters: {'pretrain_epochs': 0, 'lr': 1.0962454827051684e-05, 'mc_samples_train': 2, 'prior_scale': 0.13160546287420333, 'q_scale': 0.00011306332444916999, 'obs_scale': 0.10193657033086194, 'batch_size': 128}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 11:33:23,254] Trial 12 finished with value: -87.86770629882812 and parameters: {'pretrain_epochs': 0, 'lr': 1.0170394077008131e-05, 'mc_samples_train': 2, 'prior_scale': 0.2238470043565636, 'q_scale': 0.00012780894352276231, 'obs_scale': 0.07946981200360269, 'batch_size': 64}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 12:57:05,785] Trial 13 finished with value: -105.39824676513672 and parameters: {'pretrain_epochs': 0, 'lr': 3.426915319227129e-05, 'mc_samples_train': 2, 'prior_scale': 0.9713491325966092, 'q_scale': 0.00011989003863340673, 'obs_scale': 0.07411551140013035, 'batch_size': 128}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-10 13:03:28,963] Trial 14 pruned. Trial was pruned at epoch 162.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 15:31:53,383] Trial 15 finished with value: -24.550382614135742 and parameters: {'pretrain_epochs': 0, 'lr': 1.0003499066452017e-05, 'mc_samples_train': 2, 'prior_scale': 0.14028905483022555, 'q_scale': 0.0005351337564036122, 'obs_scale': 0.24770840369488722, 'batch_size': 64}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 16:46:29,612] Trial 16 finished with value: 28.123003005981445 and parameters: {'pretrain_epochs': 0, 'lr': 4.884207813495069e-05, 'mc_samples_train': 2, 'prior_scale': 0.3785957853752036, 'q_scale': 0.0005845252980016993, 'obs_scale': 0.03804737433257131, 'batch_size': 128}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 18:11:22,369] Trial 17 finished with value: -69.84593963623047 and parameters: {'pretrain_epochs': 0, 'lr': 0.00038765931042035386, 'mc_samples_train': 2, 'prior_scale': 0.008493997374806427, 'q_scale': 0.0003042216712035023, 'obs_scale': 0.19048442316907535, 'batch_size': 128}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-10 18:21:54,838] Trial 18 pruned. Trial was pruned at epoch 256.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-10 18:27:02,177] Trial 19 pruned. Trial was pruned at epoch 196.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-10 18:36:18,019] Trial 20 pruned. Trial was pruned at epoch 115.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 19:53:29,786] Trial 21 finished with value: -42.04897689819336 and parameters: {'pretrain_epochs': 0, 'lr': 3.150272026579049e-05, 'mc_samples_train': 2, 'prior_scale': 0.9791127554202472, 'q_scale': 0.00011919655598830542, 'obs_scale': 0.07772371106349622, 'batch_size': 128}. Best is trial 11 with value: -138.06358337402344.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 21:08:38,815] Trial 22 finished with value: -147.96478271484375 and parameters: {'pretrain_epochs': 0, 'lr': 1.2230136160876792e-05, 'mc_samples_train': 2, 'prior_scale': 0.5007042061707683, 'q_scale': 0.00010712140178925502, 'obs_scale': 0.08079292187302518, 'batch_size': 128}. Best is trial 22 with value: -147.96478271484375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-10 22:25:55,613] Trial 23 finished with value: -20.206743240356445 and parameters: {'pretrain_epochs': 0, 'lr': 1.5064038598266075e-05, 'mc_samples_train': 2, 'prior_scale': 0.44683213860659293, 'q_scale': 0.0003170814394844082, 'obs_scale': 0.31750378081523195, 'batch_size': 128}. Best is trial 22 with value: -147.96478271484375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-10 22:37:41,884] Trial 24 pruned. Trial was pruned at epoch 303.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 00:49:12,040] Trial 25 pruned. Trial was pruned at epoch 1002.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 01:01:19,446] Trial 26 pruned. Trial was pruned at epoch 455.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 01:36:45,547] Trial 27 pruned. Trial was pruned at epoch 765.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 03:18:29,068] Trial 28 finished with value: -44.189693450927734 and parameters: {'pretrain_epochs': 0, 'lr': 2.6055430551346895e-05, 'mc_samples_train': 2, 'prior_scale': 0.624151898191203, 'q_scale': 0.0009053287528280265, 'obs_scale': 0.05340367685897512, 'batch_size': 128}. Best is trial 22 with value: -147.96478271484375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 03:51:57,725] Trial 29 pruned. Trial was pruned at epoch 1089.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 05:41:10,406] Trial 30 pruned. Trial was pruned at epoch 623.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 07:12:52,915] Trial 31 finished with value: -100.81377410888672 and parameters: {'pretrain_epochs': 0, 'lr': 3.942574900920979e-05, 'mc_samples_train': 2, 'prior_scale': 0.9334058722134129, 'q_scale': 0.0001667578874582909, 'obs_scale': 0.09592406122571859, 'batch_size': 128}. Best is trial 22 with value: -147.96478271484375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 08:58:46,720] Trial 32 finished with value: -181.36798095703125 and parameters: {'pretrain_epochs': 0, 'lr': 2.7337603911610372e-05, 'mc_samples_train': 2, 'prior_scale': 0.3031527881404457, 'q_scale': 0.0001109833280880666, 'obs_scale': 0.04872290745712348, 'batch_size': 128}. Best is trial 32 with value: -181.36798095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 09:14:05,975] Trial 33 pruned. Trial was pruned at epoch 293.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 09:35:31,901] Trial 34 pruned. Trial was pruned at epoch 441.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 09:36:04,792] Trial 35 pruned. Trial was pruned at epoch 8.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 10:23:59,642] Trial 36 finished with value: -629.23095703125 and parameters: {'pretrain_epochs': 0, 'lr': 2.3959944346130677e-05, 'mc_samples_train': 2, 'prior_scale': 0.05964167723490831, 'q_scale': 0.00010531435235600597, 'obs_scale': 0.1327402514309527, 'batch_size': 512}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 10:24:19,638] Trial 37 pruned. Trial was pruned at epoch 6.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 10:24:35,662] Trial 38 pruned. Trial was pruned at epoch 6.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 10:25:41,088] Trial 39 pruned. Trial was pruned at epoch 37.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 10:25:56,267] Trial 40 pruned. Trial was pruned at epoch 5.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 11:09:45,315] Trial 41 pruned. Trial was pruned at epoch 1274.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 11:40:56,852] Trial 42 pruned. Trial was pruned at epoch 1228.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 14:31:21,060] Trial 43 pruned. Trial was pruned at epoch 1045.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 16:38:26,370] Trial 44 pruned. Trial was pruned at epoch 1558.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 16:59:45,055] Trial 45 pruned. Trial was pruned at epoch 459.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 17:39:41,458] Trial 46 pruned. Trial was pruned at epoch 1455.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 18:24:03,213] Trial 47 finished with value: -326.8916931152344 and parameters: {'pretrain_epochs': 0, 'lr': 2.164419093975255e-05, 'mc_samples_train': 2, 'prior_scale': 0.281879254402923, 'q_scale': 0.00010146772211960182, 'obs_scale': 0.23595083683444867, 'batch_size': 512}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 18:33:25,499] Trial 48 pruned. Trial was pruned at epoch 502.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 18:39:53,692] Trial 49 pruned. Trial was pruned at epoch 508.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 18:41:24,264] Trial 50 pruned. Trial was pruned at epoch 71.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 19:02:53,031] Trial 51 pruned. Trial was pruned at epoch 1089.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 20:27:52,642] Trial 52 finished with value: -181.97064208984375 and parameters: {'pretrain_epochs': 0, 'lr': 3.024714385136114e-05, 'mc_samples_train': 2, 'prior_scale': 0.07633547613316682, 'q_scale': 0.00014740731408226067, 'obs_scale': 0.06142946953889074, 'batch_size': 128}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-11 21:48:43,025] Trial 53 finished with value: -163.0047149658203 and parameters: {'pretrain_epochs': 0, 'lr': 2.9867425279977498e-05, 'mc_samples_train': 2, 'prior_scale': 0.08323393814041379, 'q_scale': 0.0002589147384722913, 'obs_scale': 0.06773175673743885, 'batch_size': 128}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-11 21:58:08,164] Trial 54 pruned. Trial was pruned at epoch 229.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-12 00:42:19,502] Trial 55 finished with value: -67.86639404296875 and parameters: {'pretrain_epochs': 0, 'lr': 3.0881546260946814e-05, 'mc_samples_train': 2, 'prior_scale': 0.022491961778318303, 'q_scale': 0.00015509750314345592, 'obs_scale': 0.05956236418361246, 'batch_size': 64}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-12 00:58:54,552] Trial 56 pruned. Trial was pruned at epoch 680.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=2000` reached.
[I 2025-05-12 02:42:20,195] Trial 57 finished with value: -153.4126434326172 and parameters: {'pretrain_epochs': 0, 'lr': 4.8950717921106526e-05, 'mc_samples_train': 2, 'prior_scale': 0.018357090406805707, 'q_scale': 0.0001349239432150638, 'obs_scale': 0.08625194378467628, 'batch_size': 128}. Best is trial 36 with value: -629.23095703125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-12 04:58:36,514] Trial 58 pruned. Trial was pruned at epoch 851.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2025-05-12 05:39:23,873] Trial 59 pruned. Trial was pruned at epoch 850.
