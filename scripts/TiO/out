[[36m2024-07-08 11:23:53,200[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:23:53,200[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:23:54,992[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.NN>[0m
[[36m2024-07-08 11:23:55,038[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:23:55,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:23:55,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2024-07-08 11:23:55,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:23:55,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:23:55,048[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:23:55,048[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:23:55,163[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:23:55,441[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:23:58,325[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/4  ━━━━━━━━━━━━━━━━━━━━━━━ 8/8 0:00:00 • 0:00:00 181.96it/s v_num: 0.000
[[36m2024-07-08 11:24:14,595[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         mse/test          │     9.316991806030273     │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s 
[[36m2024-07-08 11:24:14,611[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: /home/g15farris/bin/forks/bayesaenet/src/logs/pretrain/runs/2024-07-08_11-23-53/checkpoints/epoch_4-step_40.ckpt[0m
[[36m2024-07-08 11:24:14,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:24:14,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/pretrain/runs/2024-07-08_11-23-53[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-08 11:30:14,932[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-08 11:30:15,048[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-08 11:30:15,083[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-08 11:42:55,565[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-07-08 11:42:56,136[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-08 11:42:56,141[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-08 11:42:56,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:42:56,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-08 11:42:56,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 1[[36m2024-07-08 11:43:08,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:43:08,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-08 11:43:08,841[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:08,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-08 11:43:08,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-08 11:43:08,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-08 11:43:08,895[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:43:08,895[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-07-08 11:43:08,896[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:08,896[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-07-08 11:43:09,111[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-08 11:43:09,116[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-08 11:43:09,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:43:09,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-08 11:43:09,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:09,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-08 11:43:09,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-08 11:43:09,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-08 11:43:09,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:43:09,263[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-07-08 11:43:09,263[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:09,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:10,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:10,194[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:10,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:10,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:10,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:10,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:10,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:10,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:10,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:10,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:10,281[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:10,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:10,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:10,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:10,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:10,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:10,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:10,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:10,468[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:10,605[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:10,667[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:43:10,671[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
[[36m2024-07-08 11:43:10,709[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:43:10,713[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/000[0m
[[36m2024-07-08 11:43:19,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:19,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-07-08 11:43:19,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:19,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-07-08 11:43:19,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-07-08 11:43:19,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-07-08 11:43:19,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:43:19,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-07-08 11:43:19,871[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:19,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:20,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:20,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:20,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:20,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:21,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:21,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:21,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:21,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:21,002[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:21,031[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:21,044[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 18.68it/s v_num: 0.000
[[36m2024-07-08 11:43:26,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:26,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/001[0m
[[36m2024-07-08 11:43:26,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:43:26,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-07-08 11:43:26,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:43:26,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-07-08 11:43:26,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-07-08 11:43:26,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-07-08 11:43:26,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:43:26,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-07-08 11:43:26,788[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:26,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:27,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:27,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:27,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:27,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:27,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:27,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:27,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:27,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:27,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:27,825[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:27,836[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:43:27,837[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:31,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/001[0m
[[36m2024-07-08 11:43:31,658[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:31,670[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-07-08 11:43:31,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:31,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-07-08 11:43:31,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-07-08 11:43:31,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-07-08 11:43:31,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:43:31,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-07-08 11:43:31,728[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:31,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:32,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:32,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:32,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:32,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:32,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:32,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:32,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:32,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:32,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:32,753[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:32,780[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 9.43it/s v_num: 0.000
[[36m2024-07-08 11:43:37,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:37,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/002[0m
[[36m2024-07-08 11:43:37,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:37,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-08 11:43:37,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:43:37,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-08 11:43:37,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-08 11:43:37,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-08 11:43:37,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:43:37,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-07-08 11:43:37,387[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:37,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:38,411[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:38,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:38,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:38,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:38,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:38,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:38,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:38,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:38,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:38,436[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:38,452[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
      
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 22.72it/s v_num: 0.000
[[36m2024-07-08 11:43:37,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:37,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/002[0m
[[36m2024-07-08 11:43:38,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:43:38,023[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-07-08 11:43:38,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:43:38,052[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-07-08 11:43:38,067[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-07-08 11:43:38,081[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-07-08 11:43:38,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:43:38,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-07-08 11:43:38,096[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:38,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:39,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:39,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:39,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:39,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:39,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:39,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:39,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:39,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:39,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:39,248[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:39,269[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:43:39,270[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 18.02it/s v_num: 0.000
[[36m2024-07-08 11:43:41,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:41,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/002[0m
[[36m2024-07-08 11:43:41,807[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:41,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-08 11:43:41,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:43:41,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-08 11:43:41,853[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-08 11:43:41,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-08 11:43:41,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:43:41,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-07-08 11:43:41,879[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:41,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:43,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:43,007[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:43,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:43,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:43,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:43,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:43,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:43,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:43,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:43,023[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:43,032[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 11.83it/s v_num: 0.000
[[36m2024-07-08 11:43:47,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:47,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/003[0m
[[36m2024-07-08 11:43:47,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:47,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-08 11:43:47,337[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:43:47,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-08 11:43:47,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-08 11:43:47,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-08 11:43:47,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:43:47,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-07-08 11:43:47,383[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:47,383[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:48,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:48,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:48,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:48,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:48,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:48,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:48,439[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:48,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:48,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:48,453[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:48,465[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 15.27it/s v_num: 0.000
[[36m2024-07-08 11:43:48,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:48,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/003[0m
[[36m2024-07-08 11:43:48,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:48,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-07-08 11:43:48,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:48,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-07-08 11:43:48,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-07-08 11:43:48,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-07-08 11:43:48,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:43:48,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-07-08 11:43:48,669[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:48,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:49,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:49,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:49,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:49,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:49,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:49,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:49,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:49,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:49,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:49,671[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:49,681[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 9.60it/s v_num: 0.000
[[36m2024-07-08 11:43:55,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:43:55,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/004[0m
[[36m2024-07-08 11:43:55,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:43:55,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-07-08 11:43:55,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:43:55,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-07-08 11:43:55,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-07-08 11:43:55,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-07-08 11:43:55,526[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:43:55,526[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-07-08 11:43:55,526[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:43:55,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:43:56,513[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:43:56,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:43:56,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:43:56,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:43:56,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:43:56,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:43:56,523[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:43:56,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:43:56,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:43:56,537[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:43:56,549[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 30.70it/s v_num: 0.000
[[36m2024-07-08 11:44:00,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:00,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/004[0m
[[36m2024-07-08 11:44:00,248[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:00,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-07-08 11:44:00,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:44:00,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-07-08 11:44:00,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-07-08 11:44:00,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-07-08 11:44:00,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:44:00,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-07-08 11:44:00,317[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:00,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:01,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:01,567[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:01,567[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:01,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:01,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:01,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:01,571[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:01,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:01,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:01,598[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:01,607[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:01,608[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 38.23it/s v_num: 0.000
[[36m2024-07-08 11:44:06,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:06,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/005[0m
[[36m2024-07-08 11:44:06,572[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:06,583[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-07-08 11:44:06,594[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:44:06,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-07-08 11:44:06,621[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-07-08 11:44:06,636[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-07-08 11:44:06,649[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:06,650[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-07-08 11:44:06,650[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:06,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:07,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:07,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:07,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:07,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:07,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:07,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:07,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:07,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:07,758[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:07,785[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:07,795[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:07,796[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 23.91it/s v_num: 0.000
[[36m2024-07-08 11:44:09,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:09,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/005[0m
[[36m2024-07-08 11:44:09,616[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:09,629[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-07-08 11:44:09,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:44:09,654[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-07-08 11:44:09,667[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-07-08 11:44:09,679[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-07-08 11:44:09,692[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:09,692[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-07-08 11:44:09,693[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:09,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:10,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:10,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:10,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:10,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:10,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:10,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:10,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:10,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:10,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:10,767[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[3m2024-07-08 11:44:09,524[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:09,527[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 28.78it/s v_num: 0.000
[[36m2024-07-08 11:44:16,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:16,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/006[0m
[[36m2024-07-08 11:44:16,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:16,535[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-07-08 11:44:16,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:44:16,558[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-07-08 11:44:16,569[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-07-08 11:44:16,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-07-08 11:44:16,593[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:16,593[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-07-08 11:44:16,593[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:16,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:17,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:17,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:17,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:17,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:17,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:17,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:17,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:17,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:17,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:17,608[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:17,620[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:17,621[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 16.61it/s v_num: 0.000
[[36m2024-07-08 11:44:30,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:30,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/006[0m
[[36m2024-07-08 11:44:31,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:44:31,077[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-07-08 11:44:31,089[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:44:31,100[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-07-08 11:44:31,112[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-07-08 11:44:31,125[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-07-08 11:44:31,136[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:44:31,137[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-07-08 11:44:31,137[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:31,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:32,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:32,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:32,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:32,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:32,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:32,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:32,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:32,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:32,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:32,257[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:32,266[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 18.06it/s v_num: 0.000
[[36m2024-07-08 11:44:31,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:31,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/007[0m
[[36m2024-07-08 11:44:31,376[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:44:31,387[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-07-08 11:44:31,398[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:44:31,409[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-07-08 11:44:31,420[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-07-08 11:44:31,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-07-08 11:44:31,440[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:31,440[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-07-08 11:44:31,441[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:31,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:32,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:32,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:32,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:32,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:32,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:32,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:32,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:32,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:32,433[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:32,446[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:32,457[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 9.93it/s v_num: 0.000
[[36m2024-07-08 11:44:41,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:41,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/007[0m
[[36m2024-07-08 11:44:41,426[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:44:41,437[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-07-08 11:44:41,450[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:44:41,464[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-07-08 11:44:41,479[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-07-08 11:44:41,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-07-08 11:44:41,507[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:41,507[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-07-08 11:44:41,508[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:41,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:42,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:42,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:42,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:42,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:42,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:42,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:42,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:42,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:42,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:42,606[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:42,631[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           �om    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 42.05it/s v_num: 0.000
[[36m2024-07-08 11:44:42,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:42,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/008[0m
[[36m2024-07-08 11:44:42,733[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:42,745[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-07-08 11:44:42,755[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:44:42,766[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-07-08 11:44:42,777[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-07-08 11:44:42,788[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-07-08 11:44:42,799[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:44:42,799[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-07-08 11:44:42,799[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:42,800[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:43,786[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:43,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:43,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:43,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:43,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:43,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:43,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:43,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:43,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:43,826[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:43,833[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:43,834[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.35it/s v_num: 0.000
[[36m2024-07-08 11:44:45,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:45,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/008[0m
[[36m2024-07-08 11:44:45,424[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:44:45,436[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-07-08 11:44:45,449[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:44:45,460[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-07-08 11:44:45,472[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-07-08 11:44:45,484[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-07-08 11:44:45,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:44:45,497[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-07-08 11:44:45,497[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:45,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:46,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:46,478[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:46,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:46,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:46,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:46,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:46,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:46,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:46,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:46,512[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:46,525[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 21.00it/s v_num: 0.000
[[36m2024-07-08 11:44:52,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:44:52,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/009[0m
[[36m2024-07-08 11:44:52,461[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:44:52,482[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028711032739869613, lr[0m
[[36m2024-07-08 11:44:52,497[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:44:52,517[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014937976642598423 prior_scale[0m
[[36m2024-07-08 11:44:52,538[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532753257812993 q_scale[0m
[[36m2024-07-08 11:44:52,558[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-07-08 11:44:52,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:44:52,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-07-08 11:44:52,574[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:44:52,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:44:53,613[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:44:53,618[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:44:53,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:44:53,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:44:53,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:44:53,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:44:53,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:44:53,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:44:53,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:44:53,636[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:44:53,753[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:44:53,754[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                 
      Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.79it/s v_num: 0.000
[[36m2024-07-08 11:45:08,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:08,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/009[0m
[[36m2024-07-08 11:45:08,189[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:08,210[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028711032739869613, lr[0m
[[36m2024-07-08 11:45:08,223[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:08,237[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014937976642598423 prior_scale[0m
[[36m2024-07-08 11:45:08,251[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532753257812993 q_scale[0m
[[36m2024-07-08 11:45:08,267[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-07-08 11:45:08,282[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:08,282[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-07-08 11:45:08,283[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:08,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:09,344[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:09,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:09,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:09,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:09,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:09,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:09,353[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:09,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:09,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:09,382[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:09,393[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:09,394[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
h 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.56it/s v_num: 0.000
[[36m2024-07-08 11:45:09,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:09,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/010[0m
[[36m2024-07-08 11:45:09,686[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:09,702[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028711032739869613, lr[0m
[[36m2024-07-08 11:45:09,715[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:09,730[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014937976642598423 prior_scale[0m
[[36m2024-07-08 11:45:09,745[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532753257812993 q_scale[0m
[[36m2024-07-08 11:45:09,760[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-07-08 11:45:09,773[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:09,773[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-07-08 11:45:09,773[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:09,773[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 43.76it/s v_num: 0.000
[[36m2024-07-08 11:45:10,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:10,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/010[0m
[[36m2024-07-08 11:45:10,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:10,437[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003871157455553778, lr[0m
[[36m2024-07-08 11:45:10,448[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:10,462[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014489987071262374 prior_scale[0m
[[36m2024-07-08 11:45:10,476[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010860093339103685 q_scale[0m
[[36m2024-07-08 11:45:10,490[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-07-08 11:45:10,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:10,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-07-08 11:45:10,502[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:10,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:10,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:10,758[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:10,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:10,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:10,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:10,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:10,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:10,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:10,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:10,778[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:10,790[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:10,791[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:11,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:11,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:11,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:11,581[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:11,581[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:11,581[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:11,582[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:11,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:11,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:11,597[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:11,611[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:11,612[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.10it/s v_num: 0.000
[[36m2024-07-08 11:45:29,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:29,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/010[0m
[[36m2024-07-08 11:45:29,210[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:29,224[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003871157455553778, lr[0m
[[36m2024-07-08 11:45:29,237[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:29,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014489987071262374 prior_scale[0m
[[36m2024-07-08 11:45:29,267[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010860093339103685 q_scale[0m
[[36m2024-07-08 11:45:29,282[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-07-08 11:45:29,292[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:29,292[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-07-08 11:45:29,292[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:29,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:30,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:30,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:30,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:30,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:30,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:30,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:30,273[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:30,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:30,273[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:30,286[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:30,296[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:30,297[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:30,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:30,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:30,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:30,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:30,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:30,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:30,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:30,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:30,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:30,351[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:30,383[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:30,384[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 34.78it/s v_num: 0.000
[[36m2024-07-08 11:45:49,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:49,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/011[0m
[[36m2024-07-08 11:45:49,630[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:49,644[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003796759473565572, lr[0m
[[36m2024-07-08 11:45:49,656[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:49,670[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014959205297763659 prior_scale[0m
[[36m2024-07-08 11:45:49,683[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010181693721223134 q_scale[0m
[[36m2024-07-08 11:45:49,697[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.9328425480641904 obs_scale[0m
[[36m2024-07-08 11:45:49,708[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:49,708[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-07-08 11:45:49,708[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:49,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:50,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:50,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:50,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:50,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:50,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:50,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:50,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:50,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:50,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:50,715[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:50,745[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:50,746[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.48it/s v_num: 0.000
[[36m2024-07-08 11:45:49,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:45:49,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/012[0m
[[36m2024-07-08 11:45:49,684[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:45:49,706[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003796759473565572, lr[0m
[[36m2024-07-08 11:45:49,723[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:45:49,745[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014959205297763659 prior_scale[0m
[[36m2024-07-08 11:45:49,767[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010181693721223134 q_scale[0m
[[36m2024-07-08 11:45:49,788[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.9328425480641904 obs_scale[0m
[[36m2024-07-08 11:45:49,804[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:45:49,804[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-07-08 11:45:49,804[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:45:49,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:45:50,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:45:50,907[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:45:50,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:45:50,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:45:50,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:45:50,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:45:50,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:45:50,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:45:50,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:45:50,925[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:45:50,936[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:45:50,937[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.25it/s v_num: 0.000
[[36m2024-07-08 11:46:09,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:09,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/012[0m
[[36m2024-07-08 11:46:10,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:10,364[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004805364291548028, lr[0m
[[36m2024-07-08 11:46:10,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:10,390[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010482874946722998 prior_scale[0m
[[36m2024-07-08 11:46:10,404[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532990129819251 q_scale[0m
[[36m2024-07-08 11:46:10,416[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.8557399609740814 obs_scale[0m
[[36m2024-07-08 11:46:10,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:10,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-07-08 11:46:10,430[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:10,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:11,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:11,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:11,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:11,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:11,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:11,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:11,400[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:11,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:11,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:11,424[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:11,440[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:11,441[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
 
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.04it/s v_num: 0.000
[[36m2024-07-08 11:46:10,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:10,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/013[0m
[[36m2024-07-08 11:46:10,645[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:10,665[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004805364291548028, lr[0m
[[36m2024-07-08 11:46:10,680[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:10,699[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010482874946722998 prior_scale[0m
[[36m2024-07-08 11:46:10,717[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532990129819251 q_scale[0m
[[36m2024-07-08 11:46:10,736[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.8557399609740814 obs_scale[0m
[[36m2024-07-08 11:46:10,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:10,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-07-08 11:46:10,751[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:10,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:11,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:11,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:11,802[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:11,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:11,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:11,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:11,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:11,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:11,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:11,837[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:11,874[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:11,876[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 41.62it/s v_num: 0.000
[[36m2024-07-08 11:46:23,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:23,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/014[0m
[[36m2024-07-08 11:46:23,569[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:23,590[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005127255173196106, lr[0m
[[36m2024-07-08 11:46:23,603[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:23,620[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.032326627210685015 prior_scale[0m
[[36m2024-07-08 11:46:23,637[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002676064292032696 q_scale[0m
[[36m2024-07-08 11:46:23,654[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7267193329726757 obs_scale[0m
[[36m2024-07-08 11:46:23,667[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:23,668[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-07-08 11:46:23,668[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:23,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:24,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:24,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:24,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:24,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:24,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:24,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:24,709[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:24,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:24,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:24,725[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:24,737[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:24,738[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 32.13it/s v_num: 0.000
[[36m2024-07-08 11:46:30,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:30,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/013[0m
[[36m2024-07-08 11:46:31,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:31,097[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042697878418142905, lr[0m
[[36m2024-07-08 11:46:31,113[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:31,134[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.025598098635809526 prior_scale[0m
[[36m2024-07-08 11:46:31,155[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025604133934126406 q_scale[0m
[[36m2024-07-08 11:46:31,177[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8078049424337922 obs_scale[0m
[[36m2024-07-08 11:46:31,192[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:31,192[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-07-08 11:46:31,193[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:31,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:32,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:32,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:32,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:32,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:32,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:32,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:32,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:32,279[0m][[34mutils..utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:32,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:32,650[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:32,663[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:32,664[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 40.83it/s v_num: 0.000
[[36m2024-07-08 11:46:42,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:42,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/015[0m
[[36m2024-07-08 11:46:42,413[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:42,434[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000683911481256934, lr[0m
[[36m2024-07-08 11:46:42,449[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:42,471[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03873241599615214 prior_scale[0m
[[36m2024-07-08 11:46:42,491[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029164124865713306 q_scale[0m
[[36m2024-07-08 11:46:42,512[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.753148056293888 obs_scale[0m
[[36m2024-07-08 11:46:42,527[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:46:42,527[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-07-08 11:46:42,528[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:42,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:43,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:43,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:43,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:43,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:43,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:43,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:43,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:43,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:43,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:43,688[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:43,699[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:43,700[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 20.01it/s v_num: 0.000
[[36m2024-07-08 11:46:49,282[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:49,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/016[0m
[[36m2024-07-08 11:46:49,978[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:49,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018259475214064708, lr[0m
[[36m2024-07-08 11:46:50,014[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:50,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029571475829064393 prior_scale[0m
[[36m2024-07-08 11:46:50,058[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006382474453239678 q_scale[0m
[[36m2024-07-08 11:46:50,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.615772723234537 obs_scale[0m
[[36m2024-07-08 11:46:50,094[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:50,095[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-07-08 11:46:50,095[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:50,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:51,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:51,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:51,174[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:51,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:51,186[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:51,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:51,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:51,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:51,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:51,216[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:51,272[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:51,274[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 37.74it/s v_num: 0.000
[[36m2024-07-08 11:46:52,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:46:52,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/015[0m
[[36m2024-07-08 11:46:52,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:46:52,623[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005127255173196106, lr[0m
[[36m2024-07-08 11:46:52,635[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:46:52,651[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.032326627210685015 prior_scale[0m
[[36m2024-07-08 11:46:52,666[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002676064292032696 q_scale[0m
[[36m2024-07-08 11:46:52,681[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7267193329726757 obs_scale[0m
[[36m2024-07-08 11:46:52,694[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:46:52,694[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-07-08 11:46:52,694[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:46:52,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:46:53,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:46:53,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:46:53,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:46:53,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:46:53,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:46:53,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:46:53,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:46:53,677[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:46:53,678[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:46:53,912[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:46:53,969[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:46:53,987[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 38.42it/s v_num: 0.000
[[36m2024-07-08 11:47:09,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:09,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/017[0m
[[36m2024-07-08 11:47:09,794[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:09,811[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005458798258745583, lr[0m
[[36m2024-07-08 11:47:09,823[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:09,838[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04873947330567944 prior_scale[0m
[[36m2024-07-08 11:47:09,853[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021537730383498302 q_scale[0m
[[36m2024-07-08 11:47:09,868[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5467096563049685 obs_scale[0m
[[36m2024-07-08 11:47:09,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:47:09,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-07-08 11:47:09,881[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:09,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:10,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:10,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:10,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:10,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:10,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:10,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:10,896[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:10,907[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:10,909[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.00it/s v_num: 0.000
[[36m2024-07-08 11:47:14,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:14,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/016[0m
[[36m2024-07-08 11:47:14,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:14,283[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000683911481256934, lr[0m
[[36m2024-07-08 11:47:14,299[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:14,321[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03873241599615214 prior_scale[0m
[[36m2024-07-08 11:47:14,343[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029164124865713306 q_scale[0m
[[36m2024-07-08 11:47:14,365[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.753148056293888 obs_scale[0m
[[36m2024-07-08 11:47:14,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:47:14,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-07-08 11:47:14,382[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:14,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:15,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:15,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:15,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:15,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:15,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:15,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:15,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:15,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:15,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:15,551[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:15,628[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:15,630[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 18.35it/s v_num: 0.000
[[36m2024-07-08 11:47:20,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:20,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/017[0m
[[36m2024-07-08 11:47:20,510[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:20,526[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018259475214064708, lr[0m
[[36m2024-07-08 11:47:20,539[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:20,556[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029571475829064393 prior_scale[0m
[[36m2024-07-08 11:47:20,571[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006382474453239678 q_scale[0m
[[36m2024-07-08 11:47:20,586[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.615772723234537 obs_scale[0m
[[36m2024-07-08 11:47:20,599[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:47:20,599[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-07-08 11:47:20,599[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:20,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:21,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:21,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:21,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:21,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:21,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:21,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:21,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:21,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:21,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:21,618[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:21,628[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:21,629[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 42.76it/s v_num: 0.000
[[36m2024-07-08 11:47:28,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:28,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/018[0m
[[36m2024-07-08 11:47:28,542[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:28,556[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002394274963123934, lr[0m
[[36m2024-07-08 11:47:28,568[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:28,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.024081545128786123 prior_scale[0m
[[36m2024-07-08 11:47:28,596[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006570381009033894 q_scale[0m
[[36m2024-07-08 11:47:28,610[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8491780931293657 obs_scale[0m
[[36m2024-07-08 11:47:28,622[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:47:28,622[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-07-08 11:47:28,622[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:28,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:29,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:29,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:29,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:29,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:29,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:29,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:29,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:29,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:29,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:29,656[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:29,671[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:29,672[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.37it/s v_num: 0.000
[[36m2024-07-08 11:47:41,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:41,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/018[0m
[[36m2024-07-08 11:47:41,345[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:41,361[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005458798258745583, lr[0m
[[36m2024-07-08 11:47:41,374[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:41,390[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04873947330567944 prior_scale[0m
[[36m2024-07-08 11:47:41,405[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021537730383498302 q_scale[0m
[[36m2024-07-08 11:47:41,421[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5467096563049685 obs_scale[0m
[[36m2024-07-08 11:47:41,434[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:47:41,434[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-07-08 11:47:41,434[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:41,434[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:42,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:42,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:42,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:42,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:42,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:42,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:42,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:42,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:42,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:42,468[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:42,479[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:42,481[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 40.35it/s v_num: 0.000
[[36m2024-07-08 11:47:47,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:47,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/019[0m
[[36m2024-07-08 11:47:47,460[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:47,475[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010010899972434438, lr[0m
[[36m2024-07-08 11:47:47,487[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:47,503[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.019776936658497977 prior_scale[0m
[[36m2024-07-08 11:47:47,517[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019715713277999153 q_scale[0m
[[36m2024-07-08 11:47:47,533[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.39966250746124515 obs_scale[0m
[[36m2024-07-08 11:47:47,545[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:47:47,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-07-08 11:47:47,546[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:47,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:48,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:48,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:48,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:48,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:48,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:48,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:48,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:48,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:48,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:48,691[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:48,703[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:48,704[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 26.23it/s v_num: 0.000
[[36m2024-07-08 11:47:52,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:47:52,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/020[0m
[[36m2024-07-08 11:47:52,779[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:47:52,793[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000541214365501478, lr[0m
[[36m2024-07-08 11:47:52,806[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:47:52,820[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.051405832951113804 prior_scale[0m
[[36m2024-07-08 11:47:52,835[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018530055560451612 q_scale[0m
[[36m2024-07-08 11:47:52,849[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5438612163044568 obs_scale[0m
[[36m2024-07-08 11:47:52,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:47:52,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-07-08 11:47:52,863[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:47:52,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:47:53,838[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:47:53,844[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:47:53,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:47:53,846[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:47:53,847[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:47:53,847[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:47:53,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:47:53,848[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:47:53,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:47:53,861[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:47:53,873[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:47:53,875[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.22it/s v_num: 0.000
[[36m2024-07-08 11:48:05,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:05,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/018[0m
[[36m2024-07-08 11:48:05,932[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:05,947[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002394274963123934, lr[0m
[[36m2024-07-08 11:48:05,959[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:05,973[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.024081545128786123 prior_scale[0m
[[36m2024-07-08 11:48:05,987[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006570381009033894 q_scale[0m
[[36m2024-07-08 11:48:06,004[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8491780931293657 obs_scale[0m
[[36m2024-07-08 11:48:06,019[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:06,019[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-07-08 11:48:06,020[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:06,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:07,091[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:07,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:07,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:07,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:07,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:07,099[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:07,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:07,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:07,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:07,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:07,141[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:07,141[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │      16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 44.33it/s v_num: 0.000
[[36m2024-07-08 11:48:10,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:10,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/021[0m
[[36m2024-07-08 11:48:11,047[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:11,068[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009808680872497924, lr[0m
[[36m2024-07-08 11:48:11,083[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:11,103[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04148718600617462 prior_scale[0m
[[36m2024-07-08 11:48:11,124[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020081908173869107 q_scale[0m
[[36m2024-07-08 11:48:11,145[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.169756389880573 obs_scale[0m
[[36m2024-07-08 11:48:11,159[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:11,160[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-07-08 11:48:11,160[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:11,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:12,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:12,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:12,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:12,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:12,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:12,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:12,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:12,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:12,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:12,261[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:12,272[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:12,273[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 34.69it/s v_num: 0.000
[[36m2024-07-08 11:48:26,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:26,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/019[0m
[[36m2024-07-08 11:48:26,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:26,508[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010010899972434438, lr[0m
[[36m2024-07-08 11:48:26,520[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:26,533[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.019776936658497977 prior_scale[0m
[[36m2024-07-08 11:48:26,548[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019715713277999153 q_scale[0m
[[36m2024-07-08 11:48:26,562[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.39966250746124515 obs_scale[0m
[[36m2024-07-08 11:48:26,574[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:48:26,574[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-07-08 11:48:26,574[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:26,575[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:27,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:27,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:27,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:27,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:27,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:27,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:27,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:27,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:27,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:27,622[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:27,636[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:27,637[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 17.89it/s v_num: 0.000
[[36m2024-07-08 11:48:28,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:28,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/021[0m
[[36m2024-07-08 11:48:28,169[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:28,184[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000541214365501478, lr[0m
[[36m2024-07-08 11:48:28,197[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:28,212[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.051405832951113804 prior_scale[0m
[[36m2024-07-08 11:48:28,227[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018530055560451612 q_scale[0m
[[36m2024-07-08 11:48:28,242[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5438612163044568 obs_scale[0m
[[36m2024-07-08 11:48:28,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:28,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-07-08 11:48:28,254[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:28,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:29,251[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:29,257[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:29,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:29,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:29,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:29,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:29,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:29,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:29,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:29,274[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:29,284[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:29,285[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 14.97it/s v_num: 0.000
[[36m2024-07-08 11:48:32,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:32,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/020[0m
[[36m2024-07-08 11:48:32,961[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:32,975[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000541214365501478, lr[0m
[[36m2024-07-08 11:48:32,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:33,000[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.051405832951113804 prior_scale[0m
[[36m2024-07-08 11:48:33,015[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018530055560451612 q_scale[0m
[[36m2024-07-08 11:48:33,036[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5438612163044568 obs_scale[0m
[[36m2024-07-08 11:48:33,051[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:33,051[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-07-08 11:48:33,052[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:33,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:34,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:34,105[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:34,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:34,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:34,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:34,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:34,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:34,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:34,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:34,123[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:34,152[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:34,153[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
h 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 34.35it/s v_num: 0.000
[[36m2024-07-08 11:48:48,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:48,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/022[0m
[[36m2024-07-08 11:48:48,542[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:48,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009808680872497924, lr[0m
[[36m2024-07-08 11:48:48,572[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:48,588[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04148718600617462 prior_scale[0m
[[36m2024-07-08 11:48:48,605[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020081908173869107 q_scale[0m
[[36m2024-07-08 11:48:48,621[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.169756389880573 obs_scale[0m
[[36m2024-07-08 11:48:48,634[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:48,635[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-07-08 11:48:48,635[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:48,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 39.65it/s v_num: 0.000
[[36m2024-07-08 11:48:48,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:48,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/023[0m
[[36m2024-07-08 11:48:49,001[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:49,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008091501924921346, lr[0m
[[36m2024-07-08 11:48:49,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:49,053[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03734850825962931 prior_scale[0m
[[36m2024-07-08 11:48:49,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005443232364930968 q_scale[0m
[[36m2024-07-08 11:48:49,097[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.2629466991510723 obs_scale[0m
[[36m2024-07-08 11:48:49,113[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:48:49,114[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-08 11:48:49,114[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:48:49,114[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:48:49,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:48:49,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:48:49,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:48:49,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:48:49,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:48:49,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:48:49,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:48:49,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:49,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:49,651[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:49,662[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:49,664[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.05it/s v_num: 0.000
[[36m2024-07-08 11:48:53,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:48:53,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/021[0m
[[36m2024-07-08 11:48:53,209[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:48:53,225[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009808680872497924, lr[0m
[[36m2024-07-08 11:48:53,239[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:48:53,262[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04148718600617462 prior_scale[0m
[[36m2024-07-08 11:48:53,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020081908173869107 q_scale[0m
[[36m2024-07-08 11:48:53,305[0m][[34msrc.ta2024-07-08 11:48:50,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:48:50,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:48:50,254[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:48:50,268[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:48:50,270[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 41.68it/s v_num: 0.000
[[36m2024-07-08 11:49:08,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:08,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/024[0m
[[36m2024-07-08 11:49:08,169[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:08,185[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009893755800209887, lr[0m
[[36m2024-07-08 11:49:08,200[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:08,220[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06344642426550323 prior_scale[0m
[[36m2024-07-08 11:49:08,234[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006574483703650397 q_scale[0m
[[36m2024-07-08 11:49:08,249[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.316299416246414 obs_scale[0m
[[36m2024-07-08 11:49:08,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:49:08,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-08 11:49:08,262[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:08,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 34.89it/s v_num: 0.000
[[36m2024-07-08 11:49:09,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:09,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/023[0m
[[36m2024-07-08 11:49:09,182[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:09,199[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009492312460480653, lr[0m
[[36m2024-07-08 11:49:09,212[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:09,229[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03702581125326657 prior_scale[0m
[[36m2024-07-08 11:49:09,245[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005683052700954933 q_scale[0m
[[36m2024-07-08 11:49:09,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.2845952109444512 obs_scale[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:09,273[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:09,276[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:49:09,277[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-08 11:49:09,277[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:09,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-07-08 11:49:09,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:09,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:09,282[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:09,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:09,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:09,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:09,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:09,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:09,298[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:09,331[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:09,332[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:10,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:10,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:10,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:10,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:10,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:10,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:10,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:10,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:10,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:10,424[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:10,445[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:10,447[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 32.02it/s v_num: 0.000
[[36m2024-07-08 11:49:14,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:14,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/022[0m
[[36m2024-07-08 11:49:14,375[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:14,390[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009492312460480653, lr[0m
[[36m2024-07-08 11:49:14,401[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:14,416[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03702581125326657 prior_scale[0m
[[36m2024-07-08 11:49:14,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005683052700954933 q_scale[0m
[[36m2024-07-08 11:49:14,444[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.2845952109444512 obs_scale[0m
[[36m2024-07-08 11:49:14,456[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:49:14,456[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-07-08 11:49:14,456[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:14,456[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:15,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:15,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:15,430[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:15,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:15,433[0m][[34mu34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:16,798[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:16,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:16,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:16,800[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:16,813[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:16,826[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                     Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 37.74it/s v_num: 0.000
[[36m2024-07-08 11:49:29,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:29,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/024[0m
[[36m2024-07-08 11:49:29,707[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:29,723[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008091501924921346, lr[0m
[[36m2024-07-08 11:49:29,736[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:29,753[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03734850825962931 prior_scale[0m
[[36m2024-07-08 11:49:29,767[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005443232364930968 q_scale[0m
[[36m2024-07-08 11:49:29,782[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.2629466991510723 obs_scale[0m
[[36m2024-07-08 11:49:29,795[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:49:29,795[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-08 11:49:29,795[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:29,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:30,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:30,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:30,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:30,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:30,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:30,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:30,781[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:30,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:30,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:30,796[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:30,810[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:30,811[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.05it/s v_num: 0.000
[[36m2024-07-08 11:49:34,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:34,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/023[0m
[[36m2024-07-08 11:49:34,960[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:34,975[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008091501924921346, lr[0m
[[36m2024-07-08 11:49:34,990[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:35,011[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03734850825962931 prior_scale[0m
[[36m2024-07-08 11:49:35,032[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005443232364930968 q_scale[0m
[[36m2024-07-08 11:49:35,053[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.2629466991510723 obs_scale[0m
[[36m2024-07-08 11:49:35,069[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:49:35,069[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-08 11:49:35,070[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:35,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:36,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:36,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:36,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:36,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:36,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:36,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:36,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:36,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:36,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:36,321[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:36,330[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:36,331[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
ls.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:50,391[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/025[0m
[[36m2024-07-08 11:49:50,507[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:50,524[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009893755800209887, lr[0m
[[36m2024-07-08 11:49:50,538[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:50,555[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06344642426550323 prior_scale[0m
[[36m2024-07-08 11:49:50,572[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006574483703650397 q_scale[0m
[[36m2024-07-08 11:49:50,589[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.316299416246414 obs_scale[0m
[[36m2024-07-08 11:49:50,602[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:49:50,602[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-07-08 11:49:50,602[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:50,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:51,613[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:51,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:51,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:51,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:51,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:51,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:51,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:51,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:51,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:51,652[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:51,679[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:51,680[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:00 • 0:00:00 35.13it/s v_num: 0.000
[[36m2024-07-08 11:49:55,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:55,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/024[0m
[[36m2024-07-08 11:49:55,643[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-08 11:49:55,664[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009893755800209887, lr[0m
[[36m2024-07-08 11:49:55,680[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-08 11:49:55,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06344642426550323 prior_scale[0m
[[36m2024-07-08 11:49:55,722[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006574483703650397 q_scale[0m
[[36m2024-07-08 11:49:55,743[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.316299416246414 obs_scale[0m
[[36m2024-07-08 11:49:55,758[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:49:55,758[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-08 11:49:55,758[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:55,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:56,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:56,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:56,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:56,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:56,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:56,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:56,854[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:56,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:56,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:56,868[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:56,880[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 11:49:56,881[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 28.19it/s v_num: 0.000
[[36m2024-07-08 11:49:58,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:49:58,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/026[0m
[[36m2024-07-08 11:49:58,428[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:49:58,452[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007258882458627011, lr[0m
[[36m2024-07-08 11:49:58,469[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:49:58,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04042519932195011 prior_scale[0m
[[36m2024-07-08 11:49:58,515[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004704109419261854 q_scale[0m
[[36m2024-07-08 11:49:58,537[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.393097653852471 obs_scale[0m
[[36m2024-07-08 11:49:58,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:49:58,554[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-07-08 11:49:58,554[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:49:58,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:49:59,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:49:59,647[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:49:59,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:49:59,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:49:59,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:49:59,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:49:59,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:49:59,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:49:59,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:49:59,666[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:49:59,674[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 25.61it/s v_num: 0.000
[[36m2024-07-08 11:50:04,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:50:04,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/025[0m
[[36m2024-07-08 11:50:04,175[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:50:04,198[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007258882458627011, lr[0m
[[36m2024-07-08 11:50:04,213[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:50:04,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04042519932195011 prior_scale[0m
[[36m2024-008 11:50:16,640[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010195201444122728 q_scale[0m
[[36m2024-07-08 11:50:16,655[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4915749614194087 obs_scale[0m
[[36m2024-07-08 11:50:16,666[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:50:16,666[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-08 11:50:16,666[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:50:16,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:50:17,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:50:17,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:50:17,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:50:17,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:50:17,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:50:17,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:50:17,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:50:17,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:50:17,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:50:17,703[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:50:17,730[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
 Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.69it/s v_num: 0.000
[[36m2024-07-08 11:50:32,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:50:32,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/027[0m
[[36m2024-07-08 11:50:32,351[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:50:32,368[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006683768968086497, lr[0m
[[36m2024-07-08 11:50:32,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:50:32,398[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04385206805651351 prior_scale[0m
[[36m2024-07-08 11:50:32,414[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009009536754612272 q_scale[0m
[[36m2024-07-08 11:50:32,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4662622957943459 obs_scale[0m
[[36m2024-07-08 11:50:32,443[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:50:32,443[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-08 11:50:32,443[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:50:32,443[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:50:33,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:50:33,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:50:33,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:50:33,440[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:50:33,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:50:33,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:50:33,442[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:50:33,442[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:50:33,443[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:50:33,472[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:50:33,481[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.55it/s v_num: 0.000
[[36m2024-07-08 11:50:38,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:50:38,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/026[0m
[[36m2024-07-08 11:50:38,267[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:50:38,288[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006683768968086497, lr[0m
[[36m2024-07-08 11:50:38,303[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:50:38,323[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04385206805651351 prior_scale[0m
[[36m2024-07-08 11:50:38,344[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009009536754612272 q_scale[0m
[[36m2024-07-08 11:50:38,366[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4662622957943459 obs_scale[0m
[[36m2024-07-08 11:50:38,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:50:38,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-07-08 11:50:38,382[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:50:38,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:50:39,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:50:39,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:50:39,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:50:39,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:50:39,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:50:39,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:50:39,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:50:39,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:50:39,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:50:39,498[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:50:39,534[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
  Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.59it/s v_num: 0.000
[[36m2024-07-08 11:51:12,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:51:12,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/027[0m
[[36m2024-07-08 11:51:12,274[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:51:12,295[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031480595261460697, lr[0m
[[36m2024-07-08 11:51:12,311[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:51:12,333[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12117060222801034 prior_scale[0m
[[36m2024-07-08 11:51:12,355[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010195201444122728 q_scale[0m
[[36m2024-07-08 11:51:12,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4915749614194087 obs_scale[0m
[[36m2024-07-08 11:51:12,394[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:51:12,394[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-08 11:51:12,395[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:51:12,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:51:13,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:51:13,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:51:13,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:51:13,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:51:13,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:51:13,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:51:13,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:51:13,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:51:13,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:51:13,504[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:51:13,528[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 21.04it/s v_num: 0.000
[[36m2024-07-08 11:51:16,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:51:16,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/029[0m
[[36m2024-07-08 11:51:16,987[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:51:17,003[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019315047499810956, lr[0m
[[36m2024-07-08 11:51:17,017[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:51:17,033[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.07711268206086948 prior_scale[0m
[[36m2024-07-08 11:51:17,049[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002263076261866401 q_scale[0m
[[36m2024-07-08 11:51:17,065[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9755742769369242 obs_scale[0m
[[36m2024-07-08 11:51:17,078[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:51:17,078[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-07-08 11:51:17,079[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:51:17,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:51:18,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:51:18,104[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:51:18,104[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:51:18,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:51:18,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:51:18,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:51:18,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:51:18,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:51:18,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:51:18,123[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:51:18,164[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 16.41it/s v_num: 0.000
[[36m2024-07-08 11:51:24,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:51:24,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/030[0m
[[36m2024-07-08 11:51:25,059[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:51:25,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006498969592726896, lr[0m
[[36m2024-07-08 11:51:25,088[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:51:25,104[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09763042905721861 prior_scale[0m
[[36m2024-07-08 11:51:25,119[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008697908253055875 q_scale[0m
[[36m2024-07-08 11:51:25,134[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4004405887632123 obs_scale[0m
[[36m2024-07-08 11:51:25,146[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:51:25,146[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-07-08 11:51:25,146[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:51:25,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:51:26,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:51:26,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:51:26,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:51:26,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:51:26,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:51:26,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:51:26,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:51:26,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:51:26,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:51:26,178[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:51:26,190[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.40it/s v_num: 0.000
[[36m2024-07-08 11:51:38,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:51:38,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/029[0m
[[36m2024-07-08 11:51:38,557[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:51:38,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028071754036929975, lr[0m
[[36m2024-07-08 11:51:38,587[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:51:38,609[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14265910258125877 prior_scale[0m
[[36m2024-07-08 11:51:38,631[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010306357969555628 q_scale[0m
[[36m2024-07-08 11:51:38,654[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5789907923288011 obs_scale[0m
[[36m2024-07-08 11:51:38,672[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:51:38,672[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-07-08 11:51:38,672[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:51:38,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:51:39,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:51:39,774[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:51:39,774[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:51:39,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:51:39,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:51:39,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:51:39,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:51:39,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:51:39,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:51:39,809[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:51:39,820[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.69it/s v_num: 0.000
[[36m2024-07-08 11:51:46,174[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:51:46,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/028[0m
[[36m2024-07-08 11:51:46,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:51:46,299[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028071754036929975, lr[0m
[[36m2024-07-08 11:51:46,310[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:51:46,325[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14265910258125877 prior_scale[0m
[[36m2024-07-08 11:51:46,339[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010306357969555628 q_scale[0m
[[36m2024-07-08 11:51:46,352[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5789907923288011 obs_scale[0m
[[36m2024-07-08 11:51:46,364[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:51:46,364[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-07-08 11:51:46,364[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:51:46,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:51:47,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:51:47,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:51:47,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:51:47,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:51:47,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:51:47,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:51:47,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:51:47,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:51:47,344[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:51:47,373[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:51:47,386[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 20.94it/s v_num: 0.000
[[36m2024-07-08 11:52:02,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:52:02,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/031[0m
[[36m2024-07-08 11:52:02,547[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:52:02,562[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006182721622361482, lr[0m
[[36m2024-07-08 11:52:02,574[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:52:02,588[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29991304478308495 prior_scale[0m
[[36m2024-07-08 11:52:02,602[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008163983583436621 q_scale[0m
[[36m2024-07-08 11:52:02,617[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5315914797512136 obs_scale[0m
[[36m2024-07-08 11:52:02,628[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:52:02,628[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-07-08 11:52:02,629[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:52:02,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:52:03,620[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:52:03,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:52:03,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:52:03,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:52:03,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:52:03,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:52:03,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:52:03,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:52:03,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:52:03,657[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:52:03,666[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.01it/s v_num: 0.000
[[36m2024-07-08 11:52:16,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:52:16,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/030[0m
[[36m2024-07-08 11:52:17,050[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:52:17,071[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019315047499810956, lr[0m
[[36m2024-07-08 11:52:17,086[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:52:17,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.07711268206086948 prior_scale[0m
[[36m2024-07-08 11:52:17,129[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002263076261866401 q_scale[0m
[[36m2024-07-08 11:52:17,149[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9755742769369242 obs_scale[0m
[[36m2024-07-08 11:52:17,165[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:52:17,165[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-07-08 11:52:17,165[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:52:17,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:52:18,290[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:52:18,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:52:18,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:52:18,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:52:18,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:52:18,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:52:18,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:52:18,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:52:18,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:52:18,327[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:52:18,337[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 11.66it/s v_num: 0.000
[[36m2024-07-08 11:52:26,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:52:26,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/031[0m
[[36m2024-07-08 11:52:26,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:52:26,447[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006498969592726896, lr[0m
[[36m2024-07-08 11:52:26,461[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:52:26,477[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09763042905721861 prior_scale[0m
[[36m2024-07-08 11:52:26,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008697908253055875 q_scale[0m
[[36m2024-07-08 11:52:26,509[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4004405887632123 obs_scale[0m
[[36m2024-07-08 11:52:26,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:52:26,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-07-08 11:52:26,523[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:52:26,523[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:52:27,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:52:27,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:52:27,517[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:52:27,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:52:27,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:52:27,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:52:27,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:52:27,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:52:27,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:52:27,534[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:52:27,582[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 20.77it/s v_num: 0.000
[[36m2024-07-08 11:52:39,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:52:39,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/032[0m
[[36m2024-07-08 11:52:39,325[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:52:39,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006555285914191962, lr[0m
[[36m2024-07-08 11:52:39,353[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:52:39,369[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.34594286982659694 prior_scale[0m
[[36m2024-07-08 11:52:39,386[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004110221190599319 q_scale[0m
[[36m2024-07-08 11:52:39,402[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9730364384612662 obs_scale[0m
[[36m2024-07-08 11:52:39,414[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:52:39,415[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-07-08 11:52:39,415[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:52:39,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:52:40,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:52:40,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:52:40,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:52:40,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:52:40,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:52:40,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:52:40,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:52:40,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:52:40,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:52:40,449[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:52:40,459[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 9.96it/s v_num: 0.000
[[36m2024-07-08 11:52:43,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:52:43,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/030[0m
[[36m2024-07-08 11:52:43,560[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:52:43,575[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006498969592726896, lr[0m
[[36m2024-07-08 11:52:43,587[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:52:43,601[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09763042905721861 prior_scale[0m
[[36m2024-07-08 11:52:43,615[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008697908253055875 q_scale[0m
[[36m2024-07-08 11:52:43,629[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4004405887632123 obs_scale[0m
[[36m2024-07-08 11:52:43,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:52:43,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-07-08 11:52:43,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:52:43,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:52:44,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:52:44,620[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:52:44,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:52:44,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:52:44,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:52:44,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:52:44,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:52:44,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:52:44,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:52:44,637[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:52:44,648[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 16.78it/s v_num: 0.000
[[36m2024-07-08 11:53:08,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:08,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/032[0m
[[36m2024-07-08 11:53:08,393[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:08,411[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006182721622361482, lr[0m
[[36m2024-07-08 11:53:08,425[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:08,442[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29991304478308495 prior_scale[0m
[[36m2024-07-08 11:53:08,461[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008163983583436621 q_scale[0m
[[36m2024-07-08 11:53:08,481[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5315914797512136 obs_scale[0m
[[36m2024-07-08 11:53:08,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:53:08,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-07-08 11:53:08,496[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:08,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:09,690[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:09,696[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:09,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:09,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:09,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:09,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:09,701[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:09,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:09,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:09,738[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:09,764[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 21.79it/s v_num: 0.000
[[36m2024-07-08 11:53:10,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:10,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/033[0m
[[36m2024-07-08 11:53:10,555[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:10,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006724855851023691, lr[0m
[[36m2024-07-08 11:53:10,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:10,596[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29650344260764144 prior_scale[0m
[[36m2024-07-08 11:53:10,611[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004328852158524289 q_scale[0m
[[36m2024-07-08 11:53:10,627[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9699058687053117 obs_scale[0m
[[36m2024-07-08 11:53:10,639[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:53:10,639[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-07-08 11:53:10,639[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:10,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:11,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:11,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:11,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:11,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:11,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:11,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:11,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:11,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:11,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:11,715[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:11,734[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 14.27it/s v_num: 0.000
[[36m2024-07-08 11:53:17,387[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:17,387[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/034[0m
[[36m2024-07-08 11:53:17,506[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:17,521[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5.701821404313182e-05, lr[0m
[[36m2024-07-08 11:53:17,534[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:17,550[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08946286273092285 prior_scale[0m
[[36m2024-07-08 11:53:17,566[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014148787427911884 q_scale[0m
[[36m2024-07-08 11:53:17,589[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9998092626078638 obs_scale[0m
[[36m2024-07-08 11:53:17,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:53:17,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-08 11:53:17,607[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:17,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:18,724[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:18,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:18,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:18,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:18,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:18,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:18,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:18,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:18,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:18,748[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:18,761[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 9/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 16.99it/s v_num: 0.000
[[36m2024-07-08 11:53:21,971[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 9.
[[36m2024-07-08 11:53:22,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:22,175[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:22,193[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012752624891627234, lr[0m
[[36m2024-07-08 11:53:22,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:22,227[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06925204748483607 prior_scale[0m
[[36m2024-07-08 11:53:22,246[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003698809405323322 q_scale[0m
[[36m2024-07-08 11:53:22,265[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.380485683893914 obs_scale[0m
[[36m2024-07-08 11:53:22,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:53:22,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-07-08 11:53:22,279[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:22,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:23,310[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:23,316[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:23,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:23,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:23,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:23,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:23,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:23,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:23,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:23,335[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:23,618[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 22.23it/s v_num: 0.000
[[36m2024-07-08 11:53:40,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:40,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/036[0m
[[36m2024-07-08 11:53:40,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:40,264[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006860592127608587, lr[0m
[[36m2024-07-08 11:53:40,277[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:40,291[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17577802319748229 prior_scale[0m
[[36m2024-07-08 11:53:40,306[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008265272653550321 q_scale[0m
[[36m2024-07-08 11:53:40,320[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3290253114763252 obs_scale[0m
[[36m2024-07-08 11:53:40,332[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:53:40,332[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-07-08 11:53:40,332[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:40,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.12it/s v_num: 0.000
[[36m2024-07-08 11:53:41,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:41,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/033[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:41,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:41,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:41,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:41,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:41,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:41,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:41,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:41,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:41,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:41,347[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:41,357[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
[[36m2024-07-08 11:53:41,438[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:41,455[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006555285914191962, lr[0m
[[36m2024-07-08 11:53:41,468[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:41,484[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.34594286982659694 prior_scale[0m
[[36m2024-07-08 11:53:41,499[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004110221190599319 q_scale[0m
[[36m2024-07-08 11:53:41,520[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9730364384612662 obs_scale[0m
[[36m2024-07-08 11:53:41,533[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:53:41,533[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-07-08 11:53:41,533[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:41,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:42,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:42,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:42,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:42,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:42,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:42,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:42,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:42,551[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:42,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:42,581[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:42,592[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.45it/s v_num: 0.000
[[36m2024-07-08 11:53:51,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:53:51,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/032[0m
[[36m2024-07-08 11:53:51,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:53:51,229[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006555285914191962, lr[0m
[[36m2024-07-08 11:53:51,244[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:53:51,266[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.34594286982659694 prior_scale[0m
[[36m2024-07-08 11:53:51,286[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004110221190599319 q_scale[0m
[[36m2024-07-08 11:53:51,307[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9730364384612662 obs_scale[0m
[[36m2024-07-08 11:53:51,323[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:53:51,323[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-07-08 11:53:51,323[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:53:51,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:53:52,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:53:52,402[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:53:52,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:53:52,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:53:52,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:53:52,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:53:52,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:53:52,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:53:52,406[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:53:52,433[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:53:52,445[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 20.08it/s v_num: 0.000
[[36m2024-07-08 11:54:15,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:15,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/034[0m
[[36m2024-07-08 11:54:15,466[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:15,482[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006724855851023691, lr[0m
[[36m2024-07-08 11:54:15,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:54:15,511[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29650344260764144 prior_scale[0m
[[36m2024-07-08 11:54:15,527[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004328852158524289 q_scale[0m
[[36m2024-07-08 11:54:15,544[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9699058687053117 obs_scale[0m
[[36m2024-07-08 11:54:15,557[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:54:15,557[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-08 11:54:15,557[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:15,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:16,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:16,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:16,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:16,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:16,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:16,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:16,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:16,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:16,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:16,643[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:16,656[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.00it/s v_num: 0.000
[[36m2024-07-08 11:54:21,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:21,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/038[0m
[[36m2024-07-08 11:54:21,681[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:21,698[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.863973212669914e-05, lr[0m
[[36m2024-07-08 11:54:21,711[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:54:21,727[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25752769058983277 prior_scale[0m
[[36m2024-07-08 11:54:21,743[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001775659911006492 q_scale[0m
[[36m2024-07-08 11:54:21,758[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.146934700626437 obs_scale[0m
[[36m2024-07-08 11:54:21,772[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:54:21,772[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-07-08 11:54:21,772[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:21,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:22,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:22,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:22,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:22,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:22,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:22,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:22,787[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:22,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:22,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:22,819[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:22,830[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.08it/s v_num: 0.000
[[36m2024-07-08 11:54:24,407[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:24,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/033[0m
[[36m2024-07-08 11:54:24,541[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:24,563[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006724855851023691, lr[0m
[[36m2024-07-08 11:54:24,578[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m202436m2024-07-08 11:54:24,009[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08946286273092285 prior_scale[0m
[[36m2024-07-08 11:54:24,026[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014148787427911884 q_scale[0m
[[36m2024-07-08 11:54:24,042[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9998092626078638 obs_scale[0m
[[36m2024-07-08 11:54:24,055[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:54:24,055[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-07-08 11:54:24,055[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:24,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:25,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:25,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:25,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:25,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:25,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:25,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:25,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:25,094[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:25,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:25,108[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:25,138[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Ttimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 7.86it/s v_num: 0.000
[[36m2024-07-08 11:54:33,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:33,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/034[0m
[[36m2024-07-08 11:54:33,910[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:33,926[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5.701821404313182e-05, lr[0m
[[36m2024-07-08 11:54:33,938[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:54:33,952[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08946286273092285 prior_scale[0m
[[36m2024-07-08 11:54:33,967[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014148787427911884 q_scale[0m
[[36m2024-07-08 11:54:33,981[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9998092626078638 obs_scale[0m
[[36m2024-07-08 11:54:33,993[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:54:33,993[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-08 11:54:33,993[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:33,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:34,989[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:34,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:34,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:34,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:34,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:34,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:34,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:34,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:34,999[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:35,012[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:35,025[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Epoch 17/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 9.62it/s v_num: 0.000
[[36m2024-07-08 11:54:42,879[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2024-07-08 11:54:42,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:42,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:42,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012752624891627234, lr[0m
[[36m2024-07-08 11:54:42,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:54:43,011[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06925204748483607 prior_scale[0m
[[36m2024-07-08 11:54:43,026[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003698809405323322 q_scale[0m
[[36m2024-07-08 11:54:43,040[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.380485683893914 obs_scale[0m
[[36m2024-07-08 11:54:43,052[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:54:43,052[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-07-08 11:54:43,052[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:43,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:44,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:44,031[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:44,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:44,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:44,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:44,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:44,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:44,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:44,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:44,048[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:44,060[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 17.25it/s v_num: 0.000
[[36m2024-07-08 11:54:50,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:54:50,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/037[0m
[[36m2024-07-08 11:54:50,290[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:54:50,307[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006860592127608587, lr[0m
[[36m2024-07-08 11:54:50,321[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:54:50,338[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17577802319748229 prior_scale[0m
[[36m2024-07-08 11:54:50,356[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008265272653550321 q_scale[0m
[[36m2024-07-08 11:54:50,373[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3290253114763252 obs_scale[0m
[[36m2024-07-08 11:54:50,388[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:54:50,388[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-07-08 11:54:50,389[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:54:50,389[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:54:51,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:54:51,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:54:51,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:54:51,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:54:51,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:54:51,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:54:51,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:54:51,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:54:51,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:54:51,514[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:54:51,527[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 16.58it/s v_num: 0.000
[[36m2024-07-08 11:55:03,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:03,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/036[0m
[[36m2024-07-08 11:55:04,038[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:55:04,059[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006860592127608587, lr[0m
[[36m2024-07-08 11:55:04,073[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:55:04,093[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17577802319748229 prior_scale[0m
[[36m2024-07-08 11:55:04,113[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008265272653550321 q_scale[0m
[[36m2024-07-08 11:55:04,133[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3290253114763252 obs_scale[0m
[[36m2024-07-08 11:55:04,147[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:55:04,147[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-07-08 11:55:04,148[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:55:04,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:55:05,228[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:55:05,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:55:05,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:55:05,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:55:05,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:55:05,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:55:05,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:55:05,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:55:05,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:55:05,262[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:55:05,270[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.33it/s v_num: 0.000
[[36m2024-07-08 11:55:17,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:17,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/037[0m
[[36m2024-07-08 11:55:17,215[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:55:17,231[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003911462947609153, lr[0m
[[36m2024-07-08 11:55:17,243[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:55:17,258[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.058632808703357256 prior_scale[0m
[[36m2024-07-08 11:55:17,272[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008194052881306241 q_scale[0m
[[36m2024-07-08 11:55:17,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.9252405718992893 obs_scale[0m
[[36m2024-07-08 11:55:19,768[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:55:19,768[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-07-08 11:55:19,768[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:55:19,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:55:20,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:55:20,758[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:55:20,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:55:20,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:55:20,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:55:20,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:55:20,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:55:20,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:55:20,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:55:20,790[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:55:20,802[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.02it/s v_num: 0.000
[[36m2024-07-08 11:55:34,798[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:34,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/039[0m
[[36m2024-07-08 11:55:34,920[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:55:34,938[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.863973212669914e-05, lr[0m
[[36m2024-07-08 11:55:34,952[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:55:34,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25752769058983277 prior_scale[0m
[[36m2024-07-08 11:55:34,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001775659911006492 q_scale[0m
[[36m2024-07-08 11:55:35,002[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.146934700626437 obs_scale[0m
[[36m2024-07-08 11:55:35,015[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:55:35,016[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-07-08 11:55:35,016[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:55:35,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:55:36,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:55:36,020[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:55:36,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:55:36,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:55:36,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:55:36,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:55:36,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:55:36,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:55:36,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:55:36,057[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:55:36,085[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.69it/s v_num: 0.000
[[36m2024-07-08 11:55:49,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:49,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/042[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.96it/s v_num: 0.000
[[36m2024-07-08 11:55:51,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:51,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/038[0m
[[36m2024-07-08 11:55:51,996[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:55:52,012[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.863973212669914e-05, lr[0m
[[36m2024-07-08 11:55:52,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:55:52,042[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25752769058983277 prior_scale[0m
[[36m2024-07-08 11:55:52,063[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001775659911006492 q_scale[0m
[[36m2024-07-08 11:55:52,084[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.146934700626437 obs_scale[0m
[[36m2024-07-08 11:55:52,101[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:55:52,102[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-07-08 11:55:52,102[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:55:52,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:55:53,183[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:55:53,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:55:53,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:55:53,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:55:53,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:55:53,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:55:53,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:55:53,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:55:53,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:55:53,224[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:55:53,250[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 17.66it/s v_num: 0.000
[[36m2024-07-08 11:55:55,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:55:55,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/040[0m
[[36m2024-07-08 11:55:55,354[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:55:55,371[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.8058268402712556e-05, lr[0m
[[36m2024-07-08 11:55:55,385[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:55:55,402[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4686555261123642 prior_scale[0m
[[36m2024-07-08 11:55:55,417[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004378109806498652 q_scale[0m
[[36m2024-07-08 11:55:55,433[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5962386075241424 obs_scale[0m
[[36m2024-07-08 11:55:55,447[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:55:55,448[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-07-08 11:55:55,448[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:55:55,448[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:55:56,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:55:56,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:55:56,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:55:56,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:55:56,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:55:56,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:55:56,474[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:55:56,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:55:56,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:55:56,488[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:55:56,502[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.10it/s v_num: 0.000
[[36m2024-07-08 11:56:04,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:04,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/041[0m
[[36m2024-07-08 11:56:04,571[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:04,588[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006234440627509736, lr[0m
[[36m2024-07-08 11:56:04,603[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:04,619[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.35293830451351843 prior_scale[0m
[[36m2024-07-08 11:56:04,635[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008250634139254276 q_scale[0m
[[36m2024-07-08 11:56:04,650[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.6377828736316695 obs_scale[0m
[[36m2024-07-08 11:56:04,662[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:56:04,662[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-07-08 11:56:04,662[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:04,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:05,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:05,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:05,802[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:05,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:05,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:05,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:05,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:05,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:05,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:05,820[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:05,829[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 17.14it/s v_num: 0.000
[[36m2024-07-08 11:56:12,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:12,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/039[0m
[[36m2024-07-08 11:56:12,720[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:12,741[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.8058268402712556e-05, lr[0m
[[36m2024-07-08 11:56:12,757[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:12,778[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4686555261123642 prior_scale[0m
[[36m2024-07-08 11:56:12,799[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004378109806498652 q_scale[0m
[[36m2024-07-08 11:56:12,820[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.5962386075241424 obs_scale[0m
[[36m2024-07-08 11:56:12,835[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-08 11:56:12,836[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-07-08 11:56:12,836[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:12,836[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:13,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:13,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:13,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:13,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:13,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:13,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:13,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:13,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:13,939[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:13,951[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:13,964[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 10.00it/s v_num: 0.000
[[36m2024-07-08 11:56:23,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:23,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/040[0m
[[36m2024-07-08 11:56:23,345[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:23,362[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006234440627509736, lr[0m
[[36m2024-07-08 11:56:23,375[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:23,393[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.35293830451351843 prior_scale[0m
[[36m2024-07-08 11:56:23,410[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008250634139254276 q_scale[0m
[[36m2024-07-08 11:56:23,428[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.6377828736316695 obs_scale[0m
[[36m2024-07-08 11:56:23,441[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:56:23,441[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-07-08 11:56:23,441[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:23,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:24,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:24,459[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:24,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:24,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:24,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:24,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:24,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:24,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:24,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:24,491[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:24,502[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.16it/s v_num: 0.000
[[36m2024-07-08 11:56:37,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:37,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/042[0m
[[36m2024-07-08 11:56:37,997[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:38,012[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007810047860749132, lr[0m
[[36m2024-07-08 11:56:38,026[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:38,042[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2539224964255174 prior_scale[0m
[[36m2024-07-08 11:56:38,057[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012475400305126518 q_scale[0m
[[36m2024-07-08 11:56:38,071[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1323904881901183 obs_scale[0m
[[36m2024-07-08 11:56:38,084[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:56:38,084[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-07-08 11:56:38,085[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:38,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:39,089[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:39,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:39,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:39,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:39,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:39,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:39,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:39,099[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:39,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:39,130[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:39,143[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.26it/s v_num: 0.000
[[36m2024-07-08 11:56:49,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:49,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/044[0m
[[36m2024-07-08 11:56:49,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:49,368[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048174320799986627, lr[0m
[[36m2024-07-08 11:56:49,385[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:49,407[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1593800124763196 prior_scale[0m
[[36m2024-07-08 11:56:49,429[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00837998805559208 q_scale[0m
[[36m2024-07-08 11:56:49,451[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.634177550414717 obs_scale[0m
[[36m2024-07-08 11:56:49,466[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:56:49,466[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-07-08 11:56:49,467[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:49,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:50,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:50,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:50,541[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:50,544[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:50,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:50,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:50,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:50,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:50,548[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:50,575[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:50,652[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.01it/s v_num: 0.000
[[36m2024-07-08 11:56:57,646[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:56:57,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/041[0m
[[36m2024-07-08 11:56:57,776[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:56:57,792[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007810047860749132, lr[0m
[[36m2024-07-08 11:56:57,804[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:56:57,826[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2539224964255174 prior_scale[0m
[[36m2024-07-08 11:56:57,847[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012475400305126518 q_scale[0m
[[36m2024-07-08 11:56:57,869[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1323904881901183 obs_scale[0m
[[36m2024-07-08 11:56:57,885[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:56:57,885[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-07-08 11:56:57,886[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:56:57,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:56:59,078[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:56:59,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:56:59,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:56:59,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:56:59,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:56:59,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:56:59,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:56:59,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:56:59,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:56:59,117[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:56:59,130[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
�┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.26it/s v_num: 0.000
[[36m2024-07-08 11:57:18,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:57:18,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/045[0m
[[36m2024-07-08 11:57:18,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:57:18,355[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004953689362579755, lr[0m
[[36m2024-07-08 11:57:18,366[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:57:18,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1633225369693176 prior_scale[0m
[[36m2024-07-08 11:57:18,395[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.009917072934430256 q_scale[0m
[[36m2024-07-08 11:57:18,409[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6306226001313937 obs_scale[0m
[[36m2024-07-08 11:57:18,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:57:18,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-08 11:57:18,423[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:57:18,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:57:19,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:57:19,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:57:19,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:57:19,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:57:19,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:57:19,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:57:19,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:57:19,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:57:19,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:57:19,467[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:57:19,480[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 20.56it/s v_num: 0.000
[[36m2024-07-08 11:57:28,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:57:28,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/046[0m
[[36m2024-07-08 11:57:28,343[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:57:28,358[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008082845923541979, lr[0m
[[36m2024-07-08 11:57:28,370[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:57:28,384[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12691892404355537 prior_scale[0m
[[36m2024-07-08 11:57:28,400[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00503267919393736 q_scale[0m
[[36m2024-07-08 11:57:28,417[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6911505474302513 obs_scale[0m
[[36m2024-07-08 11:57:28,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:57:28,431[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-07-08 11:57:28,431[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:57:28,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:57:29,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:57:29,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:57:29,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:57:29,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:57:29,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:57:29,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:57:29,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:57:29,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:57:29,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:57:29,544[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:57:29,558[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.11it/s v_num: 0.000
[[36m2024-07-08 11:57:32,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:57:32,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/042[0m
[[36m2024-07-08 11:57:32,576[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:57:32,599[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007833450978718905, lr[0m
[[36m2024-07-08 11:57:32,614[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:57:32,636[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20479302283394785 prior_scale[0m
[[36m2024-07-08 11:57:32,653[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029976097994330064 q_scale[0m
[[36m2024-07-08 11:57:32,670[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.090323652812756 obs_scale[0m
[[36m2024-07-08 11:57:32,686[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:57:32,687[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-07-08 11:57:32,687[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:57:32,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:57:33,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:57:33,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:57:33,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:57:33,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:57:33,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:57:33,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:57:33,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:57:33,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:57:33,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:57:33,795[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:57:33,804[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━�━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 21.82it/s v_num: 0.000
[[36m2024-07-08 11:57:58,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:57:58,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/047[0m
[[36m2024-07-08 11:57:58,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:57:58,298[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008240449779723665, lr[0m
[[36m2024-07-08 11:57:58,310[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:57:58,324[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23424340149611914 prior_scale[0m
[[36m2024-07-08 11:57:58,343[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.006310732714661231 q_scale[0m
[[36m2024-07-08 11:57:58,363[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.48238166507239977 obs_scale[0m
[[36m2024-07-08 11:57:58,375[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:57:58,375[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-08 11:57:58,376[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:57:58,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:57:59,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:57:59,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:57:59,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:57:59,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:57:59,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:57:59,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:57:59,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:57:59,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:57:59,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:57:59,481[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:57:59,492[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.53it/s v_num: 0.000
[[36m2024-07-08 11:58:06,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:58:06,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/043[0m
[[36m2024-07-08 11:58:06,424[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:58:06,439[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003551913627267259, lr[0m
[[36m2024-07-08 11:58:06,451[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:58:06,465[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20987793350165654 prior_scale[0m
[[36m2024-07-08 11:58:06,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0028361908535252255 q_scale[0m
[[36m2024-07-08 11:58:06,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1291261439209779 obs_scale[0m
[[36m2024-07-08 11:58:06,508[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:58:06,508[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-07-08 11:58:06,508[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:58:06,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:58:07,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:58:07,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:58:07,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:58:07,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:58:07,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:58:07,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:58:07,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:58:07,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:58:07,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:58:07,515[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:58:07,526[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       

Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.82it/s v_num: 0.000
[[36m2024-07-08 11:58:17,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:58:17,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/045[0m
[[36m2024-07-08 11:58:17,620[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:58:17,635[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048174320799986627, lr[0m
[[36m2024-07-08 11:58:17,648[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:58:17,664[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1593800124763196 prior_scale[0m
[[36m2024-07-08 11:58:17,679[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00837998805559208 q_scale[0m
[[36m2024-07-08 11:58:17,694[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.634177550414717 obs_scale[0m
[[36m2024-07-08 11:58:17,707[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:58:17,707[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-08 11:58:17,708[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:58:17,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:58:18,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:58:18,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:58:18,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:58:18,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:58:18,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:58:18,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:58:18,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:58:18,702[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:58:18,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:58:18,731[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:58:18,743[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 5/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 14.88it/s v_num: 0.000
[[36m2024-07-08 11:58:19,055[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 5.
[[36m2024-07-08 11:58:19,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:58:19,155[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:58:19,174[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004457957550603556, lr[0m
[[36m2024-07-08 11:58:19,187[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:58:19,205[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.36893252376220403 prior_scale[0m
[[36m2024-07-08 11:58:19,223[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00362677016245377 q_scale[0m
[[36m2024-07-08 11:58:19,238[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7964447009113997 obs_scale[0m
[[36m2024-07-08 11:58:19,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:58:19,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-07-08 11:58:19,250[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:58:19,251[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:58:20,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:58:20,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:58:20,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:58:20,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:58:20,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:58:20,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:58:20,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:58:20,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:58:20,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:58:20,289[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:58:20,302[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.95it/s v_num: 0.000
[[36m2024-07-08 11:58:39,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:58:39,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/044[0m
[[36m2024-07-08 11:58:39,829[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:58:39,844[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048174320799986627, lr[0m
[[36m2024-07-08 11:58:39,856[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:58:39,871[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1593800124763196 prior_scale[0m
[[36m2024-07-08 11:58:39,885[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00837998805559208 q_scale[0m
[[36m2024-07-08 11:58:39,900[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.634177550414717 obs_scale[0m
[[36m2024-07-08 11:58:39,911[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:58:39,911[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-07-08 11:58:39,911[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:58:39,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:58:40,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:58:40,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:58:40,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:58:40,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:58:40,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:58:40,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:58:40,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:58:40,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:58:40,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:58:40,923[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:58:40,938[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
�━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:58:50,842[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:58:50,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:58:50,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:58:50,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:58:50,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:58:50,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:58:50,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:58:50,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:58:50,854[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:58:50,884[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:58:50,896[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.78it/s v_num: 0.000
[[36m2024-07-08 11:59:01,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:01,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/047[0m
[[36m2024-07-08 11:59:01,764[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:01,788[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021782815398914244, lr[0m
[[36m2024-07-08 11:59:01,806[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:01,831[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3770915299810736 prior_scale[0m
[[36m2024-07-08 11:59:01,855[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012235057170794544 q_scale[0m
[[36m2024-07-08 11:59:01,879[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0848874213276756 obs_scale[0m
[[36m2024-07-08 11:59:01,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:59:01,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-08 11:59:01,898[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:01,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:02,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:02,999[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:02,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:03,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:03,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:03,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:03,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:03,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:03,004[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:03,017[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:03,029[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.02it/s v_num: 0.000
[[36m2024-07-08 11:59:13,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:13,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/045[0m
[[36m2024-07-08 11:59:13,123[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:13,139[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008060815968622424, lr[0m
[[36m2024-07-08 11:59:13,151[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:13,166[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2531341284027241 prior_scale[0m
[[36m2024-07-08 11:59:13,181[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0042581386027238845 q_scale[0m
[[36m2024-07-08 11:59:13,195[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.876116387466315 obs_scale[0m
[[36m2024-07-08 11:59:13,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-08 11:59:13,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-08 11:59:13,208[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:13,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:14,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:14,194[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:14,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:14,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:14,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:14,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:14,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:14,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:14,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:14,236[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:14,250[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.72it/s v_num: 0.000
[[36m2024-07-08 11:59:26,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:26,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/046[0m
[[36m2024-07-08 11:59:26,168[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:26,184[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021782815398914244, lr[0m
[[36m2024-07-08 11:59:26,195[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:26,210[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3770915299810736 prior_scale[0m
[[36m2024-07-08 11:59:26,225[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012235057170794544 q_scale[0m
[[36m2024-07-08 11:59:26,242[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0848874213276756 obs_scale[0m
[[36m2024-07-08 11:59:26,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:59:26,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-07-08 11:59:26,255[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:26,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:27,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:27,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:27,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:27,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:27,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:27,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:27,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:27,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:27,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:27,246[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:27,260[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.81it/s v_num: 0.000
[[36m2024-07-08 11:59:35,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:35,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/048[0m
[[36m2024-07-08 11:59:35,184[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:35,201[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008240449779723665, lr[0m
[[36m2024-07-08 11:59:35,216[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:35,233[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11979091767085709 prior_scale[0m
[[36m2024-07-08 11:59:35,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.005636826537295052 q_scale[0m
[[36m2024-07-08 11:59:35,267[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2325118209965556 obs_scale[0m
[[36m2024-07-08 11:59:35,281[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:59:35,281[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-07-08 11:59:35,282[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:35,282[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:36,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:36,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:36,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:36,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:36,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:36,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:36,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:36,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:36,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:36,466[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:36,477[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 22.44it/s v_num: 0.000
[[36m2024-07-08 11:59:48,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:48,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/052[0m
[[36m2024-07-08 11:59:48,881[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:48,899[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008426025228659382, lr[0m
[[36m2024-07-08 11:59:48,913[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:48,931[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2620998542167744 prior_scale[0m
[[36m2024-07-08 11:59:48,952[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.006444584445985829 q_scale[0m
[[36m2024-07-08 11:59:48,972[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8811541623801931 obs_scale[0m
[[36m2024-07-08 11:59:48,984[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 11:59:48,984[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-07-08 11:59:48,984[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:48,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:49,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:49,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:49,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:49,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:49,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:49,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:49,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:49,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:49,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:50,000[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:50,009[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 17.63it/s v_num: 0.000
[[36m2024-07-08 11:59:55,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:55,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/049[0m
[[36m2024-07-08 11:59:55,698[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:55,715[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005695158744033134, lr[0m
[[36m2024-07-08 11:59:55,730[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:55,746[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24576615977444397 prior_scale[0m
[[36m2024-07-08 11:59:55,764[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003051253880075337 q_scale[0m
[[36m2024-07-08 11:59:55,781[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7996902670388233 obs_scale[0m
[[36m2024-07-08 11:59:55,796[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 11:59:55,796[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-07-08 11:59:55,796[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:55,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 11:59:56,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 11:59:56,836[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 11:59:56,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 11:59:56,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 11:59:56,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 11:59:56,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 11:59:56,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 11:59:56,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 11:59:56,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 11:59:56,855[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 11:59:56,868[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.35it/s v_num: 0.000
[[36m2024-07-08 11:59:59,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 11:59:59,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/047[0m
[[36m2024-07-08 11:59:59,789[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 11:59:59,804[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008240449779723665, lr[0m
[[36m2024-07-08 11:59:59,817[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 11:59:59,833[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11979091767085709 prior_scale[0m
[[36m2024-07-08 11:59:59,855[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.005636826537295052 q_scale[0m
[[36m2024-07-08 11:59:59,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2325118209965556 obs_scale[0m
[[36m2024-07-08 11:59:59,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-08 11:59:59,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-08 11:59:59,897[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 11:59:59,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:00:00,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:00:00,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:00:00,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:00:00,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:00:00,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:00:00,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:00:00,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:00:00,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:00:00,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:00:00,919[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:00:00,929[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
     
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.56it/s v_num: 0.000
[[36m2024-07-08 12:00:17,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:00:17,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/053[0m
[[36m2024-07-08 12:00:17,888[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:00:17,903[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000846118393571837, lr[0m
[[36m2024-07-08 12:00:17,914[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:00:17,929[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1581018725733274 prior_scale[0m
[[36m2024-07-08 12:00:17,950[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0069771523579733605 q_scale[0m
[[36m2024-07-08 12:00:17,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.688404892891143 obs_scale[0m
[[36m2024-07-08 12:00:17,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:00:17,987[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-07-08 12:00:17,987[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:00:17,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 13/13 0:00:00 • 0:00:00 17.23it/s v_num: 0.000
[[36m2024-07-08 12:00:20,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:00:20,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/048[0m
[[36m2024-07-08 12:00:20,301[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:00:20,318[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005695158744033134, lr[0m
[[36m2024-07-08 12:00:20,332[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:00:20,349[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24576615977444397 prior_scale[0m
[[36m2024-07-08 12:00:20,367[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003051253880075337 q_scale[0m
[[36m2024-07-08 12:00:20,384[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7996902670388233 obs_scale[0m
[[36m2024-07-08 12:00:20,397[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-08 12:00:20,397[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-07-08 12:00:20,397[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:00:20,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:00:21,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:00:21,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:00:21,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:00:21,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:00:21,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:00:21,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:00:21,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:00:21,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:00:21,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:00:21,626[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:00:21,707[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 7.68it/s v_num: 0.000
[[36m2024-07-08 12:00:30,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:00:30,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/049[0m
[[36m2024-07-08 12:00:30,393[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:00:30,413[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045128917185956164, lr[0m
[[36m2024-07-08 12:00:30,426[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:00:30,442[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09672674203371978 prior_scale[0m
[[36m2024-07-08 12:00:30,457[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002216807633184659 q_scale[0m
[[36m2024-07-08 12:00:30,473[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7558118087196264 obs_scale[0m
[[36m2024-07-08 12:00:30,486[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:00:30,486[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-07-08 12:00:30,486[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:00:30,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:00:31,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:00:31,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:00:31,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:00:31,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:00:31,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:00:31,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:00:31,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:00:31,468[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:00:31,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:00:31,496[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:00:31,508[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
9/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.49it/s v_num: 0.000
[[36m2024-07-08 12:00:46,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:00:46,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/054[0m
[[36m2024-07-08 12:00:46,555[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:00:46,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008439137649729662, lr[0m
[[36m2024-07-08 12:00:46,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:00:46,595[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25222013847765107 prior_scale[0m
[[36m2024-07-08 12:00:46,610[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00514921094749155 q_scale[0m
[[36m2024-07-08 12:00:46,625[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8514931953332979 obs_scale[0m
[[36m2024-07-08 12:00:46,638[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:00:46,638[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-07-08 12:00:46,638[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:00:46,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:00:47,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:00:47,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:00:47,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:00:47,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:00:47,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:00:47,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:00:47,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:00:47,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:00:47,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:00:47,666[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:00:47,678[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.40it/s v_num: 0.000
[[36m2024-07-08 12:01:04,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:01:04,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/050[0m
[[36m2024-07-08 12:01:04,301[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:01:04,317[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007330710807737342, lr[0m
[[36m2024-07-08 12:01:04,329[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:01:04,343[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04445142678430464 prior_scale[0m
[[36m2024-07-08 12:01:04,360[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00133775583259617 q_scale[0m
[[36m2024-07-08 12:01:04,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4148934572066163 obs_scale[0m
[[36m2024-07-08 12:01:04,394[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:01:04,394[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-07-08 12:01:04,394[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:01:04,394[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:01:05,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:01:05,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:01:05,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:01:05,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:01:05,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:01:05,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:01:05,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:01:05,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:01:05,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:01:05,402[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:01:05,422[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
 
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.73it/s v_num: 0.000
[[36m2024-07-08 12:01:14,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:01:14,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/055[0m
[[36m2024-07-08 12:01:14,995[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:01:15,010[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009972712985773986, lr[0m
[[36m2024-07-08 12:01:15,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:01:15,040[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19489418198868783 prior_scale[0m
[[36m2024-07-08 12:01:15,053[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.005335664094638404 q_scale[0m
[[36m2024-07-08 12:01:15,067[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8659771571548253 obs_scale[0m
[[36m2024-07-08 12:01:15,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:01:15,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-07-08 12:01:15,079[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:01:15,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:01:16,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:01:16,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:01:16,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:01:16,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:01:16,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:01:16,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:01:16,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:01:16,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:01:16,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:01:16,067[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:01:16,078[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.55it/s v_num: 0.000
[[36m2024-07-08 12:01:37,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:01:37,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/051[0m
[[36m2024-07-08 12:01:37,780[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:01:37,802[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007438092654261897, lr[0m
[[36m2024-07-08 12:01:37,816[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:01:37,833[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.31540079094953843 prior_scale[0m
[[36m2024-07-08 12:01:37,851[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013099723097232687 q_scale[0m
[[36m2024-07-08 12:01:37,868[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.186348686636908 obs_scale[0m
[[36m2024-07-08 12:01:37,882[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:01:37,882[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-07-08 12:01:37,882[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:01:37,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:01:38,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:01:38,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:01:38,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:01:38,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:01:38,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:01:38,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:01:38,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:01:38,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:01:38,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:01:38,958[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:01:38,970[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:01:44,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:01:44,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:01:44,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:01:44,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:01:44,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:01:44,762[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:01:44,774[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-08 12:01:44,780[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
[[36m2024-07-08 12:01:44,790[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.00it/s v_num: 0.000
[[36m2024-07-08 12:02:11,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:02:11,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/052[0m
[[36m2024-07-08 12:02:11,527[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:02:11,544[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008023537966604441, lr[0m
[[36m2024-07-08 12:02:11,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:02:11,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.31443063728378634 prior_scale[0m
[[36m2024-07-08 12:02:11,604[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018984384128417542 q_scale[0m
[[36m2024-07-08 12:02:11,626[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0761317315192382 obs_scale[0m
[[36m2024-07-08 12:02:11,643[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:02:11,644[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-07-08 12:02:11,644[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:02:11,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:02:12,821[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:02:12,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:02:12,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:02:12,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:02:12,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:02:12,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:02:12,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:02:12,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:02:12,831[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:02:12,862[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:02:12,876[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.17it/s v_num: 0.000
[[36m2024-07-08 12:02:16,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:02:16,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/054[0m
[[36m2024-07-08 12:02:16,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:02:16,623[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000868567472916665, lr[0m
[[36m2024-07-08 12:02:16,638[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:02:16,655[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3221764173646582 prior_scale[0m
[[36m2024-07-08 12:02:16,672[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017898029274959232 q_scale[0m
[[36m2024-07-08 12:02:16,688[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0452772178064849 obs_scale[0m
[[36m2024-07-08 12:02:16,702[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:02:16,702[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-07-08 12:02:16,702[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:02:16,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:02:17,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:02:17,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:02:17,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:02:17,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:02:17,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:02:17,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:02:17,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:02:17,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:02:17,700[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:02:17,733[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:02:17,757[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 23.66it/s v_num: 0.000
[[36m2024-07-08 12:02:40,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:02:40,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-08_11-43-08/058[0m
[[36m2024-07-08 12:02:40,463[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:02:40,476[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005491702359325437, lr[0m
[[36m2024-07-08 12:02:40,487[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:02:40,500[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3016657528822238 prior_scale[0m
[[36m2024-07-08 12:02:40,517[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004730206491792868 q_scale[0m
[[36m2024-07-08 12:02:40,535[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.8687319350310035 obs_scale[0m
[[36m2024-07-08 12:02:40,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:02:40,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-07-08 12:02:40,547[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:02:40,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:02:41,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:02:41,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:02:41,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:02:41,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:02:41,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:02:41,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:02:41,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:02:41,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:02:41,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:02:41,563[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:02:41,571[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.91it/s v_num: 0.000
[[36m2024-07-08 12:02:45,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:02:45,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/053[0m
[[36m2024-07-08 12:02:45,509[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:02:45,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000868567472916665, lr[0m
[[36m2024-07-08 12:02:45,533[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:02:45,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3221764173646582 prior_scale[0m
[[36m2024-07-08 12:02:45,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017898029274959232 q_scale[0m
[[36m2024-07-08 12:02:45,572[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0452772178064849 obs_scale[0m
[[36m2024-07-08 12:02:45,583[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:02:45,583[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-07-08 12:02:45,583[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:02:45,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:02:46,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:02:46,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:02:46,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:02:46,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:02:46,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:02:46,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:02:46,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:02:46,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:02:46,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:02:46,585[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:02:46,593[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 17.28it/s v_num: 0.000
[[36m2024-07-08 12:03:25,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:03:25,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/054[0m
[[36m2024-07-08 12:03:25,537[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:03:25,560[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000834342582308276, lr[0m
[[36m2024-07-08 12:03:25,576[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:03:25,598[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.49245925519134 prior_scale[0m
[[36m2024-07-08 12:03:25,619[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017799859614281088 q_scale[0m
[[36m2024-07-08 12:03:25,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6495942671300459 obs_scale[0m
[[36m2024-07-08 12:03:25,657[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:03:25,657[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-07-08 12:03:25,658[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:03:25,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:03:26,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:03:26,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:03:26,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:03:26,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:03:26,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:03:26,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:03:26,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:03:26,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:03:26,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:03:26,763[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:03:26,775[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.60it/s v_num: 0.000
[[36m2024-07-08 12:03:29,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:03:29,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-08_11-43-07/056[0m
[[36m2024-07-08 12:03:29,783[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:03:29,799[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008980140535440974, lr[0m
[[36m2024-07-08 12:03:29,817[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:03:29,837[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.483721467726006 prior_scale[0m
[[36m2024-07-08 12:03:29,852[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018289842027083135 q_scale[0m
[[36m2024-07-08 12:03:29,869[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6673185645245474 obs_scale[0m
[[36m2024-07-08 12:03:29,888[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:03:29,888[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-07-08 12:03:29,888[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:03:29,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:03:30,978[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:03:30,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:03:30,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:03:30,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:03:30,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:03:30,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:03:30,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:03:30,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:03:30,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:03:31,022[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:03:31,032[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.96it/s v_num: 0.000
[[36m2024-07-08 12:03:59,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:03:59,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/055[0m
[[36m2024-07-08 12:03:59,174[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:03:59,196[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008980140535440974, lr[0m
[[36m2024-07-08 12:03:59,213[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:03:59,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.483721467726006 prior_scale[0m
[[36m2024-07-08 12:03:59,258[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018289842027083135 q_scale[0m
[[36m2024-07-08 12:03:59,280[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6673185645245474 obs_scale[0m
[[36m2024-07-08 12:03:59,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:03:59,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-07-08 12:03:59,298[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:03:59,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:04:00,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:04:00,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:04:00,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:04:00,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:04:00,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:04:00,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:04:00,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:04:00,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:04:00,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:04:00,401[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:04:00,412[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
 Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.96it/s v_num: 0.000
[[36m2024-07-08 12:04:32,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:04:32,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/056[0m
[[36m2024-07-08 12:04:33,106[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:04:33,127[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009168825295212765, lr[0m
[[36m2024-07-08 12:04:33,144[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:04:33,165[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4326826642047144 prior_scale[0m
[[36m2024-07-08 12:04:33,186[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001766174206238929 q_scale[0m
[[36m2024-07-08 12:04:33,207[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6695094449052109 obs_scale[0m
[[36m2024-07-08 12:04:33,224[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:04:33,224[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-07-08 12:04:33,224[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:04:33,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:04:34,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:04:34,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:04:34,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:04:34,301[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:04:34,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:04:34,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:04:34,303[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:04:34,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:04:34,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:04:34,330[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:04:34,338[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
  Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.98it/s v_num: 0.000
[[36m2024-07-08 12:05:06,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:05:06,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/057[0m
[[36m2024-07-08 12:05:06,521[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:05:06,540[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008716030149804184, lr[0m
[[36m2024-07-08 12:05:06,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:05:06,571[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4539866052082195 prior_scale[0m
[[36m2024-07-08 12:05:06,588[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017729550758208328 q_scale[0m
[[36m2024-07-08 12:05:06,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.47128938697817346 obs_scale[0m
[[36m2024-07-08 12:05:06,618[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:05:06,618[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-07-08 12:05:06,618[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:05:06,618[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:05:07,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:05:07,604[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:05:07,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:05:07,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:05:07,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:05:07,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:05:07,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:05:07,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:05:07,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:05:07,638[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:05:07,650[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 18.96it/s v_num: 0.000
[[36m2024-07-08 12:05:40,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:05:40,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/058[0m
[[36m2024-07-08 12:05:40,151[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-08 12:05:40,166[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000525341479623765, lr[0m
[[36m2024-07-08 12:05:40,179[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-08 12:05:40,193[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.41050038148070606 prior_scale[0m
[[36m2024-07-08 12:05:40,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003083385037917059 q_scale[0m
[[36m2024-07-08 12:05:40,223[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5916804857422464 obs_scale[0m
[[36m2024-07-08 12:05:40,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-08 12:05:40,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-07-08 12:05:40,236[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-08 12:05:40,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[848, 205, 453, 475, 414]
0.8 0.1 0.1
[493, 772, 240, 942, 886]
[[36m2024-07-08 12:05:41,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-08 12:05:41,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-08 12:05:41,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-08 12:05:41,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-08 12:05:41,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-08 12:05:41,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-08 12:05:41,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-08 12:05:41,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-08 12:05:41,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-08 12:05:41,244[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-08 12:05:41,256[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.2 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.2 K │
│ 5  │ net.functions.0               │ Sequential │  1.1 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    855 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.1 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    855 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.2 K                                                         
Non-trainable params: 0                                                         
Total params: 2.2 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 25/25 0:00:01 • 0:00:00 19.01it/s v_num: 0.000
[[36m2024-07-08 12:06:13,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-08 12:06:13,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-08_11-42-55/059[0m
[[36m2024-07-08 12:06:13,785[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-09 11:44:35,871[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-09 11:44:36,015[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-09 11:44:36,056[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-07-09 11:44:37,696[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <src.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-09 11:44:37,698[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <src.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-09 11:44:37,698[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <src.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-09 11:44:37,704[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-09 11:44:37,704[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-09 11:44:37,707[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-09 11:44:37,993[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:44:37,997[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:44:38,007[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:44:38,023[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-09 11:44:38,128[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-09 11:44:38,137[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-09 11:44:38,137[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:44:38,187[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:44:38,188[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:44:38,188[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-09 11:44:38,216[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-09 11:44:38,217[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-09 11:44:38,218[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-09 11:44:38,249[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-09 11:44:38,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-09 11:44:38,260[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-09 11:44:38,286[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:44:38,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-07-09 11:44:38,287[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:44:38,288[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-07-09 11:44:38,309[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-09 11:44:38,311[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-09 11:44:38,380[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:44:38,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-07-09 11:44:38,381[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:44:38,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-07-09 11:44:38,396[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:44:38,397[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-07-09 11:44:38,397[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:44:38,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:44:47,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:44:48,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:44:48,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:44:48,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:44:48,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:44:48,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:44:48,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:44:48,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:44:48,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:44:48,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:44:48,124[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:44:48,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:44:48,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:44:48,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:44:48,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:44:48,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:44:48,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:44:48,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:44:48,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:44:48,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:44:48,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:44:48,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:44:48,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:44:48,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:44:48,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:44:48,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:44:48,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:44:48,867[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:44:49,000[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:44:49,038[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:44:49,492[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:44:49,492[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:44:49,507[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
[[36m2024-07-09 11:44:49,508[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:44:49,520[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-07-09 11:44:50,694[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-07-09 11:44:52,270[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <src.tasks.hpsearch.objective_bnn>[0m
[[36m2024-07-09 11:44:52,279[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-07-09 11:44:52,590[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:44:52,623[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-07-09 11:44:52,685[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:44:52,738[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-07-09 11:44:52,763[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-07-09 11:44:52,825[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-07-09 11:44:52,864[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:44:52,865[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-07-09 11:44:52,865[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:44:52,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:45:02,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:45:02,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:45:02,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:45:02,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:45:02,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:45:02,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:45:02,439[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:45:02,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:45:02,448[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:45:02,673[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
��───────────────────────┴────────────┴────────┘
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 43.98it/s v_num: 0.000
[[36m2024-07-09 11:47:17,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:47:17,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/001[0m
[[36m2024-07-09 11:47:18,265[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:47:18,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-07-09 11:47:18,301[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:47:18,374[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-07-09 11:47:18,455[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-07-09 11:47:18,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-07-09 11:47:18,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:47:18,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-07-09 11:47:18,503[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:47:18,503[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:47:27,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:47:27,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:47:27,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:47:27,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:47:27,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:47:27,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:47:27,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:47:27,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:47:27,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:47:27,930[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:47:27,954[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
�━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.92it/s v_num: 0.000
[[36m2024-07-09 11:47:33,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:47:33,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/000[0m
[[36m2024-07-09 11:47:33,378[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:47:33,428[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-07-09 11:47:33,460[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:47:33,483[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-07-09 11:47:33,507[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-07-09 11:47:33,524[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-07-09 11:47:33,550[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:47:33,550[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-07-09 11:47:33,551[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:47:33,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:47:37,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:47:37,163[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:47:37,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:47:37,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:47:37,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:47:37,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:47:37,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:47:37,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:47:37,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:47:37,218[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:47:37,460[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:47:43,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:47:43,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:47:43,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:47:43,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:47:43,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:47:43,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:47:43,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:47:43,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:47:43,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:47:43,315[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:47:43,378[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 32.23it/s v_num: 0.000
[[36m2024-07-09 11:47:56,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:47:56,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/002[0m
[[36m2024-07-09 11:47:57,779[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:47:57,927[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-07-09 11:47:58,032[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:47:58,083[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-07-09 11:47:58,167[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-07-09 11:47:58,291[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-07-09 11:47:58,355[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:47:58,355[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-07-09 11:47:58,356[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:47:58,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:48:08,073[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:48:08,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:48:08,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:48:08,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:48:08,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:48:08,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:48:08,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:48:08,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:48:08,086[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:48:08,202[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:48:08,766[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:48:08,768[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 20.99it/s v_num: 0.000
[[36m2024-07-09 11:48:16,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:48:16,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/001[0m
[[36m2024-07-09 11:48:17,145[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:48:17,239[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-07-09 11:48:17,334[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:48:17,467[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-07-09 11:48:17,547[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-07-09 11:48:17,627[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-07-09 11:48:17,697[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:48:17,697[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-07-09 11:48:17,698[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:48:17,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 17.54it/s v_num: 0.000
[[36m2024-07-09 11:48:26,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:48:26,264[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/001[0m
[[36m2024-07-09 11:48:26,815[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:48:26,887[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-07-09 11:48:26,923[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:48:26,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-07-09 11:48:27,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-07-09 11:48:27,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-07-09 11:48:27,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:48:27,109[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-07-09 11:48:27,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:48:27,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:48:27,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:48:27,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:48:27,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:48:27,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:48:27,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:48:27,747[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:48:27,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:48:27,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:48:27,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:48:27,843[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:48:27,884[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:48:27,896[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:48:37,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:48:37,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:48:37,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:48:37,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:48:37,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:48:37,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:48:37,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:48:37,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:48:37,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:48:38,001[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:48:38,063[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:48:38,074[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 16.83it/s v_num: 0.000
[[36m2024-07-09 11:48:46,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:48:46,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/004[0m
[[36m2024-07-09 11:48:47,335[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:48:47,365[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-09 11:48:47,396[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:48:47,481[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-09 11:48:47,572[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-09 11:48:47,612[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-09 11:48:47,627[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 11:48:47,628[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-07-09 11:48:47,628[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:48:47,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:48:57,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:48:57,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:48:57,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:48:57,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:48:57,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:48:57,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:48:57,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:48:57,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:48:57,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:48:58,125[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:48:58,145[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 10.71it/s v_num: 0.000
[[36m2024-07-09 11:49:26,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:49:26,407[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/002[0m
[[36m2024-07-09 11:49:27,118[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:49:27,168[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-09 11:49:27,225[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:49:27,259[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-09 11:49:27,296[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-09 11:49:27,329[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-09 11:49:27,364[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 11:49:27,364[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-07-09 11:49:27,365[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:49:27,365[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 12.77it/s v_num: 0.000
[[36m2024-07-09 11:49:29,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:49:29,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/007[0m
[[36m2024-07-09 11:49:30,196[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:49:30,271[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-07-09 11:49:30,349[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:49:30,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-07-09 11:49:30,400[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-07-09 11:49:30,501[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-07-09 11:49:30,584[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:49:30,584[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-07-09 11:49:30,585[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:49:30,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:49:34,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:49:34,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:49:34,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:49:34,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:49:34,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:49:34,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:49:34,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:49:34,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:49:34,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:49:34,605[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:49:34,620[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:49:40,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:49:40,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:49:40,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:49:40,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:49:40,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:49:40,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:49:40,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:49:40,279[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:49:40,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:49:40,334[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:49:40,343[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 8.39it/s v_num: 0.000
[[36m2024-07-09 11:49:43,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:49:43,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/002[0m
[[36m2024-07-09 11:49:43,919[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:49:44,018[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-07-09 11:49:44,052[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:49:44,136[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-07-09 11:49:44,248[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-07-09 11:49:44,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-07-09 11:49:44,391[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 11:49:44,392[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-07-09 11:49:44,392[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:49:44,393[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:49:54,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:49:54,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:49:54,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:49:54,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:49:54,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:49:54,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:49:54,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:49:54,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:49:54,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:49:54,696[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:49:54,740[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.15it/s v_num: 0.000
[[36m2024-07-09 11:50:21,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:50:21,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/003[0m
[[36m2024-07-09 11:50:21,492[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:50:21,522[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-07-09 11:50:21,547[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:50:21,605[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-07-09 11:50:21,620[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-07-09 11:50:21,652[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-07-09 11:50:21,709[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:50:21,709[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-07-09 11:50:21,710[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:50:21,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:50:31,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:50:31,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:50:31,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:50:31,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:50:31,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:50:31,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:50:31,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:50:31,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:50:31,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:50:32,009[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:50:32,033[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:02 • 0:00:00 42.17it/s v_num: 0.000
[[36m2024-07-09 11:50:40,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:50:40,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/008[0m
[[36m2024-07-09 11:50:40,362[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:50:40,425[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-07-09 11:50:40,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:50:40,561[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-07-09 11:50:40,591[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-07-09 11:50:40,618[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-07-09 11:50:40,642[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:50:40,642[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-07-09 11:50:40,642[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:50:40,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:02 • 0:00:00 38.14it/s v_num: 0.000
[[36m2024-07-09 11:50:54,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:50:54,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/009[0m
[[36m2024-07-09 11:50:55,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:50:55,483[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006693944591857215, lr[0m
[[36m2024-07-09 11:50:55,551[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:50:55,613[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-07-09 11:50:55,636[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532753257812993 q_scale[0m
[[36m2024-07-09 11:50:55,683[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-07-09 11:50:55,746[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:50:55,746[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-07-09 11:50:55,747[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:50:55,747[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:50:57,539[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:50:57,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:50:57,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:50:57,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:50:57,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:50:57,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:50:57,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:50:57,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:50:57,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:50:57,690[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:50:57,703[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:51:05,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:51:05,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:51:05,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:51:05,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:51:05,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:51:05,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:51:05,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:51:05,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:51:05,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:51:05,231[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:51:05,260[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:51:05,267[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 40.31it/s v_num: 0.000
[[36m2024-07-09 11:51:26,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:51:26,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/010[0m
[[36m2024-07-09 11:51:26,805[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:51:26,839[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007593724599349318, lr[0m
[[36m2024-07-09 11:51:26,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:51:26,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-07-09 11:51:26,899[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001057083596191432 q_scale[0m
[[36m2024-07-09 11:51:26,918[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6015314001646519 obs_scale[0m
[[36m2024-07-09 11:51:26,932[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:51:26,932[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-07-09 11:51:26,933[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:51:26,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:51:36,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:51:36,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:51:36,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:51:36,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:51:36,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:51:36,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:51:36,127[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:51:36,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:51:36,128[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:51:36,166[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:51:36,175[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:51:36,176[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 40.15it/s v_num: 0.000
[[36m2024-07-09 11:52:11,993[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:52:12,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/012[0m
[[36m2024-07-09 11:52:12,970[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:52:13,056[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007315029607171022, lr[0m
[[36m2024-07-09 11:52:13,126[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:52:13,221[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.023313357110760373 prior_scale[0m
[[36m2024-07-09 11:52:13,320[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033098999638812355 q_scale[0m
[[36m2024-07-09 11:52:13,360[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7150991795028825 obs_scale[0m
[[36m2024-07-09 11:52:13,431[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:52:13,431[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-07-09 11:52:13,432[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:52:13,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:52:22,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:52:22,967[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:52:22,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:52:22,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:52:22,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:52:22,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:52:22,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:52:22,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:52:22,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:52:23,144[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:52:23,409[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:52:23,419[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params:.7 K                                                             
Total estimated model params size (MB): 0                                       
  Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 29.04it/s v_num: 0.000
[[36m2024-07-09 11:52:36,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:52:36,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/004[0m
[[36m2024-07-09 11:52:49,973[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:52:50,134[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-07-09 11:52:50,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:52:50,374[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-07-09 11:52:50,486[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-07-09 11:52:50,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-07-09 11:52:50,741[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:52:50,741[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-07-09 11:52:50,742[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:52:50,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:53:00,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:53:00,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:53:00,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:53:00,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:53:00,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:53:00,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:53:00,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:53:00,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:53:00,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:53:00,576[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:53:00,636[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:53:00,638[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.95it/s v_num: 0.000
[[36m2024-07-09 11:53:24,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:53:24,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/005[0m
[[36m2024-07-09 11:53:25,335[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:53:25,368[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-07-09 11:53:25,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:53:25,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-07-09 11:53:25,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-07-09 11:53:25,891[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-07-09 11:53:25,908[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:53:25,908[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-07-09 11:53:25,909[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:53:25,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 42.60it/s v_num: 0.000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [[36m2024-07-09 11:53:21,935[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:53:21,937[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       

[[36m2024-07-09 11:53:28,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:53:28,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/011[0m
[[36m2024-07-09 11:53:28,926[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:53:29,030[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004017236815022609, lr[0m
[[36m2024-07-09 11:53:29,536[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:53:29,691[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.026612116779992163 prior_scale[0m
[[36m2024-07-09 11:53:29,879[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006522452233346787 q_scale[0m
[[36m2024-07-09 11:53:29,903[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5379874760869617 obs_scale[0m
[[36m2024-07-09 11:53:29,920[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:53:29,921[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-07-09 11:53:29,921[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:53:29,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:53:35,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:53:35,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:53:35,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:53:35,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:53:35,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:53:35,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:53:35,926[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:53:35,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:53:35,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:53:36,013[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:53:36,028[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:53:36,029[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:53:39,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:53:39,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:53:39,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:53:39,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:53:39,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:53:39,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:53:39,697[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:53:39,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:53:39,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:53:39,744[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:53:39,752[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:53:39,753[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 24.37it/s v_num: 0.000
[[36m2024-07-09 11:53:53,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:53:53,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/005[0m
[[36m2024-07-09 11:53:54,309[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:53:54,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-07-09 11:53:54,373[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:53:54,392[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-07-09 11:53:54,416[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-07-09 11:53:54,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-07-09 11:53:54,443[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:53:54,443[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-07-09 11:53:54,443[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:53:54,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:54:04,082[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:54:04,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:54:04,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:54:04,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:54:04,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:54:04,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:54:04,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:54:04,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:54:04,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:54:04,542[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:54:04,596[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:54:04,613[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 35.24it/s v_num: 0.000
[[36m2024-07-09 11:54:21,430[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:54:21,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/015[0m
[[36m2024-07-09 11:54:22,026[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:54:22,101[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034066651754276173, lr[0m
[[36m2024-07-09 11:54:22,181[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:54:22,215[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16917318179496746 prior_scale[0m
[[36m2024-07-09 11:54:22,241[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020893343698365954 q_scale[0m
[[36m2024-07-09 11:54:22,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3064145046162923 obs_scale[0m
[[36m2024-07-09 11:54:22,320[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:54:22,320[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-07-09 11:54:22,321[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:54:22,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:54:31,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:54:32,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:54:32,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:54:32,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:54:32,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:54:32,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:54:32,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:54:32,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:54:32,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:54:32,154[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:54:32,196[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:54:32,198[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.90it/s v_num: 0.000
[[36m2024-07-09 11:55:24,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:55:24,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/014[0m
[[36m2024-07-09 11:55:24,629[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:55:24,692[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003207094884484382, lr[0m
[[36m2024-07-09 11:55:24,881[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:55:24,982[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20932710968921078 prior_scale[0m
[[36m2024-07-09 11:55:25,056[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0019757756370445355 q_scale[0m
[[36m2024-07-09 11:55:25,103[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3474634383053177 obs_scale[0m
[[36m2024-07-09 11:55:25,155[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:55:25,155[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-07-09 11:55:25,156[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:55:25,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:55:34,362[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:55:34,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:55:34,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:55:34,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:55:34,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:55:34,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:55:34,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:55:34,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:55:34,377[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:55:34,797[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:55:34,855[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:55:34,874[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.56it/s v_num: 0.000
[[36m2024-07-09 11:56:01,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:56:01,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/006[0m
[[36m2024-07-09 11:56:01,727[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:56:01,742[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-07-09 11:56:01,754[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:56:01,767[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-07-09 11:56:01,781[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-07-09 11:56:01,797[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-07-09 11:56:01,848[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:56:01,848[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-07-09 11:56:01,849[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:56:01,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 39.45it/s v_num: 0.000
[[36m2024-07-09 11:56:12,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:56:12,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/017[0m
[[36m2024-07-09 11:56:12,943[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:56:12,978[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003268343193517564, lr[0m
[[36m2024-07-09 11:56:13,019[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:56:13,039[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08094263488239263 prior_scale[0m
[[36m2024-07-09 11:56:13,083[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022040956629295182 q_scale[0m
[[36m2024-07-09 11:56:13,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3237566997049265 obs_scale[0m
[[36m2024-07-09 11:56:13,149[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:56:13,150[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-07-09 11:56:13,150[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:56:13,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
��━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:56:22,452[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:56:22,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:56:22,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:56:22,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:56:22,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:56:22,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:56:22,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:56:22,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:56:22,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:56:22,559[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:56:22,573[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:56:22,575[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.85it/s v_num: 0.000
[[36m2024-07-09 11:56:32,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:56:32,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/006[0m
[[36m2024-07-09 11:56:32,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:56:32,530[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-07-09 11:56:32,562[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:56:32,585[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-07-09 11:56:32,633[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-07-09 11:56:32,687[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-07-09 11:56:32,704[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 11:56:32,705[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-07-09 11:56:32,705[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:56:32,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:56:42,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:56:42,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:56:42,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:56:42,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:56:42,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:56:42,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:56:42,565[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:56:42,565[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:56:42,566[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:56:42,615[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:56:42,633[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 39.59it/s v_num: 0.000
[[36m2024-07-09 11:56:45,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:56:45,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/016[0m
[[36m2024-07-09 11:56:45,253[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:56:45,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003207094884484382, lr[0m
[[36m2024-07-09 11:56:45,300[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:56:45,351[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.07884448586381554 prior_scale[0m
[[36m2024-07-09 11:56:45,379[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006362944819598631 q_scale[0m
[[36m2024-07-09 11:56:45,425[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21851624497029568 obs_scale[0m
[[36m2024-07-09 11:56:45,445[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:56:45,446[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-07-09 11:56:45,446[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:56:45,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:56:54,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:56:54,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:56:54,763[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:56:54,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:56:54,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:56:54,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:56:54,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:56:54,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:56:54,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:56:54,803[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:56:54,908[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:56:54,910[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 10.31it/s v_num: 0.000
[[36m2024-07-09 11:57:04,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:57:04,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/007[0m
[[36m2024-07-09 11:57:04,938[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:57:04,963[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-07-09 11:57:05,029[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:57:05,050[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-07-09 11:57:05,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-07-09 11:57:05,109[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-07-09 11:57:05,146[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:57:05,146[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-07-09 11:57:05,147[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:57:05,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:57:14,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:57:14,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:57:14,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:57:14,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:57:14,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:57:14,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:57:14,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:57:14,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:57:14,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:57:14,724[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:57:14,740[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.43it/s v_num: 0.000
[[36m2024-07-09 11:57:42,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:57:42,966[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/007[0m
[[36m2024-07-09 11:57:43,301[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 11:57:43,341[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-07-09 11:57:43,370[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 11:57:43,450[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-07-09 11:57:43,584[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-07-09 11:57:43,728[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-07-09 11:57:43,763[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 11:57:43,763[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-07-09 11:57:43,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:57:43,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:57:53,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:57:53,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:57:53,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:57:53,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:57:53,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:57:53,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:57:53,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:57:53,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:57:53,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:57:53,296[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:57:53,345[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.55it/s v_num: 0.000
[[36m2024-07-09 11:58:25,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:58:25,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/018[0m
[[36m2024-07-09 11:58:25,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:58:25,379[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002717687466807556, lr[0m
[[36m2024-07-09 11:58:25,398[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:58:25,458[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10043756459327038 prior_scale[0m
[[36m2024-07-09 11:58:25,499[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0021671330022955924 q_scale[0m
[[36m2024-07-09 11:58:25,567[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21992593356579937 obs_scale[0m
[[36m2024-07-09 11:58:25,599[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 11:58:25,599[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-07-09 11:58:25,600[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:58:25,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:58:34,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:58:34,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:58:34,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:58:34,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:58:34,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:58:34,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:58:34,965[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:58:34,966[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:58:34,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:58:35,178[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:58:35,205[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:58:35,207[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/chec/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 28.44it/s v_num: 0.000
[[36m2024-07-09 11:59:23,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 11:59:23,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/008[0m
[[36m2024-07-09 11:59:23,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 11:59:23,567[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-07-09 11:59:23,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 11:59:23,596[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-07-09 11:59:23,611[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-07-09 11:59:23,626[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-07-09 11:59:23,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 11:59:23,641[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-07-09 11:59:23,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 11:59:23,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 11:59:33,101[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 11:59:33,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 11:59:33,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 11:59:33,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 11:59:33,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 11:59:33,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 11:59:33,122[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 11:59:33,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 11:59:33,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 11:59:33,323[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 11:59:33,382[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 11:59:33,391[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 13.26it/s v_num: 0.000
[[36m2024-07-09 12:00:13,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:00:13,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/009[0m
[[36m2024-07-09 12:00:13,524[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:00:13,545[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008749841130332734, lr[0m
[[36m2024-07-09 12:00:13,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:00:13,602[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-07-09 12:00:13,632[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011901958954178608 q_scale[0m
[[36m2024-07-09 12:00:13,659[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5416946309703993 obs_scale[0m
[[36m2024-07-09 12:00:13,680[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:00:13,681[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-07-09 12:00:13,681[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:00:13,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:00:23,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:00:23,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:00:23,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:00:23,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:00:23,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:00:23,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:00:23,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:00:23,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:00:23,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:00:23,954[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:00:23,973[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:00:23,976[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 20.96it/s v_num: 0.000
[[36m2024-07-09 12:00:37,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:00:37,124[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/019[0m
[[36m2024-07-09 12:00:37,494[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:00:37,538[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000222945797087718, lr[0m
[[36m2024-07-09 12:00:37,558[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:00:37,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1467446611512071 prior_scale[0m
[[36m2024-07-09 12:00:37,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002141173313346355 q_scale[0m
[[36m2024-07-09 12:00:37,663[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22778401142756444 obs_scale[0m
[[36m2024-07-09 12:00:37,703[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:00:37,703[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-07-09 12:00:37,704[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:00:37,704[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:00:47,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:00:47,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:00:47,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:00:47,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:00:47,279[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:00:47,279[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:00:47,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:00:47,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:00:47,281[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:00:47,369[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:00:47,432[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:00:47,434[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 12.57it/s v_num: 0.000
[[36m2024-07-09 12:01:06,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:01:06,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/009[0m
[[36m2024-07-09 12:01:06,576[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:01:06,622[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008749841130332734, lr[0m
[[36m2024-07-09 12:01:06,662[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:01:06,716[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.011399374124093269 prior_scale[0m
[[36m2024-07-09 12:01:06,773[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011901958954178608 q_scale[0m
[[36m2024-07-09 12:01:06,814[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5416946309703993 obs_scale[0m
[[36m2024-07-09 12:01:06,840[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:01:06,840[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-07-09 12:01:06,841[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:01:06,841[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.95it/s v_num: 0.000
[[36m2024-07-09 12:01:13,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:01:13,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/010[0m
[[36m2024-07-09 12:01:13,905[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:01:13,972[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004017236815022609, lr[0m
[[36m2024-07-09 12:01:14,035[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:01:14,055[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.026612116779992163 prior_scale[0m
[[36m2024-07-09 12:01:14,081[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033098999638812355 q_scale[0m
[[36m2024-07-09 12:01:14,138[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.7150991795028825 obs_scale[0m
[[36m2024-07-09 12:01:14,200[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:01:14,200[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-07-09 12:01:14,201[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:01:14,201[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:01:16,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:01:16,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:01:16,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:01:16,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:01:16,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:01:16,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:01:16,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:01:16,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:01:16,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:01:16,709[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:01:16,731[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:01:16,733[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:01:24,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:01:24,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:01:24,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:01:24,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:01:24,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:01:24,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:01:24,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:01:24,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:01:24,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:01:24,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:01:24,145[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:01:24,148[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.75it/s v_num: 0.000
[[36m2024-07-09 12:01:57,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:01:57,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/020[0m
[[36m2024-07-09 12:01:58,173[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:01:58,207[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004853005395787485, lr[0m
[[36m2024-07-09 12:01:58,246[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:01:58,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13281928662525783 prior_scale[0m
[[36m2024-07-09 12:01:58,367[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029061052305012526 q_scale[0m
[[36m2024-07-09 12:01:58,399[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21957967296898875 obs_scale[0m
[[36m2024-07-09 12:01:58,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:01:58,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[3[[36m2024-07-09 12:02:11,603[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:02:11,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:02:21,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:02:21,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:02:21,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:02:21,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:02:21,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:02:21,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:02:21,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:02:21,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:02:21,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:02:21,487[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:02:21,525[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:02:21,535[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 35.01it/s v_num: 0.000
[[36m2024-07-09 12:03:53,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:03:53,716[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/011[0m
[[36m2024-07-09 12:03:54,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:03:54,334[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5.958985968686439e-05, lr[0m
[[36m2024-07-09 12:03:54,370[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:03:54,410[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03552945073202078 prior_scale[0m
[[36m2024-07-09 12:03:54,433[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004951927991510019 q_scale[0m
[[36m2024-07-09 12:03:54,455[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5814436530662673 obs_scale[0m
[[36m2024-07-09 12:03:54,482[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:03:54,482[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-07-09 12:03:54,482[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:03:54,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:04:03,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:04:04,187[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:04:04,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:04:04,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:04:04,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:04:04,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:04:04,203[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:04:04,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:04:04,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:04:04,418[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:04:04,459[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:04:04,462[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.81it/s v_num: 0.000
[[36m2024-07-09 12:04:22,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:04:22,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/021[0m
[[36m2024-07-09 12:04:22,459[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:04:22,477[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004801370322291576, lr[0m
[[36m2024-07-09 12:04:22,518[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:04:22,540[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13905410901884774 prior_scale[0m
[[36m2024-07-09 12:04:22,568[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020148553020090916 q_scale[0m
[[36m2024-07-09 12:04:22,601[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22539739035886178 obs_scale[0m
[[36m2024-07-09 12:04:22,634[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:04:22,635[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-07-09 12:04:22,635[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:04:22,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:04:32,104[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:04:32,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:04:32,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:04:32,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:04:32,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:04:32,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:04:32,127[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:04:32,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:04:32,128[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:04:32,213[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:04:32,250[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:04:32,251[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.38it/s v_num: 0.000
[[36m2024-07-09 12:04:52,243[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:04:52,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/011[0m
[[36m2024-07-09 12:04:52,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:04:52,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5.958985968686439e-05, lr[0m
[[36m2024-07-09 12:04:52,518[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:04:52,584[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03552945073202078 prior_scale[0m
[[36m2024-07-09 12:04:52,621[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004951927991510019 q_scale[0m
[[36m2024-07-09 12:04:52,659[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5814436530662673 obs_scale[0m
[[36m2024-07-09 12:04:52,682[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:04:52,683[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-07-09 12:04:52,683[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:04:52,683[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:05:02,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:05:02,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:05:02,200[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:05:02,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:05:02,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:05:02,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:05:02,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:05:02,204[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:05:02,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:05:02,344[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:05:02,392[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:05:02,408[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.23it/s v_num: 0.000
[[36m2024-07-09 12:05:32,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:05:32,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/022[0m
[[36m2024-07-09 12:05:32,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:05:32,366[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005158327090136266, lr[0m
[[36m2024-07-09 12:05:32,388[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:05:32,409[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3330378044089423 prior_scale[0m
[[36m2024-07-09 12:05:32,440[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019104526865378524 q_scale[0m
[[36m2024-07-09 12:05:32,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21854903053744024 obs_scale[0m
[[36m2024-07-09 12:05:32,510[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:05:32,511[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-09 12:05:32,511[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:05:32,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:05:41,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:05:41,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:05:41,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:05:41,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:05:41,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:05:41,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:05:41,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:05:41,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:05:41,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:05:41,935[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:05:42,013[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:05:42,015[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.92it/s v_num: 0.000
[[36m2024-07-09 12:06:32,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:06:33,004[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/012[0m
[[36m2024-07-09 12:06:33,186[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:06:33,208[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 3.660410384294975e-05, lr[0m
[[36m2024-07-09 12:06:33,243[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:06:33,265[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.037304224190673876 prior_scale[0m
[[36m2024-07-09 12:06:33,288[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006758570283248524 q_scale[0m
[[36m2024-07-09 12:06:33,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5428257065996276 obs_scale[0m
[[36m2024-07-09 12:06:33,353[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:06:33,353[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-07-09 12:06:33,354[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:06:33,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:06:43,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:06:43,519[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:06:43,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:06:43,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:06:43,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:06:43,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:06:43,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:06:43,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:06:43,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:06:43,614[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:06:43,636[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:06:43,639[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 28.24it/s v_num: 0.000
[[36m2024-07-09 12:07:30,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:07:30,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/013[0m
[[36m2024-07-09 12:07:30,314[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:07:30,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00030874133209717074, lr[0m
[[36m2024-07-09 12:07:30,357[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:07:30,404[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014089063369792725 prior_scale[0m
[[36m2024-07-09 12:07:30,427[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014086225607513886 q_scale[0m
[[36m2024-07-09 12:07:30,464[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3762273452694772 obs_scale[0m
[[36m2024-07-09 12:07:30,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:07:30,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-07-09 12:07:30,481[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:07:30,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.87it/s v_num: 0.000
[[36m2024-07-09 12:07:31,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:07:31,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/012[0m
[[36m2024-07-09 12:07:31,774[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:07:31,797[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 3.660410384294975e-05, lr[0m
[[36m2024-07-09 12:07:31,813[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:07:31,874[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.037304224190673876 prior_scale[0m
[[36m2024-07-09 12:07:31,896[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006758570283248524 q_scale[0m
[[36m2024-07-09 12:07:31,915[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.5428257065996276 obs_scale[0m
[[36m2024-07-09 12:07:31,931[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:07:31,932[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-07-09 12:07:31,932[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:07:31,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:07:40,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:07:40,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:07:40,161[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:07:40,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:07:40,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:07:40,164[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:07:40,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:07:40,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:07:40,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:07:40,195[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:07:40,208[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:07:40,210[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:07:41,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:07:41,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:07:41,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:07:41,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:07:41,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:07:41,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:07:41,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:07:41,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:07:41,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:07:41,298[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:07:41,314[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:07:41,315[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.25it/s v_num: 0.000
[[36m2024-07-09 12:08:01,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:08:01,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/023[0m
[[36m2024-07-09 12:08:01,560[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:08:01,583[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004695441003605788, lr[0m
[[36m2024-07-09 12:08:01,598[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:08:01,618[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13418488837361053 prior_scale[0m
[[36m2024-07-09 12:08:01,639[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019349772425998236 q_scale[0m
[[36m2024-07-09 12:08:01,659[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22490378640005232 obs_scale[0m
[[36m2024-07-09 12:08:01,674[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:08:01,674[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-09 12:08:01,675[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:08:01,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:08:11,177[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:08:11,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:08:11,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:08:11,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:08:11,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:08:11,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:08:11,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:08:11,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:08:11,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:08:11,220[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:08:11,233[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:08:11,234[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.37it/s v_num: 0.000
[[36m2024-07-09 12:08:34,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:08:34,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/013[0m
[[36m2024-07-09 12:08:34,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:08:34,342[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00030874133209717074, lr[0m
[[36m2024-07-09 12:08:34,357[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:08:34,379[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014089063369792725 prior_scale[0m
[[36m2024-07-09 12:08:34,400[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014086225607513886 q_scale[0m
[[36m2024-07-09 12:08:34,422[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3762273452694772 obs_scale[0m
[[36m2024-07-09 12:08:34,438[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:08:34,438[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-07-09 12:08:34,438[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:08:34,439[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:08:43,914[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:08:43,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:08:43,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:08:43,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:08:43,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:08:43,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:08:43,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:08:43,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:08:43,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:08:43,961[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:08:43,978[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:08:43,980[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 24.00it/s v_num: 0.000
[[36m2024-07-09 12:09:09,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:09:09,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/024[0m
[[36m2024-07-09 12:09:10,136[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:09:10,157[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005251598046482949, lr[0m
[[36m2024-07-09 12:09:10,173[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:09:10,242[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.281869495444061 prior_scale[0m
[[36m2024-07-09 12:09:10,263[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018203598729772325 q_scale[0m
[[36m2024-07-09 12:09:10,295[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16802286669140307 obs_scale[0m
[[36m2024-07-09 12:09:10,310[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:09:10,311[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-07-09 12:09:10,311[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:09:10,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:09:19,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:09:19,604[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:09:19,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:09:19,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:09:19,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:09:19,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:09:19,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:09:19,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:09:19,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:09:19,646[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:09:19,654[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:09:19,655[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.83it/s v_num: 0.000
[[36m2024-07-09 12:10:06,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:10:06,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/014[0m
[[36m2024-07-09 12:10:06,454[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:10:06,505[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040270304267411367, lr[0m
[[36m2024-07-09 12:10:06,521[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:10:06,543[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01165476589566204 prior_scale[0m
[[36m2024-07-09 12:10:06,565[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010708589563582773 q_scale[0m
[[36m2024-07-09 12:10:06,587[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7817553254117744 obs_scale[0m
[[36m2024-07-09 12:10:06,603[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:10:06,603[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-07-09 12:10:06,604[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:10:06,604[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:10:15,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:10:23,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:10:23,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:10:23,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:10:23,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:10:23,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:10:23,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:10:23,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:10:23,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:10:23,696[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:10:23,706[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:10:23,709[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 33.27it/s v_num: 0.000
[[36m2024-07-09 12:11:23,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:11:23,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/014[0m
[[36m2024-07-09 12:11:23,217[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:11:23,240[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040270304267411367, lr[0m
[[36m2024-07-09 12:11:23,255[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:11:23,276[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01165476589566204 prior_scale[0m
[[36m2024-07-09 12:11:23,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010708589563582773 q_scale[0m
[[36m2024-07-09 12:11:23,318[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7817553254117744 obs_scale[0m
[[36m2024-07-09 12:11:23,334[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:11:23,334[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-07-09 12:11:23,335[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:11:23,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:11:32,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:11:32,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:11:32,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:11:32,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:11:32,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:11:32,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:11:32,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:11:32,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:11:32,882[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:11:32,923[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:11:32,935[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:11:32,937[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.95it/s v_num: 0.000
[[36m2024-07-09 12:11:46,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:11:46,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/025[0m
[[36m2024-07-09 12:11:46,759[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:11:46,775[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005617974603797491, lr[0m
[[36m2024-07-09 12:11:46,788[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:11:46,803[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.331150691426927 prior_scale[0m
[[36m2024-07-09 12:11:46,820[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015814109106890807 q_scale[0m
[[36m2024-07-09 12:11:46,843[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16570786516100633 obs_scale[0m
[[36m2024-07-09 12:11:46,859[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 12:11:46,860[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-07-09 12:11:46,860[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:11:46,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:11:56,105[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:11:56,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:11:56,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:11:56,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:11:56,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:11:56,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:11:56,115[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:11:56,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:11:56,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:11:56,147[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:11:56,160[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:11:56,161[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 24.20it/s v_num: 0.000
[[36m2024-07-09 12:12:44,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:12:44,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/026[0m
[[36m2024-07-09 12:12:44,227[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:12:44,249[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005333992864306848, lr[0m
[[36m2024-07-09 12:12:44,265[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:12:44,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3117610177333276 prior_scale[0m
[[36m2024-07-09 12:12:44,309[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014728033278776402 q_scale[0m
[[36m2024-07-09 12:12:44,331[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1857969828874201 obs_scale[0m
[[36m2024-07-09 12:12:44,346[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:12:44,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-09 12:12:44,347[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:12:44,347[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:12:54,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:12:54,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:12:54,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:12:54,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:12:54,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:12:54,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:12:54,383[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:12:54,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:12:54,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:12:54,423[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:12:54,432[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:12:54,433[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1 1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 22.57it/s v_num: 0.000
[[36m2024-07-09 12:13:44,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:13:44,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/027[0m
[[36m2024-07-09 12:13:44,792[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:13:44,808[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009932707999947526, lr[0m
[[36m2024-07-09 12:13:44,820[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:13:44,835[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04324985395282586 prior_scale[0m
[[36m2024-07-09 12:13:44,851[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003202601315135912 q_scale[0m
[[36m2024-07-09 12:13:44,866[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10306684414257386 obs_scale[0m
[[36m2024-07-09 12:13:44,879[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:13:44,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-07-09 12:13:44,880[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:13:44,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:13:28,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:13:28,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:13:28,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:13:28,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:13:28,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:13:28,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:13:28,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:13:28,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:13:28,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:13:28,690[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:13:28,715[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:13:28,716[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:13:54,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:13:54,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:13:54,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:13:54,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:13:54,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:13:54,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:13:54,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:13:54,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:13:54,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:13:54,410[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:13:54,424[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:13:54,426[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 31.37it/s v_num: 0.000
[[36m2024-07-09 12:14:08,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:14:08,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/015[0m
[[36m2024-07-09 12:14:08,777[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:14:08,792[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028642052312784607, lr[0m
[[36m2024-07-09 12:14:08,803[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:14:08,817[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.017699643187624833 prior_scale[0m
[[36m2024-07-09 12:14:08,830[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015123828390712098 q_scale[0m
[[36m2024-07-09 12:14:08,844[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3528427952088744 obs_scale[0m
[[36m2024-07-09 12:14:08,854[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:14:08,854[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-07-09 12:14:08,855[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:14:08,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:14:18,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:14:18,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:14:18,103[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:14:18,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:14:18,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:14:18,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:14:18,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:14:18,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:14:18,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:14:18,137[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:14:18,148[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:14:18,150[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 22.45it/s v_num: 0.000
[[36m2024-07-09 12:15:14,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:15:14,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/029[0m
[[36m2024-07-09 12:15:14,525[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:15:14,541[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002418991045153018, lr[0m
[[36m2024-07-09 12:15:14,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:15:14,567[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04954954158512333 prior_scale[0m
[[36m2024-07-09 12:15:14,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002899846538852978 q_scale[0m
[[36m2024-07-09 12:15:14,594[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10120104752907061 obs_scale[0m
[[36m2024-07-09 12:15:14,605[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:15:14,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[3024-07-09 12:15:31,193[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:15:31,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:15:40,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:15:40,815[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:15:40,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:15:40,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:15:40,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:15:40,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:15:40,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:15:40,819[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:15:40,819[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:15:40,861[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:15:40,874[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:15:40,876[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
   Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 31.55it/s v_num: 0.000
[[36m2024-07-09 12:16:55,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:16:55,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/016[0m
[[36m2024-07-09 12:16:55,989[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:16:56,011[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018259475214064708, lr[0m
[[36m2024-07-09 12:16:56,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:16:56,049[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.020350779708492812 prior_scale[0m
[[36m2024-07-09 12:16:56,070[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002952270024825563 q_scale[0m
[[36m2024-07-09 12:16:56,092[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6911848361119882 obs_scale[0m
[[36m2024-07-09 12:16:56,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:16:56,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-07-09 12:16:56,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:16:56,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.31it/s v_num: 0.000
[[36m2024-07-09 12:17:02,288[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2024-07-09 12:17:02,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:17:02,648[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:17:02,670[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000466563765989427, lr[0m
[[36m2024-07-09 12:17:02,687[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:17:02,708[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13002780776075887 prior_scale[0m
[[36m2024-07-09 12:17:02,730[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022727815648369335 q_scale[0m
[[36m2024-07-09 12:17:02,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2510331016397683 obs_scale[0m
[[36m2024-07-09 12:17:02,768[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:17:02,768[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-07-09 12:17:02,768[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:17:02,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:17:06,246[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:17:06,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:17:06,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:17:06,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:17:06,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:17:06,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:17:06,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:17:06,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:17:06,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:17:06,345[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:17:06,407[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:17:06,410[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:17:12,388[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:17:12,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:17:12,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:17:12,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:17:12,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:17:12,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:17:12,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:17:12,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:17:12,400[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:17:12,430[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:17:12,440[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:17:12,442[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.24it/s v_num: 0.000
[[36m2024-07-09 12:18:21,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:18:21,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/017[0m
[[36m2024-07-09 12:18:21,285[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:18:21,301[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 9.117879983306133e-05, lr[0m
[[36m2024-07-09 12:18:21,314[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:18:21,331[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0482824888204931 prior_scale[0m
[[36m2024-07-09 12:18:21,354[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002144494810423813 q_scale[0m
[[36m2024-07-09 12:18:21,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2687426847086829 obs_scale[0m
[[36m2024-07-09 12:18:21,393[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:18:21,393[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-07-09 12:18:21,394[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:18:21,394[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:18:32,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:18:32,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:18:32,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:18:32,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:18:32,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:18:32,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:18:32,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:18:32,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:18:32,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:18:32,333[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:18:32,351[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:18:32,353[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.51it/s v_num: 0.000
[[36m2024-07-09 12:18:46,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:18:46,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/031[0m
[[36m2024-07-09 12:18:46,887[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:18:46,930[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045545909979494246, lr[0m
[[36m2024-07-09 12:18:46,946[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:18:46,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13296813659391732 prior_scale[0m
[[36m2024-07-09 12:18:46,991[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023814053427689518 q_scale[0m
[[36m2024-07-09 12:18:47,013[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.253934298044683 obs_scale[0m
[[36m2024-07-09 12:18:47,029[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:18:47,030[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-07-09 12:18:47,030[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:18:47,030[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:18:56,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:18:56,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:18:56,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:18:56,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:18:56,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:18:56,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLchLightningPruningCallback>[0m
[[36m2024-07-09 12:19:06,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:19:06,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:19:06,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:19:06,483[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:19:06,500[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:19:06,502[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.05it/s v_num: 0.000
[[36m2024-07-09 12:20:06,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:20:06,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/017[0m
[[36m2024-07-09 12:20:06,534[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:20:06,563[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 9.117879983306133e-05, lr[0m
[[36m2024-07-09 12:20:06,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:20:06,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0482824888204931 prior_scale[0m
[[36m2024-07-09 12:20:06,632[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002144494810423813 q_scale[0m
[[36m2024-07-09 12:20:06,659[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2687426847086829 obs_scale[0m
[[36m2024-07-09 12:20:06,680[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:20:06,681[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-07-09 12:20:06,681[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:20:06,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:20:17,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:20:17,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:20:17,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:20:17,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:20:17,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:20:17,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:20:17,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:20:17,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:20:17,740[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:20:17,787[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:20:17,797[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:20:17,834[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.05it/s v_num: 0.000
[[36m2024-07-09 12:20:40,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:20:40,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/032[0m
[[36m2024-07-09 12:20:40,991[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:20:41,006[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004449079968604925, lr[0m
[[36m2024-07-09 12:20:41,018[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:20:41,033[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1276905938625638 prior_scale[0m
[[36m2024-07-09 12:20:41,049[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023893152105139138 q_scale[0m
[[36m2024-07-09 12:20:41,064[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25466053480915657 obs_scale[0m
[[36m2024-07-09 12:20:41,076[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:20:41,076[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-07-09 12:20:41,077[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:20:41,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 10.22it/s v_num: 0.000
[[36m2024-07-09 12:20:47,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:20:47,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/018[0m
[[36m2024-07-09 12:20:47,547[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:20:47,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5.102043984649523e-05, lr[0m
[[36m2024-07-09 12:20:47,591[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:20:47,617[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01840735251621294 prior_scale[0m
[[36m2024-07-09 12:20:47,642[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006820521087790581 q_scale[0m
[[36m2024-07-09 12:20:47,667[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.9441375642692655 obs_scale[0m
[[36m2024-07-09 12:20:47,686[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:20:47,686[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-07-09 12:20:47,687[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:20:47,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:20:50,379[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:20:50,386[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:20:50,387[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:20:50,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:20:50,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:20:50,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:20:50,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:20:50,391[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:20:50,392[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:20:50,430[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:20:50,460[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:20:50,463[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:20:57,989[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:20:57,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:20:57,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:20:57,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:20:57,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:20:57,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:20:58,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:20:58,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:20:58,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:20:58,030[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:20:58,040[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:20:58,041[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 30.72it/s v_num: 0.000
[[36m2024-07-09 12:21:52,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:21:52,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/019[0m
[[36m2024-07-09 12:21:52,142[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:21:52,161[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.111366268912434e-05, lr[0m
[[36m2024-07-09 12:21:52,178[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:21:52,196[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03983713871300368 prior_scale[0m
[[36m2024-07-09 12:21:52,216[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016364140659829292 q_scale[0m
[[36m2024-07-09 12:21:52,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0407928731506795 obs_scale[0m
[[36m2024-07-09 12:21:52,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:21:52,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-07-09 12:21:52,253[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:21:52,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:22:01,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:22:01,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:22:01,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:22:01,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:22:01,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:22:01,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:22:01,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:22:01,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:22:01,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:22:01,795[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:22:01,806[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:22:01,809[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.09it/s v_num: 0.000
[[36m2024-07-09 12:22:20,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:22:20,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/033[0m
[[36m2024-07-09 12:22:21,143[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:22:21,185[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011670336689028585, lr[0m
[[36m2024-07-09 12:22:21,206[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:22:21,228[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.26588007739555375 prior_scale[0m
[[36m2024-07-09 12:22:21,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001274733821419204 q_scale[0m
[[36m2024-07-09 12:22:21,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4072323695873015 obs_scale[0m
[[36m2024-07-09 12:22:21,304[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:22:21,304[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-09 12:22:21,305[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:22:21,305[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:22:30,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:22:30,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:22:30,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:22:30,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:22:30,712[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:22:30,712[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:22:30,713[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:22:30,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:22:30,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:22:30,753[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:22:30,762[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:22:30,763[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.52it/s v_num: 0.000
[[36m2024-07-09 12:23:56,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:23:56,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/019[0m
[[36m2024-07-09 12:23:56,951[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:23:56,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.111366268912434e-05, lr[0m
[[36m2024-07-09 12:23:56,983[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:23:57,000[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03983713871300368 prior_scale[0m
[[36m2024-07-09 12:23:57,018[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016364140659829292 q_scale[0m
[[36m2024-07-09 12:23:57,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0407928731506795 obs_scale[0m
[[36m2024-07-09 12:23:57,054[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:23:57,054[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-07-09 12:23:57,055[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:23:57,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:24:06,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:24:06,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:24:06,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:24:06,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:24:06,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:24:06,978[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:24:06,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:24:06,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:24:06,980[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:24:07,030[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:24:07,096[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:24:07,098[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.46it/s v_num: 0.000
[[36m2024-07-09 12:24:22,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:24:22,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/034[0m
[[36m2024-07-09 12:24:22,449[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:24:22,465[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 8.595839452067181e-05, lr[0m
[[36m2024-07-09 12:24:22,478[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:24:22,493[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.26594168224544845 prior_scale[0m
[[36m2024-07-09 12:24:22,508[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004477638555955167 q_scale[0m
[[36m2024-07-09 12:24:22,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12692466373361494 obs_scale[0m
[[36m2024-07-09 12:24:22,536[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:24:22,536[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-07-09 12:24:22,536[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:24:22,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:24:32,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:24:32,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:24:32,172[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:24:32,174[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:24:32,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:24:32,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:24:32,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:24:32,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:24:32,177[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:24:32,217[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:24:32,235[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 29.91it/s v_num: 0.000
[[36m2024-07-09 12:24:52,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:24:52,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/020[0m
[[36m2024-07-09 12:24:52,867[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:24:52,886[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00039407037916080795, lr[0m
[[36m2024-07-09 12:24:52,905[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:24:52,921[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.016060635371656577 prior_scale[0m
[[36m2024-07-09 12:24:52,937[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019215187595043512 q_scale[0m
[[36m2024-07-09 12:24:52,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.37527746383222377 obs_scale[0m
[[36m2024-07-09 12:24:52,966[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:24:52,966[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-07-09 12:24:52,966[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:24:52,967[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:25:02,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:25:02,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:25:02,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:25:02,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:25:02,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:25:02,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:25:02,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:25:02,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:25:02,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:25:02,953[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:25:03,005[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:25:03,009[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.58it/s v_num: 0.000
[[36m2024-07-09 12:25:59,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:25:59,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/035[0m
[[36m2024-07-09 12:25:59,747[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:25:59,763[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 6.986123667546036e-05, lr[0m
[[36m2024-07-09 12:25:59,794[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:25:59,811[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24340044127912186 prior_scale[0m
[[36m2024-07-09 12:25:59,829[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005245226066380773 q_scale[0m
[[36m2024-07-09 12:25:59,846[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13478663047797693 obs_scale[0m
[[36m2024-07-09 12:25:59,859[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 12:25:59,860[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-07-09 12:25:59,860[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:25:59,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:26:09,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:26:09,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:26:09,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:26:09,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:26:09,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:26:09,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:26:09,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:26:09,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:26:09,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:26:09,312[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:26:09,557[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.37it/s v_num: 0.000
[[36m2024-07-09 12:27:01,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:27:01,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/020[0m
[[36m2024-07-09 12:27:02,009[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:27:02,047[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018018035199200791, lr[0m
[[36m2024-07-09 12:27:02,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:27:02,127[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.02058406030177909 prior_scale[0m
[[36m2024-07-09 12:27:02,160[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022104733256752667 q_scale[0m
[[36m2024-07-09 12:27:02,197[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6259615429702018 obs_scale[0m
[[36m2024-07-09 12:27:02,248[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:27:02,249[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-07-09 12:27:02,249[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:27:02,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:27:11,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:27:11,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:27:11,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:27:11,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:27:11,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:27:11,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:27:11,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:27:11,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:27:11,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:27:11,971[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:27:11,981[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:27:11,984[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 29.94it/s v_num: 0.000
[[36m2024-07-09 12:27:51,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:27:51,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/021[0m
[[36m2024-07-09 12:27:51,295[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:27:51,322[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004999230517669421, lr[0m
[[36m2024-07-09 12:27:51,337[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:27:51,357[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.017692827351334647 prior_scale[0m
[[36m2024-07-09 12:27:51,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002265251566467407 q_scale[0m
[[36m2024-07-09 12:27:51,396[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3400594420025197 obs_scale[0m
[[36m2024-07-09 12:27:51,412[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:27:51,412[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-07-09 12:27:51,413[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:27:51,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:28:01,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:28:01,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:28:01,359[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:28:01,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:28:01,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:28:01,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:28:01,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:28:01,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:28:01,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:28:01,398[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:28:01,426[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:28:01,447[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.94it/s v_num: 0.000
[[36m2024-07-09 12:28:02,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:28:02,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/036[0m
[[36m2024-07-09 12:28:02,469[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:28:02,485[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007265148968245821, lr[0m
[[36m2024-07-09 12:28:02,499[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:28:02,514[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.40678536702728607 prior_scale[0m
[[36m2024-07-09 12:28:02,530[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003719995049486262 q_scale[0m
[[36m2024-07-09 12:28:02,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.253934298044683 obs_scale[0m
[[36m2024-07-09 12:28:02,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:28:02,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-07-09 12:28:02,559[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:28:02,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:28:11,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:28:11,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:28:11,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:28:11,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:28:11,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:28:11,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:28:11,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:28:11,945[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:28:11,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:28:12,030[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:28:12,097[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:28:12,099[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:07 • 0:00:00 27.28it/s v_num: 0.000
[[36m2024-07-09 12:30:15,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:30:15,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/021[0m
[[36m2024-07-09 12:30:15,651[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:30:15,671[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005322567184924785, lr[0m
[[36m2024-07-09 12:30:15,690[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:30:15,716[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.020067069701480884 prior_scale[0m
[[36m2024-07-09 12:30:15,741[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002036247796609009 q_scale[0m
[[36m2024-07-09 12:30:15,766[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.6711973586665511 obs_scale[0m
[[36m2024-07-09 12:30:15,785[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:30:15,786[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-07-09 12:30:15,786[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:30:15,787[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.48it/s v_num: 0.000
[[36m2024-07-09 12:30:20,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:30:20,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/038[0m
[[36m2024-07-09 12:30:20,861[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:30:20,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006428807372326742, lr[0m
[[36m2024-07-09 12:30:20,895[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:30:20,916[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04015867166169632 prior_scale[0m
[[36m2024-07-09 12:30:20,938[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008276178741911245 q_scale[0m
[[36m2024-07-09 12:30:20,960[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3535167365439502 obs_scale[0m
[[36m2024-07-09 12:30:20,976[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-12:30:25,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:30:25,903[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:30:25,914[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:30:25,916[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:30:31,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:30:31,077[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:30:31,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:30:31,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:30:31,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:30:31,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:30:31,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:30:31,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:30:31,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:30:31,121[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:30:31,169[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:30:31,170[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 13.03it/s v_num: 0.000
[[36m2024-07-09 12:30:56,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:30:56,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/040[0m
[[36m2024-07-09 12:30:56,994[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:30:57,009[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020401400664311233, lr[0m
[[36m2024-07-09 12:30:57,022[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:30:57,036[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11382235511365835 prior_scale[0m
[[36m2024-07-09 12:30:57,051[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040423827500196165 q_scale[0m
[[36m2024-07-09 12:30:57,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.25202192566238907 obs_scale[0m
[[36m2024-07-09 12:30:57,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 12:30:57,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-07-09 12:30:57,079[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:30:57,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
5farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:31:06,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:31:06,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:31:06,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:31:06,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:31:06,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:31:06,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:31:06,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:31:06,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:31:06,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:31:06,681[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:31:06,696[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 19.10it/s v_num: 0.000
[[36m2024-07-09 12:31:51,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:31:51,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/039[0m
[[36m2024-07-09 12:31:51,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:31:51,272[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004163198003771243, lr[0m
[[36m2024-07-09 12:31:51,288[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:31:51,309[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.086172604076023 prior_scale[0m
[[36m2024-07-09 12:31:51,332[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025914917360152646 q_scale[0m
[[36m2024-07-09 12:31:51,353[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19058589977854268 obs_scale[0m
[[36m2024-07-09 12:31:51,368[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:31:51,369[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-07-09 12:31:51,369[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:31:51,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:31:49,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:31:49,823[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:31:49,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:31:49,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:31:49,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:31:49,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:31:49,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:31:49,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:31:49,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:31:49,856[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:31:49,866[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:31:49,867[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:32:01,230[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:32:01,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:32:01,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:32:01,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:32:01,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:32:01,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:32:01,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:32:01,242[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:32:01,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:32:01,273[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:32:01,307[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:32:01,308[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 29.49it/s v_num: 0.000
[[36m2024-07-09 12:33:40,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:33:40,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/022[0m
[[36m2024-07-09 12:33:40,675[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:33:40,698[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005186379518449633, lr[0m
[[36m2024-07-09 12:33:40,713[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:33:40,734[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.02841893165929124 prior_scale[0m
[[36m2024-07-09 12:33:40,750[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005683052700954933 q_scale[0m
[[36m2024-07-09 12:33:40,771[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.37754247367292065 obs_scale[0m
[[36m2024-07-09 12:33:40,787[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:33:40,787[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-07-09 12:33:40,787[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:33:40,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.97it/s v_num: 0.000
[[36m2024-07-09 12:33:47,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:33:47,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/023[0m
[[36m2024-07-09 12:33:47,836[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:33:47,855[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005625829206379815, lr[0m
[[36m2024-07-09 12:33:47,871[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:33:47,890[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.023886703213580007 prior_scale[0m
[[36m2024-07-09 12:33:47,908[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023486709212693028 q_scale[0m
[[36m2024-07-09 12:33:47,927[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.223751301534023 obs_scale[0m
[[36m2024-07-09 12:33:47,943[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:33:47,944[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-09 12:33:47,944[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:33:47,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:33:50,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:33:50,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:33:50,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:33:50,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:33:50,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:33:50,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:33:50,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:33:50,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:33:50,709[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:33:50,749[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:33:50,759[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:33:50,760[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:33:57,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:33:57,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:33:57,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:33:57,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:33:57,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:33:57,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:33:57,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:33:57,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:33:57,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:33:57,524[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:33:57,537[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:33:57,538[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:07 • 0:00:00 24.45it/s v_num: 0.000
[[36m2024-07-09 12:35:17,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:35:17,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/042[0m
[[36m2024-07-09 12:35:17,930[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:35:17,949[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004114250383986451, lr[0m
[[36m2024-07-09 12:35:17,963[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:35:17,982[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17246494038632174 prior_scale[0m
[[36m2024-07-09 12:35:17,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015089787619899188 q_scale[0m
[[36m2024-07-09 12:35:18,014[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19322946312093678 obs_scale[0m
[[36m2024-07-09 12:35:18,028[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:35:18,029[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-07-09 12:35:18,029[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:35:18,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:35:27,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:35:27,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:35:27,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:35:27,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:35:27,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:35:27,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:35:27,306[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:35:27,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:35:27,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:35:27,363[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:35:27,392[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:35:27,394[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.15it/s v_num: 0.000
[[36m2024-07-09 12:36:10,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:36:10,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/043[0m
[[36m2024-07-09 12:36:11,142[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:36:11,167[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002682859877991928, lr[0m
[[36m2024-07-09 12:36:11,186[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:36:11,211[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1800065924551213 prior_scale[0m
[[36m2024-07-09 12:36:11,236[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016751356929913205 q_scale[0m
[[36m2024-07-09 12:36:11,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1389306608628457 obs_scale[0m
[[36m2024-07-09 12:36:11,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:36:11,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-07-09 12:36:11,280[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:36:11,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:36:21,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:36:21,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:36:21,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:36:21,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:36:21,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:36:21,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:36:21,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:36:21,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:36:21,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:36:21,308[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:36:21,324[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:36:21,326[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 29.94it/s v_num: 0.000
[[36m2024-07-09 12:36:37,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:36:37,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/023[0m
[[36m2024-07-09 12:36:38,054[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:36:38,070[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005360447562282061, lr[0m
[[36m2024-07-09 12:36:38,086[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:36:38,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03032685423453513 prior_scale[0m
[[36m2024-07-09 12:36:38,131[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005443232364930968 q_scale[0m
[[36m2024-07-09 12:36:38,155[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.36047624368319253 obs_scale[0m
[[36m2024-07-09 12:36:38,170[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:36:38,170[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-07-09 12:36:38,171[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:36:38,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 30.56it/s v_num: 0.000
[[36m2024-07-09 12:36:44,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:36:44,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/024[0m
[[36m2024-07-09 12:36:45,076[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:36:45,095[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005719934938898689, lr[0m
[[36m2024-07-09 12:36:45,110[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:36:45,130[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.025040936490645836 prior_scale[0m
[[36m2024-07-09 12:36:45,150[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022495451054058643 q_scale[0m
[[36m2024-07-09 12:36:45,170[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21544288868301126 obs_scale[0m
[[36m2024-07-09 12:36:45,184[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:36:45,185[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-09 12:36:45,185[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:36:45,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:36:47,875[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:36:47,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:36:47,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:36:47,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:36:47,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:36:47,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:36:47,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:36:47,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:36:47,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:36:47,913[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:36:47,921[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:36:47,923[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:36:55,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:36:58,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:36:58,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:37:00,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:37:00,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:37:00,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:37:00,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:37:00,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:37:00,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:37:01,295[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:37:02,142[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:37:02,191[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 13.74it/s v_num: 0.000
[[36m2024-07-09 12:37:26,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:37:26,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/025[0m
[[36m2024-07-09 12:37:26,783[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:37:26,799[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005141309049827428, lr[0m
[[36m2024-07-09 12:37:26,813[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:37:26,829[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01034003171587243 prior_scale[0m
[[36m2024-07-09 12:37:26,847[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002446581196600478 q_scale[0m
[[36m2024-07-09 12:37:26,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2945653521600191 obs_scale[0m
[[36m2024-07-09 12:37:26,875[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:37:26,876[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-07-09 12:37:26,876[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:37:26,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:37:36,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:37:36,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:37:36,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:37:36,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:37:36,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:37:36,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:37:36,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:37:36,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:37:36,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:37:36,694[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:37:36,724[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 24.38it/s v_num: 0.000
[[36m2024-07-09 12:38:53,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:38:53,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/044[0m
[[36m2024-07-09 12:38:53,214[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:38:53,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008336119404230371, lr[0m
[[36m2024-07-09 12:38:53,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:38:53,271[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11821594564013159 prior_scale[0m
[[36m2024-07-09 12:38:53,292[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0056538195702332955 q_scale[0m
[[36m2024-07-09 12:38:53,313[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14360346971240917 obs_scale[0m
[[36m2024-07-09 12:38:53,328[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:38:53,329[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-09 12:38:53,329[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:38:53,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:39:02,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:39:02,701[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:39:02,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:39:02,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:39:02,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:39:02,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:39:02,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:39:02,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:39:02,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:39:02,743[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:39:02,763[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:39:02,764[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:06 • 0:00:00 28.66it/s v_num: 0.000
[[36m2024-07-09 12:39:53,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:39:53,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/024[0m
[[36m2024-07-09 12:39:53,310[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:39:53,327[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005719934938898689, lr[0m
[[36m2024-07-09 12:39:53,341[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:39:53,358[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06250540222971072 prior_scale[0m
[[36m2024-07-09 12:39:53,374[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007496325703921275 q_scale[0m
[[36m2024-07-09 12:39:53,390[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3449099417333888 obs_scale[0m
[[36m2024-07-09 12:39:53,403[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:39:53,404[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-07-09 12:39:53,404[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:39:53,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:40:03,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:40:03,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:40:03,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:40:03,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:40:03,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:40:03,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:40:03,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:40:03,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:40:03,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:40:03,878[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:40:03,922[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:40:03,925[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 11.96it/s v_num: 0.000
[[36m2024-07-09 12:40:30,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:40:30,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/025[0m
[[36m2024-07-09 12:40:30,453[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:40:30,476[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000257804685546723, lr[0m
[[36m2024-07-09 12:40:30,492[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:40:30,515[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014949993606760005 prior_scale[0m
[[36m2024-07-09 12:40:30,537[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009567835998820782 q_scale[0m
[[36m2024-07-09 12:40:30,559[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22927495912359605 obs_scale[0m
[[36m2024-07-09 12:40:30,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:40:30,574[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-07-09 12:40:30,574[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:40:30,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.69it/s v_num: 0.000
[[36m2024-07-09 12:40:38,540[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:40:38,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/045[0m
[[36m2024-07-09 12:40:38,658[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:40:38,674[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005966494620707108, lr[0m
[[36m2024-07-09 12:40:38,686[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:40:38,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11711237092149585 prior_scale[0m
[[36m2024-07-09 12:40:38,717[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.005562815180252588 q_scale[0m
[[36m2024-07-09 12:40:38,732[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2747445460023778 obs_scale[0m
[[36m2024-07-09 12:40:38,745[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 12:40:38,745[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-07-09 12:40:38,745[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:40:38,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:40:39,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:40:39,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:40:39,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:40:39,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:40:39,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:40:39,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:40:39,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:40:39,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:40:39,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:40:39,957[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:40:39,969[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:40:48,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:40:48,992[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:40:48,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:40:48,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:40:48,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:40:48,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:40:48,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:40:48,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:40:48,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:40:49,037[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:40:49,062[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:40:49,064[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 12.63it/s v_num: 0.000
[[36m2024-07-09 12:41:15,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:41:15,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/047[0m
[[36m2024-07-09 12:41:15,258[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:41:15,274[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008670116122509364, lr[0m
[[36m2024-07-09 12:41:15,287[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:41:15,302[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22875280905064282 prior_scale[0m
[[36m2024-07-09 12:41:15,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001257747559108068 q_scale[0m
[[36m2024-07-09 12:41:15,335[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3987880946462159 obs_scale[0m
[[36m2024-07-09 12:41:15,348[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 12:41:15,348[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-09 12:41:15,348[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:41:15,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:41:25,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:41:25,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:41:25,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:41:25,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:41:25,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:41:25,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:41:25,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:41:25,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:41:25,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:41:25,180[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:41:25,190[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 15.76it/s v_num: 0.000
[[36m2024-07-09 12:42:00,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:42:00,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/048[0m
[[36m2024-07-09 12:42:00,740[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:42:00,765[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008403355829671186, lr[0m
[[36m2024-07-09 12:42:00,782[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:42:00,806[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06688348411926652 prior_scale[0m
[[36m2024-07-09 12:42:00,829[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003560512857748518 q_scale[0m
[[36m2024-07-09 12:42:00,854[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1507478281603475 obs_scale[0m
[[36m2024-07-09 12:42:00,871[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:42:00,872[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-07-09 12:42:00,872[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:42:00,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.72it/s v_num: 0.000
[[36m2024-07-09 12:42:03,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:42:03,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/026[0m
[[36m2024-07-09 12:42:03,631[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:42:03,649[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00055418535323638, lr[0m
[[36m2024-07-09 12:42:03,664[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:42:03,683[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010985920525294304 prior_scale[0m
[[36m2024-07-09 12:42:03,700[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00069485723020072 q_scale[0m
[[36m2024-07-09 12:42:03,717[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1973985513762963 obs_scale[0m
[[36m2024-07-09 12:42:03,731[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:42:03,732[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-07-09 12:42:03,732[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:42:03,732[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:42:10,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:42:10,539[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:42:10,540[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:42:10,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:42:10,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:42:10,543[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:42:10,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:42:10,544[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:42:10,545[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:42:10,579[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:42:10,593[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:42:10,595[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:42:13,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:42:13,272[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:42:13,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:42:13,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:42:13,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:42:13,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:42:13,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:42:13,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:42:13,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:42:13,308[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:42:13,319[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 24.01it/s v_num: 0.000
[[36m2024-07-09 12:42:24,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:42:24,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/046[0m
[[36m2024-07-09 12:42:24,985[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:42:25,008[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 3.9682030476334534e-05, lr[0m
[[36m2024-07-09 12:42:25,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:42:25,046[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1498189651654043 prior_scale[0m
[[36m2024-07-09 12:42:25,068[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003692961794959635 q_scale[0m
[[36m2024-07-09 12:42:25,090[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.31232063252503955 obs_scale[0m
[[36m2024-07-09 12:42:25,106[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 12:42:25,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-07-09 12:42:25,107[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:42:25,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:42:34,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:42:34,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:42:34,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:42:34,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:42:34,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:42:34,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:42:34,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:42:34,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:42:34,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:42:34,530[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:42:34,541[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:42:34,542[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 23.35it/s v_num: 0.000
[[36m2024-07-09 12:44:19,962[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:44:19,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/050[0m
[[36m2024-07-09 12:44:20,573[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:44:20,595[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006213576606152639, lr[0m
[[36m2024-07-09 12:44:20,612[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:44:20,633[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.39234355845865015 prior_scale[0m
[[36m2024-07-09 12:44:20,655[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001190380701183488 q_scale[0m
[[36m2024-07-09 12:44:20,725[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.7377716640268721 obs_scale[0m
[[36m2024-07-09 12:44:20,809[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:44:20,810[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-07-09 12:44:20,810[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:44:20,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:44:30,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:44:30,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:44:30,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:44:30,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:44:30,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:44:30,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:44:30,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:44:30,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:44:30,203[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:44:30,241[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:44:30,251[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:44:30,252[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.92it/s v_num: 0.000
[[36m2024-07-09 12:45:11,430[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:45:11,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/026[0m
[[36m2024-07-09 12:45:11,746[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:45:11,775[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005313587978834153, lr[0m
[[36m2024-07-09 12:45:11,803[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:45:11,870[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.027574464846751044 prior_scale[0m
[[36m2024-07-09 12:45:11,894[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010458829693953697 q_scale[0m
[[36m2024-07-09 12:45:11,942[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2140382489166965 obs_scale[0m
[[36m2024-07-09 12:45:12,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:45:12,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-07-09 12:45:12,028[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:45:12,028[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:45:21,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:45:21,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:45:21,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:45:21,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:45:21,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:45:21,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:45:21,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:45:21,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:45:21,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:45:21,819[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:45:21,830[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 21.24it/s v_num: 0.000
[[36m2024-07-09 12:46:02,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:46:02,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/049[0m
[[36m2024-07-09 12:46:03,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:46:03,135[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004921696816777877, lr[0m
[[36m2024-07-09 12:46:03,157[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:46:03,482[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09926927877189952 prior_scale[0m
[[36m2024-07-09 12:46:03,513[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023177823714760722 q_scale[0m
[[36m2024-07-09 12:46:03,542[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21934875230911344 obs_scale[0m
[[36m2024-07-09 12:46:03,563[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:46:03,563[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-07-09 12:46:03,564[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:46:03,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:46:12,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:46:13,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:46:13,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:46:13,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:46:13,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:46:13,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:46:13,023[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:46:13,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:46:13,024[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:46:13,111[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:46:13,124[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:46:13,125[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.51it/s v_num: 0.000
[[36m2024-07-09 12:46:50,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:46:50,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/027[0m
[[36m2024-07-09 12:46:50,409[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:46:50,428[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019987547410029686, lr[0m
[[36m2024-07-09 12:46:50,443[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:46:50,460[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010814761914964142 prior_scale[0m
[[36m2024-07-09 12:46:50,478[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000693719437129268 q_scale[0m
[[36m2024-07-09 12:46:50,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19656104229936433 obs_scale[0m
[[36m2024-07-09 12:46:50,511[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:46:50,511[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-09 12:46:50,512[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:46:50,512[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:46:59,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:47:00,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:47:00,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:47:00,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:47:00,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:47:00,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:47:00,007[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:47:00,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:47:00,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:47:00,038[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:47:00,091[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.99it/s v_num: 0.000
[[36m2024-07-09 12:47:57,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:47:57,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/051[0m
[[36m2024-07-09 12:47:57,582[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:47:57,597[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046866623406249184, lr[0m
[[36m2024-07-09 12:47:57,609[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:47:57,630[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13783857049273862 prior_scale[0m
[[36m2024-07-09 12:47:57,651[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020633484077463141 q_scale[0m
[[36m2024-07-09 12:47:57,672[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22273948510322739 obs_scale[0m
[[36m2024-07-09 12:47:57,688[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:47:57,689[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-07-09 12:47:57,689[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:47:57,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:48:06,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:48:06,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:48:06,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:48:06,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:48:06,808[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:48:06,808[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:48:06,809[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:48:06,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:48:06,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:48:06,856[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:48:06,870[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:48:06,872[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.20it/s v_num: 0.000
[[36m2024-07-09 12:49:49,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:49:49,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/027[0m
[[36m2024-07-09 12:49:49,967[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:49:49,989[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006809091386232948, lr[0m
[[36m2024-07-09 12:49:50,004[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:49:50,025[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.014646983392804708 prior_scale[0m
[[36m2024-07-09 12:49:50,046[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010389361123585986 q_scale[0m
[[36m2024-07-09 12:49:50,067[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21037655527255994 obs_scale[0m
[[36m2024-07-09 12:49:50,081[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:49:50,082[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-07-09 12:49:50,082[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:49:50,082[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:49:59,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:49:59,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:49:59,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:49:59,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:49:59,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:49:59,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:49:59,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:49:59,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:49:59,709[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:49:59,747[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:49:59,771[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 21.02it/s v_num: 0.000
[[36m2024-07-09 12:49:59,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:49:59,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/052[0m
[[36m2024-07-09 12:49:59,979[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:49:59,999[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00039347688502487915, lr[0m
[[36m2024-07-09 12:50:00,017[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:50:00,042[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19636015090940165 prior_scale[0m
[[36m2024-07-09 12:50:00,068[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020801861314004568 q_scale[0m
[[36m2024-07-09 12:50:00,094[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16626014015920393 obs_scale[0m
[[36m2024-07-09 12:50:00,112[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:50:00,113[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-07-09 12:50:00,113[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:50:00,113[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:50:09,580[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:50:09,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:50:09,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:50:09,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:50:09,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:50:09,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:50:09,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:50:09,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:50:09,591[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:50:09,623[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:50:09,635[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:50:09,637[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.87it/s v_num: 0.000
[[36m2024-07-09 12:51:29,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:51:29,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/028[0m
[[36m2024-07-09 12:51:30,060[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:51:30,078[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006278807689564025, lr[0m
[[36m2024-07-09 12:51:30,091[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:51:30,112[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010349329101544288 prior_scale[0m
[[36m2024-07-09 12:51:30,132[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043286471603527045 q_scale[0m
[[36m2024-07-09 12:51:30,153[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14245110886675758 obs_scale[0m
[[36m2024-07-09 12:51:30,168[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:51:30,168[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-07-09 12:51:30,169[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:51:30,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:51:38,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:51:38,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:51:38,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:51:38,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:51:38,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:51:38,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:51:38,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:51:38,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:51:38,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:51:38,195[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:51:38,216[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:51:38,218[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farri�━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                     Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 21.81it/s v_num: 0.000
[[36m2024-07-09 12:54:00,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:54:00,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/054[0m
[[36m2024-07-09 12:54:00,833[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:54:00,858[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002823950334419046, lr[0m
[[36m2024-07-09 12:54:00,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:54:00,901[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09751427097783794 prior_scale[0m
[[36m2024-07-09 12:54:00,926[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012951189294052725 q_scale[0m
[[36m2024-07-09 12:54:00,950[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2829581726476467 obs_scale[0m
[[36m2024-07-09 12:54:00,968[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:54:00,968[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-07-09 12:54:00,969[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:54:00,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:54:10,902[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:54:10,908[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:54:10,909[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:54:10,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:54:10,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:54:10,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:54:10,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:54:10,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:54:10,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:54:10,956[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:54:10,987[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:54:10,990[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.93it/s v_num: 0.000
[[36m2024-07-09 12:54:26,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:54:26,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/028[0m
[[36m2024-07-09 12:54:26,189[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:54:26,213[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007066142834034308, lr[0m
[[36m2024-07-09 12:54:26,230[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:54:26,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01440471794869433 prior_scale[0m
[[36m2024-07-09 12:54:26,275[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0021749953299007745 q_scale[0m
[[36m2024-07-09 12:54:26,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.212158310643502 obs_scale[0m
[[36m2024-07-09 12:54:26,314[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:54:26,314[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-07-09 12:54:26,315[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:54:26,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:54:35,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:54:35,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:54:35,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:54:35,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:54:35,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:54:35,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:54:35,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:54:35,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:54:35,999[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:54:36,030[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:54:36,042[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.21it/s v_num: 0.000
[[36m2024-07-09 12:55:04,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:55:04,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/055[0m
[[36m2024-07-09 12:55:04,649[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:55:04,670[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002762579301146922, lr[0m
[[36m2024-07-09 12:55:04,684[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:55:04,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.07399877020433666 prior_scale[0m
[[36m2024-07-09 12:55:04,718[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0027061484579067327 q_scale[0m
[[36m2024-07-09 12:55:04,735[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3466290088038608 obs_scale[0m
[[36m2024-07-09 12:55:04,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 12:55:04,752[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-07-09 12:55:04,752[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:55:04,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:55:14,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:55:14,303[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:55:14,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:55:14,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:55:14,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:55:14,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:55:14,306[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:55:14,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:55:14,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:55:14,344[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:55:14,407[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:55:14,408[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 ──────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.93it/s v_num: 0.000
[[36m2024-07-09 12:56:18,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:56:18,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/057[0m
[[36m2024-07-09 12:56:18,467[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:56:18,485[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005154469847124106, lr[0m
[[36m2024-07-09 12:56:18,501[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:56:18,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11652673231535852 prior_scale[0m
[[36m2024-07-09 12:56:18,545[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002812746633534169 q_scale[0m
[[36m2024-07-09 12:56:18,566[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.380485683893914 obs_scale[0m
[[36m2024-07-09 12:56:18,580[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:56:18,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-07-09 12:56:18,581[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:56:18,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:56:27,973[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:56:27,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:56:27,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:56:27,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:56:27,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:56:27,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:56:27,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:56:27,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:56:27,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:56:28,012[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:56:28,024[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.46it/s v_num: 0.000
[[36m2024-07-09 12:58:54,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:58:54,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/029[0m
[[36m2024-07-09 12:58:54,808[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 12:58:54,823[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003867735852746079, lr[0m
[[36m2024-07-09 12:58:54,837[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 12:58:54,856[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010159514761175386 prior_scale[0m
[[36m2024-07-09 12:58:54,878[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0023323736943132523 q_scale[0m
[[36m2024-07-09 12:58:54,898[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19683990525920253 obs_scale[0m
[[36m2024-07-09 12:58:54,912[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:58:54,912[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-07-09 12:58:54,912[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:58:54,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:59:04,257[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:59:04,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:59:04,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:59:04,265[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:59:04,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:59:04,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:59:04,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:59:04,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:59:04,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:59:04,313[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:59:04,327[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 21.46it/s v_num: 0.000
[[36m2024-07-09 12:59:06,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:59:06,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/058[0m
[[36m2024-07-09 12:59:06,648[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:59:06,665[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001342070434359012, lr[0m
[[36m2024-07-09 12:59:06,679[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:59:06,696[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12177266138430187 prior_scale[0m
[[36m2024-07-09 12:59:06,713[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003079151605537499 q_scale[0m
[[36m2024-07-09 12:59:06,730[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2033770057392642 obs_scale[0m
[[36m2024-07-09 12:59:06,744[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:59:06,744[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 060 __________________[0m
[[36m2024-07-09 12:59:06,744[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:59:06,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 12:59:16,316[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 12:59:16,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 12:59:16,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 12:59:16,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 12:59:16,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 12:59:16,327[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 12:59:16,328[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 12:59:16,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 12:59:16,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 12:59:16,365[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 12:59:16,377[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 12:59:16,379[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.90it/s v_num: 0.000
[[36m2024-07-09 12:59:55,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 12:59:55,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/059[0m
[[36m2024-07-09 12:59:55,674[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 12:59:55,690[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006731733005526337, lr[0m
[[36m2024-07-09 12:59:55,703[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 12:59:55,721[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1979388208501673 prior_scale[0m
[[36m2024-07-09 12:59:55,742[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016035412310709174 q_scale[0m
[[36m2024-07-09 12:59:55,758[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20236598689010452 obs_scale[0m
[[36m2024-07-09 12:59:55,770[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 12:59:55,770[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 061 __________________[0m
[[36m2024-07-09 12:59:55,771[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 12:59:55,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:00:04,982[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:00:04,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:00:04,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:00:04,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:00:04,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:00:04,993[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:00:04,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:00:04,993[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:00:04,994[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:00:05,034[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:00:05,043[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:00:05,044[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.50it/s v_num: 0.000
[[36m2024-07-09 13:00:47,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:00:47,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/030[0m
[[36m2024-07-09 13:00:47,815[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:00:47,832[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000780054955832541, lr[0m
[[36m2024-07-09 13:00:47,845[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:00:47,861[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.013514014934255483 prior_scale[0m
[[36m2024-07-09 13:00:47,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005152976382518117 q_scale[0m
[[36m2024-07-09 13:00:47,893[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13165161703186495 obs_scale[0m
[[36m2024-07-09 13:00:47,907[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:00:47,907[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-07-09 13:00:47,908[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:00:47,908[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:00:57,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:00:57,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:00:57,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:00:57,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:00:57,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:00:57,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:00:57,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:00:57,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:00:57,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:00:57,522[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:00:57,538[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 40.76it/s v_num: 0.000
[[36m2024-07-09 13:01:30,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:01:30,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/060[0m
[[36m2024-07-09 13:01:30,981[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:01:31,004[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006712713759588537, lr[0m
[[36m2024-07-09 13:01:31,023[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:01:31,046[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13465649962212872 prior_scale[0m
[[36m2024-07-09 13:01:31,070[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018649161966587935 q_scale[0m
[[36m2024-07-09 13:01:31,094[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24113571557896288 obs_scale[0m
[[36m2024-07-09 13:01:31,112[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:01:31,112[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 062 __________________[0m
[[36m2024-07-09 13:01:31,113[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:01:31,113[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:01:40,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:01:40,784[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:01:40,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:01:40,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:01:40,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:01:40,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:01:40,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:01:40,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:01:40,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:01:40,819[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:01:40,867[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:01:40,869[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.59it/s v_num: 0.000
[[36m2024-07-09 13:02:05,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:02:05,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/061[0m
[[36m2024-07-09 13:02:05,824[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:02:05,848[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006994525906865606, lr[0m
[[36m2024-07-09 13:02:05,863[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:02:05,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18078988781284824 prior_scale[0m
[[36m2024-07-09 13:02:05,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016334481621727264 q_scale[0m
[[36m2024-07-09 13:02:05,915[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2074704378348286 obs_scale[0m
[[36m2024-07-09 13:02:05,929[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:02:05,929[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 063 __________________[0m
[[36m2024-07-09 13:02:05,929[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:02:05,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:02:15,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:02:15,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:02:15,244[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:02:15,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:02:15,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:02:15,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:02:15,248[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:02:15,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:02:15,249[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:02:15,289[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:02:15,300[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:02:15,302[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 17.95it/s v_num: 0.000
[[36m2024-07-09 13:03:18,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:03:18,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/030[0m
[[36m2024-07-09 13:03:18,913[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:03:18,936[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006546414586128785, lr[0m
[[36m2024-07-09 13:03:18,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:03:18,976[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.013855324582632578 prior_scale[0m
[[36m2024-07-09 13:03:18,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009989742090514768 q_scale[0m
[[36m2024-07-09 13:03:19,020[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22185739552175102 obs_scale[0m
[[36m2024-07-09 13:03:19,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:03:19,038[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-07-09 13:03:19,038[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:03:19,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:03:28,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:03:28,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:03:28,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:03:28,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:03:28,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:03:28,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:03:28,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:03:28,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:03:28,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:03:28,373[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:03:28,385[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.56it/s v_num: 0.000
[[36m2024-07-09 13:04:15,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:04:15,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/063[0m
[[36m2024-07-09 13:04:15,824[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:04:15,840[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005954054480968391, lr[0m
[[36m2024-07-09 13:04:15,853[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:04:15,867[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15675690434309725 prior_scale[0m
[[36m2024-07-09 13:04:15,882[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015833329129567632 q_scale[0m
[[36m2024-07-09 13:04:15,897[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23994493229857208 obs_scale[0m
[[36m2024-07-09 13:04:15,909[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:04:15,909[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 064 __________________[0m
[[36m2024-07-09 13:04:15,910[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:04:15,910[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:04:25,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:04:25,149[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:04:25,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:04:25,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:04:25,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:04:25,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:04:25,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:04:25,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:04:25,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:04:25,192[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:04:25,203[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:04:25,204[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.39it/s v_num: 0.000
[[36m2024-07-09 13:05:15,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:05:15,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/031[0m
[[36m2024-07-09 13:05:15,506[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:05:15,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006437008009484151, lr[0m
[[36m2024-07-09 13:05:15,538[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:05:15,556[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01039300228711983 prior_scale[0m
[[36m2024-07-09 13:05:15,574[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008412771225651331 q_scale[0m
[[36m2024-07-09 13:05:15,593[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13852471844274655 obs_scale[0m
[[36m2024-07-09 13:05:15,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:05:15,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-07-09 13:05:15,608[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:05:15,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 21.36it/s v_num: 0.000
[[36m2024-07-09 13:05:22,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:05:22,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/062[0m
[[36m2024-07-09 13:05:22,973[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:05:22,989[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000556213838688123, lr[0m
[[36m2024-07-09 13:05:23,003[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:05:23,019[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20238988700870797 prior_scale[0m
[[36m2024-07-09 13:05:23,036[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013701929174571828 q_scale[0m
[[36m2024-07-09 13:05:23,052[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2842866735001084 obs_scale[0m
[[36m2024-07-09 13:05:23,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:05:23,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 065 __________________[0m
[[36m2024-07-09 13:05:23,066[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:05:23,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:05:24,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:05:24,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:05:24,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:05:25,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:05:25,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:05:25,231[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:05:25,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:05:25,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:05:25,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:05:25,277[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:05:25,345[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:05:32,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:05:32,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:05:32,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:05:32,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:05:32,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:05:32,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:05:32,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:05:32,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:05:32,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:05:32,478[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:05:32,487[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:05:32,489[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.11it/s v_num: 0.000
[[36m2024-07-09 13:06:25,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:06:25,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/064[0m
[[36m2024-07-09 13:06:26,144[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:06:26,168[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005557572380995904, lr[0m
[[36m2024-07-09 13:06:26,186[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:06:26,209[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21375617052057205 prior_scale[0m
[[36m2024-07-09 13:06:26,234[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014778828153087353 q_scale[0m
[[36m2024-07-09 13:06:26,256[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1716067859886241 obs_scale[0m
[[36m2024-07-09 13:06:26,274[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:06:26,274[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 066 __________________[0m
[[36m2024-07-09 13:06:26,274[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:06:26,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:06:35,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:06:35,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:06:35,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:06:35,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:06:35,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:06:35,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:06:35,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:06:35,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:06:35,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:06:35,495[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:06:35,525[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:06:35,527[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:02 • 0:00:00 43.14it/s v_num: 0.000
[[36m2024-07-09 13:07:38,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:07:38,761[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/066[0m
[[36m2024-07-09 13:07:38,870[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:07:38,886[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009940965733305231, lr[0m
[[36m2024-07-09 13:07:38,900[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:07:38,922[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.016964463174033044 prior_scale[0m
[[36m2024-07-09 13:07:38,938[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017263933383252475 q_scale[0m
[[36m2024-07-09 13:07:38,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29421253091813787 obs_scale[0m
[[36m2024-07-09 13:07:38,966[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 13:07:38,966[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 067 __________________[0m
[[36m2024-07-09 13:07:38,966[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:07:38,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:07:48,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:07:48,632[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:07:48,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:07:48,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:07:48,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:07:48,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:07:48,636[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:07:48,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:07:48,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:07:48,666[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:07:48,705[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:07:48,706[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainabl┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 24.15it/s v_num: 0.000
[[36m2024-07-09 13:08:04,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:08:04,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/067[0m
[[36m2024-07-09 13:08:05,085[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:08:05,104[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003482827786824412, lr[0m
[[36m2024-07-09 13:08:05,117[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:08:05,131[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15905085463978816 prior_scale[0m
[[36m2024-07-09 13:08:05,146[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002519127803750831 q_scale[0m
[[36m2024-07-09 13:08:05,161[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1207710958400193 obs_scale[0m
[[36m2024-07-09 13:08:05,173[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:08:05,173[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 069 __________________[0m
[[36m2024-07-09 13:08:05,173[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:08:05,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:08:14,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:08:14,390[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:08:14,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:08:14,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:08:14,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:08:14,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.i      │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 23.05it/s v_num: 0.000
[[36m2024-07-09 13:08:16,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:08:16,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/068[0m
[[36m2024-07-09 13:08:16,956[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:08:16,975[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034957774770175907, lr[0m
[[36m2024-07-09 13:08:16,988[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:08:17,006[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.399805409009818 prior_scale[0m
[[36m2024-07-09 13:08:17,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010498892557398716 q_scale[0m
[[36m2024-07-09 13:08:17,042[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12080668583194848 obs_scale[0m
[[36m2024-07-09 13:08:17,056[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:08:17,056[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 070 __________________[0m
[[36m2024-07-09 13:08:17,057[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:08:17,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:08:26,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:08:26,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:08:26,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:08:26,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:08:26,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:08:26,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:08:26,740[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:08:26,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:08:26,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:08:26,755[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:08:26,780[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:08:26,782[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.12it/s v_num: 0.000
[[36m2024-07-09 13:09:39,683[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 13.
[[36m2024-07-09 13:09:39,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:09:39,943[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:09:39,961[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008056697292903502, lr[0m
[[36m2024-07-09 13:09:39,975[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:09:39,992[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1052517937103575 prior_scale[0m
[[36m2024-07-09 13:09:40,009[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010108716619618905 q_scale[0m
[[36m2024-07-09 13:09:40,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20579663067211826 obs_scale[0m
[[36m2024-07-09 13:09:40,041[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:09:40,041[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 071 __________________[0m
[[36m2024-07-09 13:09:40,041[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:09:40,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:09:49,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:09:49,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:09:49,689[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:09:49,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:09:49,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:09:49,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:09:49,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:09:49,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:09:49,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:09:49,733[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:09:49,744[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:09:49,745[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 33.68it/s v_num: 0.000
[[36m2024-07-09 13:10:10,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:10:10,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/071[0m
[[36m2024-07-09 13:10:10,822[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:10:10,837[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004757031612539957, lr[0m
[[36m2024-07-09 13:10:10,849[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:10:10,864[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08951034606421678 prior_scale[0m
[[36m2024-07-09 13:10:10,880[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009259885587436023 q_scale[0m
[[36m2024-07-09 13:10:10,895[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2489810901041596 obs_scale[0m
[[36m2024-07-09 13:10:10,907[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:10:10,907[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 072 __________________[0m
[[36m2024-07-09 13:10:10,907[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:10:10,908[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:10:20,097[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:10:20,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:10:20,104[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:10:38,669[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004909543127369227, lr[0m
[[36m2024-07-09 13:10:38,685[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:10:38,702[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23648141357609537 prior_scale[0m
[[36m2024-07-09 13:10:38,720[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008199249352433546 q_scale[0m
[[36m2024-07-09 13:10:38,737[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2616318307479667 obs_scale[0m
[[36m2024-07-09 13:10:38,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:10:38,751[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 073 __________________[0m
[[36m2024-07-09 13:10:38,752[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:10:38,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:10:48,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:10:48,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:10:48,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:10:48,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:10:48,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:10:48,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:10:48,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:10:48,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:10:48,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:10:48,043[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:10:48,058[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:10:48,059[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 11.75it/s v_num: 0.000
[[36m2024-07-09 13:10:52,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:10:52,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/033[0m
[[36m2024-07-09 13:10:52,214[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:10:52,237[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000968260902937465, lr[0m
[[36m2024-07-09 13:10:52,252[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:10:52,274[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01025018354272621 prior_scale[0m
[[36m2024-07-09 13:10:52,297[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001163084582497266 q_scale[0m
[[36m2024-07-09 13:10:52,320[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17197043609796994 obs_scale[0m
[[36m2024-07-09 13:10:52,336[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:10:52,336[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-07-09 13:10:52,337[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:10:52,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:11:02,175[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:11:02,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:11:02,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:11:02,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:11:02,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:11:02,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:11:02,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:11:02,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:11:02,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:11:02,655[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:11:08,945[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.07it/s v_num: 0.000
[[36m2024-07-09 13:12:15,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:12:15,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/032[0m
[[36m2024-07-09 13:12:15,304[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:12:15,323[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012726061683918287, lr[0m
[[36m2024-07-09 13:12:15,337[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:12:15,355[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0240266813314553 prior_scale[0m
[[36m2024-07-09 13:12:15,373[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001476750792037015 q_scale[0m
[[36m2024-07-09 13:12:15,395[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1426255128476536 obs_scale[0m
[[36m2024-07-09 13:12:15,412[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:12:15,412[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-07-09 13:12:15,412[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:12:15,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:12:25,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:12:25,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:12:25,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:12:25,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:12:25,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:12:25,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:12:25,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:12:25,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:12:25,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:12:25,404[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 45.02it/s v_num: 0.000
[[36m2024-07-09 13:12:28,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:12:28,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/072[0m
[[36m2024-07-09 13:12:29,023[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:12:29,040[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006319287114401542, lr[0m
[[36m2024-07-09 13:12:29,052[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:12:29,068[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23879591936318834 prior_scale[0m
[[36m2024-07-09 13:12:29,083[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.004538036089608727 q_scale[0m
[[36m2024-07-09 13:12:29,099[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.46549468049074244 obs_scale[0m
[[36m2024-07-09 13:12:29,111[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:12:29,111[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 074 __________________[0m
[[36m2024-07-09 13:12:29,112[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:12:29,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
�──────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 39.70it/s v_num: 0.000
[[36m2024-07-09 13:13:10,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:13:10,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/073[0m
[[36m2024-07-09 13:13:10,601[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:13:10,619[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006090618796889169, lr[0m
[[36m2024-07-09 13:13:10,634[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:13:10,651[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12713467700161846 prior_scale[0m
[[36m2024-07-09 13:13:10,675[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002296310537681703 q_scale[0m
[[36m2024-07-09 13:13:10,694[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18301779648922994 obs_scale[0m
[[36m2024-07-09 13:13:10,710[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:13:10,710[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 075 __________________[0m
[[36m2024-07-09 13:13:10,711[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:13:10,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:13:20,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:13:20,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:13:20,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:13:20,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:13:20,103[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:13:20,104[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:13:20,104[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:13:20,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:13:20,105[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:13:20,136[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:13:20,148[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:13:20,151[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.98it/s v_num: 0.000
[[36m2024-07-09 13:13:21,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:13:21,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/033[0m
[[36m2024-07-09 13:13:21,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:13:21,985[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007030854537238259, lr[0m
[[36m2024-07-09 13:13:21,997[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:13:22,011[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01581562265311101 prior_scale[0m
[[36m2024-07-09 13:13:22,030[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008764119066469348 q_scale[0m
[[36m2024-07-09 13:13:22,051[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2304948138033928 obs_scale[0m
[[36m2024-07-09 13:13:22,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:13:22,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-07-09 13:13:22,067[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:13:22,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:13:31,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:13:31,634[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:13:31,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:13:31,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:13:31,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:13:31,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:13:31,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:13:31,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:13:31,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:13:31,688[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:13:31,703[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.43it/s v_num: 0.000
[[36m2024-07-09 13:15:36,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:15:36,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/034[0m
[[36m2024-07-09 13:15:37,061[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:15:37,077[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009890326904989396, lr[0m
[[36m2024-07-09 13:15:37,091[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:15:37,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.013811768778149155 prior_scale[0m
[[36m2024-07-09 13:15:37,123[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022186933145590605 q_scale[0m
[[36m2024-07-09 13:15:37,140[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1708839407544858 obs_scale[0m
[[36m2024-07-09 13:15:37,153[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 13:15:37,153[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-09 13:15:37,154[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:15:37,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:15:47,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:15:47,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:15:47,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:15:47,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:15:47,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:15:47,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:15:47,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:15:47,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:15:47,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:15:47,638[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:15:47,650[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.22it/s v_num: 0.000
[[36m2024-07-09 13:16:16,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:16:16,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/074[0m
[[36m2024-07-09 13:16:16,961[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:16:16,984[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003040266149719051, lr[0m
[[36m2024-07-09 13:16:17,001[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:16:17,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13557378132591172 prior_scale[0m
[[36m2024-07-09 13:16:17,047[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.009917072934430256 q_scale[0m
[[36m2024-07-09 13:16:17,062[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17814956487181702 obs_scale[0m
[[36m2024-07-09 13:16:17,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:16:17,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 076 __________________[0m
[[36m2024-07-09 13:16:17,076[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:16:17,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:16:26,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:16:26,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:16:26,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:16:26,253[0m][[34mu[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:16:33,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:16:33,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:16:33,971[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:16:33,972[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:16:33,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:16:34,001[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:16:34,014[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                               Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 19.13it/s v_num: 0.000
[[36m2024-07-09 13:17:23,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:17:23,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/075[0m
[[36m2024-07-09 13:17:23,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:17:23,564[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007296627133796101, lr[0m
[[36m2024-07-09 13:17:23,580[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:17:23,603[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10814445357473858 prior_scale[0m
[[36m2024-07-09 13:17:23,625[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005600922292447851 q_scale[0m
[[36m2024-07-09 13:17:23,648[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17832474522439862 obs_scale[0m
[[36m2024-07-09 13:17:23,665[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:17:23,665[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 077 __________________[0m
[[36m2024-07-09 13:17:23,666[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:17:23,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 11.13it/s v_num: 0.000
[[36m2024-07-09 13:17:24,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:17:24,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/036[0m
[[36m2024-07-09 13:17:24,147[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:17:24,172[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014212145177298715, lr[0m
[[36m2024-07-09 13:17:24,189[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:17:24,212[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.015348472197819884 prior_scale[0m
[[36m2024-07-09 13:17:24,236[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015647377417742244 q_scale[0m
[[36m2024-07-09 13:17:24,259[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2922453199061724 obs_scale[0m
[[36m2024-07-09 13:17:24,282[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:17:24,283[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-07-09 13:17:24,283[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:17:24,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:17:33,147[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:17:33,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:17:33,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:17:33,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:17:33,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:17:33,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:17:33,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:17:33,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:17:33,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:17:33,191[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:17:33,206[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:17:33,208[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:17:34,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:17:34,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:17:34,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:17:34,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:17:34,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:17:34,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:17:34,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:17:34,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:17:34,023[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:17:34,053[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:17:34,067[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.20it/s v_num: 0.000
[[36m2024-07-09 13:18:01,574[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:18:01,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/034[0m
[[36m2024-07-09 13:18:01,678[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:18:01,694[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009841626213864894, lr[0m
[[36m2024-07-09 13:18:01,706[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:18:01,720[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.012638275645104596 prior_scale[0m
[[36m2024-07-09 13:18:01,735[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003178987968234645 q_scale[0m
[[36m2024-07-09 13:18:01,749[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13524464141059514 obs_scale[0m
[[36m2024-07-09 13:18:01,762[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 13:18:01,762[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-07-09 13:18:01,762[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:18:01,762[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:18:11,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:18:11,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:18:11,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:18:11,951[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:18:11,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:18:11,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:18:11,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:18:11,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:18:11,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:18:11,983[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:18:11,994[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.46it/s v_num: 0.000
[[36m2024-07-09 13:18:55,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:18:55,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/035[0m
[[36m2024-07-09 13:18:55,797[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:18:55,812[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006605323360647428, lr[0m
[[36m2024-07-09 13:18:55,824[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:18:55,839[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.016433509647893103 prior_scale[0m
[[36m2024-07-09 13:18:55,853[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016314752729519504 q_scale[0m
[[36m2024-07-09 13:18:55,867[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17420956639581037 obs_scale[0m
[[36m2024-07-09 13:18:55,879[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:18:55,879[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-07-09 13:18:55,879[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:18:55,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:19:05,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:19:05,701[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:19:05,702[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:19:05,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:19:05,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:19:05,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:19:05,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:19:05,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:19:05,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:19:05,734[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:19:05,748[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.72it/s v_num: 0.000
[[36m2024-07-09 13:19:59,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:19:59,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/037[0m
[[36m2024-07-09 13:19:59,872[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:19:59,887[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004686810341787869, lr[0m
[[36m2024-07-09 13:19:59,899[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:19:59,915[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.05788983643240662 prior_scale[0m
[[36m2024-07-09 13:19:59,930[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00236350806000522 q_scale[0m
[[36m2024-07-09 13:19:59,945[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18580622456681908 obs_scale[0m
[[36m2024-07-09 13:19:59,958[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:19:59,958[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-07-09 13:19:59,958[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:19:59,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.98it/s v_num: 0.000
[[36m2024-07-09 13:20:01,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:20:01,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/036[0m
[[36m2024-07-09 13:20:01,350[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:20:01,365[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007266468630462864, lr[0m
[[36m2024-07-09 13:20:01,377[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:20:01,391[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010175227563035065 prior_scale[0m
[[36m2024-07-09 13:20:01,406[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000947734897811299 q_scale[0m
[[36m2024-07-09 13:20:01,420[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29592847735774447 obs_scale[0m
[[36m2024-07-09 13:20:01,432[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:20:01,432[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-07-09 13:20:01,432[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:20:01,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.63it/s v_num: 0.000
[[36m2024-07-09 13:20:05,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:20:05,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/076[0m
[[36m2024-07-09 13:20:05,709[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:20:05,725[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007409684240584451, lr[0m
[[36m2024-07-09 13:20:05,739[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:20:05,755[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10804013666321714 prior_scale[0m
[[36m2024-07-09 13:20:05,771[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018534331617777065 q_scale[0m
[[36m2024-07-09 13:20:05,787[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21031489819229282 obs_scale[0m
[[36m2024-07-09 13:20:05,801[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:20:05,801[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 078 __________________[0m
[[36m2024-07-09 13:20:05,802[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:20:05,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
��━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:20:10,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:20:10,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:20:10,880[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:20:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:20:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:20:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:20:10,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:20:10,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:20:10,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:20:10,914[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:20:10,924[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:20:15,078[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:20:15,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:20:15,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:20:15,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:20:15,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:20:15,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:20:15,087[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:20:15,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:20:15,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:20:15,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:20:15,155[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:20:15,157[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 21.99it/s v_num: 0.000
[[36m2024-07-09 13:21:25,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:21:25,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/077[0m
[[36m2024-07-09 13:21:25,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:21:25,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005983545205880552, lr[0m
[[36m2024-07-09 13:21:25,989[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:21:26,013[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19026788465482336 prior_scale[0m
[[36m2024-07-09 13:21:26,038[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003234422692488668 q_scale[0m
[[36m2024-07-09 13:21:26,063[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1515843492522749 obs_scale[0m
[[36m2024-07-09 13:21:26,082[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:21:26,082[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 079 __________________[0m
[[36m2024-07-09 13:21:26,082[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:21:26,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:21:35,700[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:21:35,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:21:35,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:21:35,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:21:35,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:21:35,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:21:35,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:21:35,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:21:35,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:21:35,753[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:21:35,764[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:21:35,765[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.13it/s v_num: 0.000
[[36m2024-07-09 13:22:37,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:22:37,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/037[0m
[[36m2024-07-09 13:22:37,860[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:22:37,878[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000412172650304388, lr[0m
[[36m2024-07-09 13:22:37,892[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:22:37,909[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.023008651144434546 prior_scale[0m
[[36m2024-07-09 13:22:37,926[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00647681634021421 q_scale[0m
[[36m2024-07-09 13:22:37,943[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10527170496833628 obs_scale[0m
[[36m2024-07-09 13:22:37,957[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:22:37,957[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-07-09 13:22:37,958[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:22:37,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:22:47,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:22:47,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:22:47,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:22:47,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:22:47,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:22:47,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:22:47,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:22:47,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:22:47,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:22:47,253[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:22:47,262[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.64it/s v_num: 0.000
[[36m2024-07-09 13:23:55,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:23:55,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/078[0m
[[36m2024-07-09 13:23:55,496[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:23:55,519[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.0125058472109033e-05, lr[0m
[[36m2024-07-09 13:23:55,538[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:23:55,561[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.35808734206809545 prior_scale[0m
[[36m2024-07-09 13:23:55,585[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001703363681995436 q_scale[0m
[[36m2024-07-09 13:23:55,608[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2325118209965556 obs_scale[0m
[[36m2024-07-09 13:23:55,625[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:23:55,625[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 081 __________________[0m
[[36m2024-07-09 13:23:55,626[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:23:55,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:24:04,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:24:04,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:24:04,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:24:04,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:24:04,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:24:04,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:24:04,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:24:04,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:24:04,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:24:04,912[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:24:04,971[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:24:04,265[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.11it/s v_num: 0.000
[[36m2024-07-09 13:24:23,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:24:23,442[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/038[0m
[[36m2024-07-09 13:24:23,581[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:24:23,605[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032380114736801636, lr[0m
[[36m2024-07-09 13:24:23,622[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:24:23,645[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10828679210397443 prior_scale[0m
[[36m2024-07-09 13:24:23,669[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0031197994425816986 q_scale[0m
[[36m2024-07-09 13:24:23,692[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1902823541378433 obs_scale[0m
[[36m2024-07-09 13:24:23,709[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:24:23,709[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-07-09 13:24:23,710[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:24:23,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:24:33,448[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:24:33,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:24:33,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:24:33,458[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:24:33,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:24:33,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:24:33,460[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:24:33,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:24:33,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:24:33,492[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:24:33,516[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 22.80it/s v_num: 0.000
[[36m2024-07-09 13:25:55,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:25:55,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/081[0m
[[36m2024-07-09 13:25:55,195[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:25:55,211[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004142855182866886, lr[0m
[[36m2024-07-09 13:25:55,223[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:25:55,238[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12581841022025822 prior_scale[0m
[[36m2024-07-09 13:25:55,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023206901177930955 q_scale[0m
[[36m2024-07-09 13:25:55,269[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3210324642794493 obs_scale[0m
[[36m2024-07-09 13:25:55,283[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:25:55,283[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 082 __________________[0m
[[36m2024-07-09 13:25:55,283[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:25:55,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:26:04,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:26:04,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:26:04,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:26:04,548[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:26:04,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:26:04,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:26:04,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:26:04,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:26:04,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:26:04,598[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:26:04,612[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:26:04,614[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.36it/s v_num: 0.000
[[36m2024-07-09 13:26:34,345[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2024-07-09 13:26:34,387[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:26:34,487[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:26:34,503[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003477307599947762, lr[0m
[[36m2024-07-09 13:26:34,515[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:26:34,529[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.04990238184928287 prior_scale[0m
[[36m2024-07-09 13:26:34,544[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012063442230423006 q_scale[0m
[[36m2024-07-09 13:26:34,558[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1666571572634523 obs_scale[0m
[[36m2024-07-09 13:26:34,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:26:34,570[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-07-09 13:26:34,571[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:26:34,571[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:26:44,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:26:44,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:26:44,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:26:44,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:26:44,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:26:44,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:26:44,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:26:44,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:26:44,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:26:44,109[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:26:44,131[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.00it/s v_num: 0.000
[[36m2024-07-09 13:27:00,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:27:00,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/039[0m
[[36m2024-07-09 13:27:00,182[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:27:00,200[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004772933998403706, lr[0m
[[36m2024-07-09 13:27:00,215[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:27:00,232[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14845873097589327 prior_scale[0m
[[36m2024-07-09 13:27:00,250[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.006655568075865666 q_scale[0m
[[36m2024-07-09 13:27:00,267[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16159007789648133 obs_scale[0m
[[36m2024-07-09 13:27:00,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:27:00,285[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-07-09 13:27:00,285[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:27:00,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:27:10,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:27:10,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:27:10,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:27:10,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:27:10,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:27:10,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:27:10,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:27:10,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:27:10,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:27:10,727[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:27:10,740[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 19.71it/s v_num: 0.000
[[36m2024-07-09 13:28:02,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:28:02,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/080[0m
[[36m2024-07-09 13:28:03,091[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:28:03,108[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043023461956406264, lr[0m
[[36m2024-07-09 13:28:03,123[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:28:03,141[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12629036786276165 prior_scale[0m
[[36m2024-07-09 13:28:03,157[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022070990247534955 q_scale[0m
[[36m2024-07-09 13:28:03,174[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3128678339215028 obs_scale[0m
[[36m2024-07-09 13:28:03,189[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:28:03,189[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 083 __________________[0m
[[36m2024-07-09 13:28:03,189[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:28:03,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.76it/s v_num: 0.000
[[36m2024-07-09 13:28:08,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:28:08,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/040[0m
[[36m2024-07-09 13:28:08,606[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:28:08,627[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009968103313468832, lr[0m
[[36m2024-07-09 13:28:08,644[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:28:08,663[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29017215865743806 prior_scale[0m
[[36m2024-07-09 13:28:08,684[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013462240690862264 q_scale[0m
[[36m2024-07-09 13:28:08,703[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14749381785057827 obs_scale[0m
[[36m2024-07-09 13:28:08,719[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:28:08,720[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-07-09 13:28:08,720[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:28:08,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:28:12,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:28:12,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:28:12,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:28:12,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:28:12,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:28:12,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:28:12,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:28:12,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:28:12,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:28:12,949[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:28:12,962[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:28:12,964[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:28:18,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:28:18,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:28:18,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:28:18,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:28:18,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:28:18,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:28:18,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:28:18,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:28:18,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:28:18,703[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:28:18,732[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.40it/s v_num: 0.000
[[36m2024-07-09 13:29:03,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:29:03,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/039[0m
[[36m2024-07-09 13:29:04,018[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:29:04,033[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007989066575096324, lr[0m
[[36m2024-07-09 13:29:04,044[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:29:04,059[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03245023758441066 prior_scale[0m
[[36m2024-07-09 13:29:04,074[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020001463184926814 q_scale[0m
[[36m2024-07-09 13:29:04,089[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4512694054018099 obs_scale[0m
[[36m2024-07-09 13:29:04,101[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:29:04,101[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-07-09 13:29:04,101[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:29:04,101[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:29:13,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:29:13,869[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:29:13,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:29:13,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:29:13,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:29:13,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:29:13,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:29:13,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:29:13,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:29:13,903[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:29:13,951[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 22.64it/s v_num: 0.000
[[36m2024-07-09 13:29:34,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:29:34,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/082[0m
[[36m2024-07-09 13:29:34,244[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:29:34,260[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044179958909916137, lr[0m
[[36m2024-07-09 13:29:34,273[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:29:34,289[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.29541670823200356 prior_scale[0m
[[36m2024-07-09 13:29:34,303[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024552447690046167 q_scale[0m
[[36m2024-07-09 13:29:34,318[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19318896149450132 obs_scale[0m
[[36m2024-07-09 13:29:34,331[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:29:34,331[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 084 __________________[0m
[[36m2024-07-09 13:29:34,332[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:29:34,332[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:29:43,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:29:43,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:29:43,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:29:43,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:29:43,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:29:43,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:29:43,621[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:29:43,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:29:43,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:29:43,666[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:29:43,677[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:29:43,679[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.85it/s v_num: 0.000
[[36m2024-07-09 13:30:14,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:30:14,513[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/040[0m
[[36m2024-07-09 13:30:14,616[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:30:14,631[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006455492762391573, lr[0m
[[36m2024-07-09 13:30:14,643[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:30:14,658[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.011815645376718182 prior_scale[0m
[[36m2024-07-09 13:30:14,672[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009494796537156726 q_scale[0m
[[36m2024-07-09 13:30:14,687[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3145260791332263 obs_scale[0m
[[36m2024-07-09 13:30:14,699[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:30:14,699[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-07-09 13:30:14,699[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:30:14,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:30:24,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:30:24,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:30:24,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:30:24,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:30:24,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:30:24,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:30:24,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:30:24,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:30:24,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:30:24,102[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:30:24,115[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.98it/s v_num: 0.000
[[36m2024-07-09 13:32:27,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:32:27,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/083[0m
[[36m2024-07-09 13:32:27,232[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:32:27,254[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005222115966491461, lr[0m
[[36m2024-07-09 13:32:27,271[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:32:27,292[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14482323235480146 prior_scale[0m
[[36m2024-07-09 13:32:27,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026375114633406076 q_scale[0m
[[36m2024-07-09 13:32:27,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15998763482966238 obs_scale[0m
[[36m2024-07-09 13:32:27,356[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:32:27,356[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 085 __________________[0m
[[36m2024-07-09 13:32:27,357[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:32:27,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:32:37,442[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:32:37,448[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:32:37,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:32:37,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:32:37,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:32:37,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:32:37,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:32:37,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:32:37,456[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:32:37,500[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:32:37,511[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:32:37,513[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.42it/s v_num: 0.000
[[36m2024-07-09 13:32:58,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:32:58,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/041[0m
[[36m2024-07-09 13:32:58,418[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:32:58,446[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007810047860749132, lr[0m
[[36m2024-07-09 13:32:58,461[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:32:58,483[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.010063757784385938 prior_scale[0m
[[36m2024-07-09 13:32:58,504[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012448261063456006 q_scale[0m
[[36m2024-07-09 13:32:58,525[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2692278722724206 obs_scale[0m
[[36m2024-07-09 13:32:58,541[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:32:58,541[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-07-09 13:32:58,542[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:32:58,542[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:33:08,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:33:08,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:33:08,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:33:08,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:33:08,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:33:08,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:33:08,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:33:08,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:33:08,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:33:08,245[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:33:08,284[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.61it/s v_num: 0.000
[[36m2024-07-09 13:33:28,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:33:28,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/084[0m
[[36m2024-07-09 13:33:28,671[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:33:28,687[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005159823572906446, lr[0m
[[36m2024-07-09 13:33:28,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:33:28,716[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16782099929675975 prior_scale[0m
[[36m2024-07-09 13:33:28,731[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001884685168253816 q_scale[0m
[[36m2024-07-09 13:33:28,746[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1581510682591849 obs_scale[0m
[[36m2024-07-09 13:33:28,759[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:33:28,759[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 086 __________________[0m
[[36m2024-07-09 13:33:28,759[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:33:28,760[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[19, 285, 321, 6931, 5191]
[[36m2024-07-09 13:33:37,639[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:33:37,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:33:37,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:33:37,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:33:37,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:33:37,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:33:37,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:33:37,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:33:37,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:33:37,683[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:33:37,692[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
                                                                                                                                                                                                       Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.99it/s v_num: 0.000
[[36m2024-07-09 13:35:27,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:35:27,760[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/042[0m
[[36m2024-07-09 13:35:27,864[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:35:27,881[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004781582027606257, lr[0m
[[36m2024-07-09 13:35:27,901[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:35:27,922[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01671218393818635 prior_scale[0m
[[36m2024-07-09 13:35:27,944[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0031417051312127124 q_scale[0m
[[36m2024-07-09 13:35:27,965[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.197675821808299 obs_scale[0m
[[36m2024-07-09 13:35:27,981[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:35:27,981[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-07-09 13:35:27,982[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:35:27,982[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:35:37,392[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:35:37,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:35:37,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:35:37,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:35:37,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:35:37,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:35:37,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:35:37,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:35:37,402[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:35:37,436[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:35:37,450[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 19.19it/s v_num: 0.000
[[36m2024-07-09 13:36:53,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:36:53,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/085[0m
[[36m2024-07-09 13:36:54,058[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:36:54,080[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006214999323862192, lr[0m
[[36m2024-07-09 13:36:54,097[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:36:54,116[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1690528350921827 prior_scale[0m
[[36m2024-07-09 13:36:54,136[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013996501362037746 q_scale[0m
[[36m2024-07-09 13:36:54,156[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22291348825815113 obs_scale[0m
[[36m2024-07-09 13:36:54,172[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 13:36:54,172[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 087 __________________[0m
[[36m2024-07-09 13:36:54,173[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:36:54,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.96it/s v_num: 0.000
[[36m2024-07-09 13:37:00,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:37:00,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/086[0m
[[36m2024-07-09 13:37:00,404[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:37:00,421[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.6596126921375253e-05, lr[0m
[[36m2024-07-09 13:37:00,433[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:37:00,448[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.09345845540787608 prior_scale[0m
[[36m2024-07-09 13:37:00,464[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001524105887922432 q_scale[0m
[[36m2024-07-09 13:37:00,480[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21773247049639818 obs_scale[0m
[[36m2024-07-09 13:37:00,492[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 13:37:00,492[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 088 __________________[0m
[[36m2024-07-09 13:37:00,492[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:37:00,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
me/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:37:09,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:37:09,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:37:09,945[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:37:09,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:37:09,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:37:09,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:37:09,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:37:09,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:37:09,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:37:09,987[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:37:09,996[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.60it/s v_num: 0.000
[[36m2024-07-09 13:37:56,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:37:56,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/043[0m
[[36m2024-07-09 13:37:56,347[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:37:56,363[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009109729989202154, lr[0m
[[36m2024-07-09 13:37:56,375[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:37:56,389[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.012908043914880773 prior_scale[0m
[[36m2024-07-09 13:37:56,403[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012830947168862084 q_scale[0m
[[36m2024-07-09 13:37:56,419[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24194214292141314 obs_scale[0m
[[36m2024-07-09 13:37:56,432[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:37:56,432[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-07-09 13:37:56,432[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:37:56,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 21.56it/s v_num: 0.000
[[36m2024-07-09 13:38:07,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:38:07,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/088[0m
[[36m2024-07-09 13:38:07,777[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:38:07,795[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006161540149384927, lr[0m
[[36m2024-07-09 13:38:07,810[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:38:07,834[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1432526654710922 prior_scale[0m
[[36m2024-07-09 13:38:07,858[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044692390929326303 q_scale[0m
[[36m2024-07-09 13:38:07,881[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24122047428015705 obs_scale[0m
[[36m2024-07-09 13:38:07,898[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:38:07,898[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 089 __________________[0m
[[36m2024-07-09 13:38:07,898[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:38:07,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:38:17,661[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:38:17,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:38:17,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:38:17,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:38:17,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:38:17,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:38:17,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:38:17,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:38:17,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:38:17,716[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:38:17,728[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:38:17,730[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
earch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:38:15,459[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 6.158289557640674e-05, lr[0m
[[36m2024-07-09 13:38:15,473[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:38:15,491[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08271767343019448 prior_scale[0m
[[36m2024-07-09 13:38:15,509[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043683904054700565 q_scale[0m
[[36m2024-07-09 13:38:15,526[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2446254396029097 obs_scale[0m
[[36m2024-07-09 13:38:15,540[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-07-09 13:38:15,541[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 090 __________________[0m
[[36m2024-07-09 13:38:15,541[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:38:15,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:38:25,926[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:38:25,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:38:25,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:38:25,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:38:25,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:38:25,936[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:38:25,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:38:25,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:38:25,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:38:25,968[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:38:25,981[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:38:25,983[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:12 • 0:00:00 15.72it/s v_num: 0.000
[[36m2024-07-09 13:38:29,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:38:29,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/042[0m
[[36m2024-07-09 13:38:30,024[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:38:30,044[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009541632628452573, lr[0m
[[36m2024-07-09 13:38:30,060[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:38:30,079[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.07354808682823133 prior_scale[0m
[[36m2024-07-09 13:38:30,099[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.002006732782072307 q_scale[0m
[[36m2024-07-09 13:38:30,118[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10925956535629212 obs_scale[0m
[[36m2024-07-09 13:38:30,134[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:38:30,135[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-07-09 13:38:30,135[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:38:30,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:38:40,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:38:40,175[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:38:40,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:38:40,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:38:40,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:38:40,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:38:40,180[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:38:40,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:38:40,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:38:40,213[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:38:40,222[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 18.26it/s v_num: 0.000
[[36m2024-07-09 13:38:51,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:38:51,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/089[0m
[[36m2024-07-09 13:38:51,921[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:38:51,936[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038043550440337745, lr[0m
[[36m2024-07-09 13:38:51,949[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:38:51,963[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12415277715845997 prior_scale[0m
[[36m2024-07-09 13:38:51,979[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018869928489129894 q_scale[0m
[[36m2024-07-09 13:38:51,994[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.26734884101288314 obs_scale[0m
[[36m2024-07-09 13:38:52,006[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:38:52,006[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 092 __________________[0m
[[36m2024-07-09 13:38:52,006[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:38:52,006[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:39:01,069[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:39:01,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:39:01,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:39:01,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:39:01,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:39:01,172[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:39:01,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:39:01,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:39:01,174[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:39:01,204[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:39:01,213[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:39:01,215[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.54it/s v_num: 0.000
[[36m2024-07-09 13:40:32,892[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:40:32,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/044[0m
[[36m2024-07-09 13:40:33,000[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:40:33,015[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009702966948909521, lr[0m
[[36m2024-07-09 13:40:33,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:40:33,041[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.024434224027339704 prior_scale[0m
[[36m2024-07-09 13:40:33,055[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012819411128956611 q_scale[0m
[[36m2024-07-09 13:40:33,070[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2532041103301917 obs_scale[0m
[[36m2024-07-09 13:40:33,082[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:40:33,083[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-07-09 13:40:33,083[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:40:33,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:40:42,616[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:40:42,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:40:42,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:40:42,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:40:42,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:40:42,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:40:42,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:40:42,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:40:42,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:40:42,666[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:40:42,676[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.57it/s v_num: 0.000
[[36m2024-07-09 13:42:30,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:42:30,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/092[0m
[[36m2024-07-09 13:42:30,381[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:42:30,402[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047226324541952834, lr[0m
[[36m2024-07-09 13:42:30,419[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:42:30,441[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14673729888898288 prior_scale[0m
[[36m2024-07-09 13:42:30,463[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028837670529339787 q_scale[0m
[[36m2024-07-09 13:42:30,485[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19879280480037906 obs_scale[0m
[[36m2024-07-09 13:42:30,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:42:30,502[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 093 __________________[0m
[[36m2024-07-09 13:42:30,502[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:42:30,503[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:42:39,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:42:39,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:42:39,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:42:39,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:42:39,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:42:39,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:42:39,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:42:39,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:42:39,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:42:39,902[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:42:39,938[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:42:39,941[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.62it/s v_num: 0.000
[[36m2024-07-09 13:43:01,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:43:01,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/045[0m
[[36m2024-07-09 13:43:01,220[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:43:01,235[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00099806048288702, lr[0m
[[36m2024-07-09 13:43:01,247[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:43:01,261[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.08631039161619439 prior_scale[0m
[[36m2024-07-09 13:43:01,275[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004014600966422413 q_scale[0m
[[36m2024-07-09 13:43:01,290[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.43927774763440414 obs_scale[0m
[[36m2024-07-09 13:43:01,302[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:43:01,302[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-09 13:43:01,302[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:43:01,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:43:10,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:43:10,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:43:10,845[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:43:10,848[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:43:10,848[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:43:10,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:43:10,850[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:43:10,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:43:10,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:43:10,888[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:43:10,974[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.74it/s v_num: 0.000
[[36m2024-07-09 13:43:17,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:43:17,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/091[0m
[[36m2024-07-09 13:43:17,980[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:43:18,001[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003077864059023497, lr[0m
[[36m2024-07-09 13:43:18,018[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:43:18,038[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4877593732360975 prior_scale[0m
[[36m2024-07-09 13:43:18,058[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028392569299672714 q_scale[0m
[[36m2024-07-09 13:43:18,078[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1867076987290155 obs_scale[0m
[[36m2024-07-09 13:43:18,097[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:43:18,098[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 094 __________________[0m
[[36m2024-07-09 13:43:18,098[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:43:18,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:43:28,034[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:43:28,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:43:28,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:43:28,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:43:28,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:43:28,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:43:28,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:43:28,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:43:28,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:43:28,077[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:43:28,103[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:43:28,105[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:12 • 0:00:00 16.15it/s v_num: 0.000
[[36m2024-07-09 13:43:29,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:43:29,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/043[0m
[[36m2024-07-09 13:43:29,981[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:43:30,001[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007321259472204384, lr[0m
[[36m2024-07-09 13:43:30,017[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:43:30,037[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2815638705803355 prior_scale[0m
[[36m2024-07-09 13:43:30,058[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013224535244650835 q_scale[0m
[[36m2024-07-09 13:43:30,077[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20776020751331825 obs_scale[0m
[[36m2024-07-09 13:43:30,094[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:43:30,095[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-07-09 13:43:30,095[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:43:30,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:43:40,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:43:40,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:43:40,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:43:40,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:43:40,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:43:40,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:43:40,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:43:40,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:43:40,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:43:40,170[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:43:40,198[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.02it/s v_num: 0.000
[[36m2024-07-09 13:45:30,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:45:30,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/046[0m
[[36m2024-07-09 13:45:30,561[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:45:30,577[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.5157891091780266e-05, lr[0m
[[36m2024-07-09 13:45:30,589[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:45:30,604[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.024666383602103856 prior_scale[0m
[[36m2024-07-09 13:45:30,618[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007469414515739242 q_scale[0m
[[36m2024-07-09 13:45:30,632[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12273609450960601 obs_scale[0m
[[36m2024-07-09 13:45:30,645[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:45:30,645[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-07-09 13:45:30,645[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:45:30,645[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:45:39,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:45:39,957[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:45:39,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:45:39,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:45:39,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:45:39,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:45:39,961[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:45:39,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:45:39,962[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:45:40,000[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:45:40,012[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.60it/s v_num: 0.000
[[36m2024-07-09 13:46:05,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:46:05,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/093[0m
[[36m2024-07-09 13:46:05,404[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:46:05,418[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000556884248642547, lr[0m
[[36m2024-07-09 13:46:05,430[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:46:05,444[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10461230699241658 prior_scale[0m
[[36m2024-07-09 13:46:05,458[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034448421993742357 q_scale[0m
[[36m2024-07-09 13:46:05,472[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18236448975831196 obs_scale[0m
[[36m2024-07-09 13:46:05,484[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:46:05,484[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 095 __________________[0m
[[36m2024-07-09 13:46:05,485[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:46:05,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:46:14,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:46:14,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:46:14,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:46:14,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:46:14,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:46:14,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:46:14,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:46:14,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:46:14,732[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:46:14,769[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:46:14,806[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:46:14,808[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 19.31it/s v_num: 0.000
[[36m2024-07-09 13:47:39,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:47:39,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/094[0m
[[36m2024-07-09 13:47:39,899[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:47:39,917[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003813403177040142, lr[0m
[[36m2024-07-09 13:47:39,932[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:47:39,951[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10157216257421642 prior_scale[0m
[[36m2024-07-09 13:47:39,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035307485652817845 q_scale[0m
[[36m2024-07-09 13:47:39,987[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19797157987192102 obs_scale[0m
[[36m2024-07-09 13:47:40,002[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:47:40,003[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 096 __________________[0m
[[36m2024-07-09 13:47:40,003[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:47:40,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:47:49,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:47:49,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:47:49,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:47:49,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:47:49,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:47:49,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:47:49,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:47:49,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:47:49,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:47:49,996[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:47:50,008[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:47:50,010[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.42it/s v_num: 0.000
[[36m2024-07-09 13:47:59,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:47:59,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/047[0m
[[36m2024-07-09 13:47:59,945[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:47:59,960[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008729283081223923, lr[0m
[[36m2024-07-09 13:47:59,972[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:47:59,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.044022675087812595 prior_scale[0m
[[36m2024-07-09 13:48:00,000[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013924423089012655 q_scale[0m
[[36m2024-07-09 13:48:00,015[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23531750288243622 obs_scale[0m
[[36m2024-07-09 13:48:00,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 13:48:00,027[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-09 13:48:00,027[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:48:00,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:48:09,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:48:09,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:48:09,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:48:09,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:48:09,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:48:09,738[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:48:09,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:48:09,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:48:09,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:48:09,767[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:48:09,777[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 16.60it/s v_num: 0.000
[[36m2024-07-09 13:48:29,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:48:29,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/044[0m
[[36m2024-07-09 13:48:29,737[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:48:29,757[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007321610765279702, lr[0m
[[36m2024-07-09 13:48:29,773[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:48:29,790[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2726691150785891 prior_scale[0m
[[36m2024-07-09 13:48:29,811[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012236472512046346 q_scale[0m
[[36m2024-07-09 13:48:29,830[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21534966226440866 obs_scale[0m
[[36m2024-07-09 13:48:29,844[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 13:48:29,844[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-07-09 13:48:29,845[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:48:29,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:48:39,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:48:39,957[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:48:39,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:48:39,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:48:39,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:48:39,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:48:39,962[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:48:39,962[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:48:39,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:48:39,992[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:48:44,603[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.55it/s v_num: 0.000
[[36m2024-07-09 13:49:38,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:49:38,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/095[0m
[[36m2024-07-09 13:49:38,784[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:49:38,807[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005653949681278108, lr[0m
[[36m2024-07-09 13:49:38,825[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:49:38,847[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06236141745375874 prior_scale[0m
[[36m2024-07-09 13:49:38,869[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034468570611229327 q_scale[0m
[[36m2024-07-09 13:49:38,891[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19620343194812864 obs_scale[0m
[[36m2024-07-09 13:49:38,908[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:49:38,908[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 097 __________________[0m
[[36m2024-07-09 13:49:38,908[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:49:38,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:49:48,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:49:48,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:49:48,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:49:48,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:49:48,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:49:48,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:49:48,069[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:49:48,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:49:48,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:49:48,108[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:49:48,121[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:49:48,122[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴─                                           
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.52it/s v_num: 0.000
[[36m2024-07-09 13:50:08,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:50:08,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/045[0m
[[36m2024-07-09 13:50:08,210[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:50:08,229[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009988001842903863, lr[0m
[[36m2024-07-09 13:50:08,244[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:50:08,262[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.33871262316561207 prior_scale[0m
[[36m2024-07-09 13:50:08,279[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001321137144380801 q_scale[0m
[[36m2024-07-09 13:50:08,296[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1550830026542339 obs_scale[0m
[[36m2024-07-09 13:50:08,311[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:50:08,311[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-07-09 13:50:08,312[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:50:08,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:50:17,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:50:17,887[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:50:17,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:50:17,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:50:17,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:50:17,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:50:17,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:50:17,892[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:50:17,892[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:50:17,923[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:50:17,955[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 20.78it/s v_num: 0.000
[[36m2024-07-09 13:51:55,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:51:55,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/096[0m
[[36m2024-07-09 13:51:55,461[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:51:55,481[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005593662944877016, lr[0m
[[36m2024-07-09 13:51:55,497[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:51:55,514[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.06422269322543495 prior_scale[0m
[[36m2024-07-09 13:51:55,535[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031404213018859883 q_scale[0m
[[36m2024-07-09 13:51:55,555[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14492636743788423 obs_scale[0m
[[36m2024-07-09 13:51:55,571[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:51:55,571[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 098 __________________[0m
[[36m2024-07-09 13:51:55,572[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:51:55,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:52:05,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:52:05,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:52:05,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:52:05,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:52:05,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:52:05,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:52:05,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:52:05,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:52:05,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:52:05,413[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:52:05,422[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:52:05,425[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.49it/s v_num: 0.000
[[36m2024-07-09 13:52:23,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:52:23,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/049[0m
[[36m2024-07-09 13:52:23,473[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:52:23,488[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006001796440963589, lr[0m
[[36m2024-07-09 13:52:23,501[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:52:23,515[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11929645724486387 prior_scale[0m
[[36m2024-07-09 13:52:23,530[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008421077432254113 q_scale[0m
[[36m2024-07-09 13:52:23,545[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.155436109330149 obs_scale[0m
[[36m2024-07-09 13:52:23,557[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:52:23,557[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-07-09 13:52:23,557[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:52:23,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:52:33,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:52:33,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:52:33,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:52:33,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:52:33,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:52:33,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:52:33,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:52:33,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:52:33,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:52:33,075[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:52:33,086[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 8/19 ━━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 20.67it/s v_num: 0.000
[[36m2024-07-09 13:53:48,517[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 8.
[[36m2024-07-09 13:53:48,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:53:48,628[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:53:48,649[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006828096181446091, lr[0m
[[36m2024-07-09 13:53:48,664[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:53:48,682[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11237170957916524 prior_scale[0m
[[36m2024-07-09 13:53:48,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0023344551140925267 q_scale[0m
[[36m2024-07-09 13:53:48,721[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18242967939942023 obs_scale[0m
[[36m2024-07-09 13:53:48,738[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:53:48,738[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 100 __________________[0m
[[36m2024-07-09 13:53:48,738[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:53:48,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
                                                                                                                                                                                                                                                                                                                                                                                                                                                               0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:53:58,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:53:58,569[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:53:58,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:53:58,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:53:58,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:53:58,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:53:58,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:53:58,574[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:53:58,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:53:58,607[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:53:58,617[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.67it/s v_num: 0.000
[[36m2024-07-09 13:54:46,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:54:46,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/046[0m
[[36m2024-07-09 13:54:47,002[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:54:47,021[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009565014036640069, lr[0m
[[36m2024-07-09 13:54:47,035[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:54:47,053[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.34506984509019295 prior_scale[0m
[[36m2024-07-09 13:54:47,070[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.003685455758736428 q_scale[0m
[[36m2024-07-09 13:54:47,089[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.15414064923650173 obs_scale[0m
[[36m2024-07-09 13:54:47,105[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:54:47,105[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-07-09 13:54:47,105[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:54:47,105[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.01it/s v_num: 0.000
[[36m2024-07-09 13:54:52,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:54:52,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/050[0m
[[36m2024-07-09 13:54:52,957[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:54:52,973[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008004423296681246, lr[0m
[[36m2024-07-09 13:54:52,986[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:54:53,001[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.01293252420029653 prior_scale[0m
[[36m2024-07-09 13:54:53,016[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011186743756862025 q_scale[0m
[[36m2024-07-09 13:54:53,030[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2769859168061826 obs_scale[0m
[[36m2024-07-09 13:54:53,043[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:54:53,043[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-07-09 13:54:53,043[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:54:53,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:54:56,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:54:56,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:54:56,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:54:56,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:54:56,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:54:56,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:54:56,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:54:56,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:54:56,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:54:56,946[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:54:56,957[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:55:02,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:55:02,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:55:02,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:55:02,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:55:02,355[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:55:02,355[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:55:02,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:55:02,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:55:02,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:55:02,386[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:55:02,395[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:08 • 0:00:00 23.87it/s v_num: 0.000
[[36m2024-07-09 13:56:49,404[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:56:49,407[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/099[0m
[[36m2024-07-09 13:56:49,556[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:56:49,580[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008563996009285412, lr[0m
[[36m2024-07-09 13:56:49,597[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 13:56:49,620[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11313703738507856 prior_scale[0m
[[36m2024-07-09 13:56:49,643[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013295546406292811 q_scale[0m
[[36m2024-07-09 13:56:49,661[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1311524144663996 obs_scale[0m
[[36m2024-07-09 13:56:49,675[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:56:49,675[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 101 __________________[0m
[[36m2024-07-09 13:56:49,675[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:56:49,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:56:59,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:56:59,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:56:59,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:56:59,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:56:59,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:56:59,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:56:59,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:56:59,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:56:59,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:56:59,074[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:56:59,089[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.35it/s v_num: 0.000
[[36m2024-07-09 13:57:23,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:57:23,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/051[0m
[[36m2024-07-09 13:57:23,289[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:57:23,309[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009983275142356426, lr[0m
[[36m2024-07-09 13:57:23,321[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:57:23,336[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.021674381606774942 prior_scale[0m
[[36m2024-07-09 13:57:23,352[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011064422875820064 q_scale[0m
[[36m2024-07-09 13:57:23,367[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2468998994744518 obs_scale[0m
[[36m2024-07-09 13:57:23,379[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:57:23,379[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-07-09 13:57:23,380[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:57:23,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:57:32,844[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:57:32,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:57:32,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:57:32,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:57:32,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:57:32,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:57:32,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:57:32,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:57:32,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:57:32,893[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:57:32,903[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 20.82it/s v_num: 0.000
[[36m2024-07-09 13:57:48,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:57:48,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/100[0m
[[36m2024-07-09 13:57:48,211[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-07-09 13:57:48,230[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003723936055878397, lr[0m
[[36m2024-07-09 13:57:48,245[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:57:48,263[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1010219527133161 prior_scale[0m
[[36m2024-07-09 13:57:48,281[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017077262544538239 q_scale[0m
[[36m2024-07-09 13:57:48,299[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.22265575697170692 obs_scale[0m
[[36m2024-07-09 13:57:48,314[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 13:57:48,315[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 102 __________________[0m
[[36m2024-07-09 13:57:48,315[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:57:48,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:57:57,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:57:57,705[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:57:57,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:57:57,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:57:57,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:57:57,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:57:57,709[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:57:57,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:57:57,710[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:57:57,740[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:57:57,749[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-07-09 13:57:57,751[0m][[34mtrain[0m][[32mINFO[0m] - Restoring pretrained net from: /home/g15farris/bin/forks/bayesaenet/src/results/TiO/pretrained/4/checkpoints/pretrained.ckpt[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:11 • 0:00:00 17.43it/s v_num: 0.000
[[36m2024-07-09 13:59:17,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:59:17,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/047[0m
[[36m2024-07-09 13:59:17,302[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:59:17,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2.2890169587522955e-05, lr[0m
[[36m2024-07-09 13:59:17,333[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:59:17,351[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.49714150224322423 prior_scale[0m
[[36m2024-07-09 13:59:17,368[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012976990188209795 q_scale[0m
[[36m2024-07-09 13:59:17,385[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.11988761985662352 obs_scale[0m
[[36m2024-07-09 13:59:17,399[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:59:17,399[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-07-09 13:59:17,400[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:59:17,400[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 13:59:26,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 13:59:26,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 13:59:26,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 13:59:26,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 13:59:26,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 13:59:26,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 13:59:26,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 13:59:26,772[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 13:59:26,773[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 13:59:26,803[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 13:59:26,815[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.34it/s v_num: 0.000
[[36m2024-07-09 13:59:53,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 13:59:53,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/052[0m
[[36m2024-07-09 13:59:53,787[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 13:59:53,802[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009910509003664507, lr[0m
[[36m2024-07-09 13:59:53,815[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 13:59:53,829[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.02233871411312435 prior_scale[0m
[[36m2024-07-09 13:59:53,844[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013339859150241517 q_scale[0m
[[36m2024-07-09 13:59:53,859[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24954087232591984 obs_scale[0m
[[36m2024-07-09 13:59:53,871[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 13:59:53,871[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-07-09 13:59:53,871[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 13:59:53,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:00:03,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:00:03,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:00:03,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:00:03,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:00:03,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:00:03,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:00:03,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:00:03,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:00:03,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:00:03,410[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:00:03,419[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 45.04it/s v_num: 0.000
[[36m2024-07-09 14:01:09,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:01:09,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/103[0m
[[36m2024-07-09 14:01:09,834[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:01:09,859[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008621959228834974, lr[0m
[[36m2024-07-09 14:01:09,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:01:09,894[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18536661334568047 prior_scale[0m
[[36m2024-07-09 14:01:09,912[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012948857528995068 q_scale[0m
[[36m2024-07-09 14:01:09,935[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1122258599574504 obs_scale[0m
[[36m2024-07-09 14:01:09,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:01:09,953[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 104 __________________[0m
[[36m2024-07-09 14:01:09,954[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:01:09,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:01:19,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:01:19,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:01:19,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:01:19,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:01:19,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:01:19,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:01:19,093[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:01:19,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:01:19,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:01:19,140[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:01:19,154[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:09 • 0:00:00 20.94it/s v_num: 0.000
[[36m2024-07-09 14:01:45,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:01:45,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/102[0m
[[36m2024-07-09 14:01:45,711[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:01:45,731[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008754141302576011, lr[0m
[[36m2024-07-09 14:01:45,747[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:01:45,765[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.18029945880796175 prior_scale[0m
[[36m2024-07-09 14:01:45,783[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012912450235121223 q_scale[0m
[[36m2024-07-09 14:01:45,803[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12837381829508013 obs_scale[0m
[[36m2024-07-09 14:01:45,819[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:01:45,820[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 105 __________________[0m
[[36m2024-07-09 14:01:45,820[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:01:45,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.82it/s v_num: 0.000
[[36m2024-07-09 14:01:52,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:01:52,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/048[0m
[[36m2024-07-09 14:01:52,150[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:01:52,167[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007668353308512287, lr[0m
[[36m2024-07-09 14:01:52,180[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:01:52,198[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.27782812387876704 prior_scale[0m
[[36m2024-07-09 14:01:52,215[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001833103575758552 q_scale[0m
[[36m2024-07-09 14:01:52,232[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16086286234172242 obs_scale[0m
[[36m2024-07-09 14:01:52,247[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-07-09 14:01:52,247[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-07-09 14:01:52,247[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:01:52,248[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:01:55,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:01:55,249[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:01:55,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:01:55,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:01:55,252[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:01:55,252[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:01:55,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:01:55,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:01:55,254[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:01:55,299[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:01:55,312[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:02:02,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:02:02,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:02:02,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:02:02,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:02:02,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:02:02,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:02:02,068[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:02:02,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:02:02,069[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:02:02,100[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:02:02,114[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.52it/s v_num: 0.000
[[36m2024-07-09 14:02:22,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:02:22,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/053[0m
[[36m2024-07-09 14:02:22,668[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:02:22,683[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009866511187482962, lr[0m
[[36m2024-07-09 14:02:22,695[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:02:22,710[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.021546031255890944 prior_scale[0m
[[36m2024-07-09 14:02:22,724[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013145467135159815 q_scale[0m
[[36m2024-07-09 14:02:22,738[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2445987645834857 obs_scale[0m
[[36m2024-07-09 14:02:22,750[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:02:22,750[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-07-09 14:02:22,751[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:02:22,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:02:32,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:02:32,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:02:32,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:02:32,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:02:32,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:02:32,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:02:32,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:02:32,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:02:32,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:02:32,307[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:02:32,329[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 44.28it/s v_num: 0.000
[[36m2024-07-09 14:03:34,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:03:34,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/104[0m
[[36m2024-07-09 14:03:34,657[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:03:34,677[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009370110707057495, lr[0m
[[36m2024-07-09 14:03:34,701[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:03:34,724[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1560083787351264 prior_scale[0m
[[36m2024-07-09 14:03:34,747[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001186325994314399 q_scale[0m
[[36m2024-07-09 14:03:34,788[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13171089474474162 obs_scale[0m
[[36m2024-07-09 14:03:34,807[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:03:34,807[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 106 __________________[0m
[[36m2024-07-09 14:03:34,807[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:03:34,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:03:44,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:03:44,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:03:44,194[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:03:44,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:03:44,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:03:44,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:03:44,197[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:03:44,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:03:44,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:03:44,237[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:03:44,247[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1tions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.70it/s v_num: 0.000
[[36m2024-07-09 14:04:24,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:04:24,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/050[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 38.20it/s v_num: 0.000
[[36m2024-07-09 14:04:24,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:04:24,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/105[0m
[[36m2024-07-09 14:04:24,843[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:04:24,861[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009817702883737223, lr[0m
[[36m2024-07-09 14:04:24,872[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:04:24,875[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:04:24,891[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008088248591552571, lr[0m
[[36m2024-07-09 14:04:24,893[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3648237546415477 prior_scale[0m
[[36m2024-07-09 14:04:24,905[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:04:24,910[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009208611396161119 q_scale[0m
[[36m2024-07-09 14:04:24,922[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2683876638347791 prior_scale[0m
[[36m2024-07-09 14:04:24,927[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20184212433311632 obs_scale[0m
[[36m2024-07-09 14:04:24,940[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001489233589638895 q_scale[0m
[[36m2024-07-09 14:04:24,941[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:04:24,951[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-07-09 14:04:24,951[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:04:24,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
[[36m2024-07-09 14:04:24,957[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10959774207612163 obs_scale[0m
[[36m2024-07-09 14:04:24,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:04:24,971[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 107 __________________[0m
[[36m2024-07-09 14:04:24,972[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:04:24,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:04:34,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:04:34,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:04:34,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:04:34,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:04:34,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:04:34,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:04:34,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:04:34,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:04:34,613[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:04:34,651[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:04:34,693[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:04:34,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:04:34,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:04:34,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:04:34,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:04:34,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:04:34,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:04:34,812[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:04:34,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:04:34,814[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:04:34,846[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:04:34,866[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.52it/s v_num: 0.000
[[36m2024-07-09 14:05:03,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:05:03,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/054[0m
[[36m2024-07-09 14:05:04,049[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:05:04,071[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008708548034624427, lr[0m
[[36m2024-07-09 14:05:04,087[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:05:04,126[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03380503618644328 prior_scale[0m
[[36m2024-07-09 14:05:04,151[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.001318866066071115 q_scale[0m
[[36m2024-07-09 14:05:04,202[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.326618400387211 obs_scale[0m
[[36m2024-07-09 14:05:04,219[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:05:04,219[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-07-09 14:05:04,220[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:05:04,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:05:13,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:05:13,797[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:05:13,797[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:05:13,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:05:13,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:05:13,800[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:05:13,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:05:13,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:05:13,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:05:13,852[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:05:13,862[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 43.36it/s v_num: 0.000
[[36m2024-07-09 14:05:46,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:05:46,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/106[0m
[[36m2024-07-09 14:05:46,840[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:05:46,858[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007929289120932708, lr[0m
[[36m2024-07-09 14:05:46,893[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:05:46,911[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.20174334102368915 prior_scale[0m
[[36m2024-07-09 14:05:46,929[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015264777322209111 q_scale[0m
[[36m2024-07-09 14:05:46,947[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1645088245466013 obs_scale[0m
[[36m2024-0724-07-09 14:05:47,532[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-07-09 14:05:47,532[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 109 __________________[0m
[[36m2024-07-09 14:05:47,532[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:05:47,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:05:58,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:05:58,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:05:58,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:05:58,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:05:58,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:05:58,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:05:58,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:05:58,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:05:58,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:05:58,091[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:05:58,106[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 24.29it/s v_num: 0.000
[[36m2024-07-09 14:06:15,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:06:15,246[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-50/108[0m
[[36m2024-07-09 14:06:15,349[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 110[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 22.84it/s v_num: 0.000
[[36m2024-07-09 14:06:17,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:06:17,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/109[0m
[[36m2024-07-09 14:06:17,145[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:06:17,163[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006619617052184004, lr[0m
[[36m2024-07-09 14:06:17,176[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:06:17,194[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17014048565976017 prior_scale[0m
[[36m2024-07-09 14:06:17,211[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009426751574741155 q_scale[0m
[[36m2024-07-09 14:06:17,227[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1802175174307117 obs_scale[0m
[[36m2024-07-09 14:06:17,241[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:06:17,241[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 110 __________________[0m
[[36m2024-07-09 14:06:17,241[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:06:17,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:06:26,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:06:26,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:06:26,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:06:26,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:06:26,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:06:26,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:06:26,933[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:06:26,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:06:26,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:06:26,948[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:06:26,961[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.42it/s v_num: 0.000
[[36m2024-07-09 14:07:39,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:07:39,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/055[0m
[[36m2024-07-09 14:07:40,036[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:07:40,059[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009977362906709595, lr[0m
[[36m2024-07-09 14:07:40,075[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:07:40,097[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.02805662970683291 prior_scale[0m
[[36m2024-07-09 14:07:40,119[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00270273739043871 q_scale[0m
[[36m2024-07-09 14:07:40,141[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2937197160987717 obs_scale[0m
[[36m2024-07-09 14:07:40,158[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:07:40,158[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-07-09 14:07:40,158[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:07:40,159[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:07:49,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:07:49,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:07:49,737[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:07:49,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:07:49,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:07:49,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:07:49,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:07:49,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:07:49,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:07:49,787[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:07:49,799[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 38.28it/s v_num: 0.000
[[36m2024-07-09 14:08:49,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:08:49,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/110[0m
[[36m2024-07-09 14:08:49,415[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:08:49,432[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006566138750342505, lr[0m
[[36m2024-07-09 14:08:49,445[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:08:49,462[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16497616004247403 prior_scale[0m
[[36m2024-07-09 14:08:49,479[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000926690799521946 q_scale[0m
[[36m2024-07-09 14:08:49,495[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13597829721164453 obs_scale[0m
[[36m2024-07-09 14:08:49,510[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:08:49,510[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 111 __________________[0m
[[36m2024-07-09 14:08:49,510[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:08:49,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:08:59,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:08:59,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:08:59,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:08:59,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:08:59,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:08:59,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:08:59,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:08:59,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:08:59,339[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:08:59,369[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:08:59,380[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 17.79it/s v_num: 0.000
[[36m2024-07-09 14:09:00,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:09:00,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/051[0m
[[36m2024-07-09 14:09:00,319[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:09:00,337[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009987751098448742, lr[0m
[[36m2024-07-09 14:09:00,352[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:09:00,369[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.3890540265953044 prior_scale[0m
[[36m2024-07-09 14:09:00,386[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013654929213680837 q_scale[0m
[[36m2024-07-09 14:09:00,405[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2465638477150061 obs_scale[0m
[[36m2024-07-09 14:09:00,419[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:09:00,420[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-07-09 14:09:00,420[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:09:00,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:09:10,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:09:10,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:09:10,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:09:10,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:09:10,169[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:09:10,169[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:09:10,170[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:09:10,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:09:10,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:09:10,202[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:09:10,235[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.49it/s v_num: 0.000
[[36m2024-07-09 14:10:13,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:10:13,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/056[0m
[[36m2024-07-09 14:10:13,846[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:10:13,866[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008394958029505624, lr[0m
[[36m2024-07-09 14:10:13,884[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:10:13,907[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.02197189327386971 prior_scale[0m
[[36m2024-07-09 14:10:13,929[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017543372377153402 q_scale[0m
[[36m2024-07-09 14:10:13,955[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2517412546112485 obs_scale[0m
[[36m2024-07-09 14:10:13,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:10:13,969[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-07-09 14:10:13,969[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:10:13,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:10:23,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:10:23,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:10:23,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:10:23,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:10:23,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:10:23,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:10:23,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:10:23,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:10:23,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:10:23,408[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:10:23,417[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 40.68it/s v_num: 0.000
[[36m2024-07-09 14:11:18,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:11:18,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/111[0m
[[36m2024-07-09 14:11:18,212[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:11:18,230[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000641715361349376, lr[0m
[[36m2024-07-09 14:11:18,245[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:11:18,262[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.16390192703468148 prior_scale[0m
[[36m2024-07-09 14:11:18,280[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00107640292905181 q_scale[0m
[[36m2024-07-09 14:11:18,335[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13748668422887206 obs_scale[0m
[[36m2024-07-09 14:11:18,350[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:11:18,350[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 112 __________________[0m
[[36m2024-07-09 14:11:18,350[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:11:18,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:11:27,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:11:27,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:11:27,937[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:11:27,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:11:27,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:11:27,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:11:27,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:11:27,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:11:27,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:11:27,986[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:11:27,997[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.40it/s v_num: 0.000
[[36m2024-07-09 14:12:42,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:12:42,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/057[0m
[[36m2024-07-09 14:12:43,035[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:12:43,050[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1.4584478417906338e-05, lr[0m
[[36m2024-07-09 14:12:43,062[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:12:43,076[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.019029004139403578 prior_scale[0m
[[36m2024-07-09 14:12:43,091[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006537936052597872 q_scale[0m
[[36m2024-07-09 14:12:43,113[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.19403684335925162 obs_scale[0m
[[36m2024-07-09 14:12:43,164[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:12:43,164[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-07-09 14:12:43,164[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:12:43,164[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:12:52,712[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:12:52,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:12:52,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:12:52,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:12:52,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:12:52,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:12:52,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:12:52,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:12:52,724[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:12:52,762[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:12:52,771[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.13it/s v_num: 0.000
[[36m2024-07-09 14:13:31,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:13:31,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/052[0m
[[36m2024-07-09 14:13:31,826[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:13:31,859[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008340139702733427, lr[0m
[[36m2024-07-09 14:13:31,877[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:13:31,894[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.31443063728378634 prior_scale[0m
[[36m2024-07-09 14:13:31,918[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014169641144098904 q_scale[0m
[[36m2024-07-09 14:13:31,936[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2418801640710272 obs_scale[0m
[[36m2024-07-09 14:13:31,950[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:13:31,950[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-07-09 14:13:31,950[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:13:31,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:13:41,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:13:41,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:13:41,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:13:41,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:13:41,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:13:41,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:13:41,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:13:41,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:13:41,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:13:41,655[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:13:41,665[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 38.37it/s v_num: 0.000
[[36m2024-07-09 14:13:41,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:13:41,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/112[0m
[[36m2024-07-09 14:13:42,041[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:13:42,066[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006557915428471379, lr[0m
[[36m2024-07-09 14:13:42,086[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:13:42,111[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1636510235678729 prior_scale[0m
[[36m2024-07-09 14:13:42,138[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011335086455972606 q_scale[0m
[[36m2024-07-09 14:13:42,163[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.12009277668620491 obs_scale[0m
[[36m2024-07-09 14:13:42,183[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:13:42,183[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 113 __________________[0m
[[36m2024-07-09 14:13:42,184[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:13:42,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:13:51,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:13:51,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:13:51,615[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:13:51,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:13:51,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:13:51,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:13:51,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:13:51,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:13:51,620[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:13:51,651[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:13:51,659[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.42it/s v_num: 0.000
[[36m2024-07-09 14:15:13,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:15:13,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/058[0m
[[36m2024-07-09 14:15:13,978[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:15:13,996[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004925756779926841, lr[0m
[[36m2024-07-09 14:15:14,010[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:15:14,029[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.03918055961413566 prior_scale[0m
[[36m2024-07-09 14:15:14,057[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00412245865128825 q_scale[0m
[[36m2024-07-09 14:15:14,091[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.46009189732229533 obs_scale[0m
[[36m2024-07-09 14:15:14,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-07-09 14:15:14,107[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-07-09 14:15:14,107[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:15:14,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:15:23,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:15:23,752[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:15:23,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:15:23,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:15:23,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:15:23,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:15:23,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:15:23,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:15:23,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:15:23,786[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:15:23,828[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 37.99it/s v_num: 0.000
[[36m2024-07-09 14:15:28,699[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/forks/bayesaenet/src/tasks/train.py", line 89, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 13.
[[36m2024-07-09 14:15:28,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:15:28,849[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:15:28,869[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005964703061220273, lr[0m
[[36m2024-07-09 14:15:28,888[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:15:28,909[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24847314880231502 prior_scale[0m
[[36m2024-07-09 14:15:28,928[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010668894650671856 q_scale[0m
[[36m2024-07-09 14:15:28,948[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1420654727071492 obs_scale[0m
[[36m2024-07-09 14:15:28,964[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:15:28,965[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 114 __________________[0m
[[36m2024-07-09 14:15:28,965[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:15:28,965[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:15:38,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:15:38,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:15:38,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:15:38,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:15:38,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:15:38,903[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:15:38,904[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:15:38,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:15:38,905[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:15:38,937[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:15:38,953[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.87it/s v_num: 0.000
[[36m2024-07-09 14:17:46,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:17:46,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_fo/runs/2024-07-09_11-44-35/059[0m
[[36m2024-07-09 14:17:46,700[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:05 • 0:00:00 35.57it/s v_num: 0.000
[[36m2024-07-09 14:17:59,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:17:59,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/114[0m
[[36m2024-07-09 14:17:59,445[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:17:59,464[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005781200287737217, lr[0m
[[36m2024-07-09 14:17:59,479[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:17:59,499[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.21932266431615044 prior_scale[0m
[[36m2024-07-09 14:17:59,518[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008741913122239985 q_scale[0m
[[36m2024-07-09 14:17:59,537[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.13858826588176604 obs_scale[0m
[[36m2024-07-09 14:17:59,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:17:59,553[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 115 __________________[0m
[[36m2024-07-09 14:17:59,553[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:17:59,554[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 17.84it/s v_num: 0.000
[[36m2024-07-09 14:18:06,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:18:06,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/053[0m
[[36m2024-07-09 14:18:06,552[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:18:06,576[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006639551432291082, lr[0m
[[36m2024-07-09 14:18:06,590[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:18:06,607[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4354191898790236 prior_scale[0m
[[36m2024-07-09 14:18:06,625[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009539615987324131 q_scale[0m
[[36m2024-07-09 14:18:06,642[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.17453014429763397 obs_scale[0m
[[36m2024-07-09 14:18:06,656[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:18:06,656[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-07-09 14:18:06,656[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:18:06,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:18:09,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:18:09,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:18:09,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:18:09,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:18:09,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:18:09,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:18:09,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:18:09,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:18:09,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:18:09,528[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:18:09,540[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:18:16,363[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:18:16,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:18:16,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:18:16,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:18:16,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:18:16,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:18:16,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:18:16,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:18:16,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:18:16,415[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:18:16,431[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 41.06it/s v_num: 0.000
[[36m2024-07-09 14:20:26,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:20:26,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/115[0m
[[36m2024-07-09 14:20:26,710[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:20:26,732[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005697596921423864, lr[0m
[[36m2024-07-09 14:20:26,747[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:20:26,767[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2204787043555453 prior_scale[0m
[[36m2024-07-09 14:20:26,790[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008987328765295584 q_scale[0m
[[36m2024-07-09 14:20:26,825[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374349411002972 obs_scale[0m
[[36m2024-07-09 14:20:26,842[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:20:26,842[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 116 __________________[0m
[[36m2024-07-09 14:20:26,842[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:20:26,843[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:20:36,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:20:36,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:20:36,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:20:36,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:20:36,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:20:36,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:20:36,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:20:36,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:20:36,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:20:36,243[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:20:36,258[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 17.87it/s v_num: 0.000
[[36m2024-07-09 14:22:32,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:22:32,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/054[0m
[[36m2024-07-09 14:22:32,822[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:22:32,847[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006512253027974992, lr[0m
[[36m2024-07-09 14:22:32,867[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:22:32,918[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.42419836005568834 prior_scale[0m
[[36m2024-07-09 14:22:32,943[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011553734553187997 q_scale[0m
[[36m2024-07-09 14:22:32,980[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1449338106809406 obs_scale[0m
[[36m2024-07-09 14:22:32,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:22:32,998[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-07-09 14:22:32,999[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:22:32,999[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 43.17it/s v_num: 0.000
[[36m2024-07-09 14:22:40,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:22:40,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/116[0m
[[36m2024-07-09 14:22:41,046[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:22:41,069[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006760714482394197, lr[0m
[[36m2024-07-09 14:22:41,086[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:22:41,123[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.254724931819729 prior_scale[0m
[[36m2024-07-09 14:22:41,145[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.000614064369250387 q_scale[0m
[[36m2024-07-09 14:22:41,186[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10500837994276925 obs_scale[0m
[[36m2024-07-09 14:22:41,204[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:22:41,204[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 117 __________________[0m
[[36m2024-07-09 14:22:41,205[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:22:41,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:22:42,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:22:42,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:22:42,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:22:42,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:22:42,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:22:42,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:22:42,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:22:42,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:22:42,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:22:42,658[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:22:42,666[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:22:50,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:22:50,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:22:50,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:22:50,968[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:22:50,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:22:50,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:22:50,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:22:50,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:22:50,971[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:22:51,016[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:22:51,027[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 40.53it/s v_num: 0.000
[[36m2024-07-09 14:25:04,570[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:25:04,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/117[0m
[[36m2024-07-09 14:25:04,717[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:25:04,762[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006225296780234571, lr[0m
[[36m2024-07-09 14:25:04,780[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:25:04,803[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24733102774507235 prior_scale[0m
[[36m2024-07-09 14:25:04,870[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006157726974646057 q_scale[0m
[[36m2024-07-09 14:25:05,009[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10637507378019147 obs_scale[0m
[[36m2024-07-09 14:25:05,028[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:25:05,028[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 118 __________________[0m
[[36m2024-07-09 14:25:05,029[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:25:05,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:25:14,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:25:25,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:25:25,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:25:25,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:25:25,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:25:25,962[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:25:25,964[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:25:25,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:25:25,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:25:26,062[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:25:27,931[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.43it/s v_num: 0.000
[[36m2024-07-09 14:27:08,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:27:08,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/055[0m
[[36m2024-07-09 14:27:08,255[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:27:08,322[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034317382964716895, lr[0m
[[36m2024-07-09 14:27:08,340[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:27:08,363[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.23052690124204908 prior_scale[0m
[[36m2024-07-09 14:27:08,396[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0027850434064186306 q_scale[0m
[[36m2024-07-09 14:27:08,435[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.14272606320120268 obs_scale[0m
[[36m2024-07-09 14:27:08,453[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:27:08,453[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-07-09 14:27:08,454[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:27:08,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:27:17,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:27:17,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:27:17,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:27:17,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:27:17,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:27:17,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:27:17,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:27:17,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:27:17,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:27:17,838[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:27:17,915[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 43.07it/s v_num: 0.000
[[36m2024-07-09 14:27:37,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:27:37,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/118[0m
[[36m2024-07-09 14:27:38,154[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:27:38,177[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009192320438858795, lr[0m
[[36m2024-07-09 14:27:38,194[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-07-09 14:27:38,224[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2580633626859015 prior_scale[0m
[[36m2024-07-09 14:27:38,246[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006084248515426921 q_scale[0m
[[36m2024-07-09 14:27:38,268[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10390512475588068 obs_scale[0m
[[36m2024-07-09 14:27:38,284[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:27:38,285[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 119 __________________[0m
[[36m2024-07-09 14:27:38,285[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:27:38,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:27:47,784[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:27:47,790[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:27:47,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:27:47,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:27:47,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:27:47,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:27:47,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:27:47,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:27:47,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:27:47,827[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:27:47,903[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:04 • 0:00:00 41.73it/s v_num: 0.000
[[36m2024-07-09 14:30:04,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:30:04,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_rad/runs/2024-07-09_11-44-35/119[0m
[[36m2024-07-09 14:30:04,184[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 120[0m
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.12it/s v_num: 0.000
[[36m2024-07-09 14:31:31,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:31:31,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/056[0m
[[36m2024-07-09 14:31:31,608[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:31:31,629[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006674660651851225, lr[0m
[[36m2024-07-09 14:31:31,646[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:31:31,666[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.4196490853943158 prior_scale[0m
[[36m2024-07-09 14:31:31,706[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015809000315293964 q_scale[0m
[[36m2024-07-09 14:31:31,727[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.1184810798945985 obs_scale[0m
[[36m2024-07-09 14:31:31,744[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:31:31,744[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-07-09 14:31:31,745[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:31:31,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:31:41,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:31:41,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:31:41,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:31:41,440[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:31:41,440[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:31:41,440[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:31:41,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:31:41,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:31:41,442[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:31:41,491[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:31:41,505[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.10it/s v_num: 0.000
[[36m2024-07-09 14:35:55,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:35:55,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/057[0m
[[36m2024-07-09 14:35:55,750[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:35:55,776[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006737332699442482, lr[0m
[[36m2024-07-09 14:35:55,794[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:35:55,819[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.42175487847065546 prior_scale[0m
[[36m2024-07-09 14:35:55,843[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010377973955905612 q_scale[0m
[[36m2024-07-09 14:35:55,869[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.2756122257078589 obs_scale[0m
[[36m2024-07-09 14:35:55,888[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:35:55,889[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-07-09 14:35:55,889[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:35:55,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:36:05,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:36:05,207[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:36:05,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:36:05,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:36:05,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:36:05,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:36:05,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:36:05,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:36:05,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:36:05,320[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:36:05,329[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.54it/s v_num: 0.000
[[36m2024-07-09 14:40:16,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:40:16,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/058[0m
[[36m2024-07-09 14:40:16,401[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-07-09 14:40:16,455[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008315530790318442, lr[0m
[[36m2024-07-09 14:40:16,474[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-07-09 14:40:16,498[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.24858804353372607 prior_scale[0m
[[36m2024-07-09 14:40:16,523[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017411938654766789 q_scale[0m
[[36m2024-07-09 14:40:16,546[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 0.10775203717722773 obs_scale[0m
[[36m2024-07-09 14:40:16,564[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-07-09 14:40:16,565[0m][[34msrc.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-07-09 14:40:16,565[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-07-09 14:40:16,565[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
0.8 0.1 0.1
[438, 3268, 1427, 6123, 1344]
0.8 0.1 0.1
[1982, 285, 321, 6931, 5191]
[[36m2024-07-09 14:40:26,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <src.models.bnn.BNN>[0m
[[36m2024-07-09 14:40:26,137[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-07-09 14:40:26,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-07-09 14:40:26,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-07-09 14:40:26,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-07-09 14:40:26,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-07-09 14:40:26,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-07-09 14:40:26,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-07-09 14:40:26,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-07-09 14:40:26,202[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-07-09 14:40:26,219[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  1.7 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  1.7 K │
│ 5  │ net.functions.0               │ Sequential │    831 │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │    710 │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    110 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     11 │
│ 9  │ net.functions.1               │ Sequential │    831 │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │    710 │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    110 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     11 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 1.7 K                                                         
Non-trainable params: 0                                                         
Total params: 1.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:10 • 0:00:00 18.24it/s v_num: 0.000
[[36m2024-07-09 14:44:36,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-07-09 14:44:36,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/forks/bayesaenet/src/logs/hps_lrt/runs/2024-07-09_11-44-35/059[0m
[[36m2024-07-09 14:44:37,064[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
