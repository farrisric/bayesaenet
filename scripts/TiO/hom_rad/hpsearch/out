{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 2000, 'max_epochs': 2000, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-05-12 11:50:40,893[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-05-12 11:50:40,894[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/hom_rad_100perc_big.db[0m
[[36m2025-05-12 11:50:42,146[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-05-12 11:50:42,171[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-05-12 11:50:42,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 11:50:42,351[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-05-12 11:50:42,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-12 11:50:42,443[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-05-12 11:50:42,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-05-12 11:50:42,518[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012313185468743894 obs_scale[0m
[[36m2025-05-12 11:50:42,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-12 11:50:42,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-05-12 11:50:42,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 11:50:42,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 11:50:48,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 11:50:48,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 11:50:48,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 11:50:48,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 11:50:48,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 11:50:48,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 11:50:48,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 11:50:48,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 11:50:48,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 11:50:48,559[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 11:50:48,791[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       56.61it/s v_num: 0.000    
                                      0:00:00                   rmse/val:       
                                                                180.999         
                                                                rmse/train:     
                                                                624.138         
[[36m2025-05-12 12:33:43,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-12 12:33:43,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/000[0m
[[36m2025-05-12 12:33:44,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 12:33:44,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010045932391231576, lr[0m
[[36m2025-05-12 12:33:44,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-12 12:33:44,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012904829303853454 prior_scale[0m
[[36m2025-05-12 12:33:44,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017570525244134657 q_scale[0m
[[36m2025-05-12 12:33:44,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010288040405240286 obs_scale[0m
[[36m2025-05-12 12:33:44,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-12 12:33:44,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-05-12 12:33:44,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 12:33:44,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 12:33:50,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 12:33:50,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 12:33:50,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 12:33:50,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 12:33:50,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 12:33:50,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 12:33:50,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 12:33:50,465[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 12:33:50,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 12:33:50,533[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 12:33:50,615[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       29.49it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 25.902
                                                                rmse/train:     
                                                                37.200          
[[36m2025-05-12 13:38:40,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-12 13:38:40,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/001[0m
[[36m2025-05-12 13:38:41,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 13:38:41,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4150196905720475e-05, lr[0m
[[36m2025-05-12 13:38:41,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-12 13:38:41,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08997760513084464 prior_scale[0m
[[36m2025-05-12 13:38:41,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038798086852341396 q_scale[0m
[[36m2025-05-12 13:38:41,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14286326515987452 obs_scale[0m
[[36m2025-05-12 13:38:41,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-12 13:38:41,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-05-12 13:38:41,301[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 13:38:41,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 13:38:47,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 13:38:47,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 13:38:47,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 13:38:47,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 13:38:47,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 13:38:47,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 13:38:47,061[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 13:38:47,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 13:38:47,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 13:38:48,242[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 13:38:48,320[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.13it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 20.750
                                                                rmse/train:     
                                                                31.725          
[[36m2025-05-12 14:47:14,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-12 14:47:14,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/002[0m
[[36m2025-05-12 14:47:14,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 14:47:14,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9388028480984598e-05, lr[0m
[[36m2025-05-12 14:47:14,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-12 14:47:15,045[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004532901866195528 prior_scale[0m
[[36m2025-05-12 14:47:15,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5005765657505178 q_scale[0m
[[36m2025-05-12 14:47:15,179[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005868985298319507 obs_scale[0m
[[36m2025-05-12 14:47:15,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-12 14:47:15,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-05-12 14:47:15,245[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 14:47:15,245[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 14:47:21,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 14:47:21,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 14:47:21,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 14:47:21,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 14:47:21,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 14:47:21,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 14:47:21,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 14:47:21,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 14:47:21,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 14:47:21,296[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 14:47:21,426[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:06 â€¢       29.71it/s v_num: 0.000   
                                       0:00:00                   rmse/val:      
                                                                 235.137        
                                                                 rmse/train:    
                                                                 363.324        
[[36m2025-05-12 19:41:48,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-12 19:41:49,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/003[0m
[[36m2025-05-12 19:41:51,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 19:41:52,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001546142648648772, lr[0m
[[36m2025-05-12 19:41:52,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-12 19:41:53,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04833917568085432 prior_scale[0m
[[36m2025-05-12 19:41:54,040[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020829257190366937 q_scale[0m
[[36m2025-05-12 19:41:54,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010277023093936914 obs_scale[0m
[[36m2025-05-12 19:41:55,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-12 19:41:55,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-05-12 19:41:55,330[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 19:41:55,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 19:42:04,814[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 19:42:04,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 19:42:04,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 19:42:04,968[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 19:42:04,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 19:42:04,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 19:42:04,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 19:42:04,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 19:42:04,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 19:42:24,303[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 19:42:25,606[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢       27.32it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 13.599
                                                                rmse/train:     
                                                                21.641          
[[36m2025-05-12 21:52:24,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-12 21:52:24,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/004[0m
[[36m2025-05-12 21:52:27,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-12 21:52:28,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006671842305866796, lr[0m
[[36m2025-05-12 21:52:29,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-12 21:52:29,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7523246408184491 prior_scale[0m
[[36m2025-05-12 21:52:30,404[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14718262393979 q_scale[0m
[[36m2025-05-12 21:52:31,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001383578612730786 obs_scale[0m
[[36m2025-05-12 21:52:31,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-12 21:52:31,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-05-12 21:52:31,601[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-12 21:52:31,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-12 21:52:39,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-12 21:52:39,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-12 21:52:39,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-12 21:52:39,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-12 21:52:39,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-12 21:52:39,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-12 21:52:39,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-12 21:52:39,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-12 21:52:39,631[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-12 21:53:01,183[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-12 21:53:02,694[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:05 â€¢       36.18it/s v_num: 0.000   
                                       0:00:00                   rmse/val:      
                                                                 10.613         
                                                                 rmse/train:    
                                                                 10.916         
[[36m2025-05-13 03:04:23,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 03:04:23,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/005[0m
[[36m2025-05-13 03:04:24,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 03:04:24,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.003810848108467e-05, lr[0m
[[36m2025-05-13 03:04:24,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-13 03:04:24,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022810914347080207 prior_scale[0m
[[36m2025-05-13 03:04:24,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08996886145567823 q_scale[0m
[[36m2025-05-13 03:04:25,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.022346758408902257 obs_scale[0m
[[36m2025-05-13 03:04:25,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-13 03:04:25,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-05-13 03:04:25,360[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 03:04:25,360[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 03:04:32,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 03:04:32,353[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 03:04:32,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 03:04:32,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 03:04:32,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 03:04:32,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 03:04:32,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 03:04:32,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 03:04:32,358[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 03:04:49,028[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 03:04:49,708[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 65/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       56.51it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               3622.958         
                                                               rmse/train:      
                                                               3643.943         
[[36m2025-05-13 03:06:25,929[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 65.
[[36m2025-05-13 03:06:27,202[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 03:06:27,674[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 03:06:27,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011795146111975982, lr[0m
[[36m2025-05-13 03:06:27,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 03:06:28,093[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.020449350394769326 prior_scale[0m
[[36m2025-05-13 03:06:28,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.028092862158076635 q_scale[0m
[[36m2025-05-13 03:06:28,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.470752138441911 obs_scale[0m
[[36m2025-05-13 03:06:28,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-13 03:06:28,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-05-13 03:06:28,667[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 03:06:28,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 03:06:34,865[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 03:06:34,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 03:06:34,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 03:06:34,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 03:06:34,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 03:06:34,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 03:06:34,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 03:06:34,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 03:06:34,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 03:06:36,936[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 03:06:37,764[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢       19.73it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 51.203
                                                                rmse/train:     
                                                                76.203          
[[36m2025-05-13 03:59:31,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 03:59:32,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/007[0m
[[36m2025-05-13 03:59:32,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 03:59:33,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018511923116382368, lr[0m
[[36m2025-05-13 03:59:33,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-13 03:59:33,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0507257930731161 prior_scale[0m
[[36m2025-05-13 03:59:33,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012968719897940156 q_scale[0m
[[36m2025-05-13 03:59:33,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6393152366775274 obs_scale[0m
[[36m2025-05-13 03:59:34,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-13 03:59:34,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-05-13 03:59:34,042[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 03:59:34,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 03:59:40,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 03:59:40,499[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 03:59:40,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 03:59:40,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 03:59:40,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 03:59:40,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 03:59:40,505[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 03:59:40,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 03:59:40,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 03:59:44,251[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 03:59:44,832[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       44.44it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 21.442
                                                                rmse/train:     
                                                                50.938          
[[36m2025-05-13 04:50:44,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 04:50:44,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/008[0m
[[36m2025-05-13 04:50:44,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 04:50:45,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021819434272647882, lr[0m
[[36m2025-05-13 04:50:45,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-13 04:50:45,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24581113447438505 prior_scale[0m
[[36m2025-05-13 04:50:45,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0170232827909058 q_scale[0m
[[36m2025-05-13 04:50:45,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.730039111673774 obs_scale[0m
[[36m2025-05-13 04:50:45,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-13 04:50:45,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-05-13 04:50:45,509[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 04:50:45,509[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 04:50:52,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 04:50:52,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 04:50:52,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 04:50:52,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 04:50:52,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 04:50:52,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 04:50:52,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 04:50:52,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 04:50:52,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 04:50:53,926[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 04:50:54,278[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢       35.69it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 68.582
                                                                rmse/train:     
                                                                70.553          
[[36m2025-05-13 05:34:07,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 05:34:07,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/009[0m
[[36m2025-05-13 05:34:08,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 05:34:08,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1267228743583923e-05, lr[0m
[[36m2025-05-13 05:34:08,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 05:34:08,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1438501886620343 prior_scale[0m
[[36m2025-05-13 05:34:09,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001361190166330691 q_scale[0m
[[36m2025-05-13 05:34:09,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12508757174951737 obs_scale[0m
[[36m2025-05-13 05:34:09,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 05:34:09,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-05-13 05:34:09,408[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 05:34:09,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 05:34:15,804[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 05:34:15,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 05:34:15,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 05:34:15,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 05:34:15,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 05:34:15,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 05:34:15,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 05:34:15,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 05:34:15,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 05:34:16,789[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 05:34:17,220[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.27it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 10.013
                                                                rmse/train:     
                                                                9.499           
[[36m2025-05-13 07:08:41,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 07:08:41,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/010[0m
[[36m2025-05-13 07:08:42,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 07:08:42,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0962454827051684e-05, lr[0m
[[36m2025-05-13 07:08:42,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 07:08:42,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13160546287420333 prior_scale[0m
[[36m2025-05-13 07:08:42,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011306332444916999 q_scale[0m
[[36m2025-05-13 07:08:42,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10193657033086194 obs_scale[0m
[[36m2025-05-13 07:08:43,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 07:08:43,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-05-13 07:08:43,046[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 07:08:43,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 07:08:49,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 07:08:49,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 07:08:49,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 07:08:49,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 07:08:49,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 07:08:49,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 07:08:49,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 07:08:49,517[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 07:08:49,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 07:08:55,677[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 07:08:56,030[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       27.60it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.361 
                                                                rmse/train:     
                                                                7.707           
[[36m2025-05-13 08:39:51,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 08:39:51,616[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/011[0m
[[36m2025-05-13 08:39:52,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 08:39:53,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0170394077008131e-05, lr[0m
[[36m2025-05-13 08:39:54,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 08:39:54,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2238470043565636 prior_scale[0m
[[36m2025-05-13 08:39:54,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012780894352276231 q_scale[0m
[[36m2025-05-13 08:39:55,079[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07946981200360269 obs_scale[0m
[[36m2025-05-13 08:39:55,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-13 08:39:55,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-05-13 08:39:55,326[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 08:39:55,326[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 08:40:01,773[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 08:40:01,779[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 08:40:01,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 08:40:01,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 08:40:01,800[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 08:40:01,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 08:40:01,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 08:40:01,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 08:40:01,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 08:40:03,403[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 08:40:04,231[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99/99 0:00:02 â€¢       36.02it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.815 
                                                                rmse/train:     
                                                                7.353           
[[36m2025-05-13 11:02:21,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 11:02:21,031[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/012[0m
[[36m2025-05-13 11:02:22,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 11:02:22,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.426915319227129e-05, lr[0m
[[36m2025-05-13 11:02:22,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 11:02:22,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9713491325966092 prior_scale[0m
[[36m2025-05-13 11:02:22,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011989003863340673 q_scale[0m
[[36m2025-05-13 11:02:23,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07411551140013035 obs_scale[0m
[[36m2025-05-13 11:02:23,513[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 11:02:23,513[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-05-13 11:02:23,513[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 11:02:23,514[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 11:02:29,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 11:02:29,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 11:02:29,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 11:02:29,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 11:02:29,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 11:02:29,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 11:02:29,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 11:02:29,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 11:02:29,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 11:02:31,243[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 11:02:31,357[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.52it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 14.202
                                                                rmse/train:     
                                                                12.503          
[[36m2025-05-13 12:53:54,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 12:53:54,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/013[0m
[[36m2025-05-13 12:53:56,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 12:53:56,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.646385857370898e-05, lr[0m
[[36m2025-05-13 12:53:56,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 12:53:56,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07502957320865422 prior_scale[0m
[[36m2025-05-13 12:53:56,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006624909942745963 q_scale[0m
[[36m2025-05-13 12:53:56,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019803364724850774 obs_scale[0m
[[36m2025-05-13 12:53:57,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 12:53:57,099[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-05-13 12:53:57,099[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 12:53:57,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 12:54:20,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 12:54:20,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 12:54:20,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 12:54:20,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 12:54:20,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 12:54:20,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 12:54:20,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 12:54:20,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 12:54:20,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 12:54:21,863[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 12:54:22,107[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 174/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       32.11it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 33.365 
                                                               rmse/train:      
                                                               32.453           
[[36m2025-05-13 13:01:36,603[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 174.
[[36m2025-05-13 13:01:37,204[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 13:01:38,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 13:01:38,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0003499066452017e-05, lr[0m
[[36m2025-05-13 13:01:38,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 13:01:38,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14028905483022555 prior_scale[0m
[[36m2025-05-13 13:01:39,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005351337564036122 q_scale[0m
[[36m2025-05-13 13:01:39,516[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.24770840369488722 obs_scale[0m
[[36m2025-05-13 13:01:39,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-13 13:01:39,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-05-13 13:01:39,605[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 13:01:39,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 13:01:45,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 13:01:45,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 13:01:45,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 13:01:45,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 13:01:45,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 13:01:45,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 13:01:45,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 13:01:45,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 13:01:45,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 13:01:48,013[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 13:01:48,132[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99/99 0:00:03 â€¢       29.10it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.741 
                                                                rmse/train:     
                                                                9.659           
[[36m2025-05-13 15:37:06,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 15:37:07,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/015[0m
[[36m2025-05-13 15:37:07,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 15:37:08,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.884207813495069e-05, lr[0m
[[36m2025-05-13 15:37:08,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 15:37:08,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3785957853752036 prior_scale[0m
[[36m2025-05-13 15:37:08,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005845252980016993 q_scale[0m
[[36m2025-05-13 15:37:08,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03804737433257131 obs_scale[0m
[[36m2025-05-13 15:37:08,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 15:37:08,934[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-05-13 15:37:08,934[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 15:37:08,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 15:37:15,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 15:37:15,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 15:37:15,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 15:37:15,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 15:37:15,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 15:37:15,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 15:37:15,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 15:37:15,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 15:37:15,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 15:37:17,213[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 15:37:17,604[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       25.22it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 8.260 
                                                                rmse/train:     
                                                                8.468           
[[36m2025-05-13 17:38:14,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 17:38:15,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/016[0m
[[36m2025-05-13 17:38:15,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 17:38:16,006[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038765931042035386, lr[0m
[[36m2025-05-13 17:38:16,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 17:38:16,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4343628588344081 prior_scale[0m
[[36m2025-05-13 17:38:16,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000551662647177075 q_scale[0m
[[36m2025-05-13 17:38:17,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03315568936559784 obs_scale[0m
[[36m2025-05-13 17:38:17,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 17:38:17,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-05-13 17:38:17,884[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 17:38:17,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 17:38:24,797[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 17:38:24,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 17:38:24,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 17:38:24,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 17:38:24,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 17:38:24,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 17:38:24,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 17:38:24,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 17:38:24,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 17:38:27,786[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 17:38:28,238[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.07it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 6.072 
                                                                rmse/train:     
                                                                7.614           
[[36m2025-05-13 19:33:54,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 19:33:54,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/017[0m
[[36m2025-05-13 19:33:54,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 19:33:55,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005123418043517805, lr[0m
[[36m2025-05-13 19:33:55,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 19:33:55,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5851292890746321 prior_scale[0m
[[36m2025-05-13 19:33:55,632[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015708334606843713 q_scale[0m
[[36m2025-05-13 19:33:55,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024138160548830005 obs_scale[0m
[[36m2025-05-13 19:33:56,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 19:33:56,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-05-13 19:33:56,009[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 19:33:56,009[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 19:34:02,588[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 19:34:02,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 19:34:02,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 19:34:02,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 19:34:02,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 19:34:02,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 19:34:02,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 19:34:02,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 19:34:02,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 19:34:03,337[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 19:34:03,476[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 127/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.04it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 46.073 
                                                               rmse/train:      
                                                               21.339           
[[36m2025-05-13 19:39:35,960[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 127.
[[36m2025-05-13 19:39:36,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 19:39:36,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 19:39:37,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003728050271772191, lr[0m
[[36m2025-05-13 19:39:37,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 19:39:37,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.024870896588286166 prior_scale[0m
[[36m2025-05-13 19:39:37,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003307581823536927 q_scale[0m
[[36m2025-05-13 19:39:37,857[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02751629365086828 obs_scale[0m
[[36m2025-05-13 19:39:37,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-13 19:39:37,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-05-13 19:39:37,972[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 19:39:37,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 19:39:44,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 19:39:44,575[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 19:39:44,576[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 19:39:44,578[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 19:39:44,578[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 19:39:44,578[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 19:39:44,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 19:39:44,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 19:39:44,580[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 19:39:45,474[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 19:39:45,818[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       27.23it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 9.855 
                                                                rmse/train:     
                                                                8.217           
[[36m2025-05-13 20:40:31,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 20:40:31,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/019[0m
[[36m2025-05-13 20:40:31,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 20:40:32,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009443477497964942, lr[0m
[[36m2025-05-13 20:40:32,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 20:40:32,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0103859329303333 prior_scale[0m
[[36m2025-05-13 20:40:32,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004347332133352647 q_scale[0m
[[36m2025-05-13 20:40:32,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014776575156886002 obs_scale[0m
[[36m2025-05-13 20:40:32,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-13 20:40:32,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-05-13 20:40:32,695[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 20:40:32,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 20:40:38,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 20:40:38,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 20:40:38,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 20:40:38,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 20:40:38,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 20:40:38,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 20:40:38,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 20:40:38,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 20:40:38,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 20:40:39,712[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 20:40:39,919[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99/99 0:00:02 â€¢       35.41it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.177 
                                                               rmse/train:      
                                                               51.693           
[[36m2025-05-13 20:41:53,165[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2025-05-13 20:41:53,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 20:41:54,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 20:41:54,362[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.826286832294235e-05, lr[0m
[[36m2025-05-13 20:41:54,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 20:41:54,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31747966026722296 prior_scale[0m
[[36m2025-05-13 20:41:54,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003415526872390564 q_scale[0m
[[36m2025-05-13 20:41:54,777[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03408110307600863 obs_scale[0m
[[36m2025-05-13 20:41:55,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 20:41:55,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-05-13 20:41:55,018[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 20:41:55,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 20:42:01,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 20:42:01,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 20:42:01,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 20:42:01,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 20:42:01,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 20:42:01,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 20:42:01,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 20:42:01,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 20:42:01,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 20:42:01,662[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 20:42:01,844[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       33.19it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 10.249
                                                                rmse/train:     
                                                                8.254           
[[36m2025-05-13 21:57:34,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 21:57:34,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/021[0m
[[36m2025-05-13 21:57:35,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 21:57:35,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028820788269183164, lr[0m
[[36m2025-05-13 21:57:35,363[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 21:57:35,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.43273462620143266 prior_scale[0m
[[36m2025-05-13 21:57:35,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009859287161846284 q_scale[0m
[[36m2025-05-13 21:57:35,728[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04919707176828436 obs_scale[0m
[[36m2025-05-13 21:57:35,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 21:57:35,871[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-05-13 21:57:35,871[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 21:57:35,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 21:57:41,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 21:57:41,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 21:57:41,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 21:57:41,716[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 21:57:41,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 21:57:41,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 21:57:41,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 21:57:41,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 21:57:41,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 21:57:42,003[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 21:57:42,193[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       33.42it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 8.146 
                                                                rmse/train:     
                                                                7.159           
[[36m2025-05-13 23:07:04,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-13 23:07:04,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/022[0m
[[36m2025-05-13 23:07:04,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-13 23:07:05,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.238169217845394e-05, lr[0m
[[36m2025-05-13 23:07:05,239[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-13 23:07:05,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4330488602334728 prior_scale[0m
[[36m2025-05-13 23:07:05,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028166269235788594 q_scale[0m
[[36m2025-05-13 23:07:05,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.250659780213397 obs_scale[0m
[[36m2025-05-13 23:07:05,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-13 23:07:05,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-05-13 23:07:05,481[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-13 23:07:05,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-13 23:07:11,440[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-13 23:07:11,445[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-13 23:07:11,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-13 23:07:11,470[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-13 23:07:11,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-13 23:07:11,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-13 23:07:11,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-13 23:07:11,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-13 23:07:11,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-13 23:07:12,160[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-13 23:07:12,424[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       37.15it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.945 
                                                                rmse/train:     
                                                                6.678           
[[36m2025-05-14 00:14:30,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 00:14:30,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/023[0m
[[36m2025-05-14 00:14:31,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 00:14:31,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.189808928741638e-05, lr[0m
[[36m2025-05-14 00:14:31,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 00:14:31,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13507530701341566 prior_scale[0m
[[36m2025-05-14 00:14:31,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023281785004701448 q_scale[0m
[[36m2025-05-14 00:14:31,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.014364509354844212 obs_scale[0m
[[36m2025-05-14 00:14:31,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 00:14:31,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-05-14 00:14:31,403[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 00:14:31,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 00:14:37,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 00:14:37,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 00:14:37,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 00:14:37,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 00:14:37,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 00:14:37,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 00:14:37,422[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 00:14:37,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 00:14:37,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 00:14:37,471[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 00:14:37,682[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 156/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       32.91it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 19.017 
                                                               rmse/train:      
                                                               18.970           
[[36m2025-05-14 00:19:44,570[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 156.
[[36m2025-05-14 00:19:44,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 00:19:45,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 00:19:45,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.025709591135247e-05, lr[0m
[[36m2025-05-14 00:19:45,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 00:19:45,201[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4775218922134707 prior_scale[0m
[[36m2025-05-14 00:19:45,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038765792007630453 q_scale[0m
[[36m2025-05-14 00:19:45,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004360824233693363 obs_scale[0m
[[36m2025-05-14 00:19:45,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-14 00:19:45,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-05-14 00:19:45,489[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 00:19:45,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 00:19:51,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 00:19:51,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 00:19:51,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 00:19:51,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 00:19:51,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 00:19:51,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 00:19:51,089[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 00:19:51,089[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 00:19:51,089[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 00:19:51,129[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 00:19:51,354[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 93/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:04 â€¢       40.05it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 43.364
                                                                rmse/train:     
                                                                49.513          
[[36m2025-05-14 00:29:32,485[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 93.
[[36m2025-05-14 00:29:32,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 00:29:32,868[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 00:29:32,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.6960704889299183e-05, lr[0m
[[36m2025-05-14 00:29:32,920[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 00:29:32,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09011554759866658 prior_scale[0m
[[36m2025-05-14 00:29:32,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001078753664675607 q_scale[0m
[[36m2025-05-14 00:29:33,077[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22213860766593982 obs_scale[0m
[[36m2025-05-14 00:29:33,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 00:29:33,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-05-14 00:29:33,108[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 00:29:33,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 00:29:38,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 00:29:38,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 00:29:38,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 00:29:38,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 00:29:38,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 00:29:38,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 00:29:38,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 00:29:38,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 00:29:38,722[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 00:29:38,760[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 00:29:38,941[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       55.13it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 11.099
                                                                rmse/train:     
                                                                15.762          
[[36m2025-05-14 01:10:23,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 01:10:23,358[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/026[0m
[[36m2025-05-14 01:10:23,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 01:10:23,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002832419881966086, lr[0m
[[36m2025-05-14 01:10:23,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 01:10:23,707[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19707740386367245 prior_scale[0m
[[36m2025-05-14 01:10:23,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005765651018710545 q_scale[0m
[[36m2025-05-14 01:10:23,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05620006458995668 obs_scale[0m
[[36m2025-05-14 01:10:23,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 01:10:23,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-05-14 01:10:23,816[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 01:10:23,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 01:10:29,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 01:10:29,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 01:10:29,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 01:10:29,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 01:10:29,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 01:10:29,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 01:10:29,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 01:10:29,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 01:10:29,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 01:10:29,708[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 01:10:29,860[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       31.48it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 12.924
                                                                rmse/train:     
                                                                10.678          
[[36m2025-05-14 02:13:52,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 02:13:52,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/027[0m
[[36m2025-05-14 02:13:53,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 02:13:53,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014279056018801808, lr[0m
[[36m2025-05-14 02:13:53,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 02:13:53,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.34623102072964546 prior_scale[0m
[[36m2025-05-14 02:13:53,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0075828062170623335 q_scale[0m
[[36m2025-05-14 02:13:53,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02342050474892703 obs_scale[0m
[[36m2025-05-14 02:13:53,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 02:13:53,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-05-14 02:13:53,212[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 02:13:53,212[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 02:13:59,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 02:13:59,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 02:13:59,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 02:13:59,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 02:13:59,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 02:13:59,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 02:13:59,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 02:13:59,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 02:13:59,238[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 02:14:04,660[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 02:14:04,933[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 123/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       28.23it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 53.524 
                                                               rmse/train:      
                                                               64.126           
[[36m2025-05-14 02:17:54,400[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 123.
[[36m2025-05-14 02:17:54,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 02:17:54,907[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 02:17:54,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.5229410469940185e-05, lr[0m
[[36m2025-05-14 02:17:54,976[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 02:17:54,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9551490751052607 prior_scale[0m
[[36m2025-05-14 02:17:55,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001964706891732991 q_scale[0m
[[36m2025-05-14 02:17:55,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10402803915417923 obs_scale[0m
[[36m2025-05-14 02:17:55,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 02:17:55,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-05-14 02:17:55,098[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 02:17:55,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 02:18:00,910[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 02:18:00,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 02:18:00,915[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 02:18:00,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 02:18:00,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 02:18:00,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 02:18:00,918[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 02:18:00,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 02:18:00,919[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 02:18:00,957[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 02:18:01,113[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       67.33it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 12.298
                                                                rmse/train:     
                                                                11.786          
[[36m2025-05-14 02:55:44,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 02:55:44,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/029[0m
[[36m2025-05-14 02:55:45,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 02:55:45,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.341497909300769e-05, lr[0m
[[36m2025-05-14 02:55:45,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 02:55:45,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8587595274941641 prior_scale[0m
[[36m2025-05-14 02:55:45,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001975284645156698 q_scale[0m
[[36m2025-05-14 02:55:45,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005081501590626796 obs_scale[0m
[[36m2025-05-14 02:55:45,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-14 02:55:45,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-05-14 02:55:45,336[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 02:55:45,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 02:55:51,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 02:55:51,024[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 02:55:51,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 02:55:51,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 02:55:51,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 02:55:51,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 02:55:51,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 02:55:51,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 02:55:51,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 02:55:51,060[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 02:55:51,255[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 122/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:02 â€¢       79.67it/s v_num: 0.000   
                                       0:00:00                   rmse/val:      
                                                                 46.022         
                                                                 rmse/train:    
                                                                 42.493         
[[36m2025-05-14 03:02:53,533[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 122.
[[36m2025-05-14 03:02:53,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 03:02:53,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 03:02:53,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.7520020320248394e-05, lr[0m
[[36m2025-05-14 03:02:53,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 03:02:53,938[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5212065403783638 prior_scale[0m
[[36m2025-05-14 03:02:53,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004020615230314697 q_scale[0m
[[36m2025-05-14 03:02:54,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11825917229834086 obs_scale[0m
[[36m2025-05-14 03:02:54,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 03:02:54,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-05-14 03:02:54,038[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 03:02:54,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 03:02:59,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 03:02:59,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 03:02:59,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 03:02:59,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 03:02:59,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 03:02:59,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 03:02:59,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 03:02:59,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 03:02:59,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 03:02:59,651[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 03:02:59,901[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       66.87it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 9.716 
                                                                rmse/train:     
                                                                9.750           
[[36m2025-05-14 03:40:11,971[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 03:40:11,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/031[0m
[[36m2025-05-14 03:40:12,140[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 03:40:12,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.869901477271844e-05, lr[0m
[[36m2025-05-14 03:40:12,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 03:40:12,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6854184927559372 prior_scale[0m
[[36m2025-05-14 03:40:12,336[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001926469910928216 q_scale[0m
[[36m2025-05-14 03:40:12,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.048927991669799116 obs_scale[0m
[[36m2025-05-14 03:40:12,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 03:40:12,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-05-14 03:40:12,385[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 03:40:12,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 03:40:18,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 03:40:18,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 03:40:18,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 03:40:18,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 03:40:18,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 03:40:18,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 03:40:18,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 03:40:18,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 03:40:18,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 03:40:18,234[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 03:40:18,417[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 214/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       55.34it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 33.164 
                                                               rmse/train:      
                                                               32.449           
[[36m2025-05-14 03:44:10,808[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 214.
[[36m2025-05-14 03:44:10,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 03:44:10,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 03:44:11,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4166570246230256e-05, lr[0m
[[36m2025-05-14 03:44:11,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 03:44:11,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29138647323904393 prior_scale[0m
[[36m2025-05-14 03:44:11,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010846893035953074 q_scale[0m
[[36m2025-05-14 03:44:11,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0158123337422316 obs_scale[0m
[[36m2025-05-14 03:44:11,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 03:44:11,248[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-05-14 03:44:11,248[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 03:44:11,248[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 03:44:16,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 03:44:16,857[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 03:44:16,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 03:44:16,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 03:44:16,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 03:44:16,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 03:44:16,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 03:44:16,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 03:44:16,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 03:44:16,898[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 03:44:17,024[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 456/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       67.71it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 32.030 
                                                               rmse/train:      
                                                               30.084           
[[36m2025-05-14 03:52:37,920[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 456.
[[36m2025-05-14 03:52:38,028[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 03:52:38,127[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 03:52:38,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.0847280124074187e-05, lr[0m
[[36m2025-05-14 03:52:38,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 03:52:38,314[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9892053497913509 prior_scale[0m
[[36m2025-05-14 03:52:38,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008679615254415239 q_scale[0m
[[36m2025-05-14 03:52:38,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006739486843888021 obs_scale[0m
[[36m2025-05-14 03:52:38,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 03:52:38,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-05-14 03:52:38,410[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 03:52:38,411[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 03:52:44,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 03:52:44,234[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 03:52:44,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 03:52:44,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 03:52:44,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 03:52:44,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 03:52:44,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 03:52:44,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 03:52:44,237[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 03:52:44,275[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 03:52:44,536[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 274/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:00 â€¢       67.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 85.599 
                                                               rmse/train:      
                                                               80.902           
[[36m2025-05-14 03:57:44,944[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 274.
[[36m2025-05-14 03:57:45,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 03:57:45,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 03:57:45,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.307018218980261e-05, lr[0m
[[36m2025-05-14 03:57:45,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 03:57:45,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.060892016266996626 prior_scale[0m
[[36m2025-05-14 03:57:45,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015558551569959016 q_scale[0m
[[36m2025-05-14 03:57:45,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16376442898351837 obs_scale[0m
[[36m2025-05-14 03:57:45,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 03:57:45,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-05-14 03:57:45,395[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 03:57:45,395[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 03:57:51,164[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 03:57:51,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 03:57:51,168[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 03:57:51,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 03:57:51,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 03:57:51,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 03:57:51,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 03:57:51,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 03:57:51,172[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 03:57:51,207[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 03:57:51,573[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       34.61it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 10.439
                                                                rmse/train:     
                                                                12.465          
[[36m2025-05-14 04:59:30,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 04:59:30,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/035[0m
[[36m2025-05-14 04:59:30,619[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 04:59:30,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5284659287062e-05, lr[0m
[[36m2025-05-14 04:59:30,708[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 04:59:30,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10599102237075748 prior_scale[0m
[[36m2025-05-14 04:59:30,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024853553023351234 q_scale[0m
[[36m2025-05-14 04:59:30,828[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10284702492197383 obs_scale[0m
[[36m2025-05-14 04:59:30,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-14 04:59:30,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-05-14 04:59:30,867[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 04:59:30,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 04:59:37,226[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 04:59:37,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 04:59:37,232[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 04:59:37,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 04:59:37,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 04:59:37,239[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 04:59:37,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 04:59:37,240[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 04:59:37,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 04:59:39,063[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 04:59:39,282[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 8/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢        36.82it/s v_num: 0.000     
                                    0:00:00                    rmse/val:        
                                                               4198.438         
                                                               rmse/train:      
                                                               4267.159         
[[36m2025-05-14 04:59:44,548[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 8.
[[36m2025-05-14 04:59:44,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 04:59:44,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 04:59:44,943[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.232499858350753e-05, lr[0m
[[36m2025-05-14 04:59:44,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 04:59:44,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18323069341270318 prior_scale[0m
[[36m2025-05-14 04:59:45,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020688867831255761 q_scale[0m
[[36m2025-05-14 04:59:45,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.344178389962515 obs_scale[0m
[[36m2025-05-14 04:59:45,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-14 04:59:45,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-05-14 04:59:45,076[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 04:59:45,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 04:59:51,017[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 04:59:51,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 04:59:51,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 04:59:51,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 04:59:51,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 04:59:51,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 04:59:51,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 04:59:51,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 04:59:51,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 04:59:51,039[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 04:59:51,185[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 831/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       28.54it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 11.310 
                                                               rmse/train: 7.969
[[36m2025-05-14 05:16:05,837[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 831.
[[36m2025-05-14 05:16:06,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 05:16:06,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 05:16:06,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.5400247166969838e-05, lr[0m
[[36m2025-05-14 05:16:06,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 05:16:06,372[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011992355511845796 prior_scale[0m
[[36m2025-05-14 05:16:06,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.495728969823813 q_scale[0m
[[36m2025-05-14 05:16:06,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03952204121747251 obs_scale[0m
[[36m2025-05-14 05:16:06,550[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 05:16:06,550[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-05-14 05:16:06,550[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 05:16:06,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 05:16:12,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 05:16:12,445[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 05:16:12,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 05:16:12,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 05:16:12,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 05:16:12,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 05:16:12,448[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 05:16:12,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 05:16:12,449[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 05:16:12,489[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 05:16:12,700[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 4/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢        34.92it/s v_num: 0.000     
                                    0:00:00                    rmse/val:        
                                                               4334.222         
                                                               rmse/train:      
                                                               4422.476         
[[36m2025-05-14 05:16:21,960[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 4.
[[36m2025-05-14 05:16:21,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 05:16:22,127[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 05:16:22,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.953118749894946e-05, lr[0m
[[36m2025-05-14 05:16:22,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 05:16:22,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6042376187671191 prior_scale[0m
[[36m2025-05-14 05:16:22,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043209997645016684 q_scale[0m
[[36m2025-05-14 05:16:22,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010382716649626006 obs_scale[0m
[[36m2025-05-14 05:16:22,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-14 05:16:22,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-05-14 05:16:22,368[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 05:16:22,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 05:16:28,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 05:16:28,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 05:16:28,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 05:16:28,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 05:16:28,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 05:16:28,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 05:16:28,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 05:16:28,135[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 05:16:28,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 05:16:28,143[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 05:16:28,392[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 144/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:02 â€¢       69.20it/s v_num: 0.000   
                                       0:00:00                   rmse/val:      
                                                                 22.319         
                                                                 rmse/train:    
                                                                 21.255         
[[36m2025-05-14 05:25:05,774[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 144.
[[36m2025-05-14 05:25:05,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 05:25:05,968[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 05:25:06,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8577330437506183e-05, lr[0m
[[36m2025-05-14 05:25:06,024[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 05:25:06,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29541797091698635 prior_scale[0m
[[36m2025-05-14 05:25:06,149[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03406397253205552 q_scale[0m
[[36m2025-05-14 05:25:06,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017988393443011327 obs_scale[0m
[[36m2025-05-14 05:25:06,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-14 05:25:06,224[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-05-14 05:25:06,224[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 05:25:06,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 05:25:11,822[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 05:25:11,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 05:25:11,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 05:25:11,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 05:25:11,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 05:25:11,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 05:25:11,829[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 05:25:11,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 05:25:11,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 05:25:11,867[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 05:25:12,056[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 83/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99/99 0:00:02 â€¢       38.65it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 285.121
                                                               rmse/train:      
                                                               359.558          
[[36m2025-05-14 05:29:42,405[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 83.
[[36m2025-05-14 05:29:42,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 05:29:42,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 05:29:42,688[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042005140768173045, lr[0m
[[36m2025-05-14 05:29:42,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 05:29:42,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4221057879233836 prior_scale[0m
[[36m2025-05-14 05:29:42,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009685869900113073 q_scale[0m
[[36m2025-05-14 05:29:42,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06685024427612524 obs_scale[0m
[[36m2025-05-14 05:29:42,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 05:29:42,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-05-14 05:29:42,955[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 05:29:42,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 05:29:48,703[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 05:29:48,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 05:29:48,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 05:29:48,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 05:29:48,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 05:29:48,710[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 05:29:48,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 05:29:48,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 05:29:48,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 05:29:48,747[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 05:29:49,025[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.47it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.161 
                                                                rmse/train:     
                                                                7.027           
[[36m2025-05-14 06:33:30,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 06:33:30,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/041[0m
[[36m2025-05-14 06:33:31,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 06:33:31,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006081877080686448, lr[0m
[[36m2025-05-14 06:33:31,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 06:33:31,707[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3923410955596767 prior_scale[0m
[[36m2025-05-14 06:33:31,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006110044560783872 q_scale[0m
[[36m2025-05-14 06:33:31,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16575193962845733 obs_scale[0m
[[36m2025-05-14 06:33:31,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 06:33:31,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-05-14 06:33:31,776[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 06:33:31,776[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 06:33:37,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 06:33:37,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 06:33:37,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 06:33:37,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 06:33:37,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 06:33:37,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 06:33:37,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 06:33:37,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 06:33:37,634[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 06:33:37,676[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 06:33:37,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       31.58it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 9.056 
                                                                rmse/train:     
                                                                6.073           
[[36m2025-05-14 07:40:30,938[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 07:40:30,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/042[0m
[[36m2025-05-14 07:40:31,199[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 07:40:31,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047383773595546905, lr[0m
[[36m2025-05-14 07:40:31,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 07:40:31,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7504652817461253 prior_scale[0m
[[36m2025-05-14 07:40:31,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016884874792017624 q_scale[0m
[[36m2025-05-14 07:40:31,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07789031236421033 obs_scale[0m
[[36m2025-05-14 07:40:31,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 07:40:31,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-05-14 07:40:31,407[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 07:40:31,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 07:40:37,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 07:40:37,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 07:40:37,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 07:40:37,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 07:40:37,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 07:40:37,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 07:40:37,500[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 07:40:37,500[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 07:40:37,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 07:40:38,214[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 07:40:38,444[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       30.31it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 5.641 
                                                                rmse/train:     
                                                                5.878           
[[36m2025-05-14 08:46:39,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 08:46:39,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/043[0m
[[36m2025-05-14 08:46:39,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 08:46:39,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000352112654339656, lr[0m
[[36m2025-05-14 08:46:39,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 08:46:39,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7122671272881399 prior_scale[0m
[[36m2025-05-14 08:46:39,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017674230964596156 q_scale[0m
[[36m2025-05-14 08:46:40,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08257054600173627 obs_scale[0m
[[36m2025-05-14 08:46:40,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-14 08:46:40,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-05-14 08:46:40,165[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 08:46:40,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 08:46:46,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 08:46:46,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 08:46:46,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 08:46:46,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 08:46:46,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 08:46:46,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 08:46:46,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 08:46:46,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 08:46:46,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 08:46:46,744[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 08:46:46,941[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 150/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢       18.35it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 45.637 
                                                               rmse/train:      
                                                               44.395           
[[36m2025-05-14 08:49:06,122[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 150.
[[36m2025-05-14 08:49:06,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 08:49:06,549[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 08:49:06,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008585917622019421, lr[0m
[[36m2025-05-14 08:49:06,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 08:49:06,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7556028900017333 prior_scale[0m
[[36m2025-05-14 08:49:06,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011006431030740183 q_scale[0m
[[36m2025-05-14 08:49:06,702[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4737254685303226 obs_scale[0m
[[36m2025-05-14 08:49:06,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 08:49:06,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-05-14 08:49:06,733[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 08:49:06,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 08:49:12,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 08:49:12,766[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 08:49:12,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 08:49:12,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 08:49:12,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 08:49:12,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 08:49:12,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 08:49:12,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 08:49:12,769[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 08:49:12,807[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 08:49:13,028[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 603/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       31.71it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 11.620 
                                                               rmse/train: 7.318
[[36m2025-05-14 09:09:14,151[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 603.
[[36m2025-05-14 09:09:14,230[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 09:09:14,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 09:09:14,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004611757553334225, lr[0m
[[36m2025-05-14 09:09:14,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-05-14 09:09:14,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21533994383717142 prior_scale[0m
[[36m2025-05-14 09:09:14,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000156079702274271 q_scale[0m
[[36m2025-05-14 09:09:14,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9104184084451744 obs_scale[0m
[[36m2025-05-14 09:09:14,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-14 09:09:14,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-05-14 09:09:14,601[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 09:09:14,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 09:09:20,854[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 09:09:20,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 09:09:20,860[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 09:09:20,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 09:09:20,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 09:09:20,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 09:09:20,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 09:09:20,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 09:09:20,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 09:09:20,901[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 09:09:21,008[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 352/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       46.28it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 13.734 
                                                               rmse/train:      
                                                               14.130           
[[36m2025-05-14 09:14:09,530[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 352.
[[36m2025-05-14 09:14:09,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 09:14:09,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 09:14:09,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007191400386354072, lr[0m
[[36m2025-05-14 09:14:09,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 09:14:09,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.038700289355471054 prior_scale[0m
[[36m2025-05-14 09:14:09,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037601106997545635 q_scale[0m
[[36m2025-05-14 09:14:09,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06922132018801168 obs_scale[0m
[[36m2025-05-14 09:14:09,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 09:14:09,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-05-14 09:14:09,837[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 09:14:09,837[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 09:14:16,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 09:14:16,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 09:14:16,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 09:14:16,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 09:14:16,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 09:14:16,048[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 09:14:16,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 09:14:16,048[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 09:14:16,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 09:14:16,089[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 09:14:16,247[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       35.74it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 9.750 
                                                                rmse/train:     
                                                                7.613           
[[36m2025-05-14 10:18:54,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 10:18:54,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/047[0m
[[36m2025-05-14 10:18:56,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 10:18:56,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000720421366293017, lr[0m
[[36m2025-05-14 10:18:56,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 10:18:56,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.038450340150464515 prior_scale[0m
[[36m2025-05-14 10:18:56,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014823543744103553 q_scale[0m
[[36m2025-05-14 10:18:57,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07385835433748311 obs_scale[0m
[[36m2025-05-14 10:18:57,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 10:18:57,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-05-14 10:18:57,222[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 10:18:57,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 10:19:02,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 10:19:02,913[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 10:19:02,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 10:19:03,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 10:19:03,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 10:19:03,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 10:19:03,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 10:19:03,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 10:19:03,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 10:19:03,225[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 10:19:03,612[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       34.82it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 6.457 
                                                                rmse/train:     
                                                                7.873           
[[36m2025-05-14 11:32:38,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 11:32:38,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/048[0m
[[36m2025-05-14 11:32:39,337[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 11:32:39,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006920654852517283, lr[0m
[[36m2025-05-14 11:32:39,559[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 11:32:39,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.036799296445032284 prior_scale[0m
[[36m2025-05-14 11:32:39,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025607519498798237 q_scale[0m
[[36m2025-05-14 11:32:39,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0749100097346775 obs_scale[0m
[[36m2025-05-14 11:32:40,020[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-05-14 11:32:40,020[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-05-14 11:32:40,021[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 11:32:40,021[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 11:32:46,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 11:32:46,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 11:32:46,551[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 11:32:46,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 11:32:46,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 11:32:46,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 11:32:46,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 11:32:46,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 11:32:46,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 11:32:50,454[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 11:32:50,586[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 68/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12/12 0:00:00 â€¢       20.02it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 61.458 
                                                               rmse/train:      
                                                               54.601           
[[36m2025-05-14 11:34:26,177[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 68.
[[36m2025-05-14 11:34:26,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 11:34:26,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 11:34:26,669[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007730702081887369, lr[0m
[[36m2025-05-14 11:34:26,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 11:34:26,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01152235331935026 prior_scale[0m
[[36m2025-05-14 11:34:26,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013421818436830824 q_scale[0m
[[36m2025-05-14 11:34:27,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.060808990907371706 obs_scale[0m
[[36m2025-05-14 11:34:27,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 11:34:27,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-05-14 11:34:27,331[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 11:34:27,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 11:34:33,252[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 11:34:33,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 11:34:33,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 11:34:33,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 11:34:33,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 11:34:33,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 11:34:33,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 11:34:33,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 11:34:33,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 11:34:33,881[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 11:34:34,179[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       35.87it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 18.331
                                                                rmse/train:     
                                                                11.578          
[[36m2025-05-14 12:53:39,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 12:53:39,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/050[0m
[[36m2025-05-14 12:53:40,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 12:53:40,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005118445232602843, lr[0m
[[36m2025-05-14 12:53:40,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 12:53:40,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01638228039324251 prior_scale[0m
[[36m2025-05-14 12:53:40,979[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008777591531383263 q_scale[0m
[[36m2025-05-14 12:53:41,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1700215689897516 obs_scale[0m
[[36m2025-05-14 12:53:41,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 12:53:41,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-05-14 12:53:41,329[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 12:53:41,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 12:53:47,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 12:53:47,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 12:53:47,501[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 12:53:47,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 12:53:47,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 12:53:47,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 12:53:47,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 12:53:47,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 12:53:47,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 12:53:53,406[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 12:53:53,526[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1417/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.53it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 7.451 
                                                                rmse/train:     
                                                                11.153          
[[36m2025-05-14 13:44:55,033[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 1417.
[[36m2025-05-14 13:44:55,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 13:44:55,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 13:44:55,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003866711287033719, lr[0m
[[36m2025-05-14 13:44:55,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 13:44:55,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006640422264843615 prior_scale[0m
[[36m2025-05-14 13:44:55,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031239592832920244 q_scale[0m
[[36m2025-05-14 13:44:55,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03111727039913473 obs_scale[0m
[[36m2025-05-14 13:44:56,157[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 13:44:56,157[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-05-14 13:44:56,157[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 13:44:56,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 13:45:02,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 13:45:02,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 13:45:02,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 13:45:02,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 13:45:02,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 13:45:02,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 13:45:02,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 13:45:02,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 13:45:02,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 13:45:05,917[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 13:45:06,048[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 552/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.65it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 20.267 
                                                               rmse/train:      
                                                               17.023           
[[36m2025-05-14 14:03:36,107[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 552.
[[36m2025-05-14 14:03:36,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 14:03:36,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 14:03:36,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022357950439642874, lr[0m
[[36m2025-05-14 14:03:36,977[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 14:03:37,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03738307793311759 prior_scale[0m
[[36m2025-05-14 14:03:37,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004204450632494787 q_scale[0m
[[36m2025-05-14 14:03:37,406[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08663771651007465 obs_scale[0m
[[36m2025-05-14 14:03:37,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 14:03:37,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-05-14 14:03:37,447[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 14:03:37,447[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 14:03:43,400[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 14:03:43,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 14:03:43,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 14:03:43,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 14:03:43,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 14:03:43,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 14:03:43,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 14:03:43,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 14:03:43,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 14:03:43,754[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 14:03:43,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 1999/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.13it/s v_num: 0.000    
                                      0:00:00                   rmse/val: 8.170 
                                                                rmse/train:     
                                                                6.919           
[[36m2025-05-14 15:13:22,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 15:13:22,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/hom_rad_hps_100perc/runs/2025-05-12_11-50-40/053[0m
[[36m2025-05-14 15:13:22,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 15:13:23,041[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023303793443836312, lr[0m
[[36m2025-05-14 15:13:23,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 15:13:23,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03563183640253542 prior_scale[0m
[[36m2025-05-14 15:13:23,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000760115343868976 q_scale[0m
[[36m2025-05-14 15:13:23,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02132024173371214 obs_scale[0m
[[36m2025-05-14 15:13:23,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 15:13:23,972[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-05-14 15:13:23,972[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 15:13:23,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 15:13:30,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 15:13:30,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 15:13:30,582[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 15:13:30,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 15:13:30,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 15:13:30,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 15:13:30,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 15:13:30,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 15:13:30,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 15:13:36,368[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 15:13:36,505[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 68/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.83it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 33.850 
                                                               rmse/train:      
                                                               26.093           
[[36m2025-05-14 15:16:00,777[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 68.
[[36m2025-05-14 15:16:01,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 15:16:02,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 15:16:02,528[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006166488191571716, lr[0m
[[36m2025-05-14 15:16:02,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 15:16:02,895[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.022873060997481317 prior_scale[0m
[[36m2025-05-14 15:16:03,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004773122066639206 q_scale[0m
[[36m2025-05-14 15:16:03,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35190132487702447 obs_scale[0m
[[36m2025-05-14 15:16:04,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-05-14 15:16:04,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-05-14 15:16:04,211[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 15:16:04,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 15:16:09,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 15:16:09,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 15:16:09,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 15:16:09,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 15:16:10,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 15:16:10,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 15:16:10,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 15:16:10,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 15:16:10,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 15:16:10,181[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 15:16:10,375[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 552/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 99/99 0:00:02 â€¢       40.05it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 7.674  
                                                               rmse/train:      
                                                               10.338           
[[36m2025-05-14 15:48:38,470[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 552.
[[36m2025-05-14 15:48:38,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 15:48:39,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 15:48:39,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000306882692061361, lr[0m
[[36m2025-05-14 15:48:39,459[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 15:48:39,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.047887370949955016 prior_scale[0m
[[36m2025-05-14 15:48:39,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0021250971975130925 q_scale[0m
[[36m2025-05-14 15:48:40,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.047492035307970165 obs_scale[0m
[[36m2025-05-14 15:48:40,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 15:48:40,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-05-14 15:48:40,419[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 15:48:40,420[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 15:48:46,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 15:48:46,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 15:48:46,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 15:48:46,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 15:48:46,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 15:48:46,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 15:48:46,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 15:48:46,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 15:48:46,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 15:48:47,886[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 15:48:48,109[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 247/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       36.80it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 30.381 
                                                               rmse/train:      
                                                               27.604           
[[36m2025-05-14 15:57:29,080[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 247.
[[36m2025-05-14 15:57:29,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 15:57:29,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 15:57:29,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044269943667266505, lr[0m
[[36m2025-05-14 15:57:29,907[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 15:57:30,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029976707898792795 prior_scale[0m
[[36m2025-05-14 15:57:30,091[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004730196199588347 q_scale[0m
[[36m2025-05-14 15:57:30,194[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06758173885027116 obs_scale[0m
[[36m2025-05-14 15:57:30,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-05-14 15:57:30,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-05-14 15:57:30,441[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 15:57:30,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 15:57:36,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 15:57:36,267[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 15:57:36,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 15:57:36,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 15:57:36,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 15:57:36,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 15:57:36,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 15:57:36,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 15:57:36,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 15:57:36,515[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 15:57:36,655[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 307/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 49/49 0:00:01 â€¢       32.43it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 16.205 
                                                               rmse/train:      
                                                               26.202           
[[36m2025-05-14 16:08:10,992[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 307.
[[36m2025-05-14 16:08:11,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 16:08:11,934[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 16:08:12,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002225851314983598, lr[0m
[[36m2025-05-14 16:08:12,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 16:08:12,534[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007490479799595967 prior_scale[0m
[[36m2025-05-14 16:08:12,686[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031107369950290496 q_scale[0m
[[36m2025-05-14 16:08:12,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011745297662378692 obs_scale[0m
[[36m2025-05-14 16:08:12,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-05-14 16:08:12,998[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-05-14 16:08:12,998[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 16:08:12,998[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 16:08:18,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 16:08:18,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 16:08:18,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 16:08:18,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 16:08:18,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 16:08:18,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 16:08:18,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 16:08:18,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 16:08:18,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 16:08:18,696[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 16:08:18,950[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 113/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 198/198 0:00:05 â€¢       39.51it/s v_num: 0.000   
                                       0:00:00                   rmse/val:      
                                                                 18.981         
                                                                 rmse/train:    
                                                                 19.606         
[[36m2025-05-14 16:20:03,182[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 113.
[[36m2025-05-14 16:20:03,366[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 16:20:03,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-05-14 16:20:03,718[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000554457575065993, lr[0m
[[36m2025-05-14 16:20:03,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-05-14 16:20:03,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026095204478701773 prior_scale[0m
[[36m2025-05-14 16:20:03,965[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012685355515773013 q_scale[0m
[[36m2025-05-14 16:20:04,101[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029703262066116568 obs_scale[0m
[[36m2025-05-14 16:20:04,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-05-14 16:20:04,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-05-14 16:20:04,250[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-05-14 16:20:04,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Valid indices: 704 [2735, 6889, 4459, 3205, 707]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-05-14 16:20:10,202[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hom_bnn.BNN>[0m
[[36m2025-05-14 16:20:10,206[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-05-14 16:20:10,206[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-05-14 16:20:10,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-05-14 16:20:10,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-05-14 16:20:10,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-05-14 16:20:10,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-05-14 16:20:10,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-05-14 16:20:10,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-05-14 16:20:10,365[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-05-14 16:20:10,631[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                          â”ƒ Type       â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                           â”‚ NetAtom    â”‚  2.6 K â”‚
â”‚ 1  â”‚ net.linear                    â”‚ Identity   â”‚      0 â”‚
â”‚ 2  â”‚ net.tanh                      â”‚ Tanh       â”‚      0 â”‚
â”‚ 3  â”‚ net.sigmoid                   â”‚ Sigmoid    â”‚      0 â”‚
â”‚ 4  â”‚ net.functions                 â”‚ ModuleList â”‚  2.6 K â”‚
â”‚ 5  â”‚ net.functions.0               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 6  â”‚ net.functions.0.Linear_Sp1_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 7  â”‚ net.functions.0.Linear_Sp1_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 8  â”‚ net.functions.0.Linear_Sp1_F3 â”‚ Linear     â”‚     16 â”‚
â”‚ 9  â”‚ net.functions.1               â”‚ Sequential â”‚  1.3 K â”‚
â”‚ 10 â”‚ net.functions.1.Linear_Sp2_F1 â”‚ Linear     â”‚  1.1 K â”‚
â”‚ 11 â”‚ net.functions.1.Linear_Sp2_F2 â”‚ Linear     â”‚    240 â”‚
â”‚ 12 â”‚ net.functions.1.Linear_Sp2_F3 â”‚ Linear     â”‚     16 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 59/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25/25 0:00:00 â€¢       30.19it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 29.251 
                                                               rmse/train:      
                                                               34.058           
[[36m2025-05-14 16:21:39,674[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 59.
[[36m2025-05-14 16:21:39,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-05-14 16:21:40,312[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
