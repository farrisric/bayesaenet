/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
Error executing job with overrides: ['model=bnn_lrt', 'datamodule=TiO', 'hpsearch=bnn_lrt', 'task_name=TiO_hps_lrt', 'tags=[TiO]', 'datamodule.test_split=0.85', 'datamodule.valid_split=0.1']
Error in call to target 'optuna.study.study.create_study':
OperationalError('(sqlite3.OperationalError) unable to open database file')
full_key: hpsearch.study

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2024-11-28 11:43:23,133] A new study created in RDB with name: bnn_lrt
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:44:20,513] Trial 0 finished with value: 2260.19921875 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:44:41,642] Trial 1 finished with value: 769847.625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:45:04,349] Trial 2 finished with value: 3508192.5 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:45:26,192] Trial 3 finished with value: 7699468.5 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:45:58,542] Trial 4 finished with value: 7458.89404296875 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:46:22,845] Trial 5 finished with value: 16565.841796875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:47:03,545] Trial 6 finished with value: 450565.9375 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:47:26,661] Trial 7 finished with value: 3980620.25 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:00,806] Trial 8 finished with value: 564700.0 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:30,225] Trial 9 finished with value: 266573.0 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 2260.19921875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:49:27,283] Trial 10 finished with value: 745.089111328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 745.089111328125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:24,904] Trial 11 finished with value: 687.2398681640625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 11 with value: 687.2398681640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:51:20,143] Trial 12 finished with value: 801.294921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 11 with value: 687.2398681640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:52:22,348] Trial 13 finished with value: 1191.488037109375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00041083464782765, 'mc_samples_train': 1, 'prior_scale': 0.010681584644486384, 'q_scale': 0.00010286418411102614, 'obs_scale': 1.9219688122603429, 'batch_size': 32}. Best is trial 11 with value: 687.2398681640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:53:57,152] Trial 14 finished with value: 349.45916748046875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00045339513832139654, 'mc_samples_train': 1, 'prior_scale': 0.023849059537582474, 'q_scale': 0.00020919808833152, 'obs_scale': 0.9330914898114858, 'batch_size': 32}. Best is trial 14 with value: 349.45916748046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:54:58,509] Trial 15 finished with value: 404.4218444824219 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005145519904373549, 'mc_samples_train': 1, 'prior_scale': 0.032326627210685015, 'q_scale': 0.0002639703151199391, 'obs_scale': 0.7686598871562234, 'batch_size': 32}. Best is trial 14 with value: 349.45916748046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:55:18,181] Trial 16 finished with value: 83823.609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006845758990621392, 'mc_samples_train': 1, 'prior_scale': 0.03873241599615214, 'q_scale': 0.0002842786274653047, 'obs_scale': 0.6443333128611081, 'batch_size': 512}. Best is trial 14 with value: 349.45916748046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:56:11,266] Trial 17 finished with value: 3475.68603515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00018259475214064708, 'mc_samples_train': 1, 'prior_scale': 0.028250375281397913, 'q_scale': 0.0006453166895704934, 'obs_scale': 0.6842168027625001, 'batch_size': 32}. Best is trial 14 with value: 349.45916748046875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:57:07,732] Trial 18 finished with value: 295.6241455078125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005466272984405296, 'mc_samples_train': 1, 'prior_scale': 0.02585327475043572, 'q_scale': 0.00021481579137603492, 'obs_scale': 0.7403662798180316, 'batch_size': 32}. Best is trial 18 with value: 295.6241455078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:58:20,703] Trial 19 finished with value: 993.2035522460938 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002394274963123934, 'mc_samples_train': 1, 'prior_scale': 0.021212404309244242, 'q_scale': 0.0002166044462820909, 'obs_scale': 0.4892292458746359, 'batch_size': 32}. Best is trial 18 with value: 295.6241455078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:58:41,130] Trial 20 finished with value: 52529.43359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005771310637416294, 'mc_samples_train': 1, 'prior_scale': 0.053560889517850846, 'q_scale': 0.00019153693324404375, 'obs_scale': 1.2713997870038662, 'batch_size': 512}. Best is trial 18 with value: 295.6241455078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:59:39,180] Trial 21 finished with value: 416.6799621582031 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005316051835794628, 'mc_samples_train': 1, 'prior_scale': 0.03221910949549649, 'q_scale': 0.0006534789285293199, 'obs_scale': 0.775610308294421, 'batch_size': 32}. Best is trial 18 with value: 295.6241455078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:00:30,476] Trial 22 finished with value: 409.1775817871094 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009809488183100134, 'mc_samples_train': 1, 'prior_scale': 0.02068933646999042, 'q_scale': 0.00020054242226411918, 'obs_scale': 0.8894172267357463, 'batch_size': 32}. Best is trial 18 with value: 295.6241455078125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:01:28,415] Trial 23 finished with value: 190.2017822265625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005186379518449633, 'mc_samples_train': 1, 'prior_scale': 0.0465657596151099, 'q_scale': 0.0005683052700954933, 'obs_scale': 0.508789485500504, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:02:21,138] Trial 24 finished with value: 13574.3759765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00010446980030933377, 'mc_samples_train': 1, 'prior_scale': 0.05016661008807101, 'q_scale': 0.0005478728034067496, 'obs_scale': 0.5098948243064317, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:02:48,180] Trial 25 finished with value: 79132.9921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003581410704893196, 'mc_samples_train': 1, 'prior_scale': 0.02350539399843206, 'q_scale': 0.00017493704914882372, 'obs_scale': 0.32642076699209516, 'batch_size': 128}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:03:57,817] Trial 26 finished with value: 19074.005859375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0002028755161900531, 'mc_samples_train': 2, 'prior_scale': 0.042120232003093484, 'q_scale': 0.0008415488027439788, 'obs_scale': 0.5764408563064137, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:04:53,182] Trial 27 finished with value: 298.6196594238281 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006159824445838035, 'mc_samples_train': 1, 'prior_scale': 0.06837205937871046, 'q_scale': 0.00038928668713390444, 'obs_scale': 0.39094099448092023, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:05:48,956] Trial 28 finished with value: 242.50270080566406 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006930118187478702, 'mc_samples_train': 1, 'prior_scale': 0.07092781471546794, 'q_scale': 0.00042444254284321176, 'obs_scale': 0.3709659674924489, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:06:45,729] Trial 29 finished with value: 99729.7578125 and parameters: {'pretrain_epochs': 5, 'lr': 5.792661385133158e-05, 'mc_samples_train': 1, 'prior_scale': 0.1404660040736785, 'q_scale': 0.00032198251957808217, 'obs_scale': 0.2577649602311049, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:07:23,797] Trial 30 finished with value: 76325.4765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007374455166076234, 'mc_samples_train': 1, 'prior_scale': 0.07570808236407968, 'q_scale': 0.0004810927895398964, 'obs_scale': 0.37410602949316707, 'batch_size': 256}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:08:51,901] Trial 31 finished with value: 254.8773956298828 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006283261966460361, 'mc_samples_train': 1, 'prior_scale': 0.06764077505680173, 'q_scale': 0.0003292323879620187, 'obs_scale': 0.4347763468140665, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:09:45,714] Trial 32 finished with value: 2396.486572265625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003102068520966301, 'mc_samples_train': 1, 'prior_scale': 0.06514237781081299, 'q_scale': 0.0007985508727179825, 'obs_scale': 0.5382772515616056, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:10:38,125] Trial 33 finished with value: 624.1338500976562 and parameters: {'pretrain_epochs': 5, 'lr': 0.00014007324425437467, 'mc_samples_train': 1, 'prior_scale': 0.09774303384593354, 'q_scale': 0.0004048785710082788, 'obs_scale': 0.31016511105578987, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:11:09,751] Trial 34 finished with value: 1830608.0 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007085735397886653, 'mc_samples_train': 1, 'prior_scale': 0.04225844145738929, 'q_scale': 0.0011124763887668482, 'obs_scale': 0.22737859112894407, 'batch_size': 512}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:11:35,026] Trial 35 finished with value: 667521.8125 and parameters: {'pretrain_epochs': 5, 'lr': 3.1181106311475416e-05, 'mc_samples_train': 2, 'prior_scale': 0.05939341571592686, 'q_scale': 0.00014643302226281842, 'obs_scale': 0.42951271742604996, 'batch_size': 256}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:12:12,430] Trial 36 finished with value: 231.1719970703125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009909763784500848, 'mc_samples_train': 1, 'prior_scale': 0.08651284191763688, 'q_scale': 0.0003308751116066208, 'obs_scale': 1.380485683893914, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:12:50,200] Trial 37 finished with value: 986.4826049804688 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009672308982173323, 'mc_samples_train': 1, 'prior_scale': 0.1444502941463376, 'q_scale': 0.00033200531152018765, 'obs_scale': 1.4453828736259495, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:13:34,926] Trial 38 finished with value: 10647.48046875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008033269868617764, 'mc_samples_train': 2, 'prior_scale': 0.09343204750851945, 'q_scale': 0.0015472770202428195, 'obs_scale': 0.19076564781086774, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:14:38,667] Trial 39 finished with value: 113065.359375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004852557184945005, 'mc_samples_train': 1, 'prior_scale': 0.12078763427741847, 'q_scale': 0.0006638999239178971, 'obs_scale': 0.271077181030334, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:15:40,768] Trial 40 finished with value: 634.556396484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008446572198434881, 'mc_samples_train': 2, 'prior_scale': 0.1670084059403248, 'q_scale': 0.0024311007725835504, 'obs_scale': 0.6163552082840623, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:16:09,173] Trial 41 finished with value: 2550.3408203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000608670889742926, 'mc_samples_train': 1, 'prior_scale': 0.2534754177958895, 'q_scale': 0.00028381696975508845, 'obs_scale': 1.1210446779774796, 'batch_size': 128}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:16:50,138] Trial 42 finished with value: 176357.859375 and parameters: {'pretrain_epochs': 5, 'lr': 1.3626307793529599e-05, 'mc_samples_train': 1, 'prior_scale': 0.08788888184736375, 'q_scale': 0.0004988869219729473, 'obs_scale': 0.3549034067887779, 'batch_size': 64}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:17:54,668] Trial 43 finished with value: 3749.732177734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00032861891225426, 'mc_samples_train': 1, 'prior_scale': 0.07666832790534799, 'q_scale': 0.00014620774387750704, 'obs_scale': 0.4965130307771064, 'batch_size': 32}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:18:15,307] Trial 44 finished with value: 188210.0 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004441273334092611, 'mc_samples_train': 1, 'prior_scale': 0.04858590793967003, 'q_scale': 0.00035074180594015165, 'obs_scale': 0.4490793723261879, 'batch_size': 256}. Best is trial 23 with value: 190.2017822265625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:19:14,192] Trial 45 finished with value: 107.92667388916016 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009731621477063434, 'mc_samples_train': 1, 'prior_scale': 0.11314053370703914, 'q_scale': 0.00026256928685157666, 'obs_scale': 0.9731611260603764, 'batch_size': 32}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:20:08,460] Trial 46 finished with value: 176.83883666992188 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009976727752850699, 'mc_samples_train': 1, 'prior_scale': 0.1084832650001573, 'q_scale': 0.009917072934430256, 'obs_scale': 1.3923505894914396, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:20:44,314] Trial 47 finished with value: 142.97409057617188 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009454380081024538, 'mc_samples_train': 1, 'prior_scale': 0.11134827017201387, 'q_scale': 0.008511764019394158, 'obs_scale': 1.4996348595559448, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:22:01,581] Trial 48 finished with value: 1114.552490234375 and parameters: {'pretrain_epochs': 0, 'lr': 0.0009345695213062321, 'mc_samples_train': 1, 'prior_scale': 0.13563992309636252, 'q_scale': 0.009004435545265699, 'obs_scale': 1.4403615508005898, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:22:58,806] Trial 49 finished with value: 136.506103515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008069571355559042, 'mc_samples_train': 2, 'prior_scale': 0.23691084212188213, 'q_scale': 0.006650649101091561, 'obs_scale': 1.5644749661445803, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:23:42,680] Trial 50 finished with value: 182.09800720214844 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008032836460696829, 'mc_samples_train': 2, 'prior_scale': 0.2732494723314175, 'q_scale': 0.0071296629725030244, 'obs_scale': 1.5778628053262806, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:24:30,087] Trial 51 finished with value: 179.62835693359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007879425455883685, 'mc_samples_train': 2, 'prior_scale': 0.3100644330393728, 'q_scale': 0.0068747614272944724, 'obs_scale': 1.6715635334860768, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:25:18,991] Trial 52 finished with value: 152.44558715820312 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008055602067447861, 'mc_samples_train': 2, 'prior_scale': 0.3275122693316006, 'q_scale': 0.006816749111938072, 'obs_scale': 1.6813792701841797, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:26:00,675] Trial 53 finished with value: 197.0473175048828 and parameters: {'pretrain_epochs': 5, 'lr': 0.000803411916757, 'mc_samples_train': 2, 'prior_scale': 0.31443063728378634, 'q_scale': 0.005085846881553687, 'obs_scale': 1.714302904129819, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:26:46,383] Trial 54 finished with value: 574.1787719726562 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006765995937538625, 'mc_samples_train': 2, 'prior_scale': 0.38684103204817577, 'q_scale': 0.0071531115279282135, 'obs_scale': 1.1710358355000061, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:27:32,724] Trial 55 finished with value: 562.683349609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00041396287254659805, 'mc_samples_train': 2, 'prior_scale': 0.20145712947057395, 'q_scale': 0.0029483222164495486, 'obs_scale': 1.0183768641370026, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:28:12,123] Trial 56 finished with value: 163.14639282226562 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009980132050516814, 'mc_samples_train': 2, 'prior_scale': 0.4620817968593115, 'q_scale': 0.005791562556897836, 'obs_scale': 1.6263904383462326, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:28:53,464] Trial 57 finished with value: 196.4598846435547 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009273348961245869, 'mc_samples_train': 2, 'prior_scale': 0.4284797272616394, 'q_scale': 0.009973412095057343, 'obs_scale': 1.2881824014817747, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:29:37,129] Trial 58 finished with value: 345.1190490722656 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005718132867132097, 'mc_samples_train': 2, 'prior_scale': 0.2312391376011191, 'q_scale': 0.003839330514382399, 'obs_scale': 1.9970064471371654, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:30:18,034] Trial 59 finished with value: 4254.951171875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002569172154127667, 'mc_samples_train': 2, 'prior_scale': 0.35439741392597046, 'q_scale': 0.005681897410668955, 'obs_scale': 0.9403475965675654, 'batch_size': 64}. Best is trial 45 with value: 107.92667388916016.
