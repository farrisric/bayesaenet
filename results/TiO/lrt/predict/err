GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/TiO_train_lrt_80/runs/2025-02-11_11-06-45/checkpoints/epoch_27787-step_2723224.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}", "ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/TiO_train_lrt_80/runs/2025-02-11_11-06-45/checkpoints/epoch_27787-step_2723224.ckpt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/TiO_train_lrt_80_sigmaprior10/runs/2025-02-11_14-04-56/checkpoints/epoch_16733-step_1639932.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}", "ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/TiO_train_lrt_80_sigmaprior10/runs/2025-02-11_14-04-56/checkpoints/epoch_16733-step_1639932.ckpt
GPU available: False, used: False
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_1626-step_317265.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_1626-step_317265.ckpt
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_2511-step_489840.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_2511-step_489840.ckpt
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_1737-step_338910.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_1737-step_338910.ckpt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_16817-step_3279510.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_16817-step_3279510.ckpt
GPU available: False, used: False
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
U available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_17379-step_3389100.ckpt
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_9500-step_1852695.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_9500-step_1852695.ckpt
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_11245-step_2192970.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}", "ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_11245-step_2192970.ckpt
Error executing job with overrides: ['task_name=final_TiO_pred_lrt_80_sigmaoptuna', 'prediction=TiO', 'ckpt_path=all', '+method=LRT', 'runs_dir=bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna']
Traceback (most recent call last):
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 112, in <module>
    main()
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 108, in main
    predict(cfg)
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 97, in predict
    predictions = predictions.explode(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/pandas/core/frame.py", line 9852, in explode
    raise ValueError("columns must have matching element counts")
ValueError: columns must have matching element counts
e 260, in return_value
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
    raise self._return_value
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 108, in main
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 108, in main
    predict(cfg)
    predict(cfg)
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 97, in predict
  File "/home/g15telari/TiO/bayesaenet/bnn_aenet/tasks/predict.py", line 97, in predict
    predictions = predictions.explode(
    predictions = predictions.explode(
                  ^^^^^^^^^^^^^^^^^^^^
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/pandas/core/frame.py", line 9852, in explode
  File "/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/pandas/core/frame.py", line 9852, in explode
    raise ValueError("columns must have matching element counts")
ValueError: columns must have matching element counts
    raise ValueError("columns must have matching element counts")
ValueError: columns must have matching element counts
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_11245-step_2192970.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaoptuna/runs/2025-02-13_20-24-38/checkpoints/epoch_11245-step_2192970.ckpt

/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}", "ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_9500-step_1852695.ckpt
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior10/runs/2025-02-13_20-15-48/checkpoints/epoch_17379-step_3389100.ckpt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_9500-step_1852695.ckpt
/home/g15telari/.conda/envs/bayesian/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: ["ModelCheckpoint{'monitor': 'elbo/val', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}", "EarlyStopping{'monitor': 'elbo/val', 'mode': 'min'}"].
Loaded model weights from the checkpoint at bnn_aenet/logs/final_TiO_train_lrt_80_sigmaprior1/runs/2025-02-13_20-17-21/checkpoints/epoch_9500-step_1852695.ckpt
t
t
