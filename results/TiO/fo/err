In 'hpsearch': Could not find 'hpsearch/Ti_bnn_fo'

Available options in 'hpsearch':
	bnn_fo
	bnn_lrt
	bnn_rad
Config search path:
	provider=hydra, path=pkg://hydra.conf
	provider=main, path=file:///home/g15farris/bin/bayesaenet/bnn_aenet/configs
	provider=hydra-colorlog, path=pkg://hydra_plugins.hydra_colorlog.conf
	provider=schema, path=structured://

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2024-11-28 11:46:36,370] A new study created in RDB with name: bnn_fo
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:47:30,287] Trial 0 finished with value: 3057.181640625 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:47:50,288] Trial 1 finished with value: 726082.8125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:13,378] Trial 2 finished with value: 5794264.5 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:35,024] Trial 3 finished with value: 7793916.0 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:49:05,742] Trial 4 finished with value: 6599.17529296875 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:49:28,550] Trial 5 finished with value: 5738.3369140625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:07,235] Trial 6 finished with value: 824058.1875 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:28,485] Trial 7 finished with value: 4091232.5 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:59,852] Trial 8 finished with value: 596671.1875 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:51:28,483] Trial 9 finished with value: 178157.90625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 3057.181640625.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:52:18,851] Trial 10 finished with value: 760.2855834960938 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 760.2855834960938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:53:07,575] Trial 11 finished with value: 841.848388671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 10 with value: 760.2855834960938.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:54:32,248] Trial 12 finished with value: 718.4263305664062 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 12 with value: 718.4263305664062.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:55:24,913] Trial 13 finished with value: 1301.398193359375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00041083464782765, 'mc_samples_train': 1, 'prior_scale': 0.010497343571389907, 'q_scale': 0.00010533271793746736, 'obs_scale': 1.9202403558946848, 'batch_size': 32}. Best is trial 12 with value: 718.4263305664062.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:56:17,819] Trial 14 finished with value: 357.7547912597656 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004490164214069059, 'mc_samples_train': 1, 'prior_scale': 0.026012153377691926, 'q_scale': 0.00025604133934126406, 'obs_scale': 0.9330914898114858, 'batch_size': 32}. Best is trial 14 with value: 357.7547912597656.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:57:08,508] Trial 15 finished with value: 251.86866760253906 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006353701667284982, 'mc_samples_train': 1, 'prior_scale': 0.032326627210685015, 'q_scale': 0.0002676064292032696, 'obs_scale': 0.7603508563727106, 'batch_size': 32}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:57:27,380] Trial 16 finished with value: 60096.34765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007213182009692284, 'mc_samples_train': 1, 'prior_scale': 0.03873241599615214, 'q_scale': 0.00029164124865713306, 'obs_scale': 0.6388743759863509, 'batch_size': 512}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:58:37,448] Trial 17 finished with value: 305.8333740234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005320658417317712, 'mc_samples_train': 1, 'prior_scale': 0.029886493325645913, 'q_scale': 0.0006382474453239678, 'obs_scale': 0.6842168027625001, 'batch_size': 32}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:59:29,490] Trial 18 finished with value: 6908.97265625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00018554845033497835, 'mc_samples_train': 1, 'prior_scale': 0.044831326708900415, 'q_scale': 0.0006402579633372157, 'obs_scale': 0.636818707353767, 'batch_size': 32}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:00:20,803] Trial 19 finished with value: 476.61712646484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005510676063950635, 'mc_samples_train': 1, 'prior_scale': 0.02506234883231923, 'q_scale': 0.0006788146518100568, 'obs_scale': 0.5727004052054983, 'batch_size': 32}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:00:38,879] Trial 20 finished with value: 556088.0 and parameters: {'pretrain_epochs': 5, 'lr': 0.00023983671454087888, 'mc_samples_train': 1, 'prior_scale': 0.058448596936368724, 'q_scale': 0.0001987006467534054, 'obs_scale': 0.42035828997421665, 'batch_size': 512}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:01:29,041] Trial 21 finished with value: 305.7985534667969 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005834114098227552, 'mc_samples_train': 1, 'prior_scale': 0.02539618376498917, 'q_scale': 0.0002877175571336231, 'obs_scale': 0.966237573391834, 'batch_size': 32}. Best is trial 15 with value: 251.86866760253906.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:02:18,519] Trial 22 finished with value: 205.23947143554688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009760506873875324, 'mc_samples_train': 1, 'prior_scale': 0.033029788242704465, 'q_scale': 0.0001851772903459862, 'obs_scale': 0.8318923798586104, 'batch_size': 32}. Best is trial 22 with value: 205.23947143554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:03:10,550] Trial 23 finished with value: 445.49713134765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009490250184333631, 'mc_samples_train': 1, 'prior_scale': 0.01898684817845306, 'q_scale': 0.00018066264765875714, 'obs_scale': 1.395731351358584, 'batch_size': 32}. Best is trial 22 with value: 205.23947143554688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:04:02,029] Trial 24 finished with value: 181.57408142089844 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006498526326970078, 'mc_samples_train': 1, 'prior_scale': 0.03941232966242802, 'q_scale': 0.00016080032841172623, 'obs_scale': 0.8956575779813578, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:04:26,554] Trial 25 finished with value: 2554.8525390625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009893755800209887, 'mc_samples_train': 1, 'prior_scale': 0.03943047426308883, 'q_scale': 0.00016229706289986302, 'obs_scale': 0.7860303833015364, 'batch_size': 128}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:05:33,663] Trial 26 finished with value: 2346.5400390625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0006298049951676878, 'mc_samples_train': 2, 'prior_scale': 0.07652980284920505, 'q_scale': 0.0004384190508164877, 'obs_scale': 0.517154340145321, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:06:24,771] Trial 27 finished with value: 265.6865234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00031340311191667343, 'mc_samples_train': 1, 'prior_scale': 0.04673558107514053, 'q_scale': 0.0001567097272021368, 'obs_scale': 1.3221659228676614, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:07:27,496] Trial 28 finished with value: 1153.6761474609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0001130855506529453, 'mc_samples_train': 1, 'prior_scale': 0.02042179208923509, 'q_scale': 0.0002217057043966086, 'obs_scale': 0.7924794714016553, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:08:47,616] Trial 29 finished with value: 4178.701171875 and parameters: {'pretrain_epochs': 5, 'lr': 5.465539784653375e-05, 'mc_samples_train': 1, 'prior_scale': 0.030887461210967932, 'q_scale': 0.000383518181805017, 'obs_scale': 1.323130667065093, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:09:10,430] Trial 30 finished with value: 14004.744140625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007374455166076234, 'mc_samples_train': 1, 'prior_scale': 0.035393920946278495, 'q_scale': 0.00014884150560246032, 'obs_scale': 0.4753457197961466, 'batch_size': 256}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:10:01,727] Trial 31 finished with value: 237.03866577148438 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003590033195434328, 'mc_samples_train': 1, 'prior_scale': 0.05533267646046374, 'q_scale': 0.0001500557403703246, 'obs_scale': 1.316270275734023, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:11:06,749] Trial 32 finished with value: 197.07904052734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00047397580431948505, 'mc_samples_train': 1, 'prior_scale': 0.05726837752645235, 'q_scale': 0.00014126422096359494, 'obs_scale': 0.8581123668323366, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:11:57,535] Trial 33 finished with value: 379.5278015136719 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002027217214089206, 'mc_samples_train': 1, 'prior_scale': 0.059213050151263, 'q_scale': 0.00014421992612685458, 'obs_scale': 1.1822053830165824, 'batch_size': 32}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:12:16,410] Trial 34 finished with value: 778961.1875 and parameters: {'pretrain_epochs': 0, 'lr': 0.00046799587756732514, 'mc_samples_train': 1, 'prior_scale': 0.11074279530114882, 'q_scale': 0.00013400414271584797, 'obs_scale': 0.3423495612207277, 'batch_size': 512}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:12:39,667] Trial 35 finished with value: 36141.41015625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003122643157544166, 'mc_samples_train': 2, 'prior_scale': 0.05054509751383798, 'q_scale': 0.00020946112860912935, 'obs_scale': 0.9770787213992793, 'batch_size': 256}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:13:12,981] Trial 36 finished with value: 651.0009765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00014931547612611468, 'mc_samples_train': 1, 'prior_scale': 0.07056527634743119, 'q_scale': 0.0005192049163578535, 'obs_scale': 1.56760276882537, 'batch_size': 64}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:13:36,875] Trial 37 finished with value: 24339.30859375 and parameters: {'pretrain_epochs': 0, 'lr': 8.031721150312077e-05, 'mc_samples_train': 1, 'prior_scale': 0.09040702873793187, 'q_scale': 0.00022207937100425114, 'obs_scale': 1.1478515988506368, 'batch_size': 128}. Best is trial 24 with value: 181.57408142089844.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:15:02,801] Trial 38 finished with value: 114.83016967773438 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007907836420514082, 'mc_samples_train': 2, 'prior_scale': 0.06323634222536433, 'q_scale': 0.0003222891785364371, 'obs_scale': 0.8214153323932953, 'batch_size': 32}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:15:53,053] Trial 39 finished with value: 23828.609375 and parameters: {'pretrain_epochs': 0, 'lr': 2.2658882311763373e-05, 'mc_samples_train': 2, 'prior_scale': 0.15827383999943515, 'q_scale': 0.0009652673539406904, 'obs_scale': 0.8469874508556762, 'batch_size': 64}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:16:17,474] Trial 40 finished with value: 36283.33203125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008339921875782832, 'mc_samples_train': 2, 'prior_scale': 0.1395558122659741, 'q_scale': 0.00034464453045616013, 'obs_scale': 0.3483274507923578, 'batch_size': 256}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:17:25,897] Trial 41 finished with value: 141.23443603515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007632533534796608, 'mc_samples_train': 2, 'prior_scale': 0.06127425064308496, 'q_scale': 0.0001229718063537162, 'obs_scale': 1.1093579824177058, 'batch_size': 32}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:18:27,471] Trial 42 finished with value: 128.1669921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007810047860749132, 'mc_samples_train': 2, 'prior_scale': 0.06331148265850886, 'q_scale': 0.00012648681105424564, 'obs_scale': 1.0598103130121626, 'batch_size': 32}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:19:48,783] Trial 43 finished with value: 129.42489624023438 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007245120799197799, 'mc_samples_train': 2, 'prior_scale': 0.06698275297120657, 'q_scale': 0.00013278527152892235, 'obs_scale': 1.0837316196677358, 'batch_size': 32}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:20:57,947] Trial 44 finished with value: 122.5661849975586 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007109593593485903, 'mc_samples_train': 2, 'prior_scale': 0.0682092094501062, 'q_scale': 0.0001226462873915921, 'obs_scale': 1.1203572395972674, 'batch_size': 32}. Best is trial 38 with value: 114.83016967773438.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:22:30,978] Trial 45 finished with value: 94.12403106689453 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007892292501819303, 'mc_samples_train': 2, 'prior_scale': 0.09520703526103874, 'q_scale': 0.002290405685846643, 'obs_scale': 1.0853562544854425, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:22:59,142] Trial 46 finished with value: 809.02294921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007726060276836364, 'mc_samples_train': 2, 'prior_scale': 0.09686247335434338, 'q_scale': 0.003149800988944712, 'obs_scale': 1.6526027995042674, 'batch_size': 128}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:24:05,752] Trial 47 finished with value: 116.32831573486328 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005442403629372462, 'mc_samples_train': 2, 'prior_scale': 0.1292581370465642, 'q_scale': 0.00682186739889526, 'obs_scale': 1.0670184963468017, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:24:47,349] Trial 48 finished with value: 2865.593017578125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005114292950260654, 'mc_samples_train': 2, 'prior_scale': 0.203122738309256, 'q_scale': 0.009008244224643632, 'obs_scale': 1.52985571396277, 'batch_size': 64}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-11-28 12:25:01,303] Trial 49 pruned. Trial was pruned at epoch 4.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:26:07,136] Trial 50 finished with value: 113.7361831665039 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003718213149103792, 'mc_samples_train': 2, 'prior_scale': 0.11929645724486387, 'q_scale': 0.0023344551140925267, 'obs_scale': 1.0069392172265743, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:27:08,773] Trial 51 finished with value: 130.67359924316406 and parameters: {'pretrain_epochs': 5, 'lr': 0.00037713293369229505, 'mc_samples_train': 2, 'prior_scale': 0.1324546034842874, 'q_scale': 0.0018284658841550808, 'obs_scale': 1.0444237446016407, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:28:11,595] Trial 52 finished with value: 109.26459503173828 and parameters: {'pretrain_epochs': 5, 'lr': 0.000603206818813224, 'mc_samples_train': 2, 'prior_scale': 0.08821058063960838, 'q_scale': 0.003762824811631957, 'obs_scale': 1.2460667126869271, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:29:18,291] Trial 53 finished with value: 172.81951904296875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005740256667070738, 'mc_samples_train': 2, 'prior_scale': 0.08801641086990748, 'q_scale': 0.005085846881553687, 'obs_scale': 1.1945093640180675, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:30:23,469] Trial 54 finished with value: 1626.2752685546875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00045916958054773927, 'mc_samples_train': 2, 'prior_scale': 0.12415277715845997, 'q_scale': 0.002756448920254923, 'obs_scale': 0.2119981434021427, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:31:35,845] Trial 55 finished with value: 376.0943603515625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00023452585929942363, 'mc_samples_train': 2, 'prior_scale': 0.15573745289608676, 'q_scale': 0.002157503021653378, 'obs_scale': 1.4141278459453983, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:32:43,966] Trial 56 finished with value: 104.61642456054688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006174313330758462, 'mc_samples_train': 2, 'prior_scale': 0.25503222573758055, 'q_scale': 0.003532110460431399, 'obs_scale': 1.7686548562006532, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:33:58,048] Trial 57 finished with value: 452.4774169921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00041604280848580964, 'mc_samples_train': 2, 'prior_scale': 0.27603630779247607, 'q_scale': 0.0035395835554952004, 'obs_scale': 1.7208807445374013, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:35:02,775] Trial 58 finished with value: 94.80198669433594 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003316100653634292, 'mc_samples_train': 2, 'prior_scale': 0.2645208487022466, 'q_scale': 0.0047150073297010054, 'obs_scale': 1.8334206921765754, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:36:04,794] Trial 59 finished with value: 95.9330825805664 and parameters: {'pretrain_epochs': 5, 'lr': 0.00033291034666772633, 'mc_samples_train': 2, 'prior_scale': 0.3896265323507242, 'q_scale': 0.004583090015994247, 'obs_scale': 1.8452727313947415, 'batch_size': 32}. Best is trial 45 with value: 94.12403106689453.
