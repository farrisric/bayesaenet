In 'hpsearch': Could not find 'hpsearch/Ti_bnn_rad'

Available options in 'hpsearch':
	bnn_fo
	bnn_lrt
	bnn_rad
Config search path:
	provider=hydra, path=pkg://hydra.conf
	provider=main, path=file:///home/g15farris/bin/bayesaenet/bnn_aenet/configs
	provider=hydra-colorlog, path=pkg://hydra_plugins.hydra_colorlog.conf
	provider=schema, path=structured://

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: ExperimentalWarning: PatientPruner is experimental (supported from v2.8.0). The interface can change in the future.
  return _target_(*args, **kwargs)
[I 2024-11-28 11:46:51,417] A new study created in RDB with name: bnn_rad
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/likelihoods.py:260: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)
  scale = predictions.var(dim).add(self.scale ** 2).sqrt()
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:47:42,845] Trial 0 finished with value: 3224.018798828125 and parameters: {'pretrain_epochs': 5, 'lr': 7.50681093606854e-05, 'mc_samples_train': 1, 'prior_scale': 0.029048697214318013, 'q_scale': 0.0003572140318996377, 'obs_scale': 1.1047391773518673, 'batch_size': 32}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:01,569] Trial 1 finished with value: 612575.8125 and parameters: {'pretrain_epochs': 0, 'lr': 0.0001325538578998538, 'mc_samples_train': 1, 'prior_scale': 0.20559343783957656, 'q_scale': 0.0058248182837850404, 'obs_scale': 0.29835107709343195, 'batch_size': 256}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:22,221] Trial 2 finished with value: 4231415.0 and parameters: {'pretrain_epochs': 5, 'lr': 4.3020182095898586e-05, 'mc_samples_train': 2, 'prior_scale': 0.05508654872763757, 'q_scale': 0.004020640881061957, 'obs_scale': 0.1538313853200085, 'batch_size': 256}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:48:41,350] Trial 3 finished with value: 7510496.5 and parameters: {'pretrain_epochs': 0, 'lr': 2.336545096950015e-05, 'mc_samples_train': 2, 'prior_scale': 0.1023881426733586, 'q_scale': 0.001165790000863127, 'obs_scale': 0.11385861721302043, 'batch_size': 512}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:49:13,187] Trial 4 finished with value: 10549.9990234375 and parameters: {'pretrain_epochs': 0, 'lr': 0.00017174472922154303, 'mc_samples_train': 1, 'prior_scale': 0.48474869983391317, 'q_scale': 0.008271866644681318, 'obs_scale': 1.0724303485094406, 'batch_size': 64}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:49:35,654] Trial 5 finished with value: 32402.099609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009204696704635324, 'mc_samples_train': 1, 'prior_scale': 0.17977467814503606, 'q_scale': 0.0014948832198169292, 'obs_scale': 0.4107788493789703, 'batch_size': 128}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:13,808] Trial 6 finished with value: 452251.0 and parameters: {'pretrain_epochs': 5, 'lr': 7.478015213333154e-05, 'mc_samples_train': 2, 'prior_scale': 0.1156399334005538, 'q_scale': 0.002582231235363856, 'obs_scale': 0.15665279892931577, 'batch_size': 64}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:50:35,488] Trial 7 finished with value: 3889251.75 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007995719083844353, 'mc_samples_train': 2, 'prior_scale': 0.0816845546830656, 'q_scale': 0.004349147472454846, 'obs_scale': 0.11866131541331688, 'batch_size': 256}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:51:09,567] Trial 8 finished with value: 633483.6875 and parameters: {'pretrain_epochs': 0, 'lr': 1.1462886732717548e-05, 'mc_samples_train': 1, 'prior_scale': 0.4124747947662307, 'q_scale': 0.00044814115470497614, 'obs_scale': 0.17860915820030454, 'batch_size': 64}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:51:37,107] Trial 9 finished with value: 380190.78125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0002588548618299899, 'mc_samples_train': 2, 'prior_scale': 0.21075404848706095, 'q_scale': 0.0015787361777166986, 'obs_scale': 0.23920082660450653, 'batch_size': 128}. Best is trial 0 with value: 3224.018798828125.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:52:32,298] Trial 10 finished with value: 812.2300415039062 and parameters: {'pretrain_epochs': 5, 'lr': 0.00028711032739869613, 'mc_samples_train': 1, 'prior_scale': 0.014937976642598423, 'q_scale': 0.00010532753257812993, 'obs_scale': 1.7109716370480204, 'batch_size': 32}. Best is trial 10 with value: 812.2300415039062.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:54:00,950] Trial 11 finished with value: 764.5827026367188 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003871157455553778, 'mc_samples_train': 1, 'prior_scale': 0.014489987071262374, 'q_scale': 0.00010860093339103685, 'obs_scale': 1.9746524398983547, 'batch_size': 32}. Best is trial 11 with value: 764.5827026367188.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:54:52,147] Trial 12 finished with value: 811.7261962890625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003796759473565572, 'mc_samples_train': 1, 'prior_scale': 0.014959205297763659, 'q_scale': 0.00010181693721223134, 'obs_scale': 1.9328425480641904, 'batch_size': 32}. Best is trial 11 with value: 764.5827026367188.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:55:42,568] Trial 13 finished with value: 1064.1650390625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004805364291548028, 'mc_samples_train': 1, 'prior_scale': 0.010482874946722998, 'q_scale': 0.00010532990129819251, 'obs_scale': 1.8557399609740814, 'batch_size': 32}. Best is trial 11 with value: 764.5827026367188.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:56:32,999] Trial 14 finished with value: 416.92083740234375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00042697878418142905, 'mc_samples_train': 1, 'prior_scale': 0.025598098635809526, 'q_scale': 0.00025604133934126406, 'obs_scale': 0.8078049424337922, 'batch_size': 32}. Best is trial 14 with value: 416.92083740234375.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:57:22,924] Trial 15 finished with value: 280.2371826171875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005145519904373549, 'mc_samples_train': 1, 'prior_scale': 0.03427732934987163, 'q_scale': 0.0002676064292032696, 'obs_scale': 0.7267193329726757, 'batch_size': 32}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:58:02,132] Trial 16 finished with value: 38188.40625 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006845758990621392, 'mc_samples_train': 1, 'prior_scale': 0.03934593703776678, 'q_scale': 0.00029164124865713306, 'obs_scale': 0.753148056293888, 'batch_size': 512}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:58:54,415] Trial 17 finished with value: 2343.477294921875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00018259475214064708, 'mc_samples_train': 1, 'prior_scale': 0.029571475829064393, 'q_scale': 0.0006382474453239678, 'obs_scale': 0.615772723234537, 'batch_size': 32}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 11:59:46,779] Trial 18 finished with value: 335.5061950683594 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005466272984405296, 'mc_samples_train': 1, 'prior_scale': 0.026889557956323362, 'q_scale': 0.00021537730383498302, 'obs_scale': 0.5467096563049685, 'batch_size': 32}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:00:36,981] Trial 19 finished with value: 7966.0986328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00010213287278124237, 'mc_samples_train': 1, 'prior_scale': 0.050213913521911666, 'q_scale': 0.00017888448190867405, 'obs_scale': 0.47433311999912126, 'batch_size': 32}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:01:00,102] Trial 20 finished with value: 366160.625 and parameters: {'pretrain_epochs': 5, 'lr': 0.000620967796265798, 'mc_samples_train': 1, 'prior_scale': 0.020656955506946063, 'q_scale': 0.0005983473546430672, 'obs_scale': 0.39966250746124515, 'batch_size': 512}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:01:52,122] Trial 21 finished with value: 1668.385498046875 and parameters: {'pretrain_epochs': 5, 'lr': 0.00024147316537158573, 'mc_samples_train': 1, 'prior_scale': 0.027345697020444405, 'q_scale': 0.00018530055560451612, 'obs_scale': 0.8266914963413151, 'batch_size': 32}. Best is trial 15 with value: 280.2371826171875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:02:44,744] Trial 22 finished with value: 239.50411987304688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005300372762341876, 'mc_samples_train': 1, 'prior_scale': 0.04148718600617462, 'q_scale': 0.00023814053427689518, 'obs_scale': 0.5823490629749011, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:03:36,084] Trial 23 finished with value: 362.302734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005915480256102324, 'mc_samples_train': 1, 'prior_scale': 0.040598443886462894, 'q_scale': 0.00019171745896197966, 'obs_scale': 0.5725218248603321, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:04:27,263] Trial 24 finished with value: 2646.50634765625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00030194888201240323, 'mc_samples_train': 1, 'prior_scale': 0.06098623208346963, 'q_scale': 0.0007250050807785253, 'obs_scale': 0.34668835566857065, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:04:50,777] Trial 25 finished with value: 3091.888671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009893755800209887, 'mc_samples_train': 1, 'prior_scale': 0.041475374397210926, 'q_scale': 0.0004414854894248194, 'obs_scale': 1.1478933032232752, 'batch_size': 128}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:05:51,862] Trial 26 finished with value: 5846.4765625 and parameters: {'pretrain_epochs': 0, 'lr': 0.0005009208504779268, 'mc_samples_train': 2, 'prior_scale': 0.019613257664570945, 'q_scale': 0.0002446581196600478, 'obs_scale': 0.5717212259872233, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:06:45,759] Trial 27 finished with value: 1885.933837890625 and parameters: {'pretrain_epochs': 5, 'lr': 0.00020212184594889442, 'mc_samples_train': 1, 'prior_scale': 0.08266938931957973, 'q_scale': 0.00015744551774649575, 'obs_scale': 0.29370445271460777, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:08:06,896] Trial 28 finished with value: 13249.771484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00012824989123784162, 'mc_samples_train': 1, 'prior_scale': 0.03550491546800765, 'q_scale': 0.00036587603136139135, 'obs_scale': 0.50471600819179, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:09:19,554] Trial 29 finished with value: 2157.355224609375 and parameters: {'pretrain_epochs': 5, 'lr': 6.121729646628824e-05, 'mc_samples_train': 1, 'prior_scale': 0.023929520047462086, 'q_scale': 0.0003175270740301742, 'obs_scale': 1.0545770836411659, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:09:41,467] Trial 30 finished with value: 19478.798828125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00033572285377045597, 'mc_samples_train': 1, 'prior_scale': 0.010171711652668334, 'q_scale': 0.0008633899524995144, 'obs_scale': 1.3439611979375592, 'batch_size': 256}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:10:41,157] Trial 31 finished with value: 410.7704162597656 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005857351348590563, 'mc_samples_train': 1, 'prior_scale': 0.034171758922499004, 'q_scale': 0.00016081249222893332, 'obs_scale': 0.6665021017512357, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:11:51,927] Trial 32 finished with value: 253.10247802734375 and parameters: {'pretrain_epochs': 5, 'lr': 0.000738994397449305, 'mc_samples_train': 1, 'prior_scale': 0.05043054403044956, 'q_scale': 0.00022270322586265598, 'obs_scale': 0.5126661303049702, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:12:50,192] Trial 33 finished with value: 724.86328125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007791912800003949, 'mc_samples_train': 1, 'prior_scale': 0.053510721691270094, 'q_scale': 0.0004960600636549616, 'obs_scale': 0.33543398659191886, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:13:10,179] Trial 34 finished with value: 198340.5 and parameters: {'pretrain_epochs': 0, 'lr': 0.0004906610092688826, 'mc_samples_train': 1, 'prior_scale': 0.0759737416396417, 'q_scale': 0.00022630295084617185, 'obs_scale': 0.717039544392667, 'batch_size': 512}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:13:31,531] Trial 35 finished with value: 8423.3974609375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009851121754330778, 'mc_samples_train': 2, 'prior_scale': 0.04790816465477203, 'q_scale': 0.00014291674174416878, 'obs_scale': 0.9438927803157233, 'batch_size': 256}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:14:08,601] Trial 36 finished with value: 65509.17578125 and parameters: {'pretrain_epochs': 5, 'lr': 2.336178932942835e-05, 'mc_samples_train': 1, 'prior_scale': 0.10587477263326932, 'q_scale': 0.0003612684662215798, 'obs_scale': 0.48098420120707314, 'batch_size': 64}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:14:53,255] Trial 37 finished with value: 397330.21875 and parameters: {'pretrain_epochs': 0, 'lr': 0.0007057459329136829, 'mc_samples_train': 1, 'prior_scale': 0.06195308251725808, 'q_scale': 0.0001355752109506696, 'obs_scale': 0.2621291641759981, 'batch_size': 128}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:16:17,703] Trial 38 finished with value: 30292.751953125 and parameters: {'pretrain_epochs': 5, 'lr': 4.440221093331539e-05, 'mc_samples_train': 2, 'prior_scale': 0.03104993106791847, 'q_scale': 0.00021417402729798999, 'obs_scale': 0.39849284349561337, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:16:53,649] Trial 39 finished with value: 52962.1640625 and parameters: {'pretrain_epochs': 0, 'lr': 0.00021990239281792907, 'mc_samples_train': 1, 'prior_scale': 0.14552747606398175, 'q_scale': 0.0011062488939832988, 'obs_scale': 0.5171141933797249, 'batch_size': 64}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:17:16,894] Trial 40 finished with value: 71249.4453125 and parameters: {'pretrain_epochs': 5, 'lr': 0.00014237494126371605, 'mc_samples_train': 2, 'prior_scale': 0.01819868777291645, 'q_scale': 0.002245402421896622, 'obs_scale': 0.9003162146803202, 'batch_size': 256}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:18:14,450] Trial 41 finished with value: 917.9346923828125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005785420416022076, 'mc_samples_train': 1, 'prior_scale': 0.04142685722003495, 'q_scale': 0.00020661166639893624, 'obs_scale': 0.5292551286463258, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:19:12,015] Trial 42 finished with value: 369.6506042480469 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007810047860749132, 'mc_samples_train': 1, 'prior_scale': 0.044684358353213396, 'q_scale': 0.00029327753647947975, 'obs_scale': 0.6045528669187713, 'batch_size': 32}. Best is trial 22 with value: 239.50411987304688.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:20:24,545] Trial 43 finished with value: 157.16844177246094 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005501985108060345, 'mc_samples_train': 1, 'prior_scale': 0.06592386825580732, 'q_scale': 0.00012859287579581363, 'obs_scale': 0.6234961296230779, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:21:48,472] Trial 44 finished with value: 507.2229919433594 and parameters: {'pretrain_epochs': 5, 'lr': 0.0003551913627267259, 'mc_samples_train': 1, 'prior_scale': 0.06793047538337531, 'q_scale': 0.00013209191137827957, 'obs_scale': 0.44029720451864535, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:22:56,205] Trial 45 finished with value: 460.32415771484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0004425571259478007, 'mc_samples_train': 1, 'prior_scale': 0.09430699221074577, 'q_scale': 0.007303873797044915, 'obs_scale': 0.6890437430260082, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:23:21,137] Trial 46 finished with value: 100713.125 and parameters: {'pretrain_epochs': 5, 'lr': 0.000830886626548478, 'mc_samples_train': 1, 'prior_scale': 0.0578202156273333, 'q_scale': 0.0004014600966422413, 'obs_scale': 0.2149308248551558, 'batch_size': 128}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:24:15,428] Trial 47 finished with value: 2177.462646484375 and parameters: {'pretrain_epochs': 5, 'lr': 0.00030008057969486073, 'mc_samples_train': 1, 'prior_scale': 0.28552360570829, 'q_scale': 0.0001254031452959363, 'obs_scale': 0.36439219493385777, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[I 2024-11-28 12:24:31,152] Trial 48 pruned. Trial was pruned at epoch 8.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:25:11,924] Trial 49 finished with value: 1659.4249267578125 and parameters: {'pretrain_epochs': 5, 'lr': 0.0005158169521863118, 'mc_samples_train': 2, 'prior_scale': 0.029981742001992957, 'q_scale': 0.0005503211768617498, 'obs_scale': 0.9533983848748065, 'batch_size': 64}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:26:05,469] Trial 50 finished with value: 667.8159790039062 and parameters: {'pretrain_epochs': 5, 'lr': 0.00039930872008178084, 'mc_samples_train': 1, 'prior_scale': 0.1260367477724092, 'q_scale': 0.0003239676847456265, 'obs_scale': 0.6454913363008826, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:26:58,199] Trial 51 finished with value: 292.1883850097656 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006201188407301074, 'mc_samples_train': 1, 'prior_scale': 0.03594592186345558, 'q_scale': 0.0001772173783597581, 'obs_scale': 0.5658649606783299, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:27:51,789] Trial 52 finished with value: 247.38421630859375 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006973709746854855, 'mc_samples_train': 1, 'prior_scale': 0.035612149056819045, 'q_scale': 0.0001691743871368334, 'obs_scale': 0.783380382713991, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:28:45,409] Trial 53 finished with value: 236.21998596191406 and parameters: {'pretrain_epochs': 5, 'lr': 0.0006935091961653507, 'mc_samples_train': 1, 'prior_scale': 0.035159117539783714, 'q_scale': 0.00016256067760282432, 'obs_scale': 0.7865626567959234, 'batch_size': 32}. Best is trial 43 with value: 157.16844177246094.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:29:39,167] Trial 54 finished with value: 130.7428741455078 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008452284954597257, 'mc_samples_train': 1, 'prior_scale': 0.06987271173706976, 'q_scale': 0.0001233032713887315, 'obs_scale': 0.8304285741680748, 'batch_size': 32}. Best is trial 54 with value: 130.7428741455078.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:30:32,804] Trial 55 finished with value: 135.66049194335938 and parameters: {'pretrain_epochs': 5, 'lr': 0.0007274523060058394, 'mc_samples_train': 1, 'prior_scale': 0.06927924430883516, 'q_scale': 0.0001205823571561385, 'obs_scale': 1.5295038935889438, 'batch_size': 32}. Best is trial 54 with value: 130.7428741455078.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:31:36,457] Trial 56 finished with value: 114.46942138671875 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009942687980983148, 'mc_samples_train': 1, 'prior_scale': 0.08577226270346741, 'q_scale': 0.00011793730404486873, 'obs_scale': 1.5103687141173905, 'batch_size': 32}. Best is trial 56 with value: 114.46942138671875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:32:31,564] Trial 57 finished with value: 119.56466674804688 and parameters: {'pretrain_epochs': 5, 'lr': 0.0009269967120007916, 'mc_samples_train': 1, 'prior_scale': 0.08689991373132314, 'q_scale': 0.00011755979527109387, 'obs_scale': 1.60446752405765, 'batch_size': 32}. Best is trial 56 with value: 114.46942138671875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:33:34,959] Trial 58 finished with value: 124.67506408691406 and parameters: {'pretrain_epochs': 5, 'lr': 0.0008612101940019267, 'mc_samples_train': 1, 'prior_scale': 0.08961704729847049, 'q_scale': 0.0001181217757950735, 'obs_scale': 1.4714631121606054, 'batch_size': 32}. Best is trial 56 with value: 114.46942138671875.
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer.fit` stopped: `max_epochs=20` reached.
[I 2024-11-28 12:34:27,089] Trial 59 finished with value: 121.59960174560547 and parameters: {'pretrain_epochs': 5, 'lr': 0.000913456641494291, 'mc_samples_train': 1, 'prior_scale': 0.15527657546208767, 'q_scale': 0.00011992075891980954, 'obs_scale': 1.543318439980895, 'batch_size': 32}. Best is trial 56 with value: 114.46942138671875.
