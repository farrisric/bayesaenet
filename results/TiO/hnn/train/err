Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer was signaled to stop but the required `min_epochs=20000` or `min_steps=None` has not been met. Training will continue...
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer was signaled to stop but the required `min_epochs=20000` or `min_steps=None` has not been met. Training will continue...
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Trainer was signaled to stop but the required `min_epochs=20000` or `min_steps=None` has not been met. Training will continue...
Exception in thread Thread-1:
Exception in threading.excepthook:
Exception ignored in thread started by: <bound method Thread._bootstrap of <_AsyncWriterThread(Thread-1, started daemon 47647324595968)>>
Exception ignored in sys.unraisablehook: <built-in function unraisablehook>
--- Logging error ---
--- Logging error ---
Error executing job with overrides: ['task_name=TiO_train_hnn_80perc', 'experiment=hnn', 'datamodule=TiO', 'model.optimizer.lr=0.0013422359776024458', 'datamodule.batch_size=32']
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/core/utils.py", line 257, in return_value
    sys.stderr.write(
OSError: [Errno 5] Input/output error
.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 265, in on_run_end
    self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 150, in log_eval_end_metrics
    self.log_metrics(metrics)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 118, in log_metrics
    logger.save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loggers/tensorboard.py", line 213, in save
    super().save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/fabric/loggers/tensorboard.py", line 293, in save
    self.experiment.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 1256, in flush
    writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 152, in flush
    self.event_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 125, in flush
    self._async_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 194, in flush
    self._check_worker_status()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 212, in _check_worker_status
    raise exception
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 244, in run
    self._run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 275, in _run
    self._record_writer.write(data)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/record_writer.py", line 40, in write
    self._writer.write(header + header_crc + data + footer_crc)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 773, in write
    self.fs.append(self.filename, file_content, self.binary_mode)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 167, in append
    self._write(filename, file_content, "ab" if binary_mode else "a")
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 171, in _write
    with io.open(filename, mode, encoding=encoding) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: b'/home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_train_hnn_80perc/runs/2025-02-18_17-16-25/tensorboard/version_0/events.out.tfevents.1739895399.g16noder24.44435.0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 64, in _call_and_handle_interrupt
    _call_callback_hooks(trainer, "on_exception", exception)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 641, in on_exception
    self._stop_progress()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 614, in _stop_progress
    self.progress.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/progress.py", line 1163, in stop
    self.live.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/live.py", line 147, in stop
    with self.console:
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 865, in __exit__
    self._exit_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 823, in _exit_buffer
    self._check_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 2065, in _check_buffer
    self.file.flush()
OSError: [Errno 5] Input/output error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/logging/__init__.py", line 1164, in emit
    self.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/logging/__init__.py", line 1144, in flush
    self.stream.flush()
OSError: [Errno 5] Input/output error
Call stack:
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 154, in <module>
    main()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 150, in main
    train(cfg, trial=None)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 41, in wrap
    log.exception("")  # save exception to `.log` file
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/logging/__init__.py", line 1574, in exception
    self.error(msg, *args, exc_info=exc_info, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
Message: ''
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 265, in on_run_end
    self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 150, in log_eval_end_metrics
    self.log_metrics(metrics)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 118, in log_metrics
    logger.save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loggers/tensorboard.py", line 213, in save
    super().save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/fabric/loggers/tensorboard.py", line 293, in save
    self.experiment.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 1256, in flush
    writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 152, in flush
    self.event_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 125, in flush
    self._async_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 194, in flush
    self._check_worker_status()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 212, in _check_worker_status
    raise exception
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 244, in run
    self._run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 275, in _run
    self._record_writer.write(data)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/record_writer.py", line 40, in write
    self._writer.write(header + header_crc + data + footer_crc)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 773, in write
    self.fs.append(self.filename, file_content, self.binary_mode)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 167, in append
    self._write(filename, file_content, "ab" if binary_mode else "a")
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 171, in _write
    with io.open(filename, mode, encoding=encoding) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: b'/home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_train_hnn_80perc/runs/2025-02-18_17-16-25/tensorboard/version_0/events.out.tfevents.1739895399.g16noder24.44435.0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 42, in wrap
    raise ex
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 64, in _call_and_handle_interrupt
    _call_callback_hooks(trainer, "on_exception", exception)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 641, in on_exception
    self._stop_progress()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 614, in _stop_progress
    self.progress.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/progress.py", line 1163, in stop
    self.live.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/live.py", line 147, in stop
    with self.console:
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 865, in __exit__
    self._exit_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 823, in _exit_buffer
    self._check_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 2065, in _check_buffer
    self.file.flush()
OSError: [Errno 5] Input/output error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/logging/__init__.py", line 1164, in emit
    self.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/logging/__init__.py", line 1144, in flush
    self.stream.flush()
OSError: [Errno 116] Stale file handle
Call stack:
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 154, in <module>
    main()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 150, in main
    train(cfg, trial=None)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 51, in wrap
    close_loggers()  # close loggers (even if exception occurs so multirun won't fail)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 215, in close_loggers
    log.info("Closing loggers...")
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
Message: 'Closing loggers...'
Arguments: ()
Error executing job with overrides: ['task_name=TiO_train_hnn_80perc', 'experiment=hnn', 'datamodule=TiO', 'model.optimizer.lr=0.0013422359776024458', 'datamodule.batch_size=32']
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 265, in on_run_end
    self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 150, in log_eval_end_metrics
    self.log_metrics(metrics)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py", line 118, in log_metrics
    logger.save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loggers/tensorboard.py", line 213, in save
    super().save()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/fabric/loggers/tensorboard.py", line 293, in save
    self.experiment.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 1256, in flush
    writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py", line 152, in flush
    self.event_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 125, in flush
    self._async_writer.flush()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 194, in flush
    self._check_worker_status()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 212, in _check_worker_status
    raise exception
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 244, in run
    self._run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/event_file_writer.py", line 275, in _run
    self._record_writer.write(data)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/summary/writer/record_writer.py", line 40, in write
    self._writer.write(header + header_crc + data + footer_crc)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 773, in write
    self.fs.append(self.filename, file_content, self.binary_mode)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 167, in append
    self._write(filename, file_content, "ab" if binary_mode else "a")
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 171, in _write
    with io.open(filename, mode, encoding=encoding) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 5] Input/output error: b'/home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_train_hnn_80perc/runs/2025-02-18_17-16-25/tensorboard/version_0/events.out.tfevents.1739895399.g16noder24.44435.0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 150, in main
    train(cfg, trial=None)
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 42, in wrap
    raise ex
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 64, in _call_and_handle_interrupt
    _call_callback_hooks(trainer, "on_exception", exception)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 641, in on_exception
    self._stop_progress()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 614, in _stop_progress
    self.progress.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/progress.py", line 1163, in stop
    self.live.stop()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/live.py", line 147, in stop
    with self.console:
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 865, in __exit__
    self._exit_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 823, in _exit_buffer
    self._check_buffer()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/rich/console.py", line 2065, in _check_buffer
    self.file.flush()
OSError: [Errno 5] Input/output error

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
