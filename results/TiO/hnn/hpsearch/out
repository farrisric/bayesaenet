{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-18 10:01:59,817[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-18 10:01:59,818[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/hnn.db[0m
[[36m2025-02-18 10:02:11,293[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_hnn>[0m
[[36m2025-02-18 10:02:11,484[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-18 10:02:13,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003655732368605816 lr[0m
[[36m2025-02-18 10:02:13,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:02:13,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 074 __________________[0m
[[36m2025-02-18 10:02:13,188[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:02:13,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:02:24,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:03:42,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:03:42,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:03:42,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:03:42,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:03:42,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:03:42,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:03:42,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:03:42,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:03:43,174[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:03:49,620[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 56.34it/s v_num: 0.000
[[36m2025-02-18 10:04:41,172[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:04:41,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/074[0m
[[36m2025-02-18 10:04:42,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0049753653982777014 lr[0m
[[36m2025-02-18 10:04:42,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:04:42,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 083 __________________[0m
[[36m2025-02-18 10:04:42,083[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:04:42,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:04:52,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:04:52,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:04:52,171[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:04:52,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:04:52,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:04:52,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:04:52,257[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:04:52,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:04:52,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:04:52,360[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:04:52,370[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 72.08it/s v_num: 0.000
[[36m2025-02-18 10:04:59,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:04:59,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/083[0m
[[36m2025-02-18 10:05:00,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0049177907636811305 lr[0m
[[36m2025-02-18 10:05:00,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:05:00,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 084 __________________[0m
[[36m2025-02-18 10:05:00,298[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:05:00,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:05:10,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:05:10,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:05:10,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:05:10,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:05:10,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:05:10,497[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:05:10,498[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:05:10,498[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:05:10,499[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:05:10,512[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:05:10,519[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 70.73it/s v_num: 0.000
[[36m2025-02-18 10:05:12,598[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:05:12,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/084[0m
[[36m2025-02-18 10:05:12,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004998225441004059 lr[0m
[[36m2025-02-18 10:05:12,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:05:12,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 085 __________________[0m
[[36m2025-02-18 10:05:12,723[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:05:12,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:05:22,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:05:22,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:05:22,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:05:22,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:05:22,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:05:22,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:05:22,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:05:22,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:05:22,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:05:22,763[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:05:22,770[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 65.05it/s v_num: 0.000
[[36m2025-02-18 10:05:25,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:05:25,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/085[0m
[[36m2025-02-18 10:05:25,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004324797124958337 lr[0m
[[36m2025-02-18 10:05:25,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:05:25,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 087 __________________[0m
[[36m2025-02-18 10:05:25,824[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:05:25,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:05:36,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:05:36,132[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:05:36,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:05:36,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:05:36,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:05:36,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:05:36,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:05:36,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:05:36,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:05:36,158[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:05:36,168[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 71.65it/s v_num: 0.000
[[36m2025-02-18 10:05:40,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:05:40,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/087[0m
[[36m2025-02-18 10:05:40,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0032836758268710246 lr[0m
[[36m2025-02-18 10:05:41,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:05:41,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 088 __________________[0m
[[36m2025-02-18 10:05:41,013[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:05:41,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:05:51,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:05:51,114[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:05:51,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:05:51,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:05:51,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:05:51,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:05:51,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:05:51,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:05:51,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:05:51,132[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:05:51,139[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 48.10it/s v_num: 0.000
[[36m2025-02-18 10:05:57,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:05:57,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/088[0m
[[36m2025-02-18 10:05:58,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004415321143048175 lr[0m
[[36m2025-02-18 10:05:58,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 10:05:58,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 090 __________________[0m
[[36m2025-02-18 10:05:58,877[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:05:58,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:06:09,033[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:06:09,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:06:09,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:06:09,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:06:09,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:06:09,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:06:09,082[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:06:09,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:06:09,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:06:09,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:06:09,135[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 54.13it/s v_num: 0.000
[[36m2025-02-18 10:06:15,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:06:15,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/090[0m
[[36m2025-02-18 10:06:16,334[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033211759137216352 lr[0m
[[36m2025-02-18 10:06:16,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:06:16,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 092 __________________[0m
[[36m2025-02-18 10:06:16,381[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:06:16,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:06:25,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:06:26,005[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:06:26,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:06:26,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:06:26,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:06:26,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:06:26,009[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:06:26,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:06:26,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:06:26,034[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:06:26,078[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 122.76it/s v_num: 0.000
[[36m2025-02-18 10:06:29,627[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:06:29,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/092[0m
[[36m2025-02-18 10:06:30,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033734124863066565 lr[0m
[[36m2025-02-18 10:06:30,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:06:30,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 094 __________________[0m
[[36m2025-02-18 10:06:30,167[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:06:30,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:06:39,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:06:39,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:06:39,886[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:06:39,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:06:39,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:06:39,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:06:39,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:06:39,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:06:39,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:06:39,945[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:06:39,963[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 89.78it/s v_num: 0.000
[[36m2025-02-18 10:06:43,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:06:43,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/094[0m
[[36m2025-02-18 10:06:43,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003009294296697903 lr[0m
[[36m2025-02-18 10:06:43,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:06:43,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 096 __________________[0m
[[36m2025-02-18 10:06:43,261[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:06:43,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:06:52,787[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:06:52,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:06:52,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:06:52,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:06:52,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:06:52,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:06:52,831[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:06:52,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:06:52,832[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:06:52,848[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:06:52,982[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 66.35it/s v_num: 0.000
[[36m2025-02-18 10:07:01,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:07:01,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/096[0m
[[36m2025-02-18 10:07:02,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0031908818237214656 lr[0m
[[36m2025-02-18 10:07:02,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:07:02,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 097 __________________[0m
[[36m2025-02-18 10:07:02,361[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:07:02,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:07:11,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:07:12,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:07:12,004[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:07:12,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:07:12,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:07:12,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:07:12,046[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:07:12,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:07:12,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:07:12,198[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:07:12,234[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 111.35it/s v_num: 0.000
[[36m2025-02-18 10:07:19,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:07:19,437[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/097[0m
[[36m2025-02-18 10:07:20,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002533283465932684 lr[0m
[[36m2025-02-18 10:07:20,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:07:20,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 099 __________________[0m
[[36m2025-02-18 10:07:20,416[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:07:20,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:07:30,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:07:30,080[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:07:30,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:07:30,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:07:30,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:07:30,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:07:30,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:07:30,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:07:30,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:07:30,125[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:07:30,156[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 131.12it/s v_num: 0.000
[[36m2025-02-18 10:07:35,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:07:35,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/099[0m
[[36m2025-02-18 10:07:36,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002682429797562552 lr[0m
[[36m2025-02-18 10:07:36,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:07:36,534[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 101 __________________[0m
[[36m2025-02-18 10:07:36,534[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:07:36,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:07:46,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:07:46,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:07:46,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:07:46,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:07:46,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:07:46,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:07:46,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:07:46,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:07:46,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:07:46,238[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:07:46,263[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 71.83it/s v_num: 0.000
[[36m2025-02-18 10:07:53,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:07:53,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/101[0m
[[36m2025-02-18 10:07:53,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002357663772748823 lr[0m
[[36m2025-02-18 10:07:53,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:07:53,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 103 __________________[0m
[[36m2025-02-18 10:07:53,656[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:07:53,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:08:03,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:08:03,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:08:03,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:08:03,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:08:03,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:08:03,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:08:03,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:08:03,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:08:03,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:08:03,428[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:08:03,711[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 96.10it/s v_num: 0.000
[[36m2025-02-18 10:08:08,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:08:08,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/103[0m
[[36m2025-02-18 10:08:09,323[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024272585540501632 lr[0m
[[36m2025-02-18 10:08:09,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:08:09,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 105 __________________[0m
[[36m2025-02-18 10:08:09,400[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:08:09,401[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:08:19,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:08:19,306[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:08:19,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:08:19,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:08:19,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:08:19,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:08:19,310[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:08:19,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:08:19,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:08:19,392[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:08:19,399[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 87.94it/s v_num: 0.000
[[36m2025-02-18 10:08:26,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:08:26,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/105[0m
[[36m2025-02-18 10:08:27,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003154800126049887 lr[0m
[[36m2025-02-18 10:08:27,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:08:27,710[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 107 __________________[0m
[[36m2025-02-18 10:08:27,711[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:08:27,711[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:08:37,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:08:37,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:08:37,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:08:37,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:08:37,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:08:37,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:08:37,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:08:37,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:08:37,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:08:37,273[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:08:37,888[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 65.73it/s v_num: 0.000
[[36m2025-02-18 10:08:50,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:08:50,908[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/107[0m
[[36m2025-02-18 10:08:52,019[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003295422150174482 lr[0m
[[36m2025-02-18 10:08:52,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:08:52,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 109 __________________[0m
[[36m2025-02-18 10:08:52,247[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:08:52,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:09:01,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:09:01,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:09:01,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:09:01,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:09:01,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:09:01,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:09:01,894[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:09:01,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:09:01,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:09:01,915[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:09:01,954[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 73.80it/s v_num: 0.000
[[36m2025-02-18 10:09:16,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:09:16,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/109[0m
[[36m2025-02-18 10:09:19,191[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0019683570225012713 lr[0m
[[36m2025-02-18 10:09:19,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:09:19,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 111 __________________[0m
[[36m2025-02-18 10:09:19,360[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:09:19,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:09:28,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:09:28,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:09:28,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:09:28,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:09:28,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:09:28,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:09:28,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:09:28,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:09:28,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:09:29,041[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:09:29,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 84.60it/s v_num: 0.000
[[36m2025-02-18 10:09:37,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:09:37,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/111[0m
[[36m2025-02-18 10:09:38,964[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0019320707165386651 lr[0m
[[36m2025-02-18 10:09:39,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:09:39,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 112 __________________[0m
[[36m2025-02-18 10:09:39,060[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:09:39,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:09:48,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:09:48,621[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:09:48,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:09:48,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:09:48,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:09:48,625[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:09:48,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:09:48,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:09:48,627[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:09:48,639[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:09:48,734[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 152.21it/s v_num: 0.000
[[36m2025-02-18 10:09:54,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:09:54,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/112[0m
[[36m2025-02-18 10:09:54,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033613121829765306 lr[0m
[[36m2025-02-18 10:09:54,465[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:09:54,465[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 114 __________________[0m
[[36m2025-02-18 10:09:54,465[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:09:54,465[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:10:04,102[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:10:09,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:10:09,126[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:10:09,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:10:09,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:10:09,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:10:09,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:10:09,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:10:09,134[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:10:09,156[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:10:09,177[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 105.76it/s v_num: 0.000
[[36m2025-02-18 10:10:13,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:10:13,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/114[0m
[[36m2025-02-18 10:10:13,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0027977673449214456 lr[0m
[[36m2025-02-18 10:10:13,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:10:13,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 115 __________________[0m
[[36m2025-02-18 10:10:13,580[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:10:13,580[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:10:23,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:10:23,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:10:23,241[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:10:23,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:10:23,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:10:23,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:10:23,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:10:23,262[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:10:23,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:10:23,290[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:10:23,598[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 133.95it/s v_num: 0.000
[[36m2025-02-18 10:10:27,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:10:27,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/115[0m
[[36m2025-02-18 10:10:28,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022354483380787184 lr[0m
[[36m2025-02-18 10:10:28,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:10:28,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 116 __________________[0m
[[36m2025-02-18 10:10:28,743[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:10:28,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:10:38,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:10:38,290[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:10:38,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:10:38,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:10:38,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:10:38,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:10:38,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:10:38,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:10:38,339[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:10:38,478[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:10:38,538[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 70.15it/s v_num: 0.000
[[36m2025-02-18 10:10:43,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:10:43,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/116[0m
[[36m2025-02-18 10:10:44,658[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022678655284748715 lr[0m
[[36m2025-02-18 10:10:44,683[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:10:44,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 118 __________________[0m
[[36m2025-02-18 10:10:44,684[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:10:44,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:10:54,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:10:54,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:10:54,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:10:54,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:10:54,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:10:54,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:10:54,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:10:54,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:10:54,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:10:54,584[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:10:54,759[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 112.77it/s v_num: 0.000
[[36m2025-02-18 10:11:01,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:11:01,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/118[0m
[[36m2025-02-18 10:11:01,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017365509619937064 lr[0m
[[36m2025-02-18 10:11:02,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:11:02,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 120 __________________[0m
[[36m2025-02-18 10:11:02,018[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:11:02,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:11:11,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:11:11,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:11:11,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:11:12,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:11:12,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:11:12,161[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:11:12,162[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:11:12,162[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:11:12,164[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:11:12,183[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:11:12,316[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 86.81it/s v_num: 0.000
[[36m2025-02-18 10:11:18,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:11:18,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/120[0m
[[36m2025-02-18 10:11:18,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002254653466697671 lr[0m
[[36m2025-02-18 10:11:18,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:11:18,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 122 __________________[0m
[[36m2025-02-18 10:11:18,759[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:11:18,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:11:28,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:11:28,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:11:28,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:11:28,690[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:11:28,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:11:28,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:11:28,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:11:28,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:11:28,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:11:28,708[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:11:28,720[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 66.20it/s v_num: 0.000
[[36m2025-02-18 10:11:34,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:11:34,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/122[0m
[[36m2025-02-18 10:11:35,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029000640243886655 lr[0m
[[36m2025-02-18 10:11:35,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:11:35,578[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 123 __________________[0m
[[36m2025-02-18 10:11:35,578[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:11:35,579[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:11:45,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:11:45,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:11:45,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:11:45,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:11:45,615[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:11:45,616[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:11:45,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:11:45,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:11:45,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:11:45,713[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:11:45,720[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 79.13it/s v_num: 0.000
[[36m2025-02-18 10:11:53,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:11:53,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/123[0m
[[36m2025-02-18 10:11:53,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0034760253245858176 lr[0m
[[36m2025-02-18 10:11:54,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:11:54,040[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 125 __________________[0m
[[36m2025-02-18 10:11:54,040[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:11:54,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:12:03,545[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:12:03,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:12:03,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:12:03,708[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:12:03,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:12:03,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:12:03,719[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:12:03,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:12:03,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:12:03,751[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:12:03,840[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 129.74it/s v_num: 0.000
[[36m2025-02-18 10:12:13,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:12:13,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/125[0m
[[36m2025-02-18 10:12:14,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030853421855419052 lr[0m
[[36m2025-02-18 10:12:14,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:12:14,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 127 __________________[0m
[[36m2025-02-18 10:12:14,278[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:12:14,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:12:23,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:12:23,834[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:12:23,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:12:23,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:12:23,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:12:23,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:12:23,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:12:23,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:12:23,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:12:23,865[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:12:23,886[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 73.99it/s v_num: 0.000
[[36m2025-02-18 10:12:31,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:12:31,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/127[0m
[[36m2025-02-18 10:12:33,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002308651076712279 lr[0m
[[36m2025-02-18 10:12:33,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:12:33,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 129 __________________[0m
[[36m2025-02-18 10:12:33,291[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:12:33,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:12:42,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:12:42,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:12:42,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:12:42,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:12:42,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:12:42,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:12:42,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:12:42,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:12:42,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:12:42,961[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:12:43,268[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 73.50it/s v_num: 0.000
[[36m2025-02-18 10:12:54,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:12:54,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/129[0m
[[36m2025-02-18 10:12:55,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0027263486826510155 lr[0m
[[36m2025-02-18 10:12:56,106[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:12:56,106[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 131 __________________[0m
[[36m2025-02-18 10:12:56,107[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:12:56,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:13:05,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:13:05,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:13:05,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:13:05,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:13:05,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:13:05,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:13:05,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:13:05,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:13:05,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:13:06,265[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:13:06,436[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 73.90it/s v_num: 0.000
[[36m2025-02-18 10:13:17,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:13:17,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/131[0m
[[36m2025-02-18 10:13:18,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025924294616583845 lr[0m
[[36m2025-02-18 10:13:18,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:13:18,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 133 __________________[0m
[[36m2025-02-18 10:13:18,441[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:13:18,442[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:13:28,014[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:13:28,031[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:13:28,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:13:28,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:13:28,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:13:28,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:13:28,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:13:28,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:13:28,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:13:28,050[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:13:28,066[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 87.93it/s v_num: 0.000
[[36m2025-02-18 10:13:40,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:13:40,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/133[0m
[[36m2025-02-18 10:13:42,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003083949268189477 lr[0m
[[36m2025-02-18 10:13:42,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 10:13:42,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 135 __________________[0m
[[36m2025-02-18 10:13:42,278[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:13:42,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:13:51,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:13:51,877[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:13:51,877[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:13:51,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:13:51,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:13:51,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:13:51,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:13:51,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:13:51,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:13:51,896[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:13:51,921[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 68.86it/s v_num: 0.000
[[36m2025-02-18 10:13:59,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:13:59,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/135[0m
[[36m2025-02-18 10:14:00,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002799265517437967 lr[0m
[[36m2025-02-18 10:14:01,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:14:01,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 137 __________________[0m
[[36m2025-02-18 10:14:01,756[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:14:01,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:14:11,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:14:11,639[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:14:11,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:14:11,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:14:11,772[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:14:11,772[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:14:11,773[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:14:11,774[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:14:11,774[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:14:12,074[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:14:12,155[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 115.80it/s v_num: 0.000
[[36m2025-02-18 10:14:19,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:14:19,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/137[0m
[[36m2025-02-18 10:14:20,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00246137432523996 lr[0m
[[36m2025-02-18 10:14:20,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:14:20,428[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 139 __________________[0m
[[36m2025-02-18 10:14:20,428[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:14:20,429[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:14:29,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:14:29,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:14:29,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:14:29,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:14:30,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:14:30,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:14:30,002[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:14:30,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:14:30,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:14:30,015[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:14:30,044[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 105.44it/s v_num: 0.000
[[36m2025-02-18 10:14:37,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:14:37,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/139[0m
[[36m2025-02-18 10:14:39,566[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0028300072423471877 lr[0m
[[36m2025-02-18 10:14:39,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:14:39,651[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 141 __________________[0m
[[36m2025-02-18 10:14:39,652[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:14:39,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:14:49,176[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:14:49,228[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:14:49,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:14:49,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:14:49,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:14:49,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:14:49,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:14:49,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:14:49,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:14:49,330[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:14:49,623[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 84.38it/s v_num: 0.000
[[36m2025-02-18 10:15:08,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:15:08,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/141[0m
[[36m2025-02-18 10:15:08,581[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024521738595443235 lr[0m
[[36m2025-02-18 10:15:08,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:15:08,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 142 __________________[0m
[[36m2025-02-18 10:15:08,601[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:15:08,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:15:18,128[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:15:18,154[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:15:18,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:15:18,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:15:18,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:15:18,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:15:18,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:15:18,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:15:18,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:15:18,514[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:15:18,524[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 194.26it/s v_num: 0.000
[[36m2025-02-18 10:15:23,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:15:23,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/142[0m
[[36m2025-02-18 10:15:24,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024179382429515644 lr[0m
[[36m2025-02-18 10:15:24,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:15:24,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 143 __________________[0m
[[36m2025-02-18 10:15:24,417[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:15:24,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:15:33,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:15:33,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:15:33,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:15:33,858[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:15:33,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:15:33,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:15:33,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:15:33,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:15:33,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:15:33,881[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:15:33,927[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 91.26it/s v_num: 0.000
[[36m2025-02-18 10:15:41,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:15:41,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/143[0m
[[36m2025-02-18 10:15:43,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024514769009982844 lr[0m
[[36m2025-02-18 10:15:44,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:15:44,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 144 __________________[0m
[[36m2025-02-18 10:15:44,033[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:15:44,033[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:15:53,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:15:53,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:15:53,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:15:53,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:15:53,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:15:53,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:15:53,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:15:53,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:15:53,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:15:53,598[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:15:53,609[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 91.02it/s v_num: 0.000
[[36m2025-02-18 10:15:58,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:15:58,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/144[0m
[[36m2025-02-18 10:15:59,044[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024010418851277224 lr[0m
[[36m2025-02-18 10:15:59,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:15:59,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 145 __________________[0m
[[36m2025-02-18 10:15:59,098[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:15:59,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:16:08,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:16:08,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:16:08,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:16:08,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:16:08,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:16:08,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:16:08,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:16:08,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:16:08,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:16:08,748[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:16:08,763[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 111.82it/s v_num: 0.000
[[36m2025-02-18 10:16:13,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:16:13,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/145[0m
[[36m2025-02-18 10:16:14,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002454681156307347 lr[0m
[[36m2025-02-18 10:16:14,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:16:14,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 147 __________________[0m
[[36m2025-02-18 10:16:14,304[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:16:14,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:16:23,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:16:23,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:16:23,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:16:23,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:16:23,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:16:23,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:16:23,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:16:23,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:16:23,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:16:23,897[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:16:23,903[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 82.85it/s v_num: 0.000
[[36m2025-02-18 10:16:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:16:32,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/147[0m
[[36m2025-02-18 10:16:33,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014897529257272058 lr[0m
[[36m2025-02-18 10:16:33,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:16:33,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 148 __________________[0m
[[36m2025-02-18 10:16:33,723[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:16:33,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:16:43,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:16:43,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:16:43,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:16:43,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:16:43,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:16:43,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:16:43,274[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:16:43,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:16:43,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:16:43,288[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:16:43,324[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 181.50it/s v_num: 0.000
[[36m2025-02-18 10:16:49,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:16:49,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/148[0m
[[36m2025-02-18 10:16:50,615[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029148569569376792 lr[0m
[[36m2025-02-18 10:16:50,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:16:50,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 151 __________________[0m
[[36m2025-02-18 10:16:50,636[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:16:50,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:17:00,178[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:17:00,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:17:00,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:17:00,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:17:00,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:17:00,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:17:00,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:17:00,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:17:00,386[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:17:00,413[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:17:00,715[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 117.98it/s v_num: 0.000
[[36m2025-02-18 10:17:27,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:17:27,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/151[0m
[[36m2025-02-18 10:17:28,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002874229411748782 lr[0m
[[36m2025-02-18 10:17:29,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:17:29,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 152 __________________[0m
[[36m2025-02-18 10:17:29,032[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:17:29,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:17:38,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:17:38,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:17:38,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:17:38,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:17:38,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:17:38,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:17:38,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:17:38,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:17:38,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:17:38,927[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:17:38,936[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 140.38it/s v_num: 0.000
[[36m2025-02-18 10:17:44,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:17:44,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/152[0m
[[36m2025-02-18 10:17:45,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002601708621674192 lr[0m
[[36m2025-02-18 10:17:45,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:17:45,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 154 __________________[0m
[[36m2025-02-18 10:17:45,700[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:17:45,700[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:17:55,241[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:17:55,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:17:55,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:17:55,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:17:55,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:17:55,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:17:55,282[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:17:55,282[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:17:55,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:17:55,295[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:17:55,336[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 110.74it/s v_num: 0.000
[[36m2025-02-18 10:18:03,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:18:03,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/154[0m
[[36m2025-02-18 10:18:04,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026348547675695143 lr[0m
[[36m2025-02-18 10:18:04,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:18:04,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 156 __________________[0m
[[36m2025-02-18 10:18:04,925[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:18:04,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:18:14,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:18:14,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:18:14,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:18:14,537[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:18:14,538[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:18:14,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:18:14,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:18:14,540[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:18:14,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:18:14,554[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:18:14,640[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 93.51it/s v_num: 0.000
[[36m2025-02-18 10:18:21,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:18:21,367[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/156[0m
[[36m2025-02-18 10:18:22,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026298816743936734 lr[0m
[[36m2025-02-18 10:18:22,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:18:22,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 158 __________________[0m
[[36m2025-02-18 10:18:22,989[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:18:22,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:18:32,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:18:32,719[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:18:32,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:18:32,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:18:32,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:18:32,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:18:32,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:18:32,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:18:32,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:18:32,873[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:18:33,383[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 131.04it/s v_num: 0.000
[[36m2025-02-18 10:18:38,541[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:18:38,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/158[0m
[[36m2025-02-18 10:18:39,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002586314578564104 lr[0m
[[36m2025-02-18 10:18:39,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:18:39,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 160 __________________[0m
[[36m2025-02-18 10:18:39,266[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:18:39,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:18:48,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:18:49,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:18:49,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:18:49,038[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:18:49,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:18:49,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:18:49,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:18:49,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:18:49,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:18:49,087[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:18:49,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 180.24it/s v_num: 0.000
[[36m2025-02-18 10:18:55,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:18:55,425[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/160[0m
[[36m2025-02-18 10:18:55,891[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026683681518847578 lr[0m
[[36m2025-02-18 10:18:55,958[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:18:55,958[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 161 __________________[0m
[[36m2025-02-18 10:18:55,959[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:18:55,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:19:05,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:19:05,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:19:05,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:19:05,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:19:05,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:19:05,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:19:05,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:19:05,611[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:19:05,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:19:05,626[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:19:05,634[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 148.69it/s v_num: 0.000
[[36m2025-02-18 10:19:11,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:19:11,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/161[0m
[[36m2025-02-18 10:19:11,516[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0021491737390067793 lr[0m
[[36m2025-02-18 10:19:11,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:19:11,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 163 __________________[0m
[[36m2025-02-18 10:19:11,544[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:19:11,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:19:21,199[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:19:21,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:19:21,205[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:19:21,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:19:21,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:19:21,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:19:21,209[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:19:21,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:19:21,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:19:21,223[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:19:21,262[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 137.36it/s v_num: 0.000
[[36m2025-02-18 10:19:27,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:19:27,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/163[0m
[[36m2025-02-18 10:19:27,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014586460159809523 lr[0m
[[36m2025-02-18 10:19:27,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:19:27,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 165 __________________[0m
[[36m2025-02-18 10:19:27,411[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:19:27,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:19:37,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:19:37,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:19:37,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:19:37,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:19:37,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:19:37,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:19:37,139[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:19:37,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:19:37,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:19:37,184[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:19:37,268[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 151.91it/s v_num: 0.000
[[36m2025-02-18 10:19:44,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:19:44,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/165[0m
[[36m2025-02-18 10:19:45,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0025682843416768093 lr[0m
[[36m2025-02-18 10:19:45,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:19:45,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 167 __________________[0m
[[36m2025-02-18 10:19:45,166[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:19:45,166[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:19:54,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:19:54,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:19:54,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:19:54,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:19:54,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:19:54,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:19:54,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:19:54,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:19:54,833[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:19:54,864[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:19:54,871[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 145.17it/s v_num: 0.000
[[36m2025-02-18 10:19:59,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:19:59,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/167[0m
[[36m2025-02-18 10:20:00,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00111628224451933 lr[0m
[[36m2025-02-18 10:20:00,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:20:00,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 170 __________________[0m
[[36m2025-02-18 10:20:00,257[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:20:00,258[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:20:09,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:20:09,989[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:20:09,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:20:09,993[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:20:09,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:20:09,994[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:20:09,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:20:09,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:20:09,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:20:10,011[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:20:10,057[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 145.69it/s v_num: 0.000
[[36m2025-02-18 10:20:18,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:20:18,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/170[0m
[[36m2025-02-18 10:20:18,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029417778207941774 lr[0m
[[36m2025-02-18 10:20:18,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:20:18,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 172 __________________[0m
[[36m2025-02-18 10:20:18,895[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:20:18,895[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:20:28,470[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:20:28,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:20:28,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:20:28,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:20:28,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:20:28,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:20:28,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:20:28,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:20:28,497[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:20:28,511[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:20:28,556[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 159.19it/s v_num: 0.000
[[36m2025-02-18 10:20:38,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:20:38,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/172[0m
[[36m2025-02-18 10:20:38,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029225761537001425 lr[0m
[[36m2025-02-18 10:20:38,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:20:38,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 173 __________________[0m
[[36m2025-02-18 10:20:38,662[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:20:38,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:20:48,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:20:48,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:20:48,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:20:48,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:20:48,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:20:48,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:20:48,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:20:48,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:20:48,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:20:48,320[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:20:48,377[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 85.81it/s v_num: 0.000
[[36m2025-02-18 10:21:01,102[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:21:01,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/173[0m
[[36m2025-02-18 10:21:01,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003038851140264783 lr[0m
[[36m2025-02-18 10:21:01,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:21:01,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 174 __________________[0m
[[36m2025-02-18 10:21:01,955[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:21:01,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:21:11,545[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:21:11,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:21:11,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:21:11,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:21:11,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:21:11,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:21:11,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:21:11,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:21:11,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:21:11,803[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:21:11,896[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 171.82it/s v_num: 0.000
[[36m2025-02-18 10:21:45,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:21:45,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/174[0m
[[36m2025-02-18 10:21:47,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002984709895351543 lr[0m
[[36m2025-02-18 10:21:47,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:21:47,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 176 __________________[0m
[[36m2025-02-18 10:21:47,208[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:21:47,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:21:56,750[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:21:56,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:21:56,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:21:56,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:21:56,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:21:56,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:21:56,766[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:21:56,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:21:56,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:21:56,783[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:21:56,802[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 123.90it/s v_num: 0.000
[[36m2025-02-18 10:22:04,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:22:04,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/176[0m
[[36m2025-02-18 10:22:04,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003598433222664228 lr[0m
[[36m2025-02-18 10:22:05,036[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:22:05,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 178 __________________[0m
[[36m2025-02-18 10:22:05,037[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:22:05,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:22:14,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:22:14,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:22:14,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:22:14,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:22:14,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:22:14,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:22:14,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:22:14,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:22:14,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:22:14,924[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:22:14,971[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 176.62it/s v_num: 0.000
[[36m2025-02-18 10:22:22,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:22:22,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/178[0m
[[36m2025-02-18 10:22:23,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030097245500392373 lr[0m
[[36m2025-02-18 10:22:24,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:22:24,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 179 __________________[0m
[[36m2025-02-18 10:22:24,096[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:22:24,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:22:33,620[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:22:33,648[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:22:33,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:22:33,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:22:33,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:22:33,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:22:33,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:22:33,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:22:33,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:22:33,667[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:22:33,726[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 92.95it/s v_num: 0.000
[[36m2025-02-18 10:22:57,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:22:57,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/179[0m
[[36m2025-02-18 10:22:58,962[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002662672542970215 lr[0m
[[36m2025-02-18 10:22:59,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:22:59,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 181 __________________[0m
[[36m2025-02-18 10:22:59,095[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:22:59,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:23:08,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:23:08,934[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:23:08,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:23:09,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:23:09,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:23:09,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:23:09,123[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:23:09,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:23:09,124[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:23:09,176[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:23:09,622[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 91.00it/s v_num: 0.000
[[36m2025-02-18 10:23:37,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:23:37,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/181[0m
[[36m2025-02-18 10:23:37,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002238008218080981 lr[0m
[[36m2025-02-18 10:23:37,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 10:23:37,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 183 __________________[0m
[[36m2025-02-18 10:23:37,718[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 10:23:37,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
Train indices: 782 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [4881, 5338, 4524, 210, 6013]
Test indices: 6252 [2040, 3521, 6861, 740, 5962]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 10:23:47,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 10:23:47,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 10:23:47,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 10:23:47,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 10:23:47,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 10:23:47,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 10:23:47,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 10:23:47,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 10:23:47,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 10:23:47,562[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 10:23:47,569[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 159.68it/s v_num: 0.000
[[36m2025-02-18 10:23:55,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 10:23:55,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_10-01-59/183[0m
[[36m2025-02-18 10:23:55,705[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 185[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-18 15:43:42,400[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-18 15:43:42,437[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/hnn.db[0m
[[36m2025-02-18 15:44:32,604[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_hnn>[0m
[[36m2025-02-18 15:44:33,128[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-18 15:44:38,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021153673722318394 lr[0m
[[36m2025-02-18 15:44:39,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 15:44:39,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-18 15:44:39,835[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 15:44:39,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 15:44:54,475[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 15:47:01,432[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 15:47:01,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 15:47:01,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 15:47:01,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 15:47:01,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 15:47:02,533[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 15:47:02,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 15:47:03,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 15:47:41,135[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 15:48:10,973[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 72.11it/s v_num: 0.000
[[36m2025-02-18 15:52:43,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 15:52:43,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/000[0m
[[36m2025-02-18 15:53:00,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002949201708073891 lr[0m
[[36m2025-02-18 15:53:01,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 15:53:01,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-18 15:53:01,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 15:53:01,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 15:53:12,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 15:53:13,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 15:53:13,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 15:53:13,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 15:53:13,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 15:53:13,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 15:53:13,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 15:53:13,722[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 15:53:13,724[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 15:53:17,961[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 15:53:19,045[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:01 • 0:00:00 92.43it/s v_num: 0.000
[[36m2025-02-18 15:54:43,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 15:54:44,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/001[0m
[[36m2025-02-18 15:54:56,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014493825421745437 lr[0m
[[36m2025-02-18 15:54:57,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 15:54:57,995[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-18 15:54:57,996[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 15:54:57,996[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 15:55:08,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 15:55:08,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 15:55:08,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 15:55:09,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 15:55:09,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 15:55:09,002[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 15:55:09,003[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 15:55:09,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 15:55:09,005[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 15:55:13,739[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 15:55:15,273[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 104.00it/s v_num: 0.000
[[36m2025-02-18 15:56:46,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 15:56:46,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/002[0m
[[36m2025-02-18 15:57:01,631[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020559343783957663 lr[0m
[[36m2025-02-18 15:57:03,003[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 15:57:03,003[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-18 15:57:03,004[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 15:57:03,004[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 15:57:13,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 15:57:13,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 15:57:13,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 15:57:13,981[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 15:57:13,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 15:57:13,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 15:57:13,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 15:57:13,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 15:57:13,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 15:57:17,128[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 15:57:17,687[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 98.71it/s v_num: 0.000
[[36m2025-02-18 15:58:54,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 15:58:54,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/003[0m
[[36m2025-02-18 15:59:08,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038492581955287116 lr[0m
[[36m2025-02-18 15:59:10,761[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 15:59:10,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-18 15:59:10,762[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 15:59:10,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 15:59:21,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 15:59:21,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 15:59:21,255[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 15:59:21,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 15:59:21,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 15:59:21,377[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 15:59:21,378[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 15:59:21,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 15:59:21,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 15:59:24,932[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 15:59:25,506[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 74.34it/s v_num: 0.000
[[36m2025-02-18 16:00:39,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:00:39,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/004[0m
[[36m2025-02-18 16:00:47,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002996548869421276 lr[0m
[[36m2025-02-18 16:00:48,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 16:00:48,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-18 16:00:48,995[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:00:48,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:00:59,586[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:00:59,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:00:59,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:00:59,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:00:59,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:00:59,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:00:59,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:00:59,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:00:59,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:01:02,171[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:01:03,069[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:00 • 0:00:00 102.31it/s v_num: 0.000
[[36m2025-02-18 16:02:10,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:02:10,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/005[0m
[[36m2025-02-18 16:02:25,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002353538053917445 lr[0m
[[36m2025-02-18 16:02:27,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:02:27,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-18 16:02:27,922[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:02:27,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:02:39,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:02:39,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:02:39,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:02:39,399[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:02:39,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:02:39,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:02:39,560[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:02:39,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:02:39,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:02:43,562[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:02:43,700[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 111.39it/s v_num: 0.000
[[36m2025-02-18 16:03:53,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:03:53,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/006[0m
[[36m2025-02-18 16:03:58,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012035252278617201 lr[0m
[[36m2025-02-18 16:03:58,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:03:58,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-18 16:03:58,234[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:03:58,235[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:04:08,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:04:08,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:04:08,473[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:04:08,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:04:08,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:04:08,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:04:08,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:04:08,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:04:08,486[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:04:09,981[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:04:10,757[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 114.80it/s v_num: 0.000
[[36m2025-02-18 16:05:10,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:05:10,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/007[0m
[[36m2025-02-18 16:05:15,236[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00036315899074972665 lr[0m
[[36m2025-02-18 16:05:15,686[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 16:05:15,687[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-18 16:05:15,688[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:05:15,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:05:26,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:05:26,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:05:26,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:05:26,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:05:26,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:05:26,812[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:05:26,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:05:26,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:05:26,814[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:05:27,725[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:05:28,633[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 121.36it/s v_num: 0.000
[[36m2025-02-18 16:06:06,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:06:06,176[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/008[0m
[[36m2025-02-18 16:06:09,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001119476400407963 lr[0m
[[36m2025-02-18 16:06:09,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 16:06:09,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-18 16:06:09,832[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:06:09,832[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:06:19,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:06:19,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:06:19,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:06:19,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:06:19,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:06:19,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:06:19,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:06:19,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:06:19,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:06:19,760[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:06:21,440[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 101.80it/s v_num: 0.000
[[36m2025-02-18 16:06:55,714[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:06:55,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/009[0m
[[36m2025-02-18 16:06:59,337[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017534556535748797 lr[0m
[[36m2025-02-18 16:07:00,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 16:07:00,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-18 16:07:00,372[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:07:00,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:07:11,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:07:11,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:07:11,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:07:11,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:07:11,124[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:07:11,124[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:07:11,125[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:07:11,125[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:07:11,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:07:11,986[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:07:13,064[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 32.27it/s v_num: 0.000
[[36m2025-02-18 16:07:40,368[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[[36m2025-02-18 16:07:41,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:07:53,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006487878389547674 lr[0m
[[36m2025-02-18 16:07:53,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:07:53,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-18 16:07:53,185[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:07:53,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:08:03,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:08:03,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:08:03,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:08:03,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:08:03,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:08:03,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:08:03,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:08:03,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:08:03,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:08:03,331[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:08:04,785[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 140.40it/s v_num: 0.000
[[36m2025-02-18 16:08:47,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:08:47,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/011[0m
[[36m2025-02-18 16:08:50,731[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005534360814307639 lr[0m
[[36m2025-02-18 16:08:50,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-18 16:08:50,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-18 16:08:50,757[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:08:50,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:09:00,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:09:00,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:09:00,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:09:00,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:09:00,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:09:00,783[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:09:00,784[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:09:00,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:09:00,785[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:09:00,956[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:09:01,888[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 73.74it/s v_num: 0.000
[[36m2025-02-18 16:09:37,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:09:37,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/012[0m
[[36m2025-02-18 16:09:40,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008116260978756384 lr[0m
[[36m2025-02-18 16:09:41,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:09:41,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-18 16:09:41,655[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:09:41,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:09:51,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:09:51,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:09:51,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:09:52,104[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:09:52,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:09:52,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:09:52,282[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:09:52,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:09:52,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:09:52,354[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:09:53,149[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 106.68it/s v_num: 0.000
[[36m2025-02-18 16:10:47,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:10:47,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/013[0m
[[36m2025-02-18 16:10:52,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007655516618843977 lr[0m
[[36m2025-02-18 16:10:53,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:10:53,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-18 16:10:53,327[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:10:53,328[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:11:03,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:11:04,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:11:04,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:11:04,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:11:04,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:11:04,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:11:04,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:11:04,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:11:04,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:11:04,313[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:11:05,211[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 107.87it/s v_num: 0.000
[[36m2025-02-18 16:12:31,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:12:31,762[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/014[0m
[[36m2025-02-18 16:12:46,891[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000636444812344129 lr[0m
[[36m2025-02-18 16:12:47,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 16:12:47,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-18 16:12:47,055[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:12:47,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:12:59,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:12:59,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:12:59,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:12:59,800[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:12:59,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:12:59,802[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:12:59,803[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:12:59,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:12:59,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:13:00,479[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:13:02,405[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 26.19it/s v_num: 0.000
[[36m2025-02-18 16:13:35,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:13:35,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/015[0m
[[36m2025-02-18 16:13:39,194[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009774399797893543 lr[0m
[[36m2025-02-18 16:13:39,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-18 16:13:39,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-18 16:13:39,850[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:13:39,850[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:13:51,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:13:51,781[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:13:51,782[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:13:51,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:13:51,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:13:51,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:13:51,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:13:51,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:13:51,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:13:51,812[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:13:53,090[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 52.50it/s v_num: 0.000
[[36m2025-02-18 16:14:23,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:14:23,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/016[0m
[[36m2025-02-18 16:14:25,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038217516406368544 lr[0m
[[36m2025-02-18 16:14:25,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:14:25,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-18 16:14:25,570[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:14:25,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:14:36,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:14:36,389[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:14:36,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:14:36,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:14:36,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:14:36,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:14:36,534[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:14:36,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:14:36,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:14:38,528[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:14:38,888[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 103.85it/s v_num: 0.000
[[36m2025-02-18 16:16:05,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:16:05,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/017[0m
[[36m2025-02-18 16:16:19,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015054182878898074 lr[0m
[[36m2025-02-18 16:16:21,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:16:21,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-18 16:16:21,348[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:16:21,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:16:32,344[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:16:32,460[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:16:32,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:16:32,541[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:16:32,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:16:32,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:16:32,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:16:32,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:16:32,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:16:39,166[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:16:40,129[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 101.72it/s v_num: 0.000
[[36m2025-02-18 16:18:07,932[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:18:08,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/018[0m
[[36m2025-02-18 16:18:17,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005033690549580847 lr[0m
[[36m2025-02-18 16:18:18,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:18:18,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-18 16:18:18,427[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:18:18,428[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:18:28,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:18:29,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:18:29,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:18:29,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:18:29,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:18:29,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:18:29,023[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:18:29,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:18:29,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:18:33,871[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:18:35,857[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:02 • 0:00:00 93.31it/s v_num: 0.000
[[36m2025-02-18 16:19:53,381[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:19:53,448[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/019[0m
[[36m2025-02-18 16:20:06,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008984870310503699 lr[0m
[[36m2025-02-18 16:20:09,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 16:20:09,499[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-18 16:20:09,499[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:20:09,500[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:20:21,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:20:21,942[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:20:21,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:20:22,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:20:22,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:20:22,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:20:22,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:20:22,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:20:22,195[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:20:27,068[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:20:28,874[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 29.84it/s v_num: 0.000
[[36m2025-02-18 16:21:12,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:21:12,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/020[0m
[[36m2025-02-18 16:21:14,017[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004604912087275508 lr[0m
[[36m2025-02-18 16:21:14,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:21:14,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-18 16:21:14,187[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:21:14,187[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:21:25,296[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:21:25,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:21:25,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:21:25,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:21:25,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:21:25,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:21:25,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:21:25,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:21:25,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:21:29,096[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:21:29,565[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 108.15it/s v_num: 0.000
[[36m2025-02-18 16:22:54,857[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:22:54,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/021[0m
[[36m2025-02-18 16:23:07,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005215009225566659 lr[0m
[[36m2025-02-18 16:23:10,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:23:10,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-18 16:23:10,275[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:23:10,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:23:21,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:23:21,717[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:23:21,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:23:21,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:23:21,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:23:21,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:23:21,743[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:23:21,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:23:21,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:23:22,703[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:23:24,249[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 107.10it/s v_num: 0.000
[[36m2025-02-18 16:24:58,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:24:58,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/022[0m
[[36m2025-02-18 16:25:15,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012618562456224024 lr[0m
[[36m2025-02-18 16:25:16,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:25:16,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-18 16:25:16,574[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:25:16,575[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:25:27,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:25:27,990[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:25:27,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:25:28,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:25:28,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:25:28,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:25:28,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:25:28,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:25:28,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:25:30,542[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:25:31,712[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 115.10it/s v_num: 0.000
[[36m2025-02-18 16:26:42,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:26:42,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/023[0m
[[36m2025-02-18 16:26:54,528[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000426011623531081 lr[0m
[[36m2025-02-18 16:26:56,115[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:26:56,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-18 16:26:56,116[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:26:56,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:27:06,236[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:27:06,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:27:06,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:27:06,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:27:06,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:27:06,355[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:27:06,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:27:06,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:27:06,357[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:27:09,694[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:27:10,577[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 142.48it/s v_num: 0.000
[[36m2025-02-18 16:28:16,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:28:16,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/024[0m
[[36m2025-02-18 16:28:17,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007397568831405336 lr[0m
[[36m2025-02-18 16:28:17,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-18 16:28:17,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-18 16:28:17,172[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:28:17,172[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:28:27,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:28:27,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:28:27,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:28:27,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:28:27,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:28:27,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:28:27,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:28:27,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:28:27,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:28:29,407[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:28:33,655[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 60.21it/s v_num: 0.000
[[36m2025-02-18 16:29:22,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:29:22,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/025[0m
[[36m2025-02-18 16:29:35,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002469059533150303 lr[0m
[[36m2025-02-18 16:29:35,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 16:29:35,951[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-18 16:29:35,951[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:29:35,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:29:46,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:29:46,188[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:29:46,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:29:46,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:29:46,356[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:29:46,357[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:29:46,359[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:29:46,359[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:29:46,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:29:46,728[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:29:47,519[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:00 • 0:00:00 102.04it/s v_num: 0.000
[[36m2025-02-18 16:30:38,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:30:38,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/026[0m
[[36m2025-02-18 16:30:46,777[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002308201625059043 lr[0m
[[36m2025-02-18 16:30:47,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:30:47,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-18 16:30:47,423[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:30:47,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:30:58,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:30:58,072[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:30:58,072[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:30:58,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:30:58,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:30:58,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:30:58,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:30:58,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:30:58,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:30:59,414[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:31:00,063[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 118.85it/s v_num: 0.000
[[36m2025-02-18 16:32:07,680[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:32:07,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/027[0m
[[36m2025-02-18 16:32:18,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016853144688226373 lr[0m
[[36m2025-02-18 16:32:20,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:32:20,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-18 16:32:20,054[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:32:20,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:32:29,646[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:32:29,683[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:32:29,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:32:29,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:32:29,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:32:29,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:32:29,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:32:29,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:32:29,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:32:32,837[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:32:33,790[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 133.98it/s v_num: 0.000
[[36m2025-02-18 16:33:39,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:33:39,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/028[0m
[[36m2025-02-18 16:33:40,673[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031284268817360775 lr[0m
[[36m2025-02-18 16:33:41,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:33:41,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-18 16:33:41,816[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:33:41,816[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:33:52,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:33:52,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:33:52,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:33:52,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:33:52,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:33:52,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:33:52,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:33:52,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:33:52,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:33:54,445[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:33:55,331[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 118.50it/s v_num: 0.000
[[36m2025-02-18 16:35:05,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:35:05,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/029[0m
[[36m2025-02-18 16:35:07,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000758994516748174 lr[0m
[[36m2025-02-18 16:35:07,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-18 16:35:07,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-18 16:35:07,266[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:35:07,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:35:17,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:35:17,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:35:17,745[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:35:17,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:35:17,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:35:17,831[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:35:17,832[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:35:17,833[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:35:17,834[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:35:20,294[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:35:21,145[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 64.69it/s v_num: 0.000
[[36m2025-02-18 16:36:07,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:36:07,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/030[0m
[[36m2025-02-18 16:36:22,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005064479562796861 lr[0m
[[36m2025-02-18 16:36:23,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:36:23,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-18 16:36:23,525[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:36:23,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:36:33,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:36:33,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:36:33,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:36:33,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:36:33,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:36:33,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:36:33,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:36:33,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:36:33,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:36:35,719[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:36:36,289[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:02 • 0:00:00 95.76it/s v_num: 0.000
[[36m2025-02-18 16:37:48,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:37:48,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/031[0m
[[36m2025-02-18 16:37:58,032[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006007080854251743 lr[0m
[[36m2025-02-18 16:37:59,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:37:59,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-18 16:37:59,009[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:37:59,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:38:09,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:38:09,244[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:38:09,245[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:38:09,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:38:09,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:38:09,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:38:09,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:38:09,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:38:09,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:38:12,683[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:38:13,174[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 116.17it/s v_num: 0.000
[[36m2025-02-18 16:39:36,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:39:36,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/032[0m
[[36m2025-02-18 16:39:36,737[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044186101778241355 lr[0m
[[36m2025-02-18 16:39:36,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 16:39:36,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-18 16:39:36,759[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:39:36,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:39:47,500[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:39:47,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:39:47,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:39:47,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:39:47,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:39:47,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:39:47,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:39:47,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:39:47,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:39:49,868[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:39:51,683[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:00 • 0:00:00 107.07it/s v_num: 0.000
[[36m2025-02-18 16:40:43,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:40:43,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/033[0m
[[36m2025-02-18 16:40:51,784[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00030501435997871106 lr[0m
[[36m2025-02-18 16:40:52,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:40:52,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-18 16:40:52,518[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:40:52,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:41:02,679[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:41:02,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:41:02,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:41:02,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:41:02,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:41:02,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:41:02,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:41:02,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:41:02,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:41:06,928[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:41:09,353[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 112.32it/s v_num: 0.000
[[36m2025-02-18 16:42:29,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:42:29,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/034[0m
[[36m2025-02-18 16:42:39,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001501478100346681 lr[0m
[[36m2025-02-18 16:42:40,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:42:40,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-18 16:42:40,956[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:42:40,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:42:51,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:42:51,273[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:42:51,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:42:51,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:42:51,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:42:51,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:42:51,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:42:51,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:42:51,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:42:52,341[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:42:52,745[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 149.19it/s v_num: 0.000
[[36m2025-02-18 16:44:03,103[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:44:03,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/035[0m
[[36m2025-02-18 16:44:15,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015463724575724767 lr[0m
[[36m2025-02-18 16:44:16,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 16:44:16,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-18 16:44:16,929[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:44:16,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:44:27,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:44:27,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:44:27,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:44:27,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:44:27,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:44:27,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:44:27,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:44:27,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:44:27,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:44:30,888[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:44:31,053[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 97.26it/s v_num: 0.000
[[36m2025-02-18 16:45:21,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:45:21,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/036[0m
[[36m2025-02-18 16:45:30,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024919334538441537 lr[0m
[[36m2025-02-18 16:45:31,179[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:45:31,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-18 16:45:31,180[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:45:31,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:45:42,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:45:42,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:45:42,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:45:42,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:45:42,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:45:42,194[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:45:42,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:45:42,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:45:42,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:45:45,954[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:45:46,843[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 120.69it/s v_num: 0.000
[[36m2025-02-18 16:46:54,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:46:54,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/037[0m
[[36m2025-02-18 16:47:00,861[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004616938802211679 lr[0m
[[36m2025-02-18 16:47:01,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 16:47:01,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-18 16:47:01,739[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:47:01,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:47:12,893[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:47:12,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:47:12,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:47:12,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:47:12,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:47:12,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:47:12,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:47:12,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:47:12,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:47:15,836[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:47:17,296[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:00 • 0:00:00 107.68it/s v_num: 0.000
[[36m2025-02-18 16:48:16,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:48:16,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/038[0m
[[36m2025-02-18 16:48:28,666[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002645149401604244 lr[0m
[[36m2025-02-18 16:48:29,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:48:29,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-18 16:48:29,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:48:29,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:48:40,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:48:40,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:48:40,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:48:40,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:48:40,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:48:40,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:48:40,537[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:48:40,538[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:48:40,539[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:48:43,438[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:48:43,785[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 114.80it/s v_num: 0.000
[[36m2025-02-18 16:49:45,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:49:45,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/039[0m
[[36m2025-02-18 16:49:51,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0032310288126191065 lr[0m
[[36m2025-02-18 16:49:52,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 16:49:52,308[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-18 16:49:52,308[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:49:52,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:50:03,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:50:03,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:50:03,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:50:03,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:50:03,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:50:03,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:50:03,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:50:03,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:50:03,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:50:06,895[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:50:11,497[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 30.11it/s v_num: 0.000
[[36m2025-02-18 16:50:41,245[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2025-02-18 16:50:41,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:50:44,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001835581098511726 lr[0m
[[36m2025-02-18 16:50:45,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:50:45,096[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-18 16:50:45,096[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:50:45,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:50:55,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:50:55,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:50:55,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:50:55,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:50:55,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:50:55,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:50:55,495[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:50:55,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:50:55,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:50:55,772[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:50:56,980[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 137.37it/s v_num: 0.000
[[36m2025-02-18 16:51:39,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:51:39,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/041[0m
[[36m2025-02-18 16:51:40,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018807041204848456 lr[0m
[[36m2025-02-18 16:51:40,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:51:40,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-18 16:51:40,899[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:51:40,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:51:51,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:51:51,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:51:51,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:51:51,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:51:51,267[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:51:51,268[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:51:51,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:51:51,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:51:51,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:51:51,942[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:51:53,803[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 136.33it/s v_num: 0.000
[[36m2025-02-18 16:52:37,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:52:37,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/042[0m
[[36m2025-02-18 16:52:37,553[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001421381015854891 lr[0m
[[36m2025-02-18 16:52:37,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:52:37,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-18 16:52:37,575[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:52:37,576[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:52:48,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:52:48,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:52:48,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:52:48,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:52:48,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:52:48,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:52:48,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:52:48,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:52:48,229[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:52:48,264[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:52:48,986[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 132.67it/s v_num: 0.000
[[36m2025-02-18 16:53:43,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:53:43,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/043[0m
[[36m2025-02-18 16:53:44,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002226399627659571 lr[0m
[[36m2025-02-18 16:53:44,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 16:53:44,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-18 16:53:44,942[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:53:44,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:53:55,690[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:53:55,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:53:55,746[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:53:55,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:53:55,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:53:55,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:53:55,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:53:55,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:53:55,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:53:56,571[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:53:56,584[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 83.80it/s v_num: 0.000
[[36m2025-02-18 16:54:17,041[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2025-02-18 16:54:17,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:54:18,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001101221954632785 lr[0m
[[36m2025-02-18 16:54:18,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:54:18,059[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-18 16:54:18,060[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:54:18,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:54:28,360[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:54:28,407[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:54:28,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:54:28,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:54:28,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:54:28,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:54:28,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:54:28,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:54:28,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:54:28,493[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:54:28,689[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 191.08it/s v_num: 0.000
[[36m2025-02-18 16:55:05,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:55:05,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/045[0m
[[36m2025-02-18 16:55:06,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016494379050422643 lr[0m
[[36m2025-02-18 16:55:06,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:55:06,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-18 16:55:06,570[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:55:06,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:55:16,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:55:16,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:55:16,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:55:16,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:55:16,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:55:16,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:55:16,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:55:16,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:55:16,659[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:55:18,939[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:55:18,987[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 116.99it/s v_num: 0.000
[[36m2025-02-18 16:56:18,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:56:18,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/046[0m
[[36m2025-02-18 16:56:21,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00150830494203306 lr[0m
[[36m2025-02-18 16:56:21,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:56:21,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-18 16:56:21,990[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:56:21,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:56:32,232[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:56:32,328[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:56:32,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:56:32,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:56:32,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:56:32,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:56:32,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:56:32,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:56:32,366[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:56:32,397[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:56:32,420[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 111.16it/s v_num: 0.000
[[36m2025-02-18 16:57:21,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:57:21,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/047[0m
[[36m2025-02-18 16:57:22,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008943154716685022 lr[0m
[[36m2025-02-18 16:57:22,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 16:57:22,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-18 16:57:22,891[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:57:22,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:57:33,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:57:33,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:57:33,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:57:33,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:57:33,645[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:57:33,646[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:57:33,648[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:57:33,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:57:33,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:57:34,201[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:57:34,280[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 99.25it/s v_num: 0.000
[[36m2025-02-18 16:58:48,893[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 16:58:48,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/048[0m
[[36m2025-02-18 16:58:59,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008718072697081299 lr[0m
[[36m2025-02-18 16:59:00,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-18 16:59:00,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-18 16:59:00,458[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 16:59:00,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 16:59:10,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 16:59:10,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 16:59:10,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 16:59:10,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 16:59:10,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 16:59:10,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 16:59:10,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 16:59:10,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 16:59:10,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 16:59:14,377[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 16:59:14,613[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 16/19 ━━━━━━━━━━━━━━━━━━━━━ 49/49 0:00:00 • 0:00:00 74.36it/s v_num: 0.000
[[36m2025-02-18 16:59:57,566[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 16.
[[36m2025-02-18 16:59:57,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:00:08,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011047663990476166 lr[0m
[[36m2025-02-18 17:00:09,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-18 17:00:09,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-18 17:00:09,714[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:00:09,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:00:20,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:00:20,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:00:20,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:00:20,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:00:21,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:00:21,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:00:21,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:00:21,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:00:21,017[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:00:22,662[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:00:22,897[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 31.51it/s v_num: 0.000
[[36m2025-02-18 17:01:12,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:01:12,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/050[0m
[[36m2025-02-18 17:01:26,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016987897343162743 lr[0m
[[36m2025-02-18 17:01:27,658[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:01:27,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-18 17:01:27,666[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:01:27,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:01:37,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:01:37,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:01:37,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:01:38,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:01:38,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:01:38,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:01:38,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:01:38,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:01:38,373[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:01:43,391[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:01:43,641[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 106.29it/s v_num: 0.000
[[36m2025-02-18 17:03:00,568[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:03:00,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/051[0m
[[36m2025-02-18 17:03:13,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018204995222127565 lr[0m
[[36m2025-02-18 17:03:15,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:03:15,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-18 17:03:15,185[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:03:15,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:03:25,778[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:03:25,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:03:25,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:03:26,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:03:26,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:03:26,139[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:03:26,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:03:26,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:03:26,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:03:28,070[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:03:29,886[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 145.06it/s v_num: 0.000
[[36m2025-02-18 17:04:47,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:04:47,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/052[0m
[[36m2025-02-18 17:04:57,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001222872248509944 lr[0m
[[36m2025-02-18 17:04:59,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:04:59,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-18 17:04:59,726[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:04:59,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:05:10,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:05:10,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:05:10,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:05:10,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:05:10,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:05:10,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:05:10,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:05:10,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:05:10,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:05:16,394[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:05:17,736[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:02 • 0:00:00 97.18it/s v_num: 0.000
[[36m2025-02-18 17:06:44,712[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:06:44,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/053[0m
[[36m2025-02-18 17:06:55,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011892495419401463 lr[0m
[[36m2025-02-18 17:06:56,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:06:56,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-18 17:06:56,717[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:06:56,717[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:07:07,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:07:07,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:07:07,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:07:08,003[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:07:08,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:07:08,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:07:08,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:07:08,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:07:08,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:07:10,278[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:07:11,076[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━ 195/195 0:00:02 • 0:00:00 96.17it/s v_num: 0.000
[[36m2025-02-18 17:08:19,549[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:08:19,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/054[0m
[[36m2025-02-18 17:08:27,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020094113093920714 lr[0m
[[36m2025-02-18 17:08:30,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:08:30,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-18 17:08:30,271[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:08:30,272[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:08:40,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:08:40,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:08:40,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:08:40,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:08:40,683[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:08:40,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:08:40,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:08:40,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:08:40,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:08:43,086[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:08:44,081[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 100.42it/s v_num: 0.000
[[36m2025-02-18 17:09:55,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:09:55,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/055[0m
[[36m2025-02-18 17:10:06,306[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009701448776603962 lr[0m
[[36m2025-02-18 17:10:07,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:10:07,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-18 17:10:07,665[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:10:07,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:10:18,847[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:10:18,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:10:18,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:10:18,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:10:18,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:10:18,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:10:18,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:10:18,901[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:10:18,902[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:10:20,400[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:10:22,356[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 126.20it/s v_num: 0.000
[[36m2025-02-18 17:11:06,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:11:06,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/056[0m
[[36m2025-02-18 17:11:07,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002977367546873335 lr[0m
[[36m2025-02-18 17:11:07,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-18 17:11:07,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-18 17:11:07,100[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:11:07,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:11:18,844[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:11:18,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:11:18,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:11:18,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:11:18,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:11:18,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:11:18,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:11:18,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:11:18,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:11:19,090[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:11:19,553[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 54.79it/s v_num: 0.000
[[36m2025-02-18 17:11:32,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:11:32,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/057[0m
[[36m2025-02-18 17:11:32,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013422359776024458 lr[0m
[[36m2025-02-18 17:11:32,980[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-18 17:11:32,981[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-18 17:11:32,981[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:11:32,981[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:11:44,840[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:11:44,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:11:44,848[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:11:44,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:11:44,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:11:44,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:11:44,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:11:44,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:11:44,858[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:11:44,903[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:11:46,303[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 195/195 0:00:01 • 0:00:00 118.82it/s v_num: 0.000
[[36m2025-02-18 17:12:23,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:12:23,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/058[0m
[[36m2025-02-18 17:12:23,618[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017035266383308146 lr[0m
[[36m2025-02-18 17:12:23,639[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-18 17:12:23,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-18 17:12:23,640[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-18 17:12:23,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-18 17:12:34,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.hnn.HNN>[0m
[[36m2025-02-18 17:12:34,320[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-18 17:12:34,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-18 17:12:34,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-18 17:12:34,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-18 17:12:34,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-18 17:12:34,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-18 17:12:34,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-18 17:12:34,326[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-18 17:12:34,364[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-18 17:12:35,525[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━━━━ 98/98 0:00:01 • 0:00:00 60.90it/s v_num: 0.000
[[36m2025-02-18 17:13:05,538[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-18 17:13:05,539[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_hnn/runs/2025-02-18_15-43-41/059[0m
[[36m2025-02-18 17:13:05,773[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
