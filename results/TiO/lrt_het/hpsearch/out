{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-11-28 11:41:19,955[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-11-28 11:41:19,956[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_lrt.db[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 1, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2024-11-28 11:43:21,137[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2024-11-28 11:43:21,138[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_lrt.db[0m
[[36m2024-11-28 11:43:23,144[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2024-11-28 11:43:23,171[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2024-11-28 11:43:23,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:43:23,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.50681093606854e-05, lr[0m
[[36m2024-11-28 11:43:23,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:43:23,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029048697214318013 prior_scale[0m
[[36m2024-11-28 11:43:23,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003572140318996377 q_scale[0m
[[36m2024-11-28 11:43:23,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1047391773518673 obs_scale[0m
[[36m2024-11-28 11:43:23,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:43:23,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2024-11-28 11:43:23,376[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:43:23,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:43:33,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:43:33,282[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:43:33,283[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:43:33,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:43:33,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:43:33,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:43:33,337[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:43:33,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:43:33,347[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:43:33,571[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:43:33,779[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:43:33,782[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 29.55it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2191.617         
                                                               rmse/train:      
                                                               2094.425         
[[36m2024-11-28 11:44:20,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:44:20,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/000[0m
[[36m2024-11-28 11:44:20,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 11:44:20,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001325538578998538, lr[0m
[[36m2024-11-28 11:44:20,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:44:20,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20559343783957656 prior_scale[0m
[[36m2024-11-28 11:44:20,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0058248182837850404 q_scale[0m
[[36m2024-11-28 11:44:20,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29835107709343195 obs_scale[0m
[[36m2024-11-28 11:44:20,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 11:44:20,653[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2024-11-28 11:44:20,653[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:44:20,653[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:44:31,032[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:44:31,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:44:31,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:44:31,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:44:31,045[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:44:31,046[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:44:31,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:44:31,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:44:31,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:44:31,082[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:44:31,091[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 25.17it/s v_num: 0.000      
                                                              rmse/val: 4213.481
                                                              rmse/train:       
                                                              4241.186          
[[36m2024-11-28 11:44:41,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:44:41,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/001[0m
[[36m2024-11-28 11:44:41,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:44:41,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.3020182095898586e-05, lr[0m
[[36m2024-11-28 11:44:41,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 11:44:41,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05508654872763757 prior_scale[0m
[[36m2024-11-28 11:44:41,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004020640881061957 q_scale[0m
[[36m2024-11-28 11:44:41,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1538313853200085 obs_scale[0m
[[36m2024-11-28 11:44:41,751[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 11:44:41,751[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2024-11-28 11:44:41,751[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:44:41,751[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:44:51,645[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:44:51,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:44:51,651[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:44:51,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:44:51,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:44:51,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:44:51,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:44:51,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:44:51,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:44:51,670[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:44:51,678[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:44:51,679[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 11.43it/s v_num: 0.000      
                                                              rmse/val: 4587.804
                                                              rmse/train:       
                                                              4511.548          
[[36m2024-11-28 11:45:04,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:45:04,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/002[0m
[[36m2024-11-28 11:45:04,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 11:45:04,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.336545096950015e-05, lr[0m
[[36m2024-11-28 11:45:04,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 11:45:04,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1023881426733586 prior_scale[0m
[[36m2024-11-28 11:45:04,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001165790000863127 q_scale[0m
[[36m2024-11-28 11:45:04,473[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11385861721302043 obs_scale[0m
[[36m2024-11-28 11:45:04,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-11-28 11:45:04,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2024-11-28 11:45:04,487[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:45:04,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:45:15,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:45:15,193[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:45:15,193[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:45:15,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:45:15,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:45:15,196[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:45:15,197[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:45:15,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:45:15,198[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:45:15,228[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:45:15,236[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4162.771
                                                              rmse/train:       
                                                              4194.595          
[[36m2024-11-28 11:45:26,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:45:26,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/003[0m
[[36m2024-11-28 11:45:26,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 11:45:26,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017174472922154303, lr[0m
[[36m2024-11-28 11:45:26,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:45:26,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.48474869983391317 prior_scale[0m
[[36m2024-11-28 11:45:26,295[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008271866644681318 q_scale[0m
[[36m2024-11-28 11:45:26,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0724303485094406 obs_scale[0m
[[36m2024-11-28 11:45:26,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 11:45:26,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2024-11-28 11:45:26,319[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:45:26,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:45:35,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:45:35,766[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:45:35,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:45:35,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:45:35,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:45:35,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:45:35,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:45:35,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:45:35,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:45:35,787[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:45:35,797[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 29.51it/s v_num: 0.000      
                                                              rmse/val: 3007.404
                                                              rmse/train:       
                                                              3037.457          
[[36m2024-11-28 11:45:58,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:45:58,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/004[0m
[[36m2024-11-28 11:45:58,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:45:58,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009204696704635324, lr[0m
[[36m2024-11-28 11:45:58,649[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:45:58,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17977467814503606 prior_scale[0m
[[36m2024-11-28 11:45:58,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0014948832198169292 q_scale[0m
[[36m2024-11-28 11:45:58,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4107788493789703 obs_scale[0m
[[36m2024-11-28 11:45:58,711[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-11-28 11:45:58,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2024-11-28 11:45:58,712[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:45:58,712[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:46:08,919[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:46:08,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:46:08,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:46:08,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:46:08,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:46:08,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:46:08,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:46:08,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:46:08,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:46:08,962[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:46:08,970[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:46:08,972[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 24.76it/s v_num: 0.000      
                                                              rmse/val: 935.311 
                                                              rmse/train:       
                                                              851.415           
[[36m2024-11-28 11:46:22,788[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:46:22,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/005[0m
[[36m2024-11-28 11:46:22,906[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:46:22,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2024-11-28 11:46:22,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 11:46:22,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2024-11-28 11:46:22,962[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2024-11-28 11:46:22,978[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15665279892931577 obs_scale[0m
[[36m2024-11-28 11:46:22,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 11:46:22,994[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2024-11-28 11:46:22,994[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:46:22,994[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:46:32,859[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:46:32,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:46:32,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:46:32,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:46:32,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:46:32,870[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:46:32,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:46:32,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:46:32,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:46:32,888[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:46:32,916[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:46:32,917[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.17it/s v_num: 0.000      
                                                              rmse/val: 3340.415
                                                              rmse/train:       
                                                              3256.477          
[[36m2024-11-28 11:47:03,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:47:03,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/006[0m
[[36m2024-11-28 11:47:03,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 11:47:03,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007995719083844353, lr[0m
[[36m2024-11-28 11:47:03,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 11:47:03,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0816845546830656 prior_scale[0m
[[36m2024-11-28 11:47:03,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004349147472454846 q_scale[0m
[[36m2024-11-28 11:47:03,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11866131541331688 obs_scale[0m
[[36m2024-11-28 11:47:03,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 11:47:03,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2024-11-28 11:47:03,668[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:47:03,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:47:13,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:47:13,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:47:13,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:47:13,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:47:13,327[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:47:13,327[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:47:13,328[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:47:13,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:47:13,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:47:13,359[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:47:13,366[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 11.57it/s v_num: 0.000      
                                                              rmse/val: 3839.609
                                                              rmse/train:       
                                                              3838.040          
[[36m2024-11-28 11:47:26,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:47:26,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/007[0m
[[36m2024-11-28 11:47:26,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 11:47:26,750[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1462886732717548e-05, lr[0m
[[36m2024-11-28 11:47:26,765[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:47:26,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4124747947662307 prior_scale[0m
[[36m2024-11-28 11:47:26,796[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044814115470497614 q_scale[0m
[[36m2024-11-28 11:47:26,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17860915820030454 obs_scale[0m
[[36m2024-11-28 11:47:26,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 11:47:26,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2024-11-28 11:47:26,828[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:47:26,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:47:36,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:47:36,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:47:36,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:47:36,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:47:36,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:47:36,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:47:36,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:47:36,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:47:36,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:47:36,574[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:47:36,584[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 27.94it/s v_num: 0.000      
                                                              rmse/val: 4365.324
                                                              rmse/train:       
                                                              4411.366          
[[36m2024-11-28 11:48:00,741[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:48:00,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/008[0m
[[36m2024-11-28 11:48:00,870[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:48:00,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002588548618299899, lr[0m
[[36m2024-11-28 11:48:00,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 11:48:00,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21075404848706095 prior_scale[0m
[[36m2024-11-28 11:48:00,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015787361777166986 q_scale[0m
[[36m2024-11-28 11:48:00,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23920082660450653 obs_scale[0m
[[36m2024-11-28 11:48:00,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-11-28 11:48:00,951[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2024-11-28 11:48:00,951[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:48:00,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:48:10,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:48:10,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:48:10,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:48:10,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:48:10,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:48:10,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:48:10,639[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:48:10,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:48:10,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:48:10,671[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:48:10,684[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:48:10,685[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.57it/s v_num: 0.000      
                                                              rmse/val: 2839.355
                                                              rmse/train:       
                                                              2881.459          
[[36m2024-11-28 11:48:30,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:48:30,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/009[0m
[[36m2024-11-28 11:48:30,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:48:30,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028711032739869613, lr[0m
[[36m2024-11-28 11:48:30,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:48:30,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.014937976642598423 prior_scale[0m
[[36m2024-11-28 11:48:30,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010532753257812993 q_scale[0m
[[36m2024-11-28 11:48:30,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.7109716370480204 obs_scale[0m
[[36m2024-11-28 11:48:30,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:48:30,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2024-11-28 11:48:30,410[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:48:30,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:48:40,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:48:40,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:48:40,511[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:48:40,513[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:48:40,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:48:40,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:48:40,515[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:48:40,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:48:40,516[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:48:40,531[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:48:40,541[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:48:40,542[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 26.47it/s v_num: 0.000     
                                                               rmse/val: 340.475
                                                               rmse/train:      
                                                               305.925          
[[36m2024-11-28 11:49:27,211[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:49:27,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/010[0m
[[36m2024-11-28 11:49:27,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:49:27,376[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003871157455553778, lr[0m
[[36m2024-11-28 11:49:27,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:49:27,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.014489987071262374 prior_scale[0m
[[36m2024-11-28 11:49:27,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010860093339103685 q_scale[0m
[[36m2024-11-28 11:49:27,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9746524398983547 obs_scale[0m
[[36m2024-11-28 11:49:27,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:49:27,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2024-11-28 11:49:27,470[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:49:27,470[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:49:37,335[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:49:37,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:49:37,343[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:49:37,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:49:37,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:49:37,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:49:37,347[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:49:37,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:49:37,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:49:37,862[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:49:37,872[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:49:37,874[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 28.77it/s v_num: 0.000     
                                                               rmse/val: 294.638
                                                               rmse/train:      
                                                               265.673          
[[36m2024-11-28 11:50:24,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:50:24,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/011[0m
[[36m2024-11-28 11:50:24,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:50:25,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003796759473565572, lr[0m
[[36m2024-11-28 11:50:25,029[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:50:25,053[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.014959205297763659 prior_scale[0m
[[36m2024-11-28 11:50:25,078[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010181693721223134 q_scale[0m
[[36m2024-11-28 11:50:25,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9328425480641904 obs_scale[0m
[[36m2024-11-28 11:50:25,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:50:25,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2024-11-28 11:50:25,119[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:50:25,119[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:50:34,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:50:34,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:50:34,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:50:34,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:50:34,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:50:34,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:50:34,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:50:34,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:50:34,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:50:34,897[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:50:34,904[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:50:34,905[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 25.55it/s v_num: 0.000     
                                                               rmse/val: 410.059
                                                               rmse/train:      
                                                               363.013          
[[36m2024-11-28 11:51:20,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:51:20,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/012[0m
[[36m2024-11-28 11:51:20,227[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:51:20,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041083464782765, lr[0m
[[36m2024-11-28 11:51:20,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:51:20,298[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010681584644486384 prior_scale[0m
[[36m2024-11-28 11:51:20,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010286418411102614 q_scale[0m
[[36m2024-11-28 11:51:20,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9219688122603429 obs_scale[0m
[[36m2024-11-28 11:51:20,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:51:20,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2024-11-28 11:51:20,367[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:51:20,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:51:30,360[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:51:30,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:51:30,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:51:30,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:51:30,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:51:30,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:51:30,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:51:30,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:51:30,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:51:30,406[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:51:30,416[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:51:30,417[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 25.09it/s v_num: 0.000     
                                                               rmse/val: 273.652
                                                               rmse/train:      
                                                               215.616          
[[36m2024-11-28 11:52:22,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:52:22,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/013[0m
[[36m2024-11-28 11:52:22,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:52:22,441[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045339513832139654, lr[0m
[[36m2024-11-28 11:52:22,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:52:22,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023849059537582474 prior_scale[0m
[[36m2024-11-28 11:52:22,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020919808833152 q_scale[0m
[[36m2024-11-28 11:52:22,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9330914898114858 obs_scale[0m
[[36m2024-11-28 11:52:22,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:52:22,544[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2024-11-28 11:52:22,544[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:52:22,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:52:32,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:52:32,532[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:52:32,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:52:32,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:52:32,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:52:32,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:52:32,538[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:52:32,538[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:52:32,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:52:32,585[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:52:32,596[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:52:32,598[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 25.41it/s v_num: 0.000     
                                                               rmse/val: 171.720
                                                               rmse/train:      
                                                               144.860          
[[36m2024-11-28 11:53:56,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:53:56,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/014[0m
[[36m2024-11-28 11:53:57,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:53:57,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005145519904373549, lr[0m
[[36m2024-11-28 11:53:57,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:53:57,391[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.032326627210685015 prior_scale[0m
[[36m2024-11-28 11:53:57,419[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002639703151199391 q_scale[0m
[[36m2024-11-28 11:53:57,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7686598871562234 obs_scale[0m
[[36m2024-11-28 11:53:57,465[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:53:57,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2024-11-28 11:53:57,466[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:53:57,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:54:07,569[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:54:07,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:54:07,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:54:07,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:54:07,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:54:07,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:54:07,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:54:07,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:54:07,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:54:07,641[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:54:07,742[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:54:07,744[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 24.07it/s v_num: 0.000     
                                                               rmse/val: 359.777
                                                               rmse/train:      
                                                               311.197          
[[36m2024-11-28 11:54:58,457[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:54:58,458[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/015[0m
[[36m2024-11-28 11:54:58,561[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:54:58,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006845758990621392, lr[0m
[[36m2024-11-28 11:54:58,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:54:58,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03873241599615214 prior_scale[0m
[[36m2024-11-28 11:54:58,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002842786274653047 q_scale[0m
[[36m2024-11-28 11:54:58,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6443333128611081 obs_scale[0m
[[36m2024-11-28 11:54:58,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-11-28 11:54:58,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2024-11-28 11:54:58,650[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:54:58,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:55:09,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:55:09,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:55:09,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:55:09,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:55:09,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:55:09,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:55:09,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:55:09,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:55:09,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:55:09,102[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:55:09,141[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:55:09,142[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 2478.425
                                                              rmse/train:       
                                                              2366.800          
[[36m2024-11-28 11:55:18,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:55:18,118[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/016[0m
[[36m2024-11-28 11:55:18,247[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:55:18,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018259475214064708, lr[0m
[[36m2024-11-28 11:55:18,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:55:18,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.028250375281397913 prior_scale[0m
[[36m2024-11-28 11:55:18,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006453166895704934 q_scale[0m
[[36m2024-11-28 11:55:18,363[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6842168027625001 obs_scale[0m
[[36m2024-11-28 11:55:18,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:55:18,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2024-11-28 11:55:18,384[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:55:18,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:55:28,664[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:55:28,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:55:28,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:55:28,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:55:28,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:55:28,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:55:28,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:55:28,676[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:55:28,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:55:28,691[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:55:28,700[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:55:28,701[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 30.78it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1612.478         
                                                               rmse/train:      
                                                               1562.406         
[[36m2024-11-28 11:56:11,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:56:11,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/017[0m
[[36m2024-11-28 11:56:11,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:56:11,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005466272984405296, lr[0m
[[36m2024-11-28 11:56:11,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:56:11,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02585327475043572 prior_scale[0m
[[36m2024-11-28 11:56:11,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021481579137603492 q_scale[0m
[[36m2024-11-28 11:56:11,450[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.7403662798180316 obs_scale[0m
[[36m2024-11-28 11:56:11,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:56:11,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2024-11-28 11:56:11,468[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:56:11,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:56:21,945[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:56:21,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:56:21,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:56:21,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:56:21,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:56:21,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:56:21,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:56:21,958[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:56:21,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:56:21,990[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:56:21,998[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:56:21,999[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 20.81it/s v_num: 0.000     
                                                               rmse/val: 156.973
                                                               rmse/train:      
                                                               131.498          
[[36m2024-11-28 11:57:07,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:57:07,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/018[0m
[[36m2024-11-28 11:57:07,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:57:07,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002394274963123934, lr[0m
[[36m2024-11-28 11:57:07,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:57:07,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021212404309244242 prior_scale[0m
[[36m2024-11-28 11:57:07,911[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002166044462820909 q_scale[0m
[[36m2024-11-28 11:57:07,929[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4892292458746359 obs_scale[0m
[[36m2024-11-28 11:57:07,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:57:07,944[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2024-11-28 11:57:07,944[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:57:07,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:57:18,384[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:57:18,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:57:18,392[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:57:18,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:57:18,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:57:18,396[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:57:18,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:57:18,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:57:18,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:57:18,427[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:57:18,441[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:57:18,443[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 30.72it/s v_num: 0.000     
                                                               rmse/val: 355.513
                                                               rmse/train:      
                                                               303.453          
[[36m2024-11-28 11:58:20,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:58:20,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/019[0m
[[36m2024-11-28 11:58:20,786[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:58:20,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005771310637416294, lr[0m
[[36m2024-11-28 11:58:20,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:58:20,853[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.053560889517850846 prior_scale[0m
[[36m2024-11-28 11:58:20,876[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019153693324404375 q_scale[0m
[[36m2024-11-28 11:58:20,903[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2713997870038662 obs_scale[0m
[[36m2024-11-28 11:58:20,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-11-28 11:58:20,922[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2024-11-28 11:58:20,922[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:58:20,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:58:31,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:58:31,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:58:31,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:58:31,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:58:31,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:58:31,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:58:31,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:58:31,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:58:31,290[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:58:31,319[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:58:31,327[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:58:31,328[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 3771.843
                                                              rmse/train:       
                                                              3702.978          
[[36m2024-11-28 11:58:41,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:58:41,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/020[0m
[[36m2024-11-28 11:58:41,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:58:41,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005316051835794628, lr[0m
[[36m2024-11-28 11:58:41,243[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:58:41,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03221910949549649 prior_scale[0m
[[36m2024-11-28 11:58:41,295[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006534789285293199 q_scale[0m
[[36m2024-11-28 11:58:41,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.775610308294421 obs_scale[0m
[[36m2024-11-28 11:58:41,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:58:41,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2024-11-28 11:58:41,340[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:58:41,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:58:52,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:58:52,017[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:58:52,018[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:58:52,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:58:52,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:58:52,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:58:52,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:58:52,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:58:52,023[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:58:52,036[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:58:52,069[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:58:52,071[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 28.20it/s v_num: 0.000     
                                                               rmse/val: 409.622
                                                               rmse/train:      
                                                               357.002          
[[36m2024-11-28 11:59:39,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 11:59:39,121[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/021[0m
[[36m2024-11-28 11:59:39,246[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 11:59:39,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009809488183100134, lr[0m
[[36m2024-11-28 11:59:39,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 11:59:39,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02068933646999042 prior_scale[0m
[[36m2024-11-28 11:59:39,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020054242226411918 q_scale[0m
[[36m2024-11-28 11:59:39,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8894172267357463 obs_scale[0m
[[36m2024-11-28 11:59:39,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 11:59:39,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2024-11-28 11:59:39,369[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 11:59:39,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 11:59:49,433[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 11:59:49,445[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 11:59:49,446[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 11:59:49,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 11:59:49,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 11:59:49,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 11:59:49,453[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 11:59:49,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 11:59:49,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 11:59:49,499[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 11:59:49,512[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 11:59:49,514[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 31.27it/s v_num: 0.000     
                                                               rmse/val: 126.756
                                                               rmse/train:      
                                                               105.328          
[[36m2024-11-28 12:00:30,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:00:30,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/022[0m
[[36m2024-11-28 12:00:30,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:00:30,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005186379518449633, lr[0m
[[36m2024-11-28 12:00:30,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:00:30,611[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0465657596151099 prior_scale[0m
[[36m2024-11-28 12:00:30,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005683052700954933 q_scale[0m
[[36m2024-11-28 12:00:30,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.508789485500504 obs_scale[0m
[[36m2024-11-28 12:00:30,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:00:30,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2024-11-28 12:00:30,683[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:00:30,683[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:00:40,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:00:40,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:00:40,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:00:40,742[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:00:40,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:00:40,743[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:00:40,744[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:00:40,744[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:00:40,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:00:40,787[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:00:40,908[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:00:40,911[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 16.41it/s v_num: 0.000     
                                                               rmse/val: 169.123
                                                               rmse/train:      
                                                               150.052          
[[36m2024-11-28 12:01:28,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:01:28,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/023[0m
[[36m2024-11-28 12:01:28,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:01:28,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010446980030933377, lr[0m
[[36m2024-11-28 12:01:28,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:01:28,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05016661008807101 prior_scale[0m
[[36m2024-11-28 12:01:28,561[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005478728034067496 q_scale[0m
[[36m2024-11-28 12:01:28,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5098948243064317 obs_scale[0m
[[36m2024-11-28 12:01:28,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:01:28,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2024-11-28 12:01:28,599[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:01:28,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:01:38,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:01:38,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:01:38,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:01:38,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:01:38,550[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:01:38,551[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:01:38,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:01:38,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:01:38,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:01:38,584[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:01:38,613[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:01:38,615[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 31.68it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2691.925         
                                                               rmse/train:      
                                                               2676.108         
[[36m2024-11-28 12:02:21,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:02:21,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/024[0m
[[36m2024-11-28 12:02:21,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:02:21,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003581410704893196, lr[0m
[[36m2024-11-28 12:02:21,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:02:21,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02350539399843206 prior_scale[0m
[[36m2024-11-28 12:02:21,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017493704914882372 q_scale[0m
[[36m2024-11-28 12:02:21,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32642076699209516 obs_scale[0m
[[36m2024-11-28 12:02:21,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-11-28 12:02:21,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2024-11-28 12:02:21,350[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:02:21,350[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:02:31,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:02:31,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:02:31,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:02:31,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:02:31,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:02:31,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:02:31,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:02:31,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:02:31,694[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:02:31,734[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:02:31,747[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:02:31,748[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 23.17it/s v_num: 0.000      
                                                              rmse/val: 2048.327
                                                              rmse/train:       
                                                              1933.120          
[[36m2024-11-28 12:02:48,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:02:48,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/025[0m
[[36m2024-11-28 12:02:48,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 12:02:48,273[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002028755161900531, lr[0m
[[36m2024-11-28 12:02:48,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:02:48,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.042120232003093484 prior_scale[0m
[[36m2024-11-28 12:02:48,334[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008415488027439788 q_scale[0m
[[36m2024-11-28 12:02:48,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5764408563064137 obs_scale[0m
[[36m2024-11-28 12:02:48,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:02:48,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2024-11-28 12:02:48,373[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:02:48,373[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:02:58,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:02:58,248[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:02:58,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:02:58,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:02:58,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:02:58,252[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:02:58,252[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:02:58,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:02:58,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:02:58,269[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:02:58,308[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 15.48it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3645.151         
                                                               rmse/train:      
                                                               3641.969         
[[36m2024-11-28 12:03:57,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:03:57,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/026[0m
[[36m2024-11-28 12:03:57,898[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:03:57,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006159824445838035, lr[0m
[[36m2024-11-28 12:03:57,943[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:03:57,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06837205937871046 prior_scale[0m
[[36m2024-11-28 12:03:57,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00038928668713390444 q_scale[0m
[[36m2024-11-28 12:03:58,021[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39094099448092023 obs_scale[0m
[[36m2024-11-28 12:03:58,042[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:03:58,043[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2024-11-28 12:03:58,043[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:03:58,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:04:08,204[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:04:08,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:04:08,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:04:08,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:04:08,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:04:08,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:04:08,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:04:08,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:04:08,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:04:08,263[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:04:08,278[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:04:08,280[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 29.14it/s v_num: 0.000     
                                                               rmse/val: 233.132
                                                               rmse/train:      
                                                               184.454          
[[36m2024-11-28 12:04:53,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:04:53,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/027[0m
[[36m2024-11-28 12:04:53,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:04:53,290[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006930118187478702, lr[0m
[[36m2024-11-28 12:04:53,307[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:04:53,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07092781471546794 prior_scale[0m
[[36m2024-11-28 12:04:53,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042444254284321176 q_scale[0m
[[36m2024-11-28 12:04:53,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3709659674924489 obs_scale[0m
[[36m2024-11-28 12:04:53,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:04:53,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2024-11-28 12:04:53,397[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:04:53,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:05:03,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:05:03,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:05:03,495[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:05:03,496[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:05:03,498[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:05:03,498[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:05:03,499[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:05:03,499[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:05:03,500[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:05:03,543[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:05:03,556[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:05:03,558[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 28.32it/s v_num: 0.000     
                                                               rmse/val: 211.044
                                                               rmse/train:      
                                                               215.243          
[[36m2024-11-28 12:05:48,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:05:48,891[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/028[0m
[[36m2024-11-28 12:05:49,029[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:05:49,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.792661385133158e-05, lr[0m
[[36m2024-11-28 12:05:49,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:05:49,079[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1404660040736785 prior_scale[0m
[[36m2024-11-28 12:05:49,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032198251957808217 q_scale[0m
[[36m2024-11-28 12:05:49,125[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2577649602311049 obs_scale[0m
[[36m2024-11-28 12:05:49,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:05:49,145[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2024-11-28 12:05:49,145[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:05:49,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:05:59,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:05:59,379[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:05:59,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:05:59,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:05:59,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:05:59,383[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:05:59,383[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:05:59,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:05:59,385[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:05:59,426[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:05:59,440[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:05:59,441[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 28.64it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3662.158         
                                                               rmse/train:      
                                                               3740.872         
[[36m2024-11-28 12:06:45,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:06:45,657[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/029[0m
[[36m2024-11-28 12:06:45,807[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:06:45,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007374455166076234, lr[0m
[[36m2024-11-28 12:06:45,852[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:06:45,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07570808236407968 prior_scale[0m
[[36m2024-11-28 12:06:45,906[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004810927895398964 q_scale[0m
[[36m2024-11-28 12:06:45,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.37410602949316707 obs_scale[0m
[[36m2024-11-28 12:06:45,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 12:06:45,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2024-11-28 12:06:45,950[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:06:45,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:06:56,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:06:56,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:06:56,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:06:56,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:06:56,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:06:56,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:06:56,282[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:06:56,282[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:06:56,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:06:56,328[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:06:56,398[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:06:56,400[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 12.47it/s v_num: 0.000      
                                                              rmse/val: 1458.266
                                                              rmse/train:       
                                                              1326.529          
[[36m2024-11-28 12:07:23,700[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:07:23,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/030[0m
[[36m2024-11-28 12:07:23,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:07:24,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006283261966460361, lr[0m
[[36m2024-11-28 12:07:24,080[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:07:24,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06764077505680173 prior_scale[0m
[[36m2024-11-28 12:07:24,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003292323879620187 q_scale[0m
[[36m2024-11-28 12:07:24,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4347763468140665 obs_scale[0m
[[36m2024-11-28 12:07:24,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:07:24,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2024-11-28 12:07:24,181[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:07:24,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:07:34,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:07:37,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:07:37,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:07:42,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:07:42,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:07:42,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:07:42,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:07:42,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:07:42,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:07:42,172[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:07:42,185[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:07:42,188[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 29.02it/s v_num: 0.000     
                                                               rmse/val: 218.710
                                                               rmse/train:      
                                                               205.166          
[[36m2024-11-28 12:08:51,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:08:51,538[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/031[0m
[[36m2024-11-28 12:08:52,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:08:52,231[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003102068520966301, lr[0m
[[36m2024-11-28 12:08:52,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:08:52,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06514237781081299 prior_scale[0m
[[36m2024-11-28 12:08:52,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007985508727179825 q_scale[0m
[[36m2024-11-28 12:08:52,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5382772515616056 obs_scale[0m
[[36m2024-11-28 12:08:52,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:08:52,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2024-11-28 12:08:52,511[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:08:52,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:09:02,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:09:02,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:09:02,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:09:02,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:09:02,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:09:02,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:09:02,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:09:02,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:09:02,415[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:09:02,465[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:09:02,509[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:09:02,510[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 30.64it/s v_num: 0.000     
                                                               rmse/val: 833.251
                                                               rmse/train:      
                                                               738.054          
[[36m2024-11-28 12:09:45,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:09:45,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/032[0m
[[36m2024-11-28 12:09:45,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:09:45,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014007324425437467, lr[0m
[[36m2024-11-28 12:09:45,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:09:45,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09774303384593354 prior_scale[0m
[[36m2024-11-28 12:09:45,892[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004048785710082788 q_scale[0m
[[36m2024-11-28 12:09:45,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31016511105578987 obs_scale[0m
[[36m2024-11-28 12:09:45,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:09:45,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2024-11-28 12:09:45,937[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:09:45,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:09:55,858[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:09:55,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:09:55,868[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:09:55,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:09:55,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:09:55,875[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:09:55,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:09:55,876[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:09:55,877[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:09:55,931[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:09:55,958[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:09:55,960[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 31.98it/s v_num: 0.000     
                                                               rmse/val: 285.996
                                                               rmse/train:      
                                                               242.411          
[[36m2024-11-28 12:10:38,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:10:38,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/033[0m
[[36m2024-11-28 12:10:38,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 12:10:38,209[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007085735397886653, lr[0m
[[36m2024-11-28 12:10:38,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:10:38,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04225844145738929 prior_scale[0m
[[36m2024-11-28 12:10:38,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011124763887668482 q_scale[0m
[[36m2024-11-28 12:10:38,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22737859112894407 obs_scale[0m
[[36m2024-11-28 12:10:38,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2024-11-28 12:10:38,302[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2024-11-28 12:10:38,302[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:10:38,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:10:48,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:10:49,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:10:49,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:10:50,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:10:50,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:10:50,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:10:50,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:10:50,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:10:50,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:10:53,445[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:10:53,464[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4053.193
                                                              rmse/train:       
                                                              4076.895          
[[36m2024-11-28 12:11:09,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:11:09,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/034[0m
[[36m2024-11-28 12:11:09,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:11:09,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.1181106311475416e-05, lr[0m
[[36m2024-11-28 12:11:09,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:11:09,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05939341571592686 prior_scale[0m
[[36m2024-11-28 12:11:09,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014643302226281842 q_scale[0m
[[36m2024-11-28 12:11:09,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.42951271742604996 obs_scale[0m
[[36m2024-11-28 12:11:10,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 12:11:10,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2024-11-28 12:11:10,012[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:11:10,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:11:20,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:11:20,680[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:11:20,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:11:20,685[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:11:20,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:11:20,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:11:20,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:11:20,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:11:20,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:11:20,703[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:11:20,724[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:11:20,726[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 10.90it/s v_num: 0.000      
                                                              rmse/val: 5176.629
                                                              rmse/train:       
                                                              5236.810          
[[36m2024-11-28 12:11:34,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:11:34,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/035[0m
[[36m2024-11-28 12:11:35,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:11:35,129[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009909763784500848, lr[0m
[[36m2024-11-28 12:11:35,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:11:35,171[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08651284191763688 prior_scale[0m
[[36m2024-11-28 12:11:35,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003308751116066208 q_scale[0m
[[36m2024-11-28 12:11:35,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.380485683893914 obs_scale[0m
[[36m2024-11-28 12:11:35,237[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:11:35,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2024-11-28 12:11:35,238[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:11:35,239[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:11:45,355[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:11:45,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:11:45,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:11:45,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:11:45,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:11:45,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:11:45,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:11:45,377[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:11:45,379[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:11:45,412[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:11:46,542[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:11:46,543[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 26.15it/s v_num: 0.000      
                                                              rmse/val: 330.813 
                                                              rmse/train:       
                                                              304.352           
[[36m2024-11-28 12:12:12,364[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:12:12,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/036[0m
[[36m2024-11-28 12:12:12,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 12:12:12,528[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009672308982173323, lr[0m
[[36m2024-11-28 12:12:12,546[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:12:12,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1444502941463376 prior_scale[0m
[[36m2024-11-28 12:12:12,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033200531152018765 q_scale[0m
[[36m2024-11-28 12:12:12,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4453828736259495 obs_scale[0m
[[36m2024-11-28 12:12:12,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:12:12,623[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2024-11-28 12:12:12,624[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:12:12,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:12:22,803[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:12:22,814[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:12:22,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:12:22,818[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:12:22,820[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:12:22,821[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:12:22,823[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:12:22,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:12:22,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:12:22,875[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:12:23,614[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 26.23it/s v_num: 0.000      
                                                              rmse/val: 981.045 
                                                              rmse/train:       
                                                              849.038           
[[36m2024-11-28 12:12:50,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:12:50,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/037[0m
[[36m2024-11-28 12:12:50,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:12:50,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008033269868617764, lr[0m
[[36m2024-11-28 12:12:50,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:12:50,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09343204750851945 prior_scale[0m
[[36m2024-11-28 12:12:50,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015472770202428195 q_scale[0m
[[36m2024-11-28 12:12:50,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19076564781086774 obs_scale[0m
[[36m2024-11-28 12:12:50,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:12:50,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2024-11-28 12:12:50,398[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:12:50,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:13:00,787[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:13:00,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:13:00,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:13:00,798[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:13:00,798[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:13:00,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:13:00,800[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:13:00,800[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:13:00,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:13:00,828[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:13:00,838[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:13:00,840[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.92it/s v_num: 0.000      
                                                              rmse/val: 490.760 
                                                              rmse/train:       
                                                              431.690           
[[36m2024-11-28 12:13:34,862[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:13:34,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/038[0m
[[36m2024-11-28 12:13:34,989[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 12:13:35,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004852557184945005, lr[0m
[[36m2024-11-28 12:13:35,023[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:13:35,040[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12078763427741847 prior_scale[0m
[[36m2024-11-28 12:13:35,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006638999239178971 q_scale[0m
[[36m2024-11-28 12:13:35,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.271077181030334 obs_scale[0m
[[36m2024-11-28 12:13:35,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:13:35,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2024-11-28 12:13:35,092[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:13:35,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:13:44,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:13:44,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:13:44,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:13:44,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:13:44,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:13:44,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:13:44,733[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:13:44,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:13:44,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:13:44,769[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:13:44,778[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 22.80it/s v_num: 0.000      
                                                              rmse/val: 3015.198
                                                              rmse/train:       
                                                              3025.342          
[[36m2024-11-28 12:14:38,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:14:38,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/039[0m
[[36m2024-11-28 12:14:38,732[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:14:38,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008446572198434881, lr[0m
[[36m2024-11-28 12:14:38,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:14:38,789[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1670084059403248 prior_scale[0m
[[36m2024-11-28 12:14:38,807[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024311007725835504 q_scale[0m
[[36m2024-11-28 12:14:38,833[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6163552082840623 obs_scale[0m
[[36m2024-11-28 12:14:38,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:14:38,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2024-11-28 12:14:38,849[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:14:38,849[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:14:48,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:14:48,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:14:48,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:14:48,642[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:14:48,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:14:48,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:14:48,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:14:48,675[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:14:48,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:14:48,909[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:14:48,918[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:14:48,920[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.58it/s v_num: 0.000      
                                                              rmse/val: 422.741 
                                                              rmse/train:       
                                                              410.316           
[[36m2024-11-28 12:15:40,701[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:15:40,702[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/040[0m
[[36m2024-11-28 12:15:40,836[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:15:40,853[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000608670889742926, lr[0m
[[36m2024-11-28 12:15:40,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:15:40,893[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2534754177958895 prior_scale[0m
[[36m2024-11-28 12:15:40,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00028381696975508845 q_scale[0m
[[36m2024-11-28 12:15:40,934[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1210446779774796 obs_scale[0m
[[36m2024-11-28 12:15:40,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2024-11-28 12:15:40,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2024-11-28 12:15:40,948[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:15:40,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:15:52,097[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:15:52,106[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:15:52,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:15:52,108[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:15:52,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:15:52,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:15:52,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:15:52,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:15:52,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:15:52,155[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:15:52,218[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:15:52,219[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 20.54it/s v_num: 0.000      
                                                              rmse/val: 839.884 
                                                              rmse/train:       
                                                              741.457           
[[36m2024-11-28 12:16:09,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:16:09,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/041[0m
[[36m2024-11-28 12:16:09,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:16:09,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3626307793529599e-05, lr[0m
[[36m2024-11-28 12:16:09,292[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:16:09,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08788888184736375 prior_scale[0m
[[36m2024-11-28 12:16:09,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004988869219729473 q_scale[0m
[[36m2024-11-28 12:16:09,363[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3549034067887779 obs_scale[0m
[[36m2024-11-28 12:16:09,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:16:09,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2024-11-28 12:16:09,382[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:16:09,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:16:19,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:16:19,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:16:19,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:16:19,755[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:16:19,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:16:19,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:16:19,758[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:16:19,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:16:19,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:16:19,773[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:16:19,788[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:16:19,790[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 21.52it/s v_num: 0.000      
                                                              rmse/val: 4221.320
                                                              rmse/train:       
                                                              3932.133          
[[36m2024-11-28 12:16:50,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:16:50,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/042[0m
[[36m2024-11-28 12:16:50,207[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:16:50,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032861891225426, lr[0m
[[36m2024-11-28 12:16:50,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:16:50,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07666832790534799 prior_scale[0m
[[36m2024-11-28 12:16:50,280[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014620774387750704 q_scale[0m
[[36m2024-11-28 12:16:50,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4965130307771064 obs_scale[0m
[[36m2024-11-28 12:16:50,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:16:50,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2024-11-28 12:16:50,319[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:16:50,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:17:00,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:17:00,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:17:00,715[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:17:00,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:17:00,718[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:17:00,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:17:00,719[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:17:00,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:17:00,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:17:00,777[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:17:00,792[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:17:00,794[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 25.74it/s v_num: 0.000     
                                                               rmse/val: 932.553
                                                               rmse/train:      
                                                               821.408          
[[36m2024-11-28 12:17:54,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:17:54,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/043[0m
[[36m2024-11-28 12:17:54,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:17:54,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004441273334092611, lr[0m
[[36m2024-11-28 12:17:54,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:17:54,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04858590793967003 prior_scale[0m
[[36m2024-11-28 12:17:54,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035074180594015165 q_scale[0m
[[36m2024-11-28 12:17:54,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4490793723261879 obs_scale[0m
[[36m2024-11-28 12:17:54,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2024-11-28 12:17:54,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2024-11-28 12:17:54,856[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:17:54,857[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:18:05,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:18:05,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:18:05,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:18:05,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:18:05,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:18:05,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:18:05,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:18:05,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:18:05,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:18:05,637[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:18:05,652[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:18:05,653[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 21.67it/s v_num: 0.000      
                                                              rmse/val: 3118.673
                                                              rmse/train:       
                                                              3110.487          
[[36m2024-11-28 12:18:15,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:18:15,233[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/044[0m
[[36m2024-11-28 12:18:15,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:18:15,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009731621477063434, lr[0m
[[36m2024-11-28 12:18:15,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:18:15,439[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11314053370703914 prior_scale[0m
[[36m2024-11-28 12:18:15,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026256928685157666 q_scale[0m
[[36m2024-11-28 12:18:15,477[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9731611260603764 obs_scale[0m
[[36m2024-11-28 12:18:15,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2024-11-28 12:18:15,494[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2024-11-28 12:18:15,494[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:18:15,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:18:25,869[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:18:25,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:18:25,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:18:25,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:18:25,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:18:25,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:18:25,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:18:25,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:18:25,886[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:18:25,902[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:18:25,919[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:18:25,921[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 24.84it/s v_num: 0.000     
                                                               rmse/val: 142.542
                                                               rmse/train:      
                                                               113.135          
[[36m2024-11-28 12:19:14,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:19:14,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/045[0m
[[36m2024-11-28 12:19:14,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:19:14,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009976727752850699, lr[0m
[[36m2024-11-28 12:19:14,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:19:14,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1084832650001573 prior_scale[0m
[[36m2024-11-28 12:19:14,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009917072934430256 q_scale[0m
[[36m2024-11-28 12:19:14,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3923505894914396 obs_scale[0m
[[36m2024-11-28 12:19:14,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:19:14,435[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2024-11-28 12:19:14,436[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:19:14,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:19:24,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:19:40,578[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:19:40,579[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:19:40,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:19:40,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:19:40,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:19:40,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:19:40,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:19:40,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:19:40,653[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:19:40,668[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:19:40,671[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 19.47it/s v_num: 0.000      
                                                              rmse/val: 306.345 
                                                              rmse/train:       
                                                              264.116           
[[36m2024-11-28 12:20:08,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:20:08,377[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/046[0m
[[36m2024-11-28 12:20:08,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:20:08,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009454380081024538, lr[0m
[[36m2024-11-28 12:20:08,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:20:08,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11134827017201387 prior_scale[0m
[[36m2024-11-28 12:20:08,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008511764019394158 q_scale[0m
[[36m2024-11-28 12:20:08,650[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4996348595559448 obs_scale[0m
[[36m2024-11-28 12:20:08,671[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:20:08,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2024-11-28 12:20:08,672[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:20:08,672[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:20:19,876[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:20:19,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:20:19,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:20:19,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:20:19,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:20:19,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:20:19,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:20:19,890[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:20:19,891[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:20:19,908[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:20:19,922[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:20:19,923[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 29.17it/s v_num: 0.000      
                                                              rmse/val: 187.459 
                                                              rmse/train:       
                                                              181.691           
[[36m2024-11-28 12:20:44,248[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:20:44,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/047[0m
[[36m2024-11-28 12:20:44,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2024-11-28 12:20:44,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009345695213062321, lr[0m
[[36m2024-11-28 12:20:44,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2024-11-28 12:20:44,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13563992309636252 prior_scale[0m
[[36m2024-11-28 12:20:44,484[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009004435545265699 q_scale[0m
[[36m2024-11-28 12:20:44,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.4403615508005898 obs_scale[0m
[[36m2024-11-28 12:20:44,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:20:44,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2024-11-28 12:20:44,522[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:20:44,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:20:55,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:20:55,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:20:55,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:20:55,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:20:55,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:20:55,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:20:55,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:20:55,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:20:55,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:20:55,621[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:20:55,780[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 20.77it/s v_num: 0.000      
                                                              rmse/val: 1054.926
                                                              rmse/train:       
                                                              909.730           
[[36m2024-11-28 12:21:57,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:21:57,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/048[0m
[[36m2024-11-28 12:22:06,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:22:07,493[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008069571355559042, lr[0m
[[36m2024-11-28 12:22:08,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:22:08,401[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23691084212188213 prior_scale[0m
[[36m2024-11-28 12:22:08,689[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006650649101091561 q_scale[0m
[[36m2024-11-28 12:22:09,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5644749661445803 obs_scale[0m
[[36m2024-11-28 12:22:10,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:22:10,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2024-11-28 12:22:10,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:22:10,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:22:22,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:22:22,074[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:22:22,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:22:22,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:22:22,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:22:22,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:22:22,080[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:22:22,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:22:22,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:22:22,119[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:22:22,132[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:22:22,134[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.20it/s v_num: 0.000      
                                                              rmse/val: 156.120 
                                                              rmse/train:       
                                                              127.165           
[[36m2024-11-28 12:22:58,748[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:22:58,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/049[0m
[[36m2024-11-28 12:22:58,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:22:58,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008032836460696829, lr[0m
[[36m2024-11-28 12:22:58,904[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:22:58,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2732494723314175 prior_scale[0m
[[36m2024-11-28 12:22:58,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0071296629725030244 q_scale[0m
[[36m2024-11-28 12:22:58,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.5778628053262806 obs_scale[0m
[[36m2024-11-28 12:22:58,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:22:58,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2024-11-28 12:22:58,983[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:22:58,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:23:08,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:23:08,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:23:08,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:23:08,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:23:08,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:23:08,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:23:08,669[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:23:08,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:23:08,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:23:08,685[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:23:08,696[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:23:08,698[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.72it/s v_num: 0.000      
                                                              rmse/val: 330.798 
                                                              rmse/train:       
                                                              292.734           
[[36m2024-11-28 12:23:42,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:23:42,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/050[0m
[[36m2024-11-28 12:23:42,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:23:42,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007879425455883685, lr[0m
[[36m2024-11-28 12:23:42,810[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:23:42,837[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3100644330393728 prior_scale[0m
[[36m2024-11-28 12:23:42,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0068747614272944724 q_scale[0m
[[36m2024-11-28 12:23:42,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.6715635334860768 obs_scale[0m
[[36m2024-11-28 12:23:42,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:23:42,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2024-11-28 12:23:42,911[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:23:42,911[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:23:52,993[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:23:53,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:23:53,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:23:53,004[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:23:53,005[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:23:53,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:23:53,008[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:23:53,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:23:53,010[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:23:53,058[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:23:53,073[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:23:53,075[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 10.74it/s v_num: 0.000      
                                                              rmse/val: 356.940 
                                                              rmse/train:       
                                                              347.892           
[[36m2024-11-28 12:24:29,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:24:29,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/051[0m
[[36m2024-11-28 12:24:30,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:24:30,194[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008055602067447861, lr[0m
[[36m2024-11-28 12:24:30,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:24:30,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3275122693316006 prior_scale[0m
[[36m2024-11-28 12:24:30,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006816749111938072 q_scale[0m
[[36m2024-11-28 12:24:30,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.6813792701841797 obs_scale[0m
[[36m2024-11-28 12:24:30,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:24:30,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2024-11-28 12:24:30,301[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:24:30,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:24:42,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:24:42,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:24:42,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:24:42,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:24:42,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:24:42,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:24:42,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:24:42,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:24:42,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:24:42,080[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:24:42,155[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:24:42,157[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.26it/s v_num: 0.000      
                                                              rmse/val: 277.369 
                                                              rmse/train:       
                                                              251.166           
[[36m2024-11-28 12:25:18,913[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:25:18,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/052[0m
[[36m2024-11-28 12:25:19,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:25:19,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000803411916757, lr[0m
[[36m2024-11-28 12:25:19,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:25:19,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31443063728378634 prior_scale[0m
[[36m2024-11-28 12:25:19,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005085846881553687 q_scale[0m
[[36m2024-11-28 12:25:19,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.714302904129819 obs_scale[0m
[[36m2024-11-28 12:25:19,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:25:19,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2024-11-28 12:25:19,204[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:25:19,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:25:28,959[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:25:28,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:25:28,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:25:28,979[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:25:28,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:25:28,981[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:25:28,982[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:25:28,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:25:28,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:25:29,037[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:25:29,057[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:25:29,060[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.47it/s v_num: 0.000      
                                                              rmse/val: 366.312 
                                                              rmse/train:       
                                                              332.199           
[[36m2024-11-28 12:26:00,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:26:00,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/053[0m
[[36m2024-11-28 12:26:00,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:26:00,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006765995937538625, lr[0m
[[36m2024-11-28 12:26:00,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:26:00,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.38684103204817577 prior_scale[0m
[[36m2024-11-28 12:26:00,840[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0071531115279282135 q_scale[0m
[[36m2024-11-28 12:26:00,865[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.1710358355000061 obs_scale[0m
[[36m2024-11-28 12:26:00,883[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:26:00,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2024-11-28 12:26:00,885[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:26:00,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:26:10,871[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:26:10,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:26:10,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:26:10,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:26:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:26:10,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:26:10,883[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:26:10,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:26:10,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:26:10,897[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:26:10,911[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:26:10,912[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.59it/s v_num: 0.000      
                                                              rmse/val: 620.651 
                                                              rmse/train:       
                                                              550.230           
[[36m2024-11-28 12:26:46,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:26:46,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/054[0m
[[36m2024-11-28 12:26:46,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:26:46,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041396287254659805, lr[0m
[[36m2024-11-28 12:26:46,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:26:46,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20145712947057395 prior_scale[0m
[[36m2024-11-28 12:26:46,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0029483222164495486 q_scale[0m
[[36m2024-11-28 12:26:46,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0183768641370026 obs_scale[0m
[[36m2024-11-28 12:26:46,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:26:46,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2024-11-28 12:26:46,587[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:26:46,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:26:57,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:26:57,452[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:26:57,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:26:57,458[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:26:57,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:26:57,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:26:57,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:26:57,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:26:57,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:26:57,503[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:26:57,978[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:26:57,980[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.15it/s v_num: 0.000      
                                                              rmse/val: 608.120 
                                                              rmse/train:       
                                                              590.449           
[[36m2024-11-28 12:27:32,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:27:32,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/055[0m
[[36m2024-11-28 12:27:32,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:27:32,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009980132050516814, lr[0m
[[36m2024-11-28 12:27:32,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:27:32,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4620817968593115 prior_scale[0m
[[36m2024-11-28 12:27:32,887[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005791562556897836 q_scale[0m
[[36m2024-11-28 12:27:32,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.6263904383462326 obs_scale[0m
[[36m2024-11-28 12:27:32,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:27:32,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2024-11-28 12:27:32,928[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:27:32,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:27:42,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:27:42,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:27:42,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:27:42,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:27:42,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:27:42,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:27:42,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:27:42,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:27:42,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:27:42,968[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:27:42,978[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:27:42,979[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 17.62it/s v_num: 0.000      
                                                              rmse/val: 279.879 
                                                              rmse/train:       
                                                              234.682           
[[36m2024-11-28 12:28:12,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:28:12,056[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/056[0m
[[36m2024-11-28 12:28:12,201[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:28:12,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009273348961245869, lr[0m
[[36m2024-11-28 12:28:12,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:28:12,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4284797272616394 prior_scale[0m
[[36m2024-11-28 12:28:12,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009973412095057343 q_scale[0m
[[36m2024-11-28 12:28:12,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.2881824014817747 obs_scale[0m
[[36m2024-11-28 12:28:12,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:28:12,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2024-11-28 12:28:12,333[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:28:12,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:28:22,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:28:22,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:28:22,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:28:22,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:28:22,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:28:22,299[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:28:22,300[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:28:22,300[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:28:22,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:28:22,332[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:28:22,375[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:28:22,376[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.94it/s v_num: 0.000      
                                                              rmse/val: 298.243 
                                                              rmse/train:       
                                                              276.463           
[[36m2024-11-28 12:28:53,363[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:28:53,365[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/057[0m
[[36m2024-11-28 12:28:53,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:28:53,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005718132867132097, lr[0m
[[36m2024-11-28 12:28:53,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:28:53,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2312391376011191 prior_scale[0m
[[36m2024-11-28 12:28:53,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003839330514382399 q_scale[0m
[[36m2024-11-28 12:28:53,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.9970064471371654 obs_scale[0m
[[36m2024-11-28 12:28:53,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:28:53,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2024-11-28 12:28:53,713[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:28:53,713[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:29:03,418[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:29:03,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:29:03,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:29:03,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:29:03,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:29:03,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:29:03,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:29:03,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:29:03,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:29:03,451[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:29:03,465[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:29:03,466[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.88it/s v_num: 0.000      
                                                              rmse/val: 582.449 
                                                              rmse/train:       
                                                              462.198           
[[36m2024-11-28 12:29:37,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:29:37,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/058[0m
[[36m2024-11-28 12:29:37,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5 pretrain_epochs[0m
[[36m2024-11-28 12:29:37,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002569172154127667, lr[0m
[[36m2024-11-28 12:29:37,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2024-11-28 12:29:37,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.35439741392597046 prior_scale[0m
[[36m2024-11-28 12:29:37,316[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005681897410668955 q_scale[0m
[[36m2024-11-28 12:29:37,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9403475965675654 obs_scale[0m
[[36m2024-11-28 12:29:37,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2024-11-28 12:29:37,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2024-11-28 12:29:37,366[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2024-11-28 12:29:37,367[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
[[36m2024-11-28 12:29:47,623[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2024-11-28 12:29:47,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2024-11-28 12:29:47,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2024-11-28 12:29:47,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-28 12:29:47,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-28 12:29:47,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2024-11-28 12:29:47,634[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2024-11-28 12:29:47,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2024-11-28 12:29:47,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2024-11-28 12:29:47,670[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2024-11-28 12:29:47,696[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
[[36m2024-11-28 12:29:47,698[0m][[34mtrain[0m][[32mINFO[0m] - No pretrained net found in /home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/pretrained for 5[0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                          ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                           │ NetAtom    │  2.6 K │
│ 1  │ net.linear                    │ Identity   │      0 │
│ 2  │ net.tanh                      │ Tanh       │      0 │
│ 3  │ net.sigmoid                   │ Sigmoid    │      0 │
│ 4  │ net.functions                 │ ModuleList │  2.6 K │
│ 5  │ net.functions.0               │ Sequential │  1.3 K │
│ 6  │ net.functions.0.Linear_Sp1_F1 │ Linear     │  1.1 K │
│ 7  │ net.functions.0.Linear_Sp1_F2 │ Linear     │    240 │
│ 8  │ net.functions.0.Linear_Sp1_F3 │ Linear     │     16 │
│ 9  │ net.functions.1               │ Sequential │  1.3 K │
│ 10 │ net.functions.1.Linear_Sp2_F1 │ Linear     │  1.1 K │
│ 11 │ net.functions.1.Linear_Sp2_F2 │ Linear     │    240 │
│ 12 │ net.functions.1.Linear_Sp2_F3 │ Linear     │     16 │
└────┴───────────────────────────────┴────────────┴────────┘
Trainable params: 2.6 K                                                         
Non-trainable params: 0                                                         
Total params: 2.6 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.62it/s v_num: 0.000      
                                                              rmse/val: 1760.505
                                                              rmse/train:       
                                                              1642.322          
[[36m2024-11-28 12:30:17,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2024-11-28 12:30:17,969[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2024-11-28_11-43-21/059[0m
[[36m2024-11-28 12:30:18,084[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-01-21 15:10:56,187[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-01-21 15:10:56,189[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_lrt.db[0m
[[36m2025-01-21 15:11:00,041[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-01-21 15:11:00,058[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-01-21 15:11:00,125[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:11:00,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-01-21 15:11:00,175[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:11:00,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21592388039429916 prior_scale[0m
[[36m2025-01-21 15:11:00,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036303760732131728 q_scale[0m
[[36m2025-01-21 15:11:00,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 15:11:00,218[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-01-21 15:11:00,218[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:11:00,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:11:10,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:11:10,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:11:10,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:11:10,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:11:10,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:11:10,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:11:10,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:11:10,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:11:10,207[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:11:10,448[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:11:12,161[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 20.43it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4248.806         
                                                               rmse/train:      
                                                               4340.731         
[[36m2025-01-21 15:11:55,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:11:55,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-10-56/000[0m
[[36m2025-01-21 15:11:55,221[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:11:55,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-01-21 15:11:55,268[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:11:55,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16250224524496343 prior_scale[0m
[[36m2025-01-21 15:11:55,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005501758328845987 q_scale[0m
[[36m2025-01-21 15:11:55,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 15:11:55,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-01-21 15:11:55,313[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:11:55,314[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:12:05,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:12:05,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:12:05,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:12:05,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:12:05,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:12:05,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:12:05,093[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:12:05,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:12:05,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:12:05,125[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:12:05,134[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 13/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.99it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4047.638         
                                                               rmse/train:      
                                                               4143.160         
[[36m2025-01-21 15:12:35,554[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: trials

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py", line 72, in _create_scoped_session
    yield session
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py", line 683, in set_trial_intermediate_value
    self._set_trial_intermediate_value_without_commit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py", line 694, in _set_trial_intermediate_value_without_commit
    trial = models.TrialModel.find_or_raise_by_id(trial_id, session)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/models.py", line 254, in find_or_raise_by_id
    trial = query.one_or_none()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
           ^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1714, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1572, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1943, in _execute_context
    self._handle_dbapi_exception(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2124, in _handle_dbapi_exception
    util.raise_(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: trials
[SQL: SELECT trials.trial_id AS trials_trial_id, trials.number AS trials_number, trials.study_id AS trials_study_id, trials.state AS trials_state, trials.datetime_start AS trials_datetime_start, trials.datetime_complete AS trials_datetime_complete 
FROM trials 
WHERE trials.trial_id = ?]
[parameters: (2,)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 114, in on_validation_end
    self._trial.report(current_score.item(), step=epoch)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/trial/_trial.py", line 500, in report
    self.storage.set_trial_intermediate_value(self._trial_id, step, value)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_cached_storage.py", line 192, in set_trial_intermediate_value
    self._backend.set_trial_intermediate_value(trial_id, step, intermediate_value)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py", line 682, in set_trial_intermediate_value
    with _create_scoped_session(self.scoped_session, True) as session:
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py", line 90, in _create_scoped_session
    raise optuna.exceptions.StorageInternalError(message) from e
optuna.exceptions.StorageInternalError: An exception is raised during the commit. This typically happens due to invalid data in the commit, e.g. exceeding max length. 
[[36m2025-01-21 15:12:35,727[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-01-21 15:13:33,543[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-01-21 15:13:33,544[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_lrt.db[0m
[[36m2025-01-21 15:13:34,249[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-01-21 15:13:34,256[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-01-21 15:13:34,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:13:34,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-01-21 15:13:34,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:13:34,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21592388039429916 prior_scale[0m
[[36m2025-01-21 15:13:34,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036303760732131728 q_scale[0m
[[36m2025-01-21 15:13:34,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 15:13:34,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-01-21 15:13:34,412[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:13:34,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:13:44,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:13:44,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:13:44,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:13:44,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:13:44,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:13:44,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:13:44,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:13:44,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:13:44,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:13:44,546[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:13:44,798[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 20.53it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3850.125         
                                                               rmse/train:      
                                                               3935.737         
[[36m2025-01-21 15:14:18,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:14:18,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/000[0m
[[36m2025-01-21 15:14:19,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:14:19,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-01-21 15:14:19,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:14:19,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16250224524496343 prior_scale[0m
[[36m2025-01-21 15:14:19,096[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005501758328845987 q_scale[0m
[[36m2025-01-21 15:14:19,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 15:14:19,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-01-21 15:14:19,109[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:14:19,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:14:29,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:14:29,163[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:14:29,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:14:29,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:14:29,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:14:29,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:14:29,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:14:29,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:14:29,168[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:14:29,199[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:14:29,208[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.08it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4281.142         
                                                               rmse/train:      
                                                               4370.155         
[[36m2025-01-21 15:15:13,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:15:13,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/001[0m
[[36m2025-01-21 15:15:13,599[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:15:13,633[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-01-21 15:15:13,649[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:15:13,664[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04232733477101895 prior_scale[0m
[[36m2025-01-21 15:15:13,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0073498792462323385 q_scale[0m
[[36m2025-01-21 15:15:13,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:15:13,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-01-21 15:15:13,695[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:15:13,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:15:23,283[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:15:23,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:15:23,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:15:23,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:15:23,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:15:23,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:15:23,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:15:23,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:15:23,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:15:23,324[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:15:23,332[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 24.53it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3580.341         
                                                               rmse/train:      
                                                               3676.073         
[[36m2025-01-21 15:16:16,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:16:16,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/002[0m
[[36m2025-01-21 15:16:16,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:16:16,484[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-01-21 15:16:16,496[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:16:16,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017549127225111354 prior_scale[0m
[[36m2025-01-21 15:16:16,522[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002561662685923485 q_scale[0m
[[36m2025-01-21 15:16:16,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:16:16,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-01-21 15:16:16,537[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:16:16,537[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:16:26,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:16:26,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:16:26,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:16:26,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:16:26,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:16:26,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:16:26,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:16:26,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:16:26,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:16:26,412[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:16:26,421[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 12.50it/s v_num: 0.000     
                                                               rmse/val: 76.841 
                                                               rmse/train:      
                                                               68.644           
[[36m2025-01-21 15:17:58,012[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:17:58,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/003[0m
[[36m2025-01-21 15:17:58,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:17:58,148[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-01-21 15:17:58,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:17:58,179[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14015302623589543 prior_scale[0m
[[36m2025-01-21 15:17:58,194[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001546142648648774 q_scale[0m
[[36m2025-01-21 15:17:58,210[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:17:58,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-01-21 15:17:58,211[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:17:58,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:18:07,784[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:18:07,791[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:18:07,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:18:07,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:18:07,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:18:07,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:18:07,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:18:07,796[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:18:07,797[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:18:07,850[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:18:07,863[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 23.82it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4050.559         
                                                               rmse/train:      
                                                               4138.025         
[[36m2025-01-21 15:19:00,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:19:00,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/004[0m
[[36m2025-01-21 15:19:00,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:19:00,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-01-21 15:19:00,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:19:00,796[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01026814371296241 prior_scale[0m
[[36m2025-01-21 15:19:00,809[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017174472922154307 q_scale[0m
[[36m2025-01-21 15:19:00,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:19:00,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-01-21 15:19:00,824[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:19:00,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:19:10,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:19:10,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:19:10,650[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:19:10,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:19:10,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:19:10,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:19:10,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:19:10,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:19:10,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:19:10,687[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:19:10,742[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 23.94it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4056.334         
                                                               rmse/train:      
                                                               4143.882         
[[36m2025-01-21 15:20:04,359[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:20:04,361[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/005[0m
[[36m2025-01-21 15:20:04,476[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:20:04,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-01-21 15:20:04,521[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:20:04,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021500386108909676 prior_scale[0m
[[36m2025-01-21 15:20:04,550[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005816140699158816 q_scale[0m
[[36m2025-01-21 15:20:04,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:20:04,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-01-21 15:20:04,564[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:20:04,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:20:14,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:20:14,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:20:14,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:20:14,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:20:14,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:20:14,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:20:14,456[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:20:14,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:20:14,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:20:14,488[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:20:14,498[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 24.42it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3855.588         
                                                               rmse/train:      
                                                               3944.794         
[[36m2025-01-21 15:21:07,634[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:21:07,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/006[0m
[[36m2025-01-21 15:21:07,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:21:07,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-01-21 15:21:07,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:21:07,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015205659078436342 prior_scale[0m
[[36m2025-01-21 15:21:07,815[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002873671566774025 q_scale[0m
[[36m2025-01-21 15:21:07,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:21:07,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-01-21 15:21:07,830[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:21:07,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:21:17,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:21:17,174[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:21:17,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:21:17,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:21:17,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:21:17,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:21:17,179[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:21:17,179[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:21:17,180[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:21:17,212[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:21:17,222[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:06 •       28.84it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 43.489 
                                                               rmse/train:      
                                                               37.922           
[[36m2025-01-21 15:24:05,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:24:05,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/007[0m
[[36m2025-01-21 15:24:05,784[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:24:05,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-01-21 15:24:05,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:24:05,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2025-01-21 15:24:05,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2025-01-21 15:24:05,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:24:05,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-01-21 15:24:05,878[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:24:05,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:24:15,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:24:15,796[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:24:15,797[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:24:15,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:24:15,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:24:15,800[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:24:15,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:24:15,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:24:15,802[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:24:15,845[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:24:15,854[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 12.45it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2890.638         
                                                               rmse/train:      
                                                               3005.891         
[[36m2025-01-21 15:25:52,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:25:52,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/008[0m
[[36m2025-01-21 15:25:52,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:25:52,764[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-01-21 15:25:52,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:25:52,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41347469058863023 prior_scale[0m
[[36m2025-01-21 15:25:52,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009135206248796449 q_scale[0m
[[36m2025-01-21 15:25:52,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:25:52,820[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-01-21 15:25:52,820[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:25:52,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:26:02,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:26:02,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:26:02,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:26:02,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:26:02,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:26:02,423[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:26:02,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:26:02,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:26:02,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:26:02,467[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:26:02,476[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 23.26it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4396.945         
                                                               rmse/train:      
                                                               4520.270         
[[36m2025-01-21 15:26:58,236[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:26:58,238[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/009[0m
[[36m2025-01-21 15:26:58,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:26:58,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008289681104465045, lr[0m
[[36m2025-01-21 15:26:58,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:26:58,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03823730602613338 prior_scale[0m
[[36m2025-01-21 15:26:58,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011667005469831107 q_scale[0m
[[36m2025-01-21 15:26:58,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:26:58,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-01-21 15:26:58,486[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:26:58,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:27:08,535[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:27:08,541[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:27:08,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:27:08,544[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:27:08,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:27:08,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:27:08,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:27:08,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:27:08,548[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:27:08,579[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:27:08,588[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.54it/s v_num: 0.000     
                                                               rmse/val: 91.689 
                                                               rmse/train:      
                                                               45.456           
[[36m2025-01-21 15:29:49,905[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:29:49,907[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/010[0m
[[36m2025-01-21 15:29:50,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:29:50,063[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009233768742572698, lr[0m
[[36m2025-01-21 15:29:50,081[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:29:50,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04155761071630431 prior_scale[0m
[[36m2025-01-21 15:29:50,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000282794630712143 q_scale[0m
[[36m2025-01-21 15:29:50,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:29:50,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-01-21 15:29:50,156[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:29:50,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:29:59,977[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:29:59,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:29:59,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:29:59,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:29:59,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:29:59,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:29:59,988[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:29:59,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:29:59,989[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:30:00,052[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:30:00,063[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.44it/s v_num: 0.000     
                                                               rmse/val: 66.431 
                                                               rmse/train:      
                                                               58.389           
[[36m2025-01-21 15:32:38,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:32:38,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/011[0m
[[36m2025-01-21 15:32:38,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:32:38,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008502926265357448, lr[0m
[[36m2025-01-21 15:32:38,474[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:32:38,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04674991283276834 prior_scale[0m
[[36m2025-01-21 15:32:38,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010403970950299182 q_scale[0m
[[36m2025-01-21 15:32:38,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:32:38,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-01-21 15:32:38,524[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:32:38,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:32:47,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:32:47,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:32:47,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:32:47,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:32:47,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:32:47,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:32:47,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:32:47,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:32:47,949[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:32:47,992[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:32:48,003[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.32it/s v_num: 0.000     
                                                               rmse/val: 58.175 
                                                               rmse/train:      
                                                               48.068           
[[36m2025-01-21 15:35:28,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:35:28,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/012[0m
[[36m2025-01-21 15:35:28,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:35:28,868[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000237679721845533, lr[0m
[[36m2025-01-21 15:35:28,882[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:35:28,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05423451401435726 prior_scale[0m
[[36m2025-01-21 15:35:28,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010097560658390371 q_scale[0m
[[36m2025-01-21 15:35:28,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:35:28,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-01-21 15:35:28,931[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:35:28,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:35:38,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:35:38,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:35:38,432[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:35:38,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:35:38,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:35:38,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:35:38,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:35:38,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:35:38,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:35:38,476[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:35:38,484[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.27it/s v_num: 0.000     
                                                               rmse/val: 60.327 
                                                               rmse/train:      
                                                               44.473           
[[36m2025-01-21 15:38:19,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:38:19,486[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/013[0m
[[36m2025-01-21 15:38:19,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:38:19,662[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015502343844271322, lr[0m
[[36m2025-01-21 15:38:19,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:38:19,703[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07858851068156882 prior_scale[0m
[[36m2025-01-21 15:38:19,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000208024069409002 q_scale[0m
[[36m2025-01-21 15:38:19,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:38:19,746[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-01-21 15:38:19,746[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:38:19,746[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:38:29,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:38:29,273[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:38:29,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:38:29,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:38:29,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:38:29,277[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:38:29,278[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:38:29,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:38:29,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:38:29,323[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:38:29,331[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.38it/s v_num: 0.000     
                                                               rmse/val: 53.960 
                                                               rmse/train:      
                                                               50.990           
[[36m2025-01-21 15:41:10,578[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:41:10,580[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/014[0m
[[36m2025-01-21 15:41:10,696[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:41:10,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016057201989390607, lr[0m
[[36m2025-01-21 15:41:10,748[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:41:10,766[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08410776162118824 prior_scale[0m
[[36m2025-01-21 15:41:10,783[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002304510696926467 q_scale[0m
[[36m2025-01-21 15:41:10,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:41:10,799[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-01-21 15:41:10,799[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:41:10,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:41:20,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:41:20,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:41:20,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:41:20,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:41:20,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:41:20,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:41:20,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:41:20,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:41:20,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:41:20,711[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:41:20,722[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.81it/s v_num: 0.000     
                                                               rmse/val: 56.049 
                                                               rmse/train:      
                                                               50.546           
[[36m2025-01-21 15:43:55,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:43:55,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/015[0m
[[36m2025-01-21 15:43:55,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:43:55,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001184922900102256, lr[0m
[[36m2025-01-21 15:43:55,508[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:43:55,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02853210388524188 prior_scale[0m
[[36m2025-01-21 15:43:55,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002789378352322264 q_scale[0m
[[36m2025-01-21 15:43:55,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:43:55,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-01-21 15:43:55,570[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:43:55,570[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:44:05,106[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:44:05,112[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:44:05,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:44:05,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:44:05,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:44:05,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:44:05,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:44:05,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:44:05,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:44:05,165[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:44:05,176[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.63it/s v_num: 0.000     
                                                               rmse/val: 115.938
                                                               rmse/train:      
                                                               111.104          
[[36m2025-01-21 15:46:39,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:46:39,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/016[0m
[[36m2025-01-21 15:46:39,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:46:39,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035513864095282046, lr[0m
[[36m2025-01-21 15:46:39,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:46:39,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07711419497296657 prior_scale[0m
[[36m2025-01-21 15:46:39,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005213323060419205 q_scale[0m
[[36m2025-01-21 15:46:39,714[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 15:46:39,715[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-01-21 15:46:39,715[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:46:39,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:46:49,915[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:46:49,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:46:49,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:46:49,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:46:49,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:46:49,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:46:49,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:46:49,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:46:49,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:46:49,972[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:46:49,981[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 9.91it/s v_num: 0.000     
                                                               rmse/val: 653.238
                                                               rmse/train:      
                                                               765.109          
[[36m2025-01-21 15:47:48,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:47:48,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/017[0m
[[36m2025-01-21 15:47:48,235[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:47:48,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017261087175645122, lr[0m
[[36m2025-01-21 15:47:48,287[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:47:48,306[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2535070707891537 prior_scale[0m
[[36m2025-01-21 15:47:48,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018362679059720055 q_scale[0m
[[36m2025-01-21 15:47:48,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:47:48,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-01-21 15:47:48,341[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:47:48,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:47:57,770[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:47:57,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:47:57,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:47:57,779[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:47:57,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:47:57,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:47:57,781[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:47:57,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:47:57,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:47:57,815[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:47:57,823[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       16.92it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 38.801 
                                                               rmse/train:      
                                                               35.591           
[[36m2025-01-21 15:52:39,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:52:39,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/018[0m
[[36m2025-01-21 15:52:39,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:52:39,921[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005124108556934394, lr[0m
[[36m2025-01-21 15:52:39,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:52:39,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07314445065299317 prior_scale[0m
[[36m2025-01-21 15:52:39,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032703777329971763 q_scale[0m
[[36m2025-01-21 15:52:39,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 15:52:39,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-01-21 15:52:39,986[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:52:39,986[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:52:50,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:52:50,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:52:50,325[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:52:50,327[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:52:50,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:52:50,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:52:50,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:52:50,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:52:50,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:52:50,372[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:52:50,380[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.91it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1514.010         
                                                               rmse/train:      
                                                               1651.122         
[[36m2025-01-21 15:53:33,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:53:33,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/019[0m
[[36m2025-01-21 15:53:33,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:53:33,648[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004516783718777233, lr[0m
[[36m2025-01-21 15:53:33,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:53:33,692[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09948749610012697 prior_scale[0m
[[36m2025-01-21 15:53:33,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009084026670046142 q_scale[0m
[[36m2025-01-21 15:53:33,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:53:33,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-01-21 15:53:33,734[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:53:33,734[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:53:43,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:53:43,217[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:53:43,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:53:43,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:53:43,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:53:43,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:53:43,222[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:53:43,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:53:43,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:53:43,263[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:53:43,275[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.37it/s v_num: 0.000     
                                                               rmse/val: 43.804 
                                                               rmse/train:      
                                                               38.186           
[[36m2025-01-21 15:56:12,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:56:12,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/020[0m
[[36m2025-01-21 15:56:12,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:56:12,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014344688427563458, lr[0m
[[36m2025-01-21 15:56:12,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:56:12,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0643595094537792 prior_scale[0m
[[36m2025-01-21 15:56:12,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002010648591592549 q_scale[0m
[[36m2025-01-21 15:56:12,500[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:56:12,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-01-21 15:56:12,501[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:56:12,501[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:56:22,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:56:22,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:56:22,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:56:22,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:56:22,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:56:22,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:56:22,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:56:22,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:56:22,309[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:56:22,353[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:56:22,363[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.79it/s v_num: 0.000     
                                                               rmse/val: 67.043 
                                                               rmse/train:      
                                                               55.269           
[[36m2025-01-21 15:58:53,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:58:53,201[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/021[0m
[[36m2025-01-21 15:58:53,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:58:53,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.072330744731238e-05, lr[0m
[[36m2025-01-21 15:58:53,355[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:58:53,373[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02835466067037353 prior_scale[0m
[[36m2025-01-21 15:58:53,390[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017618436964097762 q_scale[0m
[[36m2025-01-21 15:58:53,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:58:53,407[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-01-21 15:58:53,408[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:58:53,408[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:59:03,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:59:03,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:59:03,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:59:03,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:59:03,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:59:03,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:59:03,159[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:59:03,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:59:03,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:59:03,203[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:59:03,211[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.82it/s v_num: 0.000     
                                                               rmse/val: 602.468
                                                               rmse/train:      
                                                               717.236          
[[36m2025-01-21 16:01:31,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:01:31,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/022[0m
[[36m2025-01-21 16:01:32,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:01:32,083[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002036274093673068, lr[0m
[[36m2025-01-21 16:01:32,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:01:32,126[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.059636311677942554 prior_scale[0m
[[36m2025-01-21 16:01:32,150[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003409067376812242 q_scale[0m
[[36m2025-01-21 16:01:32,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:01:32,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-01-21 16:01:32,169[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:01:32,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:01:41,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:01:41,801[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:01:41,801[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:01:41,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:01:41,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:01:41,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:01:41,805[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:01:41,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:01:41,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:01:41,859[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:01:41,871[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.07it/s v_num: 0.000     
                                                               rmse/val: 42.712 
                                                               rmse/train:      
                                                               37.502           
[[36m2025-01-21 16:04:11,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:04:11,427[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/023[0m
[[36m2025-01-21 16:04:11,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:04:11,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012884162545905977, lr[0m
[[36m2025-01-21 16:04:11,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:04:11,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.030676732252439456 prior_scale[0m
[[36m2025-01-21 16:04:11,620[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00041091706596331013 q_scale[0m
[[36m2025-01-21 16:04:11,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:04:11,634[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-01-21 16:04:11,634[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:04:11,635[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:04:21,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:04:21,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:04:21,220[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:04:21,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:04:21,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:04:21,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:04:21,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:04:21,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:04:21,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:04:21,267[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:04:21,275[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.77it/s v_num: 0.000     
                                                               rmse/val: 68.420 
                                                               rmse/train:      
                                                               63.518           
[[36m2025-01-21 16:06:50,603[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:06:50,605[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/024[0m
[[36m2025-01-21 16:06:50,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:06:50,743[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.853718777804374e-05, lr[0m
[[36m2025-01-21 16:06:50,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:06:50,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1017157063274602 prior_scale[0m
[[36m2025-01-21 16:06:50,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001508419506436232 q_scale[0m
[[36m2025-01-21 16:06:50,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:06:50,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-01-21 16:06:50,806[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:06:50,807[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:07:00,383[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:07:00,390[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:07:00,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:07:00,393[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:07:00,394[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:07:00,395[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:07:00,397[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:07:00,397[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:07:00,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:07:00,458[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:07:00,470[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.98it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1572.908         
                                                               rmse/train:      
                                                               1680.398         
[[36m2025-01-21 16:09:28,691[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:09:28,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/025[0m
[[36m2025-01-21 16:09:28,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:09:28,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.229126245935535e-05, lr[0m
[[36m2025-01-21 16:09:28,882[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:09:28,904[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05927918485545824 prior_scale[0m
[[36m2025-01-21 16:09:28,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026477059338866525 q_scale[0m
[[36m2025-01-21 16:09:28,938[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:09:28,939[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-01-21 16:09:28,939[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:09:28,939[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:09:38,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:09:38,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:09:38,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:09:38,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:09:38,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:09:38,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:09:38,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:09:38,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:09:38,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:09:38,659[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:09:38,667[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.91it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3347.590         
                                                               rmse/train:      
                                                               3451.674         
[[36m2025-01-21 16:12:12,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:12:12,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/026[0m
[[36m2025-01-21 16:12:12,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:12:12,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002683568616567676, lr[0m
[[36m2025-01-21 16:12:12,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:12:12,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03693221081618471 prior_scale[0m
[[36m2025-01-21 16:12:12,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007559607679243626 q_scale[0m
[[36m2025-01-21 16:12:12,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 16:12:12,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-01-21 16:12:12,412[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:12:12,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:12:22,783[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:12:22,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:12:22,790[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:12:22,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:12:22,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:12:22,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:12:22,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:12:22,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:12:22,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:12:22,845[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:12:22,856[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.80it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3402.077         
                                                               rmse/train:      
                                                               3499.350         
[[36m2025-01-21 16:13:06,513[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:13:06,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/027[0m
[[36m2025-01-21 16:13:06,627[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:13:06,661[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000684481182434033, lr[0m
[[36m2025-01-21 16:13:06,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:13:06,695[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2028515467253622 prior_scale[0m
[[36m2025-01-21 16:13:06,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021135758543242047 q_scale[0m
[[36m2025-01-21 16:13:06,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:13:06,727[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-01-21 16:13:06,728[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:13:06,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:13:16,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:13:16,336[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:13:16,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:13:16,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:13:16,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:13:16,340[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:13:16,341[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:13:16,341[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:13:16,342[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:13:16,371[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:13:16,380[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       16.80it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 38.420 
                                                               rmse/train:      
                                                               38.749           
[[36m2025-01-21 16:17:49,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:17:49,709[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/028[0m
[[36m2025-01-21 16:17:49,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:17:49,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0068092524464887e-05, lr[0m
[[36m2025-01-21 16:17:49,907[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:17:49,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.39752937290272766 prior_scale[0m
[[36m2025-01-21 16:17:49,955[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001445889369170343 q_scale[0m
[[36m2025-01-21 16:17:49,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 16:17:49,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-01-21 16:17:49,974[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:17:49,974[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:17:59,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:17:59,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:17:59,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:17:59,929[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:17:59,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:17:59,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:17:59,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:17:59,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:17:59,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:17:59,974[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:17:59,983[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 10.36it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4315.071         
                                                               rmse/train:      
                                                               4423.474         
[[36m2025-01-21 16:18:55,739[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:18:55,740[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/029[0m
[[36m2025-01-21 16:18:55,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:18:55,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003934679334283099, lr[0m
[[36m2025-01-21 16:18:55,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:18:55,958[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.28200648541633616 prior_scale[0m
[[36m2025-01-21 16:18:55,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004282265355775561 q_scale[0m
[[36m2025-01-21 16:18:56,000[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 16:18:56,001[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-01-21 16:18:56,001[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:18:56,001[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:19:05,756[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:19:05,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:19:05,763[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:19:05,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:19:05,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:19:05,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:19:05,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:19:05,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:19:05,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:19:05,811[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:19:05,821[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 10.17it/s v_num: 0.000     
                                                               rmse/val: 215.911
                                                               rmse/train:      
                                                               196.232          
[[36m2025-01-21 16:20:02,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:20:02,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/030[0m
[[36m2025-01-21 16:20:02,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:20:02,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013711221240721633, lr[0m
[[36m2025-01-21 16:20:02,914[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:20:02,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07909432358790708 prior_scale[0m
[[36m2025-01-21 16:20:02,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021404167265352334 q_scale[0m
[[36m2025-01-21 16:20:02,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:20:02,966[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-01-21 16:20:02,966[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:20:02,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:20:12,443[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:20:12,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:20:12,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:20:12,452[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:20:12,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:20:12,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:20:12,454[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:20:12,454[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:20:12,455[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:20:12,485[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:20:12,493[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.44it/s v_num: 0.000     
                                                               rmse/val: 79.912 
                                                               rmse/train:      
                                                               76.170           
[[36m2025-01-21 16:22:52,172[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:22:52,174[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/031[0m
[[36m2025-01-21 16:22:52,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:22:52,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.448400555490266e-05, lr[0m
[[36m2025-01-21 16:22:52,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:22:52,404[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14939335670197956 prior_scale[0m
[[36m2025-01-21 16:22:52,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023064495882279602 q_scale[0m
[[36m2025-01-21 16:22:52,448[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:22:52,448[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-01-21 16:22:52,449[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:22:52,449[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:23:02,096[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:23:02,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:23:02,103[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:23:02,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:23:02,105[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:23:02,106[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:23:02,106[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:23:02,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:23:02,108[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:23:02,161[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:23:02,172[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.98it/s v_num: 0.000     
                                                               rmse/val: 316.932
                                                               rmse/train:      
                                                               413.489          
[[36m2025-01-21 16:25:42,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:25:42,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/032[0m
[[36m2025-01-21 16:25:42,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:25:42,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014730838751947535, lr[0m
[[36m2025-01-21 16:25:42,202[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:25:42,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08912899435266339 prior_scale[0m
[[36m2025-01-21 16:25:42,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014860875951355223 q_scale[0m
[[36m2025-01-21 16:25:42,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:25:42,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-01-21 16:25:42,270[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:25:42,270[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:25:52,120[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:25:52,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:25:52,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:25:52,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:25:52,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:25:52,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:25:52,130[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:25:52,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:25:52,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:25:52,176[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:25:52,185[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.28it/s v_num: 0.000     
                                                               rmse/val: 64.082 
                                                               rmse/train:      
                                                               56.438           
[[36m2025-01-21 16:28:28,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:28:28,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/033[0m
[[36m2025-01-21 16:28:28,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:28:28,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020212184594889442, lr[0m
[[36m2025-01-21 16:28:28,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:28:28,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09241599914571719 prior_scale[0m
[[36m2025-01-21 16:28:28,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007406626536808786 q_scale[0m
[[36m2025-01-21 16:28:28,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:28:28,681[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-01-21 16:28:28,681[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:28:28,681[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:28:38,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:28:38,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:28:38,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:28:38,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:28:38,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:28:38,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:28:38,155[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:28:38,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:28:38,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:28:38,208[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:28:38,221[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.07it/s v_num: 0.000     
                                                               rmse/val: 86.180 
                                                               rmse/train:      
                                                               48.898           
[[36m2025-01-21 16:31:22,678[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:31:22,679[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/034[0m
[[36m2025-01-21 16:31:22,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:31:22,831[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.732735088955874e-05, lr[0m
[[36m2025-01-21 16:31:22,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:31:22,865[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12734318050289056 prior_scale[0m
[[36m2025-01-21 16:31:22,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043108617386634283 q_scale[0m
[[36m2025-01-21 16:31:22,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 16:31:22,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-01-21 16:31:22,901[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:31:22,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:31:33,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:31:33,087[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:31:33,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:31:33,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:31:33,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:31:33,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:31:33,091[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:31:33,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:31:33,092[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:31:33,135[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:31:33,143[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 6.74it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4095.215         
                                                               rmse/train:      
                                                               4183.206         
[[36m2025-01-21 16:32:17,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:32:17,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/035[0m
[[36m2025-01-21 16:32:17,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:32:17,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.061790180110037e-05, lr[0m
[[36m2025-01-21 16:32:17,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:32:17,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1707751771432694 prior_scale[0m
[[36m2025-01-21 16:32:17,858[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013156847514257368 q_scale[0m
[[36m2025-01-21 16:32:17,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:32:17,877[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-01-21 16:32:17,878[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:32:17,878[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:32:27,516[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:32:27,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:32:27,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:32:27,525[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:32:27,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:32:27,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:32:27,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:32:27,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:32:27,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:32:27,558[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:32:27,568[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 27.10it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2614.079         
                                                               rmse/train:      
                                                               2724.069         
[[36m2025-01-21 16:33:59,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:33:59,229[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/036[0m
[[36m2025-01-21 16:33:59,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:33:59,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010957540557654175, lr[0m
[[36m2025-01-21 16:33:59,389[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:33:59,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04899991202231565 prior_scale[0m
[[36m2025-01-21 16:33:59,427[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004603624831452556 q_scale[0m
[[36m2025-01-21 16:33:59,443[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:33:59,443[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-01-21 16:33:59,444[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:33:59,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:34:08,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:34:08,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:34:08,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:34:08,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:34:08,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:34:08,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:34:08,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:34:08,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:34:08,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:34:08,979[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:34:08,988[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.66it/s v_num: 0.000     
                                                               rmse/val: 116.771
                                                               rmse/train:      
                                                               131.138          
[[36m2025-01-21 16:36:42,100[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:36:42,101[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/037[0m
[[36m2025-01-21 16:36:42,221[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:36:42,255[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000291820252585763, lr[0m
[[36m2025-01-21 16:36:42,270[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:36:42,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09274550023659052 prior_scale[0m
[[36m2025-01-21 16:36:42,306[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000593059110931989 q_scale[0m
[[36m2025-01-21 16:36:42,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:36:42,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-01-21 16:36:42,321[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:36:42,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:36:52,043[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:36:52,050[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:36:52,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:36:52,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:36:52,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:36:52,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:36:52,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:36:52,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:36:52,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:36:52,100[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:36:52,108[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 29.17it/s v_num: 0.000     
                                                               rmse/val: 68.400 
                                                               rmse/train:      
                                                               38.727           
[[36m2025-01-21 16:38:16,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:38:16,577[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/038[0m
[[36m2025-01-21 16:38:16,723[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:38:16,771[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.142328235860698e-05, lr[0m
[[36m2025-01-21 16:38:16,790[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:38:16,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.020676708101278182 prior_scale[0m
[[36m2025-01-21 16:38:16,843[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016666027828979754 q_scale[0m
[[36m2025-01-21 16:38:16,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:38:16,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-01-21 16:38:16,863[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:38:16,863[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:38:26,547[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:38:26,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:38:26,554[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:38:26,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:38:26,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:38:26,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:38:26,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:38:26,558[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:38:26,559[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:38:26,590[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:38:26,618[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       16.56it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 59.464 
                                                               rmse/train:      
                                                               40.431           
[[36m2025-01-21 16:42:58,438[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:42:58,439[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/039[0m
[[36m2025-01-21 16:42:58,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:42:58,600[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 4.5831904653939286e-05, lr[0m
[[36m2025-01-21 16:42:58,618[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:42:58,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.019965111674528645 prior_scale[0m
[[36m2025-01-21 16:42:58,667[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001608494445842682 q_scale[0m
[[36m2025-01-21 16:42:58,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:42:58,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-01-21 16:42:58,686[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:42:58,686[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:43:08,369[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:43:08,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:43:08,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:43:08,378[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:43:08,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:43:08,379[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:43:08,380[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:43:08,380[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:43:08,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:43:08,423[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:43:08,431[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.67it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1089.074         
                                                               rmse/train:      
                                                               1203.702         
[[36m2025-01-21 16:45:43,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:45:43,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/040[0m
[[36m2025-01-21 16:45:43,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:45:43,281[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.5625557193357e-05, lr[0m
[[36m2025-01-21 16:45:43,295[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:45:43,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.013487540745749404 prior_scale[0m
[[36m2025-01-21 16:45:43,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013320490239163577 q_scale[0m
[[36m2025-01-21 16:45:43,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:45:43,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-01-21 16:45:43,346[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:45:43,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:45:52,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:45:52,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:45:52,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:45:52,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:45:52,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:45:52,810[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:45:52,811[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:45:52,811[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:45:52,812[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:45:52,861[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:45:52,869[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:10 •       18.25it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 43.425 
                                                               rmse/train:      
                                                               39.860           
[[36m2025-01-21 16:50:14,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:50:14,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/041[0m
[[36m2025-01-21 16:50:14,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:50:14,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.9783953245032526e-05, lr[0m
[[36m2025-01-21 16:50:14,615[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:50:14,638[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02514615721350173 prior_scale[0m
[[36m2025-01-21 16:50:14,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024811769241372185 q_scale[0m
[[36m2025-01-21 16:50:14,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:50:14,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-01-21 16:50:14,668[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:50:14,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:50:24,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:50:24,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:50:24,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:50:24,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:50:24,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:50:24,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:50:24,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:50:24,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:50:24,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:50:24,118[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:50:24,126[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.64it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               2244.574         
                                                               rmse/train:      
                                                               2356.386         
[[36m2025-01-21 16:54:50,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:54:50,777[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/042[0m
[[36m2025-01-21 16:54:50,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:54:50,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016650235266656334, lr[0m
[[36m2025-01-21 16:54:50,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:54:50,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010289526782574237 prior_scale[0m
[[36m2025-01-21 16:54:50,993[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003415582597771279 q_scale[0m
[[36m2025-01-21 16:54:51,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:54:51,009[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-01-21 16:54:51,009[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:54:51,009[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:55:00,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:55:00,458[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:55:00,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:55:00,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:55:00,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:55:00,462[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:55:00,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:55:00,463[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:55:00,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:55:00,508[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:55:00,516[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.68it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.247 
                                                               rmse/train:      
                                                               41.017           
[[36m2025-01-21 16:59:26,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:59:26,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/044[0m
[[36m2025-01-21 16:59:26,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:59:26,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000976987337003933, lr[0m
[[36m2025-01-21 16:59:26,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:59:26,756[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04318017272587117 prior_scale[0m
[[36m2025-01-21 16:59:26,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011869858529942636 q_scale[0m
[[36m2025-01-21 16:59:26,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 16:59:26,787[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-01-21 16:59:26,788[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:59:26,788[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:59:36,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:59:36,293[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:59:36,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:59:36,295[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:59:36,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:59:36,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:59:36,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:59:36,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:59:36,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:59:36,340[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:59:36,348[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 29.26it/s v_num: 0.000     
                                                               rmse/val: 96.082 
                                                               rmse/train:      
                                                               60.287           
[[36m2025-01-21 17:01:00,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:01:00,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/048[0m
[[36m2025-01-21 17:01:00,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:01:00,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.577996616940478e-05, lr[0m
[[36m2025-01-21 17:01:00,346[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:01:00,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12321288799110902 prior_scale[0m
[[36m2025-01-21 17:01:00,385[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017298034608935394 q_scale[0m
[[36m2025-01-21 17:01:00,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 17:01:00,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-01-21 17:01:00,403[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:01:00,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:01:10,374[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:01:10,381[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:01:10,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:01:10,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:01:10,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:01:10,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:01:10,386[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:01:10,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:01:10,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:01:10,430[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:01:10,438[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 10.54it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3703.435         
                                                               rmse/train:      
                                                               3791.075         
[[36m2025-01-21 17:02:05,784[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:02:05,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/049[0m
[[36m2025-01-21 17:02:05,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:02:05,963[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001077916742512544, lr[0m
[[36m2025-01-21 17:02:05,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:02:06,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08353062791962548 prior_scale[0m
[[36m2025-01-21 17:02:06,022[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023361789329428374 q_scale[0m
[[36m2025-01-21 17:02:06,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:02:06,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-01-21 17:02:06,040[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:02:06,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:02:15,806[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:02:15,812[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:02:15,813[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:02:15,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:02:15,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:02:15,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:02:15,817[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:02:15,817[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:02:15,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:02:15,858[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:02:15,871[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.26it/s v_num: 0.000     
                                                               rmse/val: 142.615
                                                               rmse/train:      
                                                               164.834          
[[36m2025-01-21 17:04:41,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:04:41,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/050[0m
[[36m2025-01-21 17:04:41,602[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:04:41,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002336305830020761, lr[0m
[[36m2025-01-21 17:04:41,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:04:41,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015581228614711444 prior_scale[0m
[[36m2025-01-21 17:04:41,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011322738163939448 q_scale[0m
[[36m2025-01-21 17:04:41,724[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 17:04:41,724[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-01-21 17:04:41,725[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:04:41,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:04:51,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:04:51,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:04:51,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:04:51,985[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:04:51,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:04:51,990[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:04:51,991[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:04:51,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:04:51,992[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:04:52,040[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:04:52,052[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.11it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3532.196         
                                                               rmse/train:      
                                                               3623.742         
[[36m2025-01-21 17:05:34,317[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:05:34,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/051[0m
[[36m2025-01-21 17:05:34,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:05:34,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.8720349453257645e-05, lr[0m
[[36m2025-01-21 17:05:34,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:05:34,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10955621527110819 prior_scale[0m
[[36m2025-01-21 17:05:34,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022238037692330253 q_scale[0m
[[36m2025-01-21 17:05:34,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 17:05:34,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-01-21 17:05:34,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:05:34,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:05:44,340[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:05:44,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:05:44,347[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:05:44,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:05:44,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:05:44,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:05:44,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:05:44,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:05:44,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:05:44,381[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:05:44,390[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.25it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3845.043         
                                                               rmse/train:      
                                                               3929.129         
[[36m2025-01-21 17:07:07,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:07:07,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/052[0m
[[36m2025-01-21 17:07:07,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:07:07,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001442281421669351, lr[0m
[[36m2025-01-21 17:07:07,566[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:07:07,584[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06369604191400549 prior_scale[0m
[[36m2025-01-21 17:07:07,601[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001982586491019044 q_scale[0m
[[36m2025-01-21 17:07:07,616[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:07:07,616[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-01-21 17:07:07,616[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:07:07,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:07:17,083[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:07:17,090[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:07:17,090[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:07:17,092[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:07:17,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:07:17,093[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:07:17,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:07:17,094[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:07:17,095[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:07:17,152[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:07:17,160[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 16.14it/s v_num: 0.000     
                                                               rmse/val: 51.195 
                                                               rmse/train:      
                                                               43.648           
[[36m2025-01-21 17:09:43,902[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:09:43,904[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/053[0m
[[36m2025-01-21 17:09:44,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:09:44,060[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000139010053470029, lr[0m
[[36m2025-01-21 17:09:44,080[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:09:44,107[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06875509805158436 prior_scale[0m
[[36m2025-01-21 17:09:44,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019045267074841842 q_scale[0m
[[36m2025-01-21 17:09:44,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:09:44,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-01-21 17:09:44,153[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:09:44,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:09:53,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:09:53,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:09:53,928[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:09:53,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:09:53,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:09:53,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:09:53,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:09:53,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:09:53,932[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:09:53,976[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:09:53,984[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 16.52it/s v_num: 0.000     
                                                               rmse/val: 62.570 
                                                               rmse/train:      
                                                               57.928           
[[36m2025-01-21 17:12:11,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:12:11,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/054[0m
[[36m2025-01-21 17:12:11,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:12:11,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019294953785666249, lr[0m
[[36m2025-01-21 17:12:11,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:12:11,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06808505973413811 prior_scale[0m
[[36m2025-01-21 17:12:11,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016576797425483895 q_scale[0m
[[36m2025-01-21 17:12:11,823[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:12:11,824[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-01-21 17:12:11,824[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:12:11,824[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:12:21,466[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:12:21,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:12:21,474[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:12:21,475[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:12:21,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:12:21,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:12:21,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:12:21,477[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:12:21,478[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:12:21,531[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:12:21,544[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.41it/s v_num: 0.000     
                                                               rmse/val: 52.648 
                                                               rmse/train:      
                                                               45.757           
[[36m2025-01-21 17:14:42,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:14:42,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/055[0m
[[36m2025-01-21 17:14:42,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:14:42,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012304261676127185, lr[0m
[[36m2025-01-21 17:14:42,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:14:42,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05066821936466481 prior_scale[0m
[[36m2025-01-21 17:14:42,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009266206861567056 q_scale[0m
[[36m2025-01-21 17:14:42,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:14:42,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-01-21 17:14:42,354[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:14:42,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:14:51,940[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:14:51,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:14:51,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:14:51,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:14:51,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:14:51,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:14:51,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:14:51,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:14:51,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:14:51,994[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:14:52,021[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.15it/s v_num: 0.000     
                                                               rmse/val: 92.434 
                                                               rmse/train:      
                                                               89.297           
[[36m2025-01-21 17:17:20,991[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:17:20,992[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/056[0m
[[36m2025-01-21 17:17:21,108[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:17:21,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001367302137531995, lr[0m
[[36m2025-01-21 17:17:21,158[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:17:21,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0545878218070785 prior_scale[0m
[[36m2025-01-21 17:17:21,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019648814254572233 q_scale[0m
[[36m2025-01-21 17:17:21,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:17:21,212[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-01-21 17:17:21,213[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:17:21,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:17:30,483[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:17:30,489[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:17:30,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:17:30,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:17:30,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:17:30,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:17:30,494[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:17:30,494[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:17:30,495[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:17:30,538[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:17:30,547[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.19it/s v_num: 0.000     
                                                               rmse/val: 74.189 
                                                               rmse/train:      
                                                               70.776           
[[36m2025-01-21 17:20:01,959[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:20:01,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/057[0m
[[36m2025-01-21 17:20:02,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:20:02,106[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003330231848015499, lr[0m
[[36m2025-01-21 17:20:02,122[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:20:02,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04039540311733499 prior_scale[0m
[[36m2025-01-21 17:20:02,156[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019421197709096384 q_scale[0m
[[36m2025-01-21 17:20:02,170[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:20:02,170[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-01-21 17:20:02,171[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:20:02,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:20:11,660[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:20:11,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:20:11,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:20:11,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:20:11,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:20:11,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:20:11,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:20:11,671[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:20:11,671[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:20:11,719[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:20:11,730[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.73it/s v_num: 0.000     
                                                               rmse/val: 51.614 
                                                               rmse/train:      
                                                               46.849           
[[36m2025-01-21 17:22:41,136[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:22:41,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/058[0m
[[36m2025-01-21 17:22:41,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:22:41,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.439335305815457e-05, lr[0m
[[36m2025-01-21 17:22:41,304[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 17:22:41,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.056164754382756026 prior_scale[0m
[[36m2025-01-21 17:22:41,341[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002862703662581015 q_scale[0m
[[36m2025-01-21 17:22:41,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:22:41,356[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-01-21 17:22:41,356[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:22:41,356[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:22:50,953[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:22:50,960[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:22:50,961[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:22:50,963[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:22:50,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:22:50,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:22:50,965[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:22:50,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:22:50,966[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:22:51,017[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:22:51,029[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 29.55it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1225.637         
                                                               rmse/train:      
                                                               1340.936         
[[36m2025-01-21 17:24:16,453[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:24:16,455[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/059[0m
[[36m2025-01-21 17:24:16,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:24:16,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023350606340767752, lr[0m
[[36m2025-01-21 17:24:16,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:24:16,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0311089891523694 prior_scale[0m
[[36m2025-01-21 17:24:16,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011702285357948164 q_scale[0m
[[36m2025-01-21 17:24:16,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:24:16,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 060 __________________[0m
[[36m2025-01-21 17:24:16,676[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:24:16,676[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:24:26,175[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:24:26,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:24:26,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:24:26,183[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:24:26,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:24:26,184[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:24:26,185[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:24:26,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:24:26,186[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:24:26,233[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:24:26,241[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.36it/s v_num: 0.000     
                                                               rmse/val: 80.754 
                                                               rmse/train:      
                                                               64.642           
[[36m2025-01-21 17:26:54,388[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:26:54,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/060[0m
[[36m2025-01-21 17:26:54,500[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:26:54,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015177831942463226, lr[0m
[[36m2025-01-21 17:26:54,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:26:54,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06402743689178925 prior_scale[0m
[[36m2025-01-21 17:26:54,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010467805466787426 q_scale[0m
[[36m2025-01-21 17:26:54,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:26:54,606[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 061 __________________[0m
[[36m2025-01-21 17:26:54,607[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:26:54,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:27:03,765[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:27:03,771[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:27:03,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:27:03,774[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:27:03,774[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:27:03,775[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:27:03,775[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:27:03,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:27:03,776[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:27:03,820[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:27:03,828[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:10 •       18.40it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 31.692 
                                                               rmse/train:      
                                                               27.370           
[[36m2025-01-21 17:31:22,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:31:22,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/061[0m
[[36m2025-01-21 17:31:22,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:31:22,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 9.774669259684e-05, lr[0m
[[36m2025-01-21 17:31:22,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:31:22,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04512017649871712 prior_scale[0m
[[36m2025-01-21 17:31:22,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014408140538565764 q_scale[0m
[[36m2025-01-21 17:31:22,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:31:22,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 062 __________________[0m
[[36m2025-01-21 17:31:22,885[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:31:22,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:31:32,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:31:32,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:31:32,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:31:32,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:31:32,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:31:32,043[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:31:32,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:31:32,044[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:31:32,045[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:31:32,088[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:31:32,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 17.16it/s v_num: 0.000     
                                                               rmse/val: 210.657
                                                               rmse/train:      
                                                               290.731          
[[36m2025-01-21 17:33:50,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:33:50,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/062[0m
[[36m2025-01-21 17:33:50,142[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:33:50,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013595235319984605, lr[0m
[[36m2025-01-21 17:33:50,187[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:33:50,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06946384295758415 prior_scale[0m
[[36m2025-01-21 17:33:50,219[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019779111618830456 q_scale[0m
[[36m2025-01-21 17:33:50,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:33:50,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 063 __________________[0m
[[36m2025-01-21 17:33:50,232[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:33:50,233[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:33:59,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:33:59,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:33:59,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:33:59,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:33:59,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:33:59,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:33:59,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:33:59,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:33:59,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:33:59,640[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:34:03,785[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 14.86it/s v_num: 0.000     
                                                               rmse/val: 72.519 
                                                               rmse/train:      
                                                               66.685           
[[36m2025-01-21 17:36:25,372[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:36:25,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-21_15-13-33/063[0m
[[36m2025-01-21 17:36:25,479[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 64[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-01-22 11:27:26,688[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-01-22 11:27:26,689[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_lrt.db[0m
[[36m2025-01-22 11:27:29,622[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-01-22 11:27:29,651[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-01-22 11:27:29,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:27:29,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-01-22 11:27:29,767[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:27:29,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21592388039429916 prior_scale[0m
[[36m2025-01-22 11:27:29,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036303760732131728 q_scale[0m
[[36m2025-01-22 11:27:29,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:27:29,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-01-22 11:27:29,813[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:27:29,813[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:27:39,815[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:27:39,826[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:27:39,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:27:39,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:27:39,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:27:39,830[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:27:40,047[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:27:40,047[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:27:40,057[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:27:40,287[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:27:40,484[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 21.00it/s v_num: 0.000      
                                                              rmse/val: 3774.237
                                                              rmse/train:       
                                                              3802.312          
[[36m2025-01-22 11:27:52,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:27:52,799[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/000[0m
[[36m2025-01-22 11:27:52,917[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:27:52,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-01-22 11:27:52,959[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:27:52,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16250224524496343 prior_scale[0m
[[36m2025-01-22 11:27:52,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005501758328845987 q_scale[0m
[[36m2025-01-22 11:27:52,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:27:52,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-01-22 11:27:53,000[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:27:53,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:28:03,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:28:03,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:28:03,346[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:28:03,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:28:03,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:28:03,350[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:28:03,351[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:28:03,351[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:28:03,352[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:28:03,367[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:28:03,378[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4175.136
                                                              rmse/train:       
                                                              4209.421          
[[36m2025-01-22 11:28:14,945[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:28:14,946[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/001[0m
[[36m2025-01-22 11:28:15,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:28:15,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-01-22 11:28:15,112[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:28:15,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04232733477101895 prior_scale[0m
[[36m2025-01-22 11:28:15,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0073498792462323385 q_scale[0m
[[36m2025-01-22 11:28:15,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:28:15,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-01-22 11:28:15,160[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:28:15,160[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:28:25,496[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:28:25,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:28:25,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:28:25,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:28:25,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:28:25,509[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:28:25,510[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:28:25,510[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:28:25,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:28:25,541[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:28:25,550[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 25.11it/s v_num: 0.000      
                                                              rmse/val: 4155.460
                                                              rmse/train:       
                                                              4189.232          
[[36m2025-01-22 11:28:41,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:28:41,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/002[0m
[[36m2025-01-22 11:28:41,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:28:41,286[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-01-22 11:28:41,299[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:28:41,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017549127225111354 prior_scale[0m
[[36m2025-01-22 11:28:41,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002561662685923485 q_scale[0m
[[36m2025-01-22 11:28:41,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:28:41,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-01-22 11:28:41,343[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:28:41,343[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:28:51,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:28:51,651[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:28:51,652[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:28:51,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:28:51,654[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:28:51,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:28:51,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:28:51,656[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:28:51,656[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:28:51,671[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:28:51,681[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 11.95it/s v_num: 0.000      
                                                              rmse/val: 3940.122
                                                              rmse/train:       
                                                              3973.433          
[[36m2025-01-22 11:29:11,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:29:11,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/003[0m
[[36m2025-01-22 11:29:11,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:29:11,747[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-01-22 11:29:11,760[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:29:11,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14015302623589543 prior_scale[0m
[[36m2025-01-22 11:29:11,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001546142648648774 q_scale[0m
[[36m2025-01-22 11:29:11,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:29:11,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-01-22 11:29:11,798[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:29:11,798[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:29:21,577[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:29:21,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:29:21,585[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:29:21,587[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:29:21,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:29:21,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:29:21,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:29:21,589[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:29:21,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:29:21,603[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:29:21,612[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 13.80it/s v_num: 0.000      
                                                              rmse/val: 4263.004
                                                              rmse/train:       
                                                              4294.863          
[[36m2025-01-22 11:29:36,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:29:36,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/004[0m
[[36m2025-01-22 11:29:36,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:29:36,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-01-22 11:29:36,516[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:29:36,530[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01026814371296241 prior_scale[0m
[[36m2025-01-22 11:29:36,544[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017174472922154307 q_scale[0m
[[36m2025-01-22 11:29:36,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:29:36,560[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-01-22 11:29:36,561[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:29:36,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:29:46,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:29:46,644[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:29:46,645[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:29:46,647[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:29:46,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:29:46,648[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:29:46,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:29:46,649[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:29:46,650[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:29:46,681[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:29:46,692[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 6/19 ━━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 16.07it/s v_num: 0.000      
                                                              rmse/val: 4184.177
                                                              rmse/train:       
                                                              4216.114          
[[36m2025-01-22 11:29:52,600[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 6.
[[36m2025-01-22 11:29:52,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:29:52,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:29:52,803[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-01-22 11:29:52,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:29:52,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021500386108909676 prior_scale[0m
[[36m2025-01-22 11:29:52,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005816140699158816 q_scale[0m
[[36m2025-01-22 11:29:52,859[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:29:52,860[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-01-22 11:29:52,860[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:29:52,860[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:30:02,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:30:02,920[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:30:02,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:30:02,922[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:30:02,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:30:02,923[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:30:02,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:30:02,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:30:02,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:30:02,939[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:30:02,950[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 22.68it/s v_num: 0.000      
                                                              rmse/val: 4159.435
                                                              rmse/train:       
                                                              4192.504          
[[36m2025-01-22 11:30:18,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:30:18,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/006[0m
[[36m2025-01-22 11:30:18,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:30:18,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-01-22 11:30:18,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:30:18,709[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015205659078436342 prior_scale[0m
[[36m2025-01-22 11:30:18,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002873671566774025 q_scale[0m
[[36m2025-01-22 11:30:18,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:30:18,741[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-01-22 11:30:18,742[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:30:18,742[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:30:28,649[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:30:28,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:30:28,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:30:28,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:30:28,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:30:28,664[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:30:28,665[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:30:28,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:30:28,666[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:30:28,681[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:30:28,690[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 27.14it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3451.532         
                                                               rmse/train:      
                                                               3497.029         
[[36m2025-01-22 11:31:15,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:31:15,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/007[0m
[[36m2025-01-22 11:31:15,857[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:31:15,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-01-22 11:31:15,905[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:31:15,920[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2025-01-22 11:31:15,933[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2025-01-22 11:31:15,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:31:15,949[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-01-22 11:31:15,949[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:31:15,950[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:31:26,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:31:26,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:31:26,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:31:26,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:31:26,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:31:26,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:31:26,069[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:31:26,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:31:26,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:31:26,100[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:31:26,109[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.26it/s v_num: 0.000      
                                                              rmse/val: 4150.367
                                                              rmse/train:       
                                                              4183.537          
[[36m2025-01-22 11:31:46,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:31:46,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/008[0m
[[36m2025-01-22 11:31:46,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:31:46,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-01-22 11:31:46,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:31:46,612[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41347469058863023 prior_scale[0m
[[36m2025-01-22 11:31:46,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009135206248796449 q_scale[0m
[[36m2025-01-22 11:31:46,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:31:46,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-01-22 11:31:46,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:31:46,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:31:56,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:31:56,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:31:56,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:31:56,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:31:56,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:31:56,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:31:56,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:31:56,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:31:56,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:31:56,750[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:31:56,762[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 23.17it/s v_num: 0.000      
                                                              rmse/val: 4267.528
                                                              rmse/train:       
                                                              4378.719          
[[36m2025-01-22 11:32:12,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:32:12,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/009[0m
[[36m2025-01-22 11:32:12,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:32:12,538[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-01-22 11:32:12,553[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:32:12,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03921865256229128 prior_scale[0m
[[36m2025-01-22 11:32:12,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011667005469831107 q_scale[0m
[[36m2025-01-22 11:32:12,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:32:12,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-01-22 11:32:12,609[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:32:12,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:32:22,391[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:32:22,398[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:32:22,398[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:32:22,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:32:22,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:32:22,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:32:22,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:32:22,403[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:32:22,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:32:22,419[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:32:22,428[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 14.86it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3558.460         
                                                               rmse/train:      
                                                               3602.810         
[[36m2025-01-22 11:33:25,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:33:25,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/010[0m
[[36m2025-01-22 11:33:25,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:33:25,932[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-01-22 11:33:25,946[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:33:25,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0477195343156064 prior_scale[0m
[[36m2025-01-22 11:33:25,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011575851073022878 q_scale[0m
[[36m2025-01-22 11:33:25,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:33:25,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-01-22 11:33:26,000[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:33:26,000[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:33:35,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:33:35,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:33:35,382[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:33:35,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:33:35,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:33:35,386[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:33:35,387[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:33:35,387[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:33:35,388[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:33:35,421[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:33:35,430[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 14.76it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3563.181         
                                                               rmse/train:      
                                                               3605.367         
[[36m2025-01-22 11:34:40,823[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:34:40,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/011[0m
[[36m2025-01-22 11:34:40,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:34:41,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-01-22 11:34:41,030[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:34:41,054[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04771174806956745 prior_scale[0m
[[36m2025-01-22 11:34:41,079[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010280709750523207 q_scale[0m
[[36m2025-01-22 11:34:41,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:34:41,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-01-22 11:34:41,098[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:34:41,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:34:51,106[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:34:51,113[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:34:51,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:34:51,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:34:51,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:34:51,116[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:34:51,117[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:34:51,117[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:34:51,118[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:34:51,158[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:34:51,167[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 15.31it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3865.653         
                                                               rmse/train:      
                                                               3902.764         
[[36m2025-01-22 11:35:59,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:35:59,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/012[0m
[[36m2025-01-22 11:35:59,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:35:59,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009998183169689775, lr[0m
[[36m2025-01-22 11:35:59,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:35:59,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03815785807574905 prior_scale[0m
[[36m2025-01-22 11:35:59,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010105337207690109 q_scale[0m
[[36m2025-01-22 11:35:59,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:35:59,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-01-22 11:35:59,526[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:35:59,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:36:09,120[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:36:09,127[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:36:09,127[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:36:09,129[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:36:09,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:36:09,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:36:09,131[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:36:09,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:36:09,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:36:09,164[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:36:09,172[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.40it/s v_num: 0.000      
                                                              rmse/val: 2471.709
                                                              rmse/train:       
                                                              2554.731          
[[36m2025-01-22 11:36:44,794[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:36:44,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/013[0m
[[36m2025-01-22 11:36:44,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:36:44,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009814260650417564, lr[0m
[[36m2025-01-22 11:36:44,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:36:45,010[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.030109954227927314 prior_scale[0m
[[36m2025-01-22 11:36:45,031[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000205863847418941 q_scale[0m
[[36m2025-01-22 11:36:45,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:36:45,049[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-01-22 11:36:45,049[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:36:45,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:36:55,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:36:55,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:36:55,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:36:55,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:36:55,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:36:55,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:36:55,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:36:55,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:36:55,738[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:36:55,754[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:36:55,764[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.93it/s v_num: 0.000      
                                                              rmse/val: 2584.438
                                                              rmse/train:       
                                                              2653.593          
[[36m2025-01-22 11:37:32,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:37:32,237[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/014[0m
[[36m2025-01-22 11:37:32,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:37:32,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009889182514223153, lr[0m
[[36m2025-01-22 11:37:32,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:37:32,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0763798812791464 prior_scale[0m
[[36m2025-01-22 11:37:32,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002397987859149259 q_scale[0m
[[36m2025-01-22 11:37:32,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:37:32,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-01-22 11:37:32,457[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:37:32,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:37:42,007[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:37:42,016[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:37:42,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:37:42,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:37:42,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:37:42,020[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:37:42,021[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:37:42,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:37:42,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:37:42,057[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:37:42,068[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 16.00it/s v_num: 0.000      
                                                              rmse/val: 2391.596
                                                              rmse/train:       
                                                              2463.593          
[[36m2025-01-22 11:38:16,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:38:16,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/015[0m
[[36m2025-01-22 11:38:17,018[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:38:17,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009048631611025431, lr[0m
[[36m2025-01-22 11:38:17,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:38:17,073[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0869754681482522 prior_scale[0m
[[36m2025-01-22 11:38:17,087[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002557136889054008 q_scale[0m
[[36m2025-01-22 11:38:17,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:38:17,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-01-22 11:38:17,100[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:38:17,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:38:26,600[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:38:26,606[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:38:26,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:38:26,608[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:38:26,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:38:26,609[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:38:26,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:38:26,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:38:26,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:38:26,625[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:38:26,633[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 16.34it/s v_num: 0.000      
                                                              rmse/val: 2710.036
                                                              rmse/train:       
                                                              2779.079          
[[36m2025-01-22 11:38:55,895[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:38:55,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/016[0m
[[36m2025-01-22 11:38:55,997[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:38:56,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005114251776979811, lr[0m
[[36m2025-01-22 11:38:56,039[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:38:56,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0709624793789417 prior_scale[0m
[[36m2025-01-22 11:38:56,071[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003979662587811028 q_scale[0m
[[36m2025-01-22 11:38:56,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:38:56,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-01-22 11:38:56,084[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:38:56,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:39:05,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:39:05,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:39:05,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:39:05,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:39:05,514[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:39:05,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:39:05,515[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:39:05,516[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:39:05,516[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:39:05,546[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:39:05,556[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.16it/s v_num: 0.000      
                                                              rmse/val: 3539.762
                                                              rmse/train:       
                                                              3577.145          
[[36m2025-01-22 11:39:38,162[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:39:38,163[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/017[0m
[[36m2025-01-22 11:39:38,291[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:39:38,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001366508290006281, lr[0m
[[36m2025-01-22 11:39:38,345[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:39:38,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.23743778541235197 prior_scale[0m
[[36m2025-01-22 11:39:38,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016350134126891122 q_scale[0m
[[36m2025-01-22 11:39:38,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:39:38,403[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-01-22 11:39:38,403[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:39:38,404[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:39:48,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:39:48,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:39:48,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:39:48,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:39:48,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:39:48,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:39:48,115[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:39:48,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:39:48,116[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:39:48,132[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:39:48,141[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.71it/s v_num: 0.000      
                                                              rmse/val: 3801.722
                                                              rmse/train:       
                                                              3811.927          
[[36m2025-01-22 11:40:20,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:40:20,450[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/018[0m
[[36m2025-01-22 11:40:20,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:40:20,613[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005500926425493779, lr[0m
[[36m2025-01-22 11:40:20,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:40:20,655[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.025970071269180207 prior_scale[0m
[[36m2025-01-22 11:40:20,679[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034560813455735583 q_scale[0m
[[36m2025-01-22 11:40:20,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:40:20,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-01-22 11:40:20,693[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:40:20,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:40:30,178[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:40:30,184[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:40:30,185[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:40:30,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:40:30,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:40:30,188[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:40:30,189[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:40:30,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:40:30,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:40:30,220[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:40:30,231[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.21it/s v_num: 0.000      
                                                              rmse/val: 3553.001
                                                              rmse/train:       
                                                              3591.438          
[[36m2025-01-22 11:40:59,133[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:40:59,134[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/019[0m
[[36m2025-01-22 11:40:59,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:40:59,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00040724260309403564, lr[0m
[[36m2025-01-22 11:40:59,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:40:59,330[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08770897145459441 prior_scale[0m
[[36m2025-01-22 11:40:59,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001889131440826285 q_scale[0m
[[36m2025-01-22 11:40:59,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:40:59,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-01-22 11:40:59,370[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:40:59,370[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:41:09,274[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:41:09,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:41:09,281[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:41:09,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:41:09,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:41:09,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:41:09,285[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:41:09,285[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:41:09,286[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:41:09,300[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:41:09,310[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4191.896
                                                              rmse/train:       
                                                              4224.682          
[[36m2025-01-22 11:41:20,348[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:41:20,349[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/020[0m
[[36m2025-01-22 11:41:20,475[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:41:20,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009679862849804655, lr[0m
[[36m2025-01-22 11:41:20,528[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:41:20,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08240455328181814 prior_scale[0m
[[36m2025-01-22 11:41:20,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002490880587228065 q_scale[0m
[[36m2025-01-22 11:41:20,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:41:20,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-01-22 11:41:20,592[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:41:20,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:41:30,156[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:41:30,164[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:41:30,165[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:41:30,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:41:30,169[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:41:30,169[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:41:30,170[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:41:30,170[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:41:30,171[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:41:30,186[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:41:30,197[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.71it/s v_num: 0.000      
                                                              rmse/val: 2458.913
                                                              rmse/train:       
                                                              2525.330          
[[36m2025-01-22 11:42:05,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:42:05,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/021[0m
[[36m2025-01-22 11:42:05,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:42:05,357[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007770265485334621, lr[0m
[[36m2025-01-22 11:42:05,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:42:05,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05405951837737887 prior_scale[0m
[[36m2025-01-22 11:42:05,418[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00016534376363412323 q_scale[0m
[[36m2025-01-22 11:42:05,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:42:05,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-01-22 11:42:05,436[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:42:05,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:42:15,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:42:15,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:42:15,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:42:15,420[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:42:15,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:42:15,422[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:42:15,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:42:15,424[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:42:15,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:42:15,472[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:42:15,485[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.99it/s v_num: 0.000      
                                                              rmse/val: 3048.691
                                                              rmse/train:       
                                                              3109.569          
[[36m2025-01-22 11:42:49,832[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:42:49,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/022[0m
[[36m2025-01-22 11:42:49,959[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:42:49,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007073051856217142, lr[0m
[[36m2025-01-22 11:42:50,016[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:42:50,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10781513953081338 prior_scale[0m
[[36m2025-01-22 11:42:50,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046469208788546074 q_scale[0m
[[36m2025-01-22 11:42:50,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:42:50,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-01-22 11:42:50,074[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:42:50,074[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:43:00,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:43:00,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:43:00,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:43:00,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:43:00,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:43:00,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:43:00,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:43:00,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:43:00,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:43:00,161[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:43:00,172[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 11.78it/s v_num: 0.000      
                                                              rmse/val: 3284.097
                                                              rmse/train:       
                                                              3334.171          
[[36m2025-01-22 11:43:38,119[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:43:38,120[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/023[0m
[[36m2025-01-22 11:43:38,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:43:38,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003558250160840399, lr[0m
[[36m2025-01-22 11:43:38,331[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:43:38,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06157980360943647 prior_scale[0m
[[36m2025-01-22 11:43:38,388[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007488257567865461 q_scale[0m
[[36m2025-01-22 11:43:38,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:43:38,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-01-22 11:43:38,409[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:43:38,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:43:49,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:43:49,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:43:49,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:43:49,328[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:43:49,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:43:49,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:43:49,330[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:43:49,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:43:49,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:43:49,365[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:43:49,374[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 9.21it/s v_num: 0.000      
                                                              rmse/val: 4102.663
                                                              rmse/train:       
                                                              4136.055          
[[36m2025-01-22 11:44:05,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:44:05,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/024[0m
[[36m2025-01-22 11:44:05,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:44:05,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017724142198647622, lr[0m
[[36m2025-01-22 11:44:05,785[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:44:05,806[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03569853242983112 prior_scale[0m
[[36m2025-01-22 11:44:05,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014620452846020177 q_scale[0m
[[36m2025-01-22 11:44:05,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:44:05,846[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-01-22 11:44:05,846[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:44:05,847[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:44:15,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:44:16,182[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:44:16,187[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:44:16,189[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:44:16,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:44:16,190[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:44:16,191[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:44:16,191[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:44:16,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:44:16,208[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:44:16,219[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.95it/s v_num: 0.000      
                                                              rmse/val: 4092.120
                                                              rmse/train:       
                                                              4126.815          
[[36m2025-01-22 11:44:50,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:44:50,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/025[0m
[[36m2025-01-22 11:44:50,680[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:44:50,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007025761259277042, lr[0m
[[36m2025-01-22 11:44:50,733[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:44:50,753[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07836114921928836 prior_scale[0m
[[36m2025-01-22 11:44:50,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00027255810611588485 q_scale[0m
[[36m2025-01-22 11:44:50,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:44:50,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-01-22 11:44:50,799[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:44:50,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:45:01,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:45:01,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:45:01,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:45:01,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:45:01,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:45:01,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:45:01,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:45:01,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:45:01,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:45:01,095[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:45:01,106[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.95it/s v_num: 0.000      
                                                              rmse/val: 3083.207
                                                              rmse/train:       
                                                              3135.445          
[[36m2025-01-22 11:45:36,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:45:36,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/026[0m
[[36m2025-01-22 11:45:36,510[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:45:36,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000990185639445059, lr[0m
[[36m2025-01-22 11:45:36,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:45:36,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18193608347274076 prior_scale[0m
[[36m2025-01-22 11:45:36,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023814053427689518 q_scale[0m
[[36m2025-01-22 11:45:36,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:45:36,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-01-22 11:45:36,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:45:36,642[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:45:46,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:45:46,247[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:45:46,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:45:46,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:45:46,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:45:46,250[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:45:46,251[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:45:46,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:45:46,252[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:45:46,270[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:45:46,281[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.64it/s v_num: 0.000      
                                                              rmse/val: 1971.396
                                                              rmse/train:       
                                                              2039.306          
[[36m2025-01-22 11:46:22,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:46:22,010[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/027[0m
[[36m2025-01-22 11:46:22,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:46:22,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004726989984622801, lr[0m
[[36m2025-01-22 11:46:22,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:46:22,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.42975021805218055 prior_scale[0m
[[36m2025-01-22 11:46:22,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010270764604224156 q_scale[0m
[[36m2025-01-22 11:46:22,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:46:22,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-01-22 11:46:22,279[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:46:22,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:46:32,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:46:32,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:46:32,302[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:46:32,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:46:32,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:46:32,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:46:32,306[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:46:32,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:46:32,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:46:32,341[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:46:32,352[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.74it/s v_num: 0.000      
                                                              rmse/val: 3741.954
                                                              rmse/train:       
                                                              3791.275          
[[36m2025-01-22 11:47:07,389[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:47:07,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/028[0m
[[36m2025-01-22 11:47:07,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:47:07,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006820041949567369, lr[0m
[[36m2025-01-22 11:47:07,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:47:07,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19845433183344957 prior_scale[0m
[[36m2025-01-22 11:47:07,617[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011960230355308327 q_scale[0m
[[36m2025-01-22 11:47:07,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:47:07,637[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-01-22 11:47:07,638[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:47:07,638[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:47:17,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:47:17,476[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:47:17,476[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:47:17,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:47:17,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:47:17,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:47:17,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:47:17,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:47:17,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:47:17,500[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:47:17,509[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 10.62it/s v_num: 0.000      
                                                              rmse/val: 3486.535
                                                              rmse/train:       
                                                              3500.743          
[[36m2025-01-22 11:47:31,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:47:31,769[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/029[0m
[[36m2025-01-22 11:47:31,887[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:47:31,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022374241409023137, lr[0m
[[36m2025-01-22 11:47:31,942[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:47:31,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2969865761840165 prior_scale[0m
[[36m2025-01-22 11:47:31,991[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00953852085011636 q_scale[0m
[[36m2025-01-22 11:47:32,012[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:47:32,013[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-01-22 11:47:32,013[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:47:32,013[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:47:42,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:47:42,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:47:42,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:47:42,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:47:42,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:47:42,638[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:47:42,639[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:47:42,639[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:47:42,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:47:42,671[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:47:42,680[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 18/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 3719.177
                                                              rmse/train:       
                                                              3736.317          
[[36m2025-01-22 11:47:54,003[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 18.
[[36m2025-01-22 11:47:54,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:47:54,094[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:47:54,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009646764555645514, lr[0m
[[36m2025-01-22 11:47:54,143[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:47:54,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10021793786481067 prior_scale[0m
[[36m2025-01-22 11:47:54,179[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002321012524663248 q_scale[0m
[[36m2025-01-22 11:47:54,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:47:54,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-01-22 11:47:54,196[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:47:54,196[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:48:04,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:48:04,284[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:48:04,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:48:04,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:48:04,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:48:04,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:48:04,288[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:48:04,288[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:48:04,289[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:48:04,303[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:48:04,313[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.37it/s v_num: 0.000      
                                                              rmse/val: 2249.374
                                                              rmse/train:       
                                                              2325.829          
[[36m2025-01-22 11:48:39,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:48:39,567[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/031[0m
[[36m2025-01-22 11:48:39,690[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:48:39,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009843906366807389, lr[0m
[[36m2025-01-22 11:48:39,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:48:39,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1563405311502479 prior_scale[0m
[[36m2025-01-22 11:48:39,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032879613807699083 q_scale[0m
[[36m2025-01-22 11:48:39,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:48:39,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-01-22 11:48:39,798[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:48:39,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:48:49,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:48:49,938[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:48:49,939[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:48:49,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:48:49,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:48:49,942[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:48:49,943[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:48:49,943[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:48:49,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:48:49,980[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:48:49,989[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.08it/s v_num: 0.000      
                                                              rmse/val: 2417.155
                                                              rmse/train:       
                                                              2483.885          
[[36m2025-01-22 11:49:24,197[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:49:24,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/032[0m
[[36m2025-01-22 11:49:24,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:49:24,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006174528519213103, lr[0m
[[36m2025-01-22 11:49:24,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:49:24,446[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14772195562306706 prior_scale[0m
[[36m2025-01-22 11:49:24,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006107125755640045 q_scale[0m
[[36m2025-01-22 11:49:24,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:49:24,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-01-22 11:49:24,492[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:49:24,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:49:34,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:49:34,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:49:34,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:49:34,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:49:34,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:49:34,416[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:49:34,417[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:49:34,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:49:34,418[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:49:34,434[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:49:34,443[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.47it/s v_num: 0.000      
                                                              rmse/val: 3126.688
                                                              rmse/train:       
                                                              3168.349          
[[36m2025-01-22 11:50:06,803[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:50:06,805[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/033[0m
[[36m2025-01-22 11:50:06,924[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:50:06,967[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003712267798262111, lr[0m
[[36m2025-01-22 11:50:06,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:50:07,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.19992696056996972 prior_scale[0m
[[36m2025-01-22 11:50:07,021[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00036259938097175877 q_scale[0m
[[36m2025-01-22 11:50:07,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:50:07,038[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-01-22 11:50:07,038[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:50:07,039[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:50:17,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:50:17,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:50:17,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:50:17,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:50:17,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:50:17,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:50:17,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:50:17,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:50:17,309[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:50:17,342[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:50:17,399[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 10.19it/s v_num: 0.000      
                                                              rmse/val: 4300.986
                                                              rmse/train:       
                                                              4315.459          
[[36m2025-01-22 11:50:31,815[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:50:31,816[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/034[0m
[[36m2025-01-22 11:50:31,951[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:50:31,987[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000749684389025907, lr[0m
[[36m2025-01-22 11:50:32,006[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:50:32,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11656176085369487 prior_scale[0m
[[36m2025-01-22 11:50:32,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021349205812016536 q_scale[0m
[[36m2025-01-22 11:50:32,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:50:32,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-01-22 11:50:32,063[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:50:32,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:50:41,749[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:50:42,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:50:42,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:50:42,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:50:42,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:50:42,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:50:42,079[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:50:42,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:50:42,081[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:50:42,095[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:50:42,105[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.87it/s v_num: 0.000      
                                                              rmse/val: 3354.749
                                                              rmse/train:       
                                                              3410.053          
[[36m2025-01-22 11:51:16,544[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:51:16,545[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/035[0m
[[36m2025-01-22 11:51:16,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:51:16,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00045610715299313186, lr[0m
[[36m2025-01-22 11:51:16,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:51:16,758[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.28982129728057526 prior_scale[0m
[[36m2025-01-22 11:51:16,778[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000510151423477696 q_scale[0m
[[36m2025-01-22 11:51:16,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:51:16,794[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-01-22 11:51:16,795[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:51:16,795[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:51:27,551[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:51:27,558[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:51:27,559[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:51:27,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:51:27,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:51:27,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:51:27,563[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:51:27,563[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:51:27,564[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:51:27,596[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:51:27,606[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 3924.694
                                                              rmse/train:       
                                                              3959.231          
[[36m2025-01-22 11:51:37,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:51:37,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/036[0m
[[36m2025-01-22 11:51:37,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:51:37,384[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005590836153201006, lr[0m
[[36m2025-01-22 11:51:37,402[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:51:37,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16869944898530467 prior_scale[0m
[[36m2025-01-22 11:51:37,444[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004603624831452556 q_scale[0m
[[36m2025-01-22 11:51:37,460[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:51:37,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-01-22 11:51:37,461[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:51:37,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:51:47,495[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:51:47,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:51:47,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:51:47,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:51:47,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:51:47,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:51:47,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:51:47,507[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:51:47,508[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:51:47,523[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:51:47,534[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.11it/s v_num: 0.000      
                                                              rmse/val: 3327.454
                                                              rmse/train:       
                                                              3361.471          
[[36m2025-01-22 11:52:21,384[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:52:21,385[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/037[0m
[[36m2025-01-22 11:52:21,512[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:52:21,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6429465259517205e-05, lr[0m
[[36m2025-01-22 11:52:21,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:52:21,583[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13903975936246293 prior_scale[0m
[[36m2025-01-22 11:52:21,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034498075135089816 q_scale[0m
[[36m2025-01-22 11:52:21,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:52:21,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-01-22 11:52:21,621[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:52:21,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:52:31,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:52:31,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:52:31,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:52:31,155[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:52:31,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:52:31,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:52:31,157[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:52:31,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:52:31,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:52:31,190[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:52:31,202[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 28.45it/s v_num: 0.000      
                                                              rmse/val: 4254.585
                                                              rmse/train:       
                                                              4291.136          
[[36m2025-01-22 11:52:55,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:52:55,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/038[0m
[[36m2025-01-22 11:52:55,740[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:52:55,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0774254950974043e-05, lr[0m
[[36m2025-01-22 11:52:55,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:52:55,812[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10138720301369564 prior_scale[0m
[[36m2025-01-22 11:52:55,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006723722881369775 q_scale[0m
[[36m2025-01-22 11:52:55,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:52:55,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-01-22 11:52:55,851[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:52:55,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:53:05,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:53:05,962[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:53:05,963[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:53:05,966[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:53:05,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:53:05,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:53:05,968[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:53:05,968[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:53:05,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:53:05,985[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:53:05,995[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.32it/s v_num: 0.000      
                                                              rmse/val: 4294.886
                                                              rmse/train:       
                                                              4329.339          
[[36m2025-01-22 11:53:39,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:53:39,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/039[0m
[[36m2025-01-22 11:53:39,563[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:53:39,665[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.98492610543479e-05, lr[0m
[[36m2025-01-22 11:53:39,681[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:53:39,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26713084826086575 prior_scale[0m
[[36m2025-01-22 11:53:39,722[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004267076687169245 q_scale[0m
[[36m2025-01-22 11:53:39,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:53:39,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-01-22 11:53:39,739[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:53:39,739[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:53:49,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:53:49,858[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:53:49,859[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:53:49,863[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:53:49,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:53:49,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:53:49,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:53:49,867[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:53:49,869[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:53:49,907[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:53:49,917[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 20.60it/s v_num: 0.000      
                                                              rmse/val: 4586.239
                                                              rmse/train:       
                                                              4644.619          
[[36m2025-01-22 11:54:01,369[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:54:01,370[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/040[0m
[[36m2025-01-22 11:54:01,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:54:01,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009146432069933014, lr[0m
[[36m2025-01-22 11:54:01,550[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:54:01,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16537120318658394 prior_scale[0m
[[36m2025-01-22 11:54:01,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013984919802601455 q_scale[0m
[[36m2025-01-22 11:54:01,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:54:01,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-01-22 11:54:01,609[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:54:01,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:54:11,012[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:54:11,019[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:54:11,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:54:11,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:54:11,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:54:11,024[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:54:11,025[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:54:11,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:54:11,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:54:11,040[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:54:11,050[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.00it/s v_num: 0.000      
                                                              rmse/val: 2910.628
                                                              rmse/train:       
                                                              2978.623          
[[36m2025-01-22 11:54:44,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:54:44,853[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/041[0m
[[36m2025-01-22 11:54:44,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:54:45,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008118377860887924, lr[0m
[[36m2025-01-22 11:54:45,065[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:54:45,093[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06145956478409956 prior_scale[0m
[[36m2025-01-22 11:54:45,120[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020795854232671075 q_scale[0m
[[36m2025-01-22 11:54:45,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:54:45,141[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-01-22 11:54:45,142[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:54:45,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:54:55,048[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:54:55,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:54:55,057[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:54:55,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:54:55,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:54:55,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:54:55,061[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:54:55,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:54:55,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:54:55,094[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:54:55,106[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.05it/s v_num: 0.000      
                                                              rmse/val: 2809.566
                                                              rmse/train:       
                                                              2866.993          
[[36m2025-01-22 11:55:28,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:55:28,714[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/042[0m
[[36m2025-01-22 11:55:28,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:55:28,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006190840286514162, lr[0m
[[36m2025-01-22 11:55:28,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:55:28,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13640122723307024 prior_scale[0m
[[36m2025-01-22 11:55:28,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00030256812620862484 q_scale[0m
[[36m2025-01-22 11:55:28,947[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:55:28,948[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-01-22 11:55:28,948[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:55:28,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:55:38,450[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:55:38,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:55:38,457[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:55:38,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:55:38,459[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:55:38,460[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:55:38,461[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:55:38,461[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:55:38,462[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:55:38,478[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:55:38,487[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 12.99it/s v_num: 0.000      
                                                              rmse/val: 3438.235
                                                              rmse/train:       
                                                              3491.375          
[[36m2025-01-22 11:56:13,352[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:56:13,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/043[0m
[[36m2025-01-22 11:56:13,459[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:56:13,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009967549580536376, lr[0m
[[36m2025-01-22 11:56:13,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:56:13,523[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015743915991210777 prior_scale[0m
[[36m2025-01-22 11:56:13,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013715352468001647 q_scale[0m
[[36m2025-01-22 11:56:13,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:56:13,555[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-01-22 11:56:13,555[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:56:13,555[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:56:23,661[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:56:23,670[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:56:23,670[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:56:23,672[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:56:23,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:56:23,673[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:56:23,674[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:56:23,674[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:56:23,675[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:56:23,707[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:56:23,717[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.36it/s v_num: 0.000      
                                                              rmse/val: 2787.093
                                                              rmse/train:       
                                                              2854.760          
[[36m2025-01-22 11:56:54,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:56:54,841[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/044[0m
[[36m2025-01-22 11:56:54,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:56:54,987[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007701902333351202, lr[0m
[[36m2025-01-22 11:56:55,003[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:56:55,026[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10022597492681883 prior_scale[0m
[[36m2025-01-22 11:56:55,048[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023488952166158256 q_scale[0m
[[36m2025-01-22 11:56:55,065[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:56:55,065[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-01-22 11:56:55,065[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:56:55,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:57:05,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:57:05,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:57:05,405[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:57:05,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:57:05,408[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:57:05,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:57:05,409[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:57:05,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:57:05,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:57:05,426[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:57:05,436[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.03it/s v_num: 0.000      
                                                              rmse/val: 3768.283
                                                              rmse/train:       
                                                              3802.232          
[[36m2025-01-22 11:57:26,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:57:26,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/045[0m
[[36m2025-01-22 11:57:26,431[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:57:26,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003151887612375361, lr[0m
[[36m2025-01-22 11:57:26,482[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:57:26,500[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011493120016045792 prior_scale[0m
[[36m2025-01-22 11:57:26,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001826556171765996 q_scale[0m
[[36m2025-01-22 11:57:26,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:57:26,536[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-01-22 11:57:26,536[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:57:26,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:57:35,962[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:57:39,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:57:39,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:57:39,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:57:39,955[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:57:39,956[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:57:39,957[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:57:39,957[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:57:39,958[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:57:39,990[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:57:40,002[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 27.58it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3681.281         
                                                               rmse/train:      
                                                               3773.856         
[[36m2025-01-22 11:58:15,319[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[[36m2025-01-22 11:58:15,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:58:15,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:58:15,448[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.116042126435585e-05, lr[0m
[[36m2025-01-22 11:58:15,465[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:58:15,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.36376199132050335 prior_scale[0m
[[36m2025-01-22 11:58:15,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012727404492185356 q_scale[0m
[[36m2025-01-22 11:58:15,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:58:15,520[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-01-22 11:58:15,521[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:58:15,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:58:25,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:58:25,022[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:58:25,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:58:25,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:58:25,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:58:25,026[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:58:25,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:58:25,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:58:25,028[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:58:25,043[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:58:25,053[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 15/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.41it/s v_num: 0.000      
                                                              rmse/val: 3794.982
                                                              rmse/train:       
                                                              3847.173          
[[36m2025-01-22 11:58:51,691[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 15.
[[36m2025-01-22 11:58:51,695[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:58:51,779[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:58:51,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046997340862863613, lr[0m
[[36m2025-01-22 11:58:51,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:58:51,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03407723251952174 prior_scale[0m
[[36m2025-01-22 11:58:51,865[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003080083843795882 q_scale[0m
[[36m2025-01-22 11:58:51,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:58:51,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-01-22 11:58:51,881[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:58:51,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:59:02,457[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:59:02,464[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:59:02,464[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:59:02,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:59:02,466[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:59:02,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:59:02,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:59:02,468[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:59:02,469[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:59:02,502[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:59:02,511[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4121.485
                                                              rmse/train:       
                                                              4153.129          
[[36m2025-01-22 11:59:14,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:59:14,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/048[0m
[[36m2025-01-22 11:59:14,470[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:59:14,515[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006112237319911698, lr[0m
[[36m2025-01-22 11:59:14,534[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:59:14,558[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12548953055135162 prior_scale[0m
[[36m2025-01-22 11:59:14,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009328242432784611 q_scale[0m
[[36m2025-01-22 11:59:14,592[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 11:59:14,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-01-22 11:59:14,593[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:59:14,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:59:24,129[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:59:24,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:59:24,137[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:59:24,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:59:24,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:59:24,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:59:24,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:59:24,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:59:24,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:59:24,157[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:59:24,169[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 15.01it/s v_num: 0.000      
                                                              rmse/val: 3447.272
                                                              rmse/train:       
                                                              3497.550          
[[36m2025-01-22 11:59:57,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:59:57,965[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/049[0m
[[36m2025-01-22 11:59:58,077[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:59:58,112[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009992853727526475, lr[0m
[[36m2025-01-22 11:59:58,127[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:59:58,146[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04237314865449115 prior_scale[0m
[[36m2025-01-22 11:59:58,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017479605700048827 q_scale[0m
[[36m2025-01-22 11:59:58,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:59:58,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-01-22 11:59:58,181[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:59:58,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:00:08,248[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:00:08,255[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:00:08,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:00:08,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:00:08,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:00:08,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:00:08,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:00:08,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:00:08,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:00:08,292[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:00:08,300[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 12.31it/s v_num: 0.000      
                                                              rmse/val: 3554.221
                                                              rmse/train:       
                                                              3590.669          
[[36m2025-01-22 12:00:27,940[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:00:27,941[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/050[0m
[[36m2025-01-22 12:00:28,057[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:00:28,096[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008214198456843767, lr[0m
[[36m2025-01-22 12:00:28,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:00:28,131[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09239841838636398 prior_scale[0m
[[36m2025-01-22 12:00:28,150[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002540664940473069 q_scale[0m
[[36m2025-01-22 12:00:28,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 12:00:28,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-01-22 12:00:28,166[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:00:28,167[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:00:37,872[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:00:37,880[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:00:37,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:00:37,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:00:37,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:00:37,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:00:37,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:00:37,884[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:00:37,885[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:00:37,899[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:00:37,907[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.93it/s v_num: 0.000      
                                                              rmse/val: 2871.559
                                                              rmse/train:       
                                                              2924.271          
[[36m2025-01-22 12:01:11,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:01:11,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/051[0m
[[36m2025-01-22 12:01:11,553[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:01:11,588[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008391929519439175, lr[0m
[[36m2025-01-22 12:01:11,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:01:11,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06952840935615917 prior_scale[0m
[[36m2025-01-22 12:01:11,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001605525097824885 q_scale[0m
[[36m2025-01-22 12:01:11,657[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 12:01:11,658[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-01-22 12:01:11,658[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:01:11,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:01:21,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:01:21,514[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:01:21,515[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:01:21,517[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:01:21,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:01:21,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:01:21,519[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:01:21,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:01:21,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:01:21,563[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:01:21,578[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 13.93it/s v_num: 0.000      
                                                              rmse/val: 2707.318
                                                              rmse/train:       
                                                              2770.866          
[[36m2025-01-22 12:01:55,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:01:55,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/052[0m
[[36m2025-01-22 12:01:55,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:01:55,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006394555780615936, lr[0m
[[36m2025-01-22 12:01:55,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:01:55,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023229378680878356 prior_scale[0m
[[36m2025-01-22 12:01:55,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023309852129689093 q_scale[0m
[[36m2025-01-22 12:01:55,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-22 12:01:55,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-01-22 12:01:55,478[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:01:55,479[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:02:05,295[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:02:05,302[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:02:05,303[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:02:05,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:02:05,305[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:02:05,306[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:02:05,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:02:05,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:02:05,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:02:05,332[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:02:05,347[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 6/6 0:00:00 • 0:00:00 14.05it/s v_num: 0.000      
                                                              rmse/val: 3476.342
                                                              rmse/train:       
                                                              3519.392          
[[36m2025-01-22 12:02:38,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:02:38,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/053[0m
[[36m2025-01-22 12:02:39,064[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:02:39,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008506684504008522, lr[0m
[[36m2025-01-22 12:02:39,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:02:39,133[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05659665637416165 prior_scale[0m
[[36m2025-01-22 12:02:39,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044230868985090056 q_scale[0m
[[36m2025-01-22 12:02:39,168[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:02:39,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-01-22 12:02:39,169[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:02:39,169[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:02:48,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:02:48,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:02:48,488[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:02:48,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:02:48,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:02:48,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:02:48,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:02:48,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:02:48,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:02:48,539[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:02:48,607[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 15.44it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1195.736         
                                                               rmse/train:      
                                                               1239.089         
[[36m2025-01-22 12:03:49,253[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:03:49,254[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/054[0m
[[36m2025-01-22 12:03:49,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:03:49,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005460624979106341, lr[0m
[[36m2025-01-22 12:03:49,453[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:03:49,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.049330426132273286 prior_scale[0m
[[36m2025-01-22 12:03:49,505[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046752732905870766 q_scale[0m
[[36m2025-01-22 12:03:49,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:03:49,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-01-22 12:03:49,526[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:03:49,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:03:59,027[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:03:59,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:03:59,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:03:59,038[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:03:59,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:03:59,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:03:59,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:03:59,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:03:59,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:03:59,087[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:03:59,102[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 14.81it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2110.921         
                                                               rmse/train:      
                                                               2172.344         
[[36m2025-01-22 12:05:02,847[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:05:02,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/055[0m
[[36m2025-01-22 12:05:02,990[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:05:03,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005268898372622154, lr[0m
[[36m2025-01-22 12:05:03,058[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:05:03,085[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06002932620258774 prior_scale[0m
[[36m2025-01-22 12:05:03,112[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004915204447357464 q_scale[0m
[[36m2025-01-22 12:05:03,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:05:03,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-01-22 12:05:03,135[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:05:03,135[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:05:12,605[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:05:12,612[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:05:12,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:05:12,616[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:05:12,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:05:12,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:05:12,618[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:05:12,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:05:12,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:05:12,653[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:05:12,661[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 14.81it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2280.260         
                                                               rmse/train:      
                                                               2346.995         
[[36m2025-01-22 12:06:11,916[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:06:11,918[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/056[0m
[[36m2025-01-22 12:06:12,037[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:06:12,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003930641644457963, lr[0m
[[36m2025-01-22 12:06:12,088[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 12:06:12,109[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04885085601767845 prior_scale[0m
[[36m2025-01-22 12:06:12,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005196005146717891 q_scale[0m
[[36m2025-01-22 12:06:12,149[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:06:12,149[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-01-22 12:06:12,150[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:06:12,150[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:06:21,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:06:21,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:06:21,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:06:21,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:06:21,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:06:21,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:06:21,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:06:21,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:06:21,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:06:21,648[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:06:21,660[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 17/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 27.54it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3118.312         
                                                               rmse/train:      
                                                               3267.351         
[[36m2025-01-22 12:07:04,473[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 17.
[[36m2025-01-22 12:07:04,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:07:04,569[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:07:04,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005054815966376051, lr[0m
[[36m2025-01-22 12:07:04,620[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:07:04,640[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05728828692886197 prior_scale[0m
[[36m2025-01-22 12:07:04,660[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000406447257278616 q_scale[0m
[[36m2025-01-22 12:07:04,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:07:04,676[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-01-22 12:07:04,677[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:07:04,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:07:14,297[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:07:14,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:07:14,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:07:14,307[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:07:14,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:07:14,309[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:07:14,310[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:07:14,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:07:14,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:07:14,325[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:07:14,335[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 14.20it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2368.236         
                                                               rmse/train:      
                                                               2430.557         
[[36m2025-01-22 12:08:22,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:08:22,814[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/058[0m
[[36m2025-01-22 12:08:23,885[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 12:08:24,002[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024867124664336714, lr[0m
[[36m2025-01-22 12:08:24,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 12:08:24,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06078221176285007 prior_scale[0m
[[36m2025-01-22 12:08:24,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007803153753409471 q_scale[0m
[[36m2025-01-22 12:08:24,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 12:08:24,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-01-22 12:08:24,261[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 12:08:24,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 12:08:33,923[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 12:08:33,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 12:08:33,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 12:08:33,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 12:08:33,933[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 12:08:33,934[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 12:08:33,935[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 12:08:33,935[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 12:08:33,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 12:08:33,989[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 12:08:34,004[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 16.94it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3613.736         
                                                               rmse/train:      
                                                               3657.538         
[[36m2025-01-22 12:09:30,986[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 12:09:30,988[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_lrt/runs/2025-01-22_11-27-26/059[0m
[[36m2025-01-22 12:09:31,078[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
