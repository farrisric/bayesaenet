{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-01-21 15:15:32,525[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-01-21 15:15:32,526[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_rad.db[0m
[[36m2025-01-21 15:15:33,040[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-01-21 15:15:33,048[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-01-21 15:15:33,118[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:15:33,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-01-21 15:15:33,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:15:33,183[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21592388039429916 prior_scale[0m
[[36m2025-01-21 15:15:33,199[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036303760732131728 q_scale[0m
[[36m2025-01-21 15:15:33,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 15:15:33,214[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-01-21 15:15:33,215[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:15:33,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:15:42,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:15:42,879[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:15:42,879[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:15:42,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:15:42,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:15:42,882[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:15:42,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:15:42,888[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:15:42,899[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:15:43,088[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:15:43,236[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 29.49it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3981.120         
                                                               rmse/train:      
                                                               4067.901         
[[36m2025-01-21 15:16:09,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:16:09,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/000[0m
[[36m2025-01-21 15:16:09,182[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:16:09,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-01-21 15:16:09,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:16:09,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16250224524496343 prior_scale[0m
[[36m2025-01-21 15:16:09,253[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005501758328845987 q_scale[0m
[[36m2025-01-21 15:16:09,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 15:16:09,267[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-01-21 15:16:09,267[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:16:09,268[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:16:19,030[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:16:19,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:16:19,038[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:16:19,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:16:19,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:16:19,041[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:16:19,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:16:19,042[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:16:19,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:16:19,071[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:16:19,079[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 9.46it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3968.203         
                                                               rmse/train:      
                                                               4057.993         
[[36m2025-01-21 15:16:50,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:16:50,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/001[0m
[[36m2025-01-21 15:16:50,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:16:50,296[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-01-21 15:16:50,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:16:50,325[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04232733477101895 prior_scale[0m
[[36m2025-01-21 15:16:50,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0073498792462323385 q_scale[0m
[[36m2025-01-21 15:16:50,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:16:50,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-01-21 15:16:50,354[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:16:50,354[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:16:59,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:16:59,609[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:16:59,610[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:16:59,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:16:59,612[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:16:59,613[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:16:59,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:16:59,614[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:16:59,615[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:16:59,653[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:16:59,664[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 35.99it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3459.470         
                                                               rmse/train:      
                                                               3551.035         
[[36m2025-01-21 15:17:39,419[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:17:39,421[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/002[0m
[[36m2025-01-21 15:17:39,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:17:39,540[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-01-21 15:17:39,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:17:39,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017549127225111354 prior_scale[0m
[[36m2025-01-21 15:17:39,575[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002561662685923485 q_scale[0m
[[36m2025-01-21 15:17:39,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:17:39,589[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-01-21 15:17:39,589[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:17:39,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:17:49,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:17:49,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:17:49,095[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:17:49,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:17:49,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:17:49,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:17:49,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:17:49,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:17:49,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:17:49,132[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:17:49,140[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.54it/s v_num: 0.000     
                                                               rmse/val: 55.935 
                                                               rmse/train:      
                                                               53.310           
[[36m2025-01-21 15:18:52,910[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:18:52,911[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/003[0m
[[36m2025-01-21 15:18:53,035[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:18:53,068[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-01-21 15:18:53,082[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:18:53,097[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14015302623589543 prior_scale[0m
[[36m2025-01-21 15:18:53,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001546142648648774 q_scale[0m
[[36m2025-01-21 15:18:53,125[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:18:53,126[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-01-21 15:18:53,126[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:18:53,126[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:19:02,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:19:02,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:19:02,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:19:02,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:19:02,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:19:02,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:19:02,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:19:02,527[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:19:02,528[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:19:02,558[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:19:02,568[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 35.93it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3906.994         
                                                               rmse/train:      
                                                               3991.166         
[[36m2025-01-21 15:19:41,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:19:41,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/004[0m
[[36m2025-01-21 15:19:41,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:19:41,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-01-21 15:19:41,468[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:19:41,481[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01026814371296241 prior_scale[0m
[[36m2025-01-21 15:19:41,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017174472922154307 q_scale[0m
[[36m2025-01-21 15:19:41,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:19:41,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-01-21 15:19:41,504[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:19:41,504[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:19:50,910[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:19:50,917[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:19:50,917[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:19:50,919[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:19:50,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:19:50,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:19:50,921[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:19:50,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:19:50,922[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:19:50,959[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:19:50,983[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 36.06it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4046.350         
                                                               rmse/train:      
                                                               4133.174         
[[36m2025-01-21 15:20:30,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:20:30,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/005[0m
[[36m2025-01-21 15:20:30,774[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:20:30,801[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-01-21 15:20:30,814[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:20:30,827[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021500386108909676 prior_scale[0m
[[36m2025-01-21 15:20:30,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005816140699158816 q_scale[0m
[[36m2025-01-21 15:20:30,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:20:30,851[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-01-21 15:20:30,851[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:20:30,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:20:40,044[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:20:40,051[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:20:40,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:20:40,053[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:20:40,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:20:40,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:20:40,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:20:40,055[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:20:40,056[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:20:40,087[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:20:40,095[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 34.38it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3840.889         
                                                               rmse/train:      
                                                               3930.729         
[[36m2025-01-21 15:21:19,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:21:19,427[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/006[0m
[[36m2025-01-21 15:21:19,549[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:21:19,579[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-01-21 15:21:19,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:21:19,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015205659078436342 prior_scale[0m
[[36m2025-01-21 15:21:19,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002873671566774025 q_scale[0m
[[36m2025-01-21 15:21:19,635[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:21:19,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-01-21 15:21:19,636[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:21:19,636[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:21:28,972[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:21:28,979[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:21:28,980[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:21:28,982[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:21:28,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:21:28,983[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:21:28,984[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:21:28,984[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:21:28,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:21:29,014[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:21:29,021[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:04 •       40.96it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.411 
                                                               rmse/train:      
                                                               40.507           
[[36m2025-01-21 15:23:41,181[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:23:41,182[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/007[0m
[[36m2025-01-21 15:23:41,279[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:23:41,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-01-21 15:23:41,315[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:23:41,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2025-01-21 15:23:41,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2025-01-21 15:23:41,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:23:41,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-01-21 15:23:41,350[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:23:41,350[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:23:50,782[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:23:50,789[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:23:50,789[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:23:50,791[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:23:50,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:23:50,792[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:23:50,793[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:23:50,793[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:23:50,794[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:23:50,832[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:23:50,839[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.50it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3060.753         
                                                               rmse/train:      
                                                               3176.902         
[[36m2025-01-21 15:24:58,731[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:24:58,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/008[0m
[[36m2025-01-21 15:24:58,845[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:24:58,878[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-01-21 15:24:58,893[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 15:24:58,905[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41347469058863023 prior_scale[0m
[[36m2025-01-21 15:24:58,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009135206248796449 q_scale[0m
[[36m2025-01-21 15:24:58,927[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 15:24:58,928[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-01-21 15:24:58,928[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:24:58,928[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:25:08,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:25:08,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:25:08,294[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:25:08,296[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:25:08,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:25:08,297[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:25:08,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:25:08,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:25:08,299[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:25:08,328[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:25:08,337[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 36.75it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4310.689         
                                                               rmse/train:      
                                                               4393.013         
[[36m2025-01-21 15:25:47,723[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:25:47,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/009[0m
[[36m2025-01-21 15:25:47,830[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:25:47,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008289681104465045, lr[0m
[[36m2025-01-21 15:25:47,876[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:25:47,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03823730602613338 prior_scale[0m
[[36m2025-01-21 15:25:47,912[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00011667005469831107 q_scale[0m
[[36m2025-01-21 15:25:47,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:25:47,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-01-21 15:25:47,927[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:25:47,927[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:25:57,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:25:57,307[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:25:57,308[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:25:57,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:25:57,310[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:25:57,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:25:57,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:25:57,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:25:57,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:25:57,340[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:25:57,347[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 21.09it/s v_num: 0.000     
                                                               rmse/val: 46.667 
                                                               rmse/train:      
                                                               47.379           
[[36m2025-01-21 15:27:54,824[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:27:54,826[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/010[0m
[[36m2025-01-21 15:27:54,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:27:54,988[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009233768742572698, lr[0m
[[36m2025-01-21 15:27:55,004[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:27:55,025[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04155761071630431 prior_scale[0m
[[36m2025-01-21 15:27:55,046[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000282794630712143 q_scale[0m
[[36m2025-01-21 15:27:55,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:27:55,062[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-01-21 15:27:55,063[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:27:55,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:28:04,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:28:04,487[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:28:04,487[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:28:04,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:28:04,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:28:04,490[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:28:04,491[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:28:04,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:28:04,492[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:28:04,532[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:28:04,540[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 21.19it/s v_num: 0.000     
                                                               rmse/val: 66.709 
                                                               rmse/train:      
                                                               49.117           
[[36m2025-01-21 15:30:00,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:30:00,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/011[0m
[[36m2025-01-21 15:30:00,839[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:30:00,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008502926265357448, lr[0m
[[36m2025-01-21 15:30:00,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:30:00,919[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.029627041695089486 prior_scale[0m
[[36m2025-01-21 15:30:00,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001048730182267508 q_scale[0m
[[36m2025-01-21 15:30:01,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:30:01,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-01-21 15:30:01,153[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:30:01,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:30:10,619[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:30:10,625[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:30:10,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:30:10,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:30:10,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:30:10,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:30:10,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:30:10,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:30:10,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:30:10,670[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:30:10,701[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 20.59it/s v_num: 0.000     
                                                               rmse/val: 40.815 
                                                               rmse/train:      
                                                               49.341           
[[36m2025-01-21 15:32:07,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:32:07,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/012[0m
[[36m2025-01-21 15:32:07,160[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:32:07,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000237679721845533, lr[0m
[[36m2025-01-21 15:32:07,201[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:32:07,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06695258493739469 prior_scale[0m
[[36m2025-01-21 15:32:07,230[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010181643448900099 q_scale[0m
[[36m2025-01-21 15:32:07,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:32:07,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-01-21 15:32:07,241[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:32:07,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:32:16,322[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:32:16,329[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:32:16,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:32:16,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:32:16,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:32:16,332[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:32:16,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:32:16,333[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:32:16,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:32:16,373[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:32:16,381[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 21.10it/s v_num: 0.000     
                                                               rmse/val: 37.991 
                                                               rmse/train:      
                                                               37.426           
[[36m2025-01-21 15:34:12,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:34:12,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/013[0m
[[36m2025-01-21 15:34:12,628[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:34:12,656[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004087264896395562, lr[0m
[[36m2025-01-21 15:34:12,668[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:34:12,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.018282903788748788 prior_scale[0m
[[36m2025-01-21 15:34:12,698[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005261536161795869 q_scale[0m
[[36m2025-01-21 15:34:12,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:34:12,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-01-21 15:34:12,714[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:34:12,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:34:22,058[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:34:22,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:34:22,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:34:22,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:34:22,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:34:22,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:34:22,070[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:34:22,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:34:22,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:34:22,110[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:34:22,118[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.58it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 39.919 
                                                               rmse/train:      
                                                               41.921           
[[36m2025-01-21 15:38:03,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:38:03,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/014[0m
[[36m2025-01-21 15:38:03,686[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:38:03,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00017450851815124254, lr[0m
[[36m2025-01-21 15:38:03,725[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:38:03,739[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05727146019576224 prior_scale[0m
[[36m2025-01-21 15:38:03,755[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00955681468403127 q_scale[0m
[[36m2025-01-21 15:38:03,767[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:38:03,767[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-01-21 15:38:03,767[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:38:03,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:38:13,042[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:38:13,049[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:38:13,049[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:38:13,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:38:13,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:38:13,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:38:13,052[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:38:13,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:38:13,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:38:13,090[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:38:13,097[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.87it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 65.445 
                                                               rmse/train:      
                                                               49.009           
[[36m2025-01-21 15:41:55,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:41:55,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/015[0m
[[36m2025-01-21 15:41:55,645[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:41:55,673[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0004411885750554313, lr[0m
[[36m2025-01-21 15:41:55,685[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:41:55,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.010337956258208221 prior_scale[0m
[[36m2025-01-21 15:41:55,716[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005160696009035955 q_scale[0m
[[36m2025-01-21 15:41:55,728[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:41:55,728[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-01-21 15:41:55,728[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:41:55,728[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:42:05,004[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:42:05,011[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:42:05,011[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:42:05,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:42:05,013[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:42:05,014[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:42:05,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:42:05,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:42:05,015[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:42:05,058[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:42:05,069[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       20.48it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.534 
                                                               rmse/train:      
                                                               41.971           
[[36m2025-01-21 15:45:48,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:45:48,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/016[0m
[[36m2025-01-21 15:45:48,321[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:45:48,350[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012252890534510187, lr[0m
[[36m2025-01-21 15:45:48,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:45:48,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02491369077328381 prior_scale[0m
[[36m2025-01-21 15:45:48,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00023106918397671766 q_scale[0m
[[36m2025-01-21 15:45:48,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 15:45:48,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-01-21 15:45:48,425[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:45:48,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:45:57,912[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:46:01,059[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:46:01,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:46:01,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:46:01,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:46:01,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:46:01,063[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:46:01,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:46:01,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:46:01,110[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:46:01,400[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 16.01it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3467.728         
                                                               rmse/train:      
                                                               3561.772         
[[36m2025-01-21 15:46:41,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:46:41,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/017[0m
[[36m2025-01-21 15:46:41,265[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:46:41,291[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047300323081230996, lr[0m
[[36m2025-01-21 15:46:41,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:46:41,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03643423730082071 prior_scale[0m
[[36m2025-01-21 15:46:41,334[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006783653592160783 q_scale[0m
[[36m2025-01-21 15:46:41,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 15:46:41,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-01-21 15:46:41,348[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:46:41,348[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:46:51,364[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:46:51,371[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:46:51,371[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:46:51,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:46:51,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:46:51,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:46:51,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:46:51,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:46:51,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:46:51,402[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:46:51,409[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 10.95it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1934.697         
                                                               rmse/train:      
                                                               2069.454         
[[36m2025-01-21 15:47:21,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:47:21,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/018[0m
[[36m2025-01-21 15:47:21,890[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:47:21,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003098691714986976, lr[0m
[[36m2025-01-21 15:47:21,937[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:47:21,954[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.014678753842394598 prior_scale[0m
[[36m2025-01-21 15:47:21,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018910023153455955 q_scale[0m
[[36m2025-01-21 15:47:21,984[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:47:21,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-01-21 15:47:21,985[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:47:21,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:47:31,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:47:31,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:47:31,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:47:31,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:47:31,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:47:31,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:47:31,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:47:31,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:47:31,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:47:31,291[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:47:31,299[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.59it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 35.398 
                                                               rmse/train:      
                                                               35.530           
[[36m2025-01-21 15:51:13,839[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:51:13,840[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/019[0m
[[36m2025-01-21 15:51:13,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:51:13,973[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006299477142377364, lr[0m
[[36m2025-01-21 15:51:13,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:51:13,999[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08523858468800087 prior_scale[0m
[[36m2025-01-21 15:51:14,015[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0012869781160448476 q_scale[0m
[[36m2025-01-21 15:51:14,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:51:14,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-01-21 15:51:14,027[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:51:14,028[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:51:23,100[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:51:23,107[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:51:23,107[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:51:23,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:51:23,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:51:23,109[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:51:23,110[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:51:23,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:51:23,111[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:51:23,163[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:51:23,174[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 21.08it/s v_num: 0.000     
                                                               rmse/val: 41.311 
                                                               rmse/train:      
                                                               37.130           
[[36m2025-01-21 15:53:20,087[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:53:20,088[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/020[0m
[[36m2025-01-21 15:53:20,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:53:20,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000511446748745484, lr[0m
[[36m2025-01-21 15:53:20,225[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:53:20,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.019297191987028176 prior_scale[0m
[[36m2025-01-21 15:53:20,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0028173842636862374 q_scale[0m
[[36m2025-01-21 15:53:20,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 15:53:20,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-01-21 15:53:20,269[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:53:20,269[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:53:29,366[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:53:29,372[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:53:29,373[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:53:29,374[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:53:29,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:53:29,375[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:53:29,376[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:53:29,376[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:53:29,377[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:53:29,687[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:53:29,697[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 19.11it/s v_num: 0.000     
                                                               rmse/val: 46.682 
                                                               rmse/train:      
                                                               46.626           
[[36m2025-01-21 15:55:27,284[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:55:27,286[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/021[0m
[[36m2025-01-21 15:55:27,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:55:27,454[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009700529618203062, lr[0m
[[36m2025-01-21 15:55:27,469[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:55:27,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.016107415233168478 prior_scale[0m
[[36m2025-01-21 15:55:27,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004259397431537661 q_scale[0m
[[36m2025-01-21 15:55:27,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:55:27,524[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-01-21 15:55:27,525[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:55:27,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:55:36,828[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:55:36,834[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:55:36,834[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:55:36,836[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:55:36,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:55:36,837[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:55:36,838[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:55:36,838[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:55:36,839[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:55:36,879[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:55:36,886[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       20.05it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 58.715 
                                                               rmse/train:      
                                                               58.025           
[[36m2025-01-21 15:59:23,069[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 15:59:23,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/022[0m
[[36m2025-01-21 15:59:23,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 15:59:23,192[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000930779818496283, lr[0m
[[36m2025-01-21 15:59:23,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 15:59:23,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02940237698629712 prior_scale[0m
[[36m2025-01-21 15:59:23,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005337060782109229 q_scale[0m
[[36m2025-01-21 15:59:23,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 15:59:23,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-01-21 15:59:23,251[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 15:59:23,251[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 15:59:32,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 15:59:32,480[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 15:59:32,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 15:59:32,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 15:59:32,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 15:59:32,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 15:59:32,484[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 15:59:32,484[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 15:59:32,485[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 15:59:32,526[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 15:59:32,534[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.76it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 68.204 
                                                               rmse/train:      
                                                               62.341           
[[36m2025-01-21 16:03:18,546[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:03:18,547[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/023[0m
[[36m2025-01-21 16:03:18,646[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:03:18,675[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000936879083027422, lr[0m
[[36m2025-01-21 16:03:18,687[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:03:18,701[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.028452407020411595 prior_scale[0m
[[36m2025-01-21 16:03:18,717[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005209996390340459 q_scale[0m
[[36m2025-01-21 16:03:18,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:03:18,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-01-21 16:03:18,729[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:03:18,729[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:03:28,029[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:03:28,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:03:28,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:03:28,038[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:03:28,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:03:28,039[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:03:28,040[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:03:28,040[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:03:28,041[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:03:28,082[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:03:28,093[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.35it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 118.820
                                                               rmse/train:      
                                                               75.551           
[[36m2025-01-21 16:07:11,987[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:07:11,989[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/024[0m
[[36m2025-01-21 16:07:12,084[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:07:12,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009962595520295419, lr[0m
[[36m2025-01-21 16:07:12,125[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:07:12,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.051220151696682745 prior_scale[0m
[[36m2025-01-21 16:07:12,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004063424272450926 q_scale[0m
[[36m2025-01-21 16:07:12,172[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:07:12,172[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-01-21 16:07:12,172[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:07:12,173[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:07:21,305[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:07:21,312[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:07:21,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:07:21,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:07:21,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:07:21,315[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:07:21,316[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:07:21,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:07:21,317[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:07:21,357[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:07:21,364[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.76it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 95.604 
                                                               rmse/train:      
                                                               71.756           
[[36m2025-01-21 16:11:10,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:11:10,418[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/025[0m
[[36m2025-01-21 16:11:10,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:11:10,542[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006792990792369706, lr[0m
[[36m2025-01-21 16:11:10,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:11:10,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.057813632412833806 prior_scale[0m
[[36m2025-01-21 16:11:10,585[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003940081317448964 q_scale[0m
[[36m2025-01-21 16:11:10,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:11:10,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-01-21 16:11:10,598[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:11:10,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:11:19,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:11:19,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:11:19,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:11:19,665[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:11:19,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:11:19,666[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:11:19,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:11:19,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:11:19,668[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:11:19,708[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:11:19,716[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.51it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 81.030 
                                                               rmse/train:      
                                                               49.648           
[[36m2025-01-21 16:14:59,006[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:14:59,007[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/026[0m
[[36m2025-01-21 16:14:59,100[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:14:59,139[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001684395390488293, lr[0m
[[36m2025-01-21 16:14:59,155[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:14:59,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.013473676795800965 prior_scale[0m
[[36m2025-01-21 16:14:59,198[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.009322449550759119 q_scale[0m
[[36m2025-01-21 16:14:59,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:14:59,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-01-21 16:14:59,216[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:14:59,216[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:15:08,519[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:15:08,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:15:08,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:15:08,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:15:08,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:15:08,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:15:08,529[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:15:08,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:15:08,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:15:08,580[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:15:08,591[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.37it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 49.625 
                                                               rmse/train:      
                                                               41.873           
[[36m2025-01-21 16:18:42,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:18:42,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/027[0m
[[36m2025-01-21 16:18:43,077[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:18:43,111[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00034711034580403263, lr[0m
[[36m2025-01-21 16:18:43,123[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:18:43,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08256865516624648 prior_scale[0m
[[36m2025-01-21 16:18:43,153[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00675137355173054 q_scale[0m
[[36m2025-01-21 16:18:43,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:18:43,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-01-21 16:18:43,165[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:18:43,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:18:52,304[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:18:52,310[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:18:52,311[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:18:52,312[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:18:52,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:18:52,313[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:18:52,314[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:18:52,314[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:18:52,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:18:52,355[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:18:52,366[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.63it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.712 
                                                               rmse/train:      
                                                               47.602           
[[36m2025-01-21 16:22:33,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:22:33,325[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/028[0m
[[36m2025-01-21 16:22:33,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:22:33,455[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003212173996683307, lr[0m
[[36m2025-01-21 16:22:33,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:22:33,483[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08605490878622188 prior_scale[0m
[[36m2025-01-21 16:22:33,497[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0067602539130360685 q_scale[0m
[[36m2025-01-21 16:22:33,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 16:22:33,509[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-01-21 16:22:33,509[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:22:33,509[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:22:43,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:22:43,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:22:43,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:22:43,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:22:43,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:22:43,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:22:43,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:22:43,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:22:43,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:22:43,103[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:22:43,111[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 16.25it/s v_num: 0.000     
                                                               rmse/val: 756.524
                                                               rmse/train:      
                                                               875.877          
[[36m2025-01-21 16:23:22,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:23:22,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/029[0m
[[36m2025-01-21 16:23:22,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:23:22,479[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021962785809566152, lr[0m
[[36m2025-01-21 16:23:22,492[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:23:22,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.28024495941969535 prior_scale[0m
[[36m2025-01-21 16:23:22,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0022110571670609603 q_scale[0m
[[36m2025-01-21 16:23:22,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:23:22,551[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-01-21 16:23:22,552[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:23:22,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:23:31,889[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:23:31,896[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:23:31,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:23:31,898[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:23:31,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:23:31,899[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:23:31,900[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:23:31,900[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:23:31,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:23:31,938[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:23:31,949[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 35.156 
                                                               rmse/train:      
                                                               32.982           
[[36m2025-01-21 16:27:10,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:27:10,736[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/030[0m
[[36m2025-01-21 16:27:10,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:27:10,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007266501899706945, lr[0m
[[36m2025-01-21 16:27:10,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:27:10,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10115013560764104 prior_scale[0m
[[36m2025-01-21 16:27:10,904[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004223717160740409 q_scale[0m
[[36m2025-01-21 16:27:10,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:27:10,916[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-01-21 16:27:10,916[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:27:10,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:27:20,203[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:27:20,210[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:27:20,210[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:27:20,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:27:20,212[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:27:20,213[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:27:20,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:27:20,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:27:20,214[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:27:20,253[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:27:20,261[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.89it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 43.940 
                                                               rmse/train:      
                                                               46.218           
[[36m2025-01-21 16:31:06,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:31:06,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/031[0m
[[36m2025-01-21 16:31:06,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:31:06,161[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005721695030692931, lr[0m
[[36m2025-01-21 16:31:06,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:31:06,189[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09664485646633801 prior_scale[0m
[[36m2025-01-21 16:31:06,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033614615084401962 q_scale[0m
[[36m2025-01-21 16:31:06,218[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:31:06,218[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-01-21 16:31:06,218[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:31:06,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:31:15,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:31:15,488[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:31:15,489[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:31:15,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:31:15,491[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:31:15,492[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:31:15,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:31:15,493[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:31:15,493[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:31:15,533[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:31:15,542[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       20.54it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.993 
                                                               rmse/train:      
                                                               43.720           
[[36m2025-01-21 16:34:55,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:34:55,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/032[0m
[[36m2025-01-21 16:34:55,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:34:55,844[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006849044388452813, lr[0m
[[36m2025-01-21 16:34:55,856[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:34:55,872[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1743256510615692 prior_scale[0m
[[36m2025-01-21 16:34:55,887[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0069232408627635635 q_scale[0m
[[36m2025-01-21 16:34:55,900[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 16:34:55,900[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-01-21 16:34:55,901[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:34:55,901[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:35:05,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:35:05,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:35:05,852[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:35:05,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:35:05,854[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:35:05,855[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:35:05,855[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:35:05,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:35:05,856[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:35:05,897[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:35:05,904[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 10.82it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1040.115         
                                                               rmse/train:      
                                                               1115.018         
[[36m2025-01-21 16:35:36,292[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:35:36,293[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/033[0m
[[36m2025-01-21 16:35:36,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:35:36,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003828675498165357, lr[0m
[[36m2025-01-21 16:35:36,434[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:35:36,448[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2404261613688742 prior_scale[0m
[[36m2025-01-21 16:35:36,461[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004395527265077258 q_scale[0m
[[36m2025-01-21 16:35:36,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:35:36,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-01-21 16:35:36,473[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:35:36,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:35:45,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:35:45,569[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:35:45,569[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:35:45,571[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:35:45,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:35:45,572[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:35:45,573[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:35:45,573[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:35:45,574[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:35:45,603[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:35:45,611[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.87it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 56.429 
                                                               rmse/train:      
                                                               38.557           
[[36m2025-01-21 16:39:29,208[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:39:29,209[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/034[0m
[[36m2025-01-21 16:39:29,367[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:39:29,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006727024702175483, lr[0m
[[36m2025-01-21 16:39:29,426[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:39:29,449[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12734318050289056 prior_scale[0m
[[36m2025-01-21 16:39:29,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006476493061041926 q_scale[0m
[[36m2025-01-21 16:39:29,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:39:29,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-01-21 16:39:29,490[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:39:29,490[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:39:38,546[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:39:38,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:39:38,553[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:39:38,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:39:38,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:39:38,555[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:39:38,556[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:39:38,556[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:39:38,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:39:38,595[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:39:38,603[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.84it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 55.098 
                                                               rmse/train:      
                                                               44.097           
[[36m2025-01-21 16:43:17,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:43:17,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/035[0m
[[36m2025-01-21 16:43:17,354[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:43:17,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007204303781872115, lr[0m
[[36m2025-01-21 16:43:17,394[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:43:17,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12463443684595249 prior_scale[0m
[[36m2025-01-21 16:43:17,424[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0019616768462038846 q_scale[0m
[[36m2025-01-21 16:43:17,437[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 16:43:17,437[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-01-21 16:43:17,437[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:43:17,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:43:26,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:43:26,948[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:43:26,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:43:26,952[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:43:26,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:43:26,953[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:43:26,954[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:43:26,954[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:43:26,955[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:43:27,002[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:43:27,011[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 28.91it/s v_num: 0.000     
                                                               rmse/val: 92.073 
                                                               rmse/train:      
                                                               82.454           
[[36m2025-01-21 16:43:51,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:43:51,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/036[0m
[[36m2025-01-21 16:43:51,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:43:51,682[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005590836153201006, lr[0m
[[36m2025-01-21 16:43:51,694[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:43:51,709[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.17018396626440718 prior_scale[0m
[[36m2025-01-21 16:43:51,724[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0034885845777127555 q_scale[0m
[[36m2025-01-21 16:43:51,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:43:51,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-01-21 16:43:51,736[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:43:51,737[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:44:01,132[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:44:01,138[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:44:01,138[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:44:01,140[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:44:01,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:44:01,141[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:44:01,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:44:01,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:44:01,143[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:44:01,172[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:44:01,179[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       20.65it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 71.077 
                                                               rmse/train:      
                                                               43.117           
[[36m2025-01-21 16:47:42,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:47:42,072[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/037[0m
[[36m2025-01-21 16:47:42,167[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:47:42,197[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.6429465259517205e-05, lr[0m
[[36m2025-01-21 16:47:42,210[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:47:42,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.3374582343207064 prior_scale[0m
[[36m2025-01-21 16:47:42,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007858957117393017 q_scale[0m
[[36m2025-01-21 16:47:42,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 16:47:42,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-01-21 16:47:42,254[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:47:42,254[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:47:52,053[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:47:52,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:47:52,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:47:52,272[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:47:52,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:47:52,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:47:52,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:47:52,279[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:47:52,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:47:52,329[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:47:52,340[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 20.12it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4409.629         
                                                               rmse/train:      
                                                               4505.786         
[[36m2025-01-21 16:48:12,008[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:48:12,009[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/038[0m
[[36m2025-01-21 16:48:12,098[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:48:12,126[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.0774254950974043e-05, lr[0m
[[36m2025-01-21 16:48:12,138[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:48:12,154[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10753359956838172 prior_scale[0m
[[36m2025-01-21 16:48:12,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013485663892149266 q_scale[0m
[[36m2025-01-21 16:48:12,189[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:48:12,190[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-01-21 16:48:12,190[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:48:12,190[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:48:21,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:48:21,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:48:21,532[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:48:21,533[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:48:21,534[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:48:21,535[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:48:21,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:48:21,536[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:48:21,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:48:21,549[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:48:21,557[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.60it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               3609.655         
                                                               rmse/train:      
                                                               3699.825         
[[36m2025-01-21 16:51:59,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:51:59,123[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/039[0m
[[36m2025-01-21 16:51:59,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:51:59,256[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001005988216107681, lr[0m
[[36m2025-01-21 16:51:59,269[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 16:51:59,285[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15333746722088773 prior_scale[0m
[[36m2025-01-21 16:51:59,301[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003099570151942651 q_scale[0m
[[36m2025-01-21 16:51:59,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:51:59,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-01-21 16:51:59,313[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:51:59,313[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:52:08,611[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:52:08,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:52:08,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:52:08,619[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:52:08,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:52:08,620[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:52:08,621[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:52:08,621[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:52:08,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:52:08,675[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:52:08,687[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:04 •       41.62it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 59.801 
                                                               rmse/train:      
                                                               54.082           
[[36m2025-01-21 16:54:18,920[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:54:18,921[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/040[0m
[[36m2025-01-21 16:54:19,034[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:54:19,077[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000804207098809051, lr[0m
[[36m2025-01-21 16:54:19,095[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:54:19,116[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07381140833812387 prior_scale[0m
[[36m2025-01-21 16:54:19,137[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006033032790807908 q_scale[0m
[[36m2025-01-21 16:54:19,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:54:19,152[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-01-21 16:54:19,153[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:54:19,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:54:28,280[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:54:28,287[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:54:28,287[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:54:28,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:54:28,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:54:28,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:54:28,291[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:54:28,291[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:54:28,292[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:54:28,330[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:54:28,338[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.46it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 65.507 
                                                               rmse/train:      
                                                               55.336           
[[36m2025-01-21 16:58:05,483[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 16:58:05,485[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/041[0m
[[36m2025-01-21 16:58:05,618[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 16:58:05,659[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035397834563856726, lr[0m
[[36m2025-01-21 16:58:05,677[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 16:58:05,700[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.20452192882241454 prior_scale[0m
[[36m2025-01-21 16:58:05,718[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007787468498334529 q_scale[0m
[[36m2025-01-21 16:58:05,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 16:58:05,736[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-01-21 16:58:05,736[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 16:58:05,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 16:58:15,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 16:58:15,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 16:58:15,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 16:58:15,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 16:58:15,070[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 16:58:15,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 16:58:15,072[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 16:58:15,072[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 16:58:15,073[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 16:58:15,112[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 16:58:15,120[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.45it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 68.333 
                                                               rmse/train:      
                                                               46.505           
[[36m2025-01-21 17:01:52,216[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:01:52,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/042[0m
[[36m2025-01-21 17:01:52,312[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:01:52,340[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005942355758687591, lr[0m
[[36m2025-01-21 17:01:52,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:01:52,368[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13683430688203815 prior_scale[0m
[[36m2025-01-21 17:01:52,383[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00996523363478746 q_scale[0m
[[36m2025-01-21 17:01:52,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:01:52,396[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-01-21 17:01:52,396[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:01:52,396[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:02:01,652[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:02:01,658[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:02:01,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:02:01,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:02:01,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:02:01,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:02:01,662[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:02:01,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:02:01,663[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:02:01,702[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:02:01,709[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.09it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 49.433 
                                                               rmse/train:      
                                                               47.822           
[[36m2025-01-21 17:05:39,058[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:05:39,059[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/043[0m
[[36m2025-01-21 17:05:39,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:05:39,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000996501299992762, lr[0m
[[36m2025-01-21 17:05:39,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:05:39,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04898283836549372 prior_scale[0m
[[36m2025-01-21 17:05:39,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004647794046554222 q_scale[0m
[[36m2025-01-21 17:05:39,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:05:39,293[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-01-21 17:05:39,294[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:05:39,294[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:05:48,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:05:48,444[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:05:48,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:05:48,447[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:05:48,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:05:48,449[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:05:48,451[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:05:48,451[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:05:48,453[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:05:48,503[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:05:48,513[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.92it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 61.041 
                                                               rmse/train:      
                                                               56.524           
[[36m2025-01-21 17:09:25,795[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:09:25,797[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/044[0m
[[36m2025-01-21 17:09:25,910[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:09:25,939[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000744194873633672, lr[0m
[[36m2025-01-21 17:09:25,952[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:09:25,968[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.033699693946432734 prior_scale[0m
[[36m2025-01-21 17:09:25,983[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002310902962852339 q_scale[0m
[[36m2025-01-21 17:09:25,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 17:09:25,996[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-01-21 17:09:25,996[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:09:25,997[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:09:35,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:09:35,517[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:09:35,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:09:35,519[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:09:35,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:09:35,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:09:35,521[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:09:35,521[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:09:35,522[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:09:35,560[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:09:35,567[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.65it/s v_num: 0.000     
                                                               rmse/val: 68.987 
                                                               rmse/train:      
                                                               71.594           
[[36m2025-01-21 17:10:39,640[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:10:39,641[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/045[0m
[[36m2025-01-21 17:10:39,752[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:10:39,781[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009831616070090001, lr[0m
[[36m2025-01-21 17:10:39,793[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 17:10:39,808[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05038349685652255 prior_scale[0m
[[36m2025-01-21 17:10:39,822[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004596654402615532 q_scale[0m
[[36m2025-01-21 17:10:39,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:10:39,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-01-21 17:10:39,835[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:10:39,835[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:10:49,074[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:10:49,080[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:10:49,081[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:10:49,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:10:49,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:10:49,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:10:49,084[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:10:49,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:10:49,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:10:49,114[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:10:49,122[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:04 •       41.74it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 44.349 
                                                               rmse/train:      
                                                               46.245           
[[36m2025-01-21 17:13:02,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:13:02,898[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/046[0m
[[36m2025-01-21 17:13:03,014[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:13:03,055[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007847886584913767, lr[0m
[[36m2025-01-21 17:13:03,070[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:13:03,086[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02704630134251292 prior_scale[0m
[[36m2025-01-21 17:13:03,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.005539702269971904 q_scale[0m
[[36m2025-01-21 17:13:03,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:13:03,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-01-21 17:13:03,114[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:13:03,115[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:13:12,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:13:12,441[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:13:12,441[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:13:12,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:13:12,443[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:13:12,444[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:13:12,445[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:13:12,445[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:13:12,446[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:13:12,485[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:13:12,493[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:09 •       21.00it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 64.497 
                                                               rmse/train:      
                                                               60.960           
[[36m2025-01-21 17:16:53,289[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:16:53,290[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/047[0m
[[36m2025-01-21 17:16:53,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:16:53,417[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00047784487127187556, lr[0m
[[36m2025-01-21 17:16:53,430[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:16:53,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.045476530277099324 prior_scale[0m
[[36m2025-01-21 17:16:53,464[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001760105017203583 q_scale[0m
[[36m2025-01-21 17:16:53,477[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-21 17:16:53,477[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-01-21 17:16:53,477[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:16:53,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:17:03,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:17:03,203[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:17:03,203[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:17:03,205[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:17:03,206[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:17:03,206[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:17:03,207[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:17:03,207[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:17:03,208[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:17:03,258[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:17:03,270[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 15.99it/s v_num: 0.000     
                                                               rmse/val: 105.155
                                                               rmse/train:      
                                                               93.963           
[[36m2025-01-21 17:17:42,541[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:17:42,542[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/048[0m
[[36m2025-01-21 17:17:42,825[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:17:42,854[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002340032486057174, lr[0m
[[36m2025-01-21 17:17:42,866[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:17:42,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023909535551169172 prior_scale[0m
[[36m2025-01-21 17:17:42,896[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002619208447984331 q_scale[0m
[[36m2025-01-21 17:17:42,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:17:42,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-01-21 17:17:42,909[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:17:42,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:17:51,941[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:17:51,947[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:17:51,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:17:51,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:17:51,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:17:51,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:17:51,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:17:51,951[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:17:51,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:17:51,981[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:17:51,988[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.01it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 36.658 
                                                               rmse/train:      
                                                               32.588           
[[36m2025-01-21 17:21:28,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:21:28,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/049[0m
[[36m2025-01-21 17:21:28,766[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:21:28,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009989103011664683, lr[0m
[[36m2025-01-21 17:21:28,821[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:21:28,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.034536042394106715 prior_scale[0m
[[36m2025-01-21 17:21:28,864[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038381451535731293 q_scale[0m
[[36m2025-01-21 17:21:28,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-21 17:21:28,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-01-21 17:21:28,881[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:21:28,881[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:21:38,864[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:21:38,870[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:21:38,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:21:38,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:21:38,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:21:38,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:21:38,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:21:38,874[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:21:38,875[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:21:38,914[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:21:38,921[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 11.02it/s v_num: 0.000     
                                                               rmse/val: 155.872
                                                               rmse/train:      
                                                               162.295          
[[36m2025-01-21 17:22:08,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:22:08,997[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/050[0m
[[36m2025-01-21 17:22:09,093[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:22:09,122[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006131397942441438, lr[0m
[[36m2025-01-21 17:22:09,135[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:22:09,151[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06518275603865199 prior_scale[0m
[[36m2025-01-21 17:22:09,166[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006174170579280775 q_scale[0m
[[36m2025-01-21 17:22:09,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:22:09,178[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-01-21 17:22:09,179[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:22:09,179[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:22:18,419[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:22:18,425[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:22:18,426[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:22:18,428[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:22:18,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:22:18,429[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:22:18,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:22:18,430[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:22:18,431[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:22:18,465[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:22:18,476[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.86it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 39.781 
                                                               rmse/train:      
                                                               39.847           
[[36m2025-01-21 17:25:57,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:25:57,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/051[0m
[[36m2025-01-21 17:25:57,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:25:57,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000626806049342454, lr[0m
[[36m2025-01-21 17:25:57,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:25:57,408[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06303828578345784 prior_scale[0m
[[36m2025-01-21 17:25:57,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004603912642139978 q_scale[0m
[[36m2025-01-21 17:25:57,436[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:25:57,437[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-01-21 17:25:57,437[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:25:57,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:26:06,471[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:26:06,477[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:26:06,478[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:26:06,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:26:06,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:26:06,480[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:26:06,481[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:26:06,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:26:06,482[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:26:06,522[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:26:06,530[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.37it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 49.550 
                                                               rmse/train:      
                                                               42.918           
[[36m2025-01-21 17:29:48,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:29:48,786[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/052[0m
[[36m2025-01-21 17:29:48,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:29:48,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 6.409433811443745e-05, lr[0m
[[36m2025-01-21 17:29:48,923[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:29:48,941[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06541774989225092 prior_scale[0m
[[36m2025-01-21 17:29:48,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006116032268875647 q_scale[0m
[[36m2025-01-21 17:29:48,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:29:48,974[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-01-21 17:29:48,974[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:29:48,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:29:58,327[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:29:58,333[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:29:58,334[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:29:58,336[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:29:58,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:29:58,337[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:29:58,338[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:29:58,338[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:29:58,339[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:29:58,378[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:29:58,386[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.22it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 111.006
                                                               rmse/train:      
                                                               167.482          
[[36m2025-01-21 17:33:37,415[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:33:37,417[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/053[0m
[[36m2025-01-21 17:33:37,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:33:37,574[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044945949993052675, lr[0m
[[36m2025-01-21 17:33:37,587[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:33:37,605[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06250780906089477 prior_scale[0m
[[36m2025-01-21 17:33:37,624[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.008621096196143326 q_scale[0m
[[36m2025-01-21 17:33:37,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-21 17:33:37,642[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-01-21 17:33:37,643[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:33:37,643[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:33:47,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:33:47,256[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:33:47,257[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:33:47,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:33:47,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:33:47,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:33:47,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:33:47,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:33:47,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:33:47,300[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:33:47,309[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 19.73it/s v_num: 0.000     
                                                               rmse/val: 44.844 
                                                               rmse/train:      
                                                               59.505           
[[36m2025-01-21 17:34:54,225[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:34:54,227[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/054[0m
[[36m2025-01-21 17:34:54,322[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:34:54,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005742290877786598, lr[0m
[[36m2025-01-21 17:34:54,378[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:34:54,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10641099964110753 prior_scale[0m
[[36m2025-01-21 17:34:54,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0049749594615800105 q_scale[0m
[[36m2025-01-21 17:34:54,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:34:54,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-01-21 17:34:54,438[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:34:54,439[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:35:03,757[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:35:03,763[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:35:03,764[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:35:03,765[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:35:03,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:35:03,766[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:35:03,767[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:35:03,767[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:35:03,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:35:03,804[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:35:03,811[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.42it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 63.228 
                                                               rmse/train:      
                                                               43.455           
[[36m2025-01-21 17:38:42,912[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:38:42,914[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/055[0m
[[36m2025-01-21 17:38:43,008[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:38:43,047[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000804508028149741, lr[0m
[[36m2025-01-21 17:38:43,061[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:38:43,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07747476210911025 prior_scale[0m
[[36m2025-01-21 17:38:43,091[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0059735073771008465 q_scale[0m
[[36m2025-01-21 17:38:43,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:38:43,103[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-01-21 17:38:43,103[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:38:43,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:38:52,136[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:38:52,142[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:38:52,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:38:52,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:38:52,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:38:52,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:38:52,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:38:52,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:38:52,146[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:38:52,197[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:38:52,209[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       22.11it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 49.196 
                                                               rmse/train:      
                                                               50.395           
[[36m2025-01-21 17:42:28,785[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:42:28,787[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/056[0m
[[36m2025-01-21 17:42:28,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:42:28,943[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008041036916498935, lr[0m
[[36m2025-01-21 17:42:28,960[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-21 17:42:28,976[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0441769171637619 prior_scale[0m
[[36m2025-01-21 17:42:28,992[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.003291458940551217 q_scale[0m
[[36m2025-01-21 17:42:29,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:42:29,005[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-01-21 17:42:29,005[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:42:29,005[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:42:38,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:42:38,071[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:42:38,071[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:42:38,073[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:42:38,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:42:38,074[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:42:38,075[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:42:38,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:42:38,076[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:42:38,115[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:42:38,122[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:04 •       41.50it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 135.626
                                                               rmse/train:      
                                                               65.380           
[[36m2025-01-21 17:44:48,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:44:48,663[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/057[0m
[[36m2025-01-21 17:44:48,759[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:44:48,788[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006815531231239136, lr[0m
[[36m2025-01-21 17:44:48,802[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:44:48,817[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05184408746349708 prior_scale[0m
[[36m2025-01-21 17:44:48,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000406447257278616 q_scale[0m
[[36m2025-01-21 17:44:48,845[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-21 17:44:48,845[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-01-21 17:44:48,845[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:44:48,845[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:44:58,121[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:44:58,128[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:44:58,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:44:58,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:44:58,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:44:58,131[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:44:58,132[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:44:58,132[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:44:58,133[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:44:58,184[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:44:58,195[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:08 •       21.88it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 57.473 
                                                               rmse/train:      
                                                               47.192           
[[36m2025-01-21 17:48:37,142[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:48:37,143[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/058[0m
[[36m2025-01-21 17:48:37,264[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-21 17:48:37,303[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048514140651364194, lr[0m
[[36m2025-01-21 17:48:37,320[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-21 17:48:37,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07411474669074951 prior_scale[0m
[[36m2025-01-21 17:48:37,364[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007891845222519123 q_scale[0m
[[36m2025-01-21 17:48:37,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-01-21 17:48:37,381[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-01-21 17:48:37,382[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-21 17:48:37,382[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-01-21 17:48:46,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-21 17:48:46,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-21 17:48:46,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-21 17:48:46,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-21 17:48:46,528[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-21 17:48:46,529[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-21 17:48:46,530[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-21 17:48:46,530[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-21 17:48:46,531[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-21 17:48:46,569[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-21 17:48:46,580[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:04 • 0:00:00 21.33it/s v_num: 0.000     
                                                               rmse/val: 49.385 
                                                               rmse/train:      
                                                               58.083           
[[36m2025-01-21 17:50:42,353[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-21 17:50:42,354[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-21_15-15-32/059[0m
[[36m2025-01-21 17:50:42,429[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-01-22 11:28:57,832[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-01-22 11:28:57,834[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_rad.db[0m
[[36m2025-01-22 11:28:58,704[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-01-22 11:28:58,715[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-01-22 11:28:58,813[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:28:58,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-01-22 11:28:58,881[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:28:58,899[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.21592388039429916 prior_scale[0m
[[36m2025-01-22 11:28:58,918[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0036303760732131728 q_scale[0m
[[36m2025-01-22 11:28:58,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-01-22 11:28:58,936[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-01-22 11:28:58,937[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:28:58,937[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:29:09,640[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:29:09,655[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:29:09,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:29:09,658[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:29:09,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:29:09,659[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:29:09,667[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:29:09,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:29:09,677[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:29:09,944[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:29:10,160[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 2/2 0:00:00 • 0:00:00 13.41it/s v_num: 0.000      
                                                              rmse/val: 3757.603
                                                              rmse/train:       
                                                              3786.474          
[[36m2025-01-22 11:29:25,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:29:25,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/000[0m
[[36m2025-01-22 11:29:25,456[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:29:25,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-01-22 11:29:25,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:29:25,519[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.16250224524496343 prior_scale[0m
[[36m2025-01-22 11:29:25,533[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005501758328845987 q_scale[0m
[[36m2025-01-22 11:29:25,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-01-22 11:29:25,548[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-01-22 11:29:25,549[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:29:25,549[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:29:37,205[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:29:37,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:29:37,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:29:37,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:29:37,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:29:37,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:29:37,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:29:37,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:29:37,224[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:29:37,241[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:29:37,252[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      
                                                              rmse/val: 4114.144
                                                              rmse/train:       
                                                              4143.452          
[[36m2025-01-22 11:29:50,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:29:50,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/001[0m
[[36m2025-01-22 11:29:51,074[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:29:51,104[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-01-22 11:29:51,119[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:29:51,134[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04232733477101895 prior_scale[0m
[[36m2025-01-22 11:29:51,149[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0073498792462323385 q_scale[0m
[[36m2025-01-22 11:29:51,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:29:51,164[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-01-22 11:29:51,165[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:29:51,165[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:30:01,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:30:01,714[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:30:01,714[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:30:01,717[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:30:01,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:30:01,719[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:30:01,720[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:30:01,720[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:30:01,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:30:01,756[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:30:01,767[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 24.21it/s v_num: 0.000      
                                                              rmse/val: 4124.388
                                                              rmse/train:       
                                                              4157.390          
[[36m2025-01-22 11:30:21,998[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:30:21,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/002[0m
[[36m2025-01-22 11:30:22,135[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:30:22,170[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-01-22 11:30:22,188[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:30:22,204[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.017549127225111354 prior_scale[0m
[[36m2025-01-22 11:30:22,223[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002561662685923485 q_scale[0m
[[36m2025-01-22 11:30:22,239[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:30:22,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-01-22 11:30:22,240[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:30:22,240[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:30:33,072[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:30:33,080[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:30:33,080[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:30:33,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:30:33,083[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:30:33,084[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:30:33,085[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:30:33,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:30:33,086[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:30:33,106[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:30:33,116[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 13.16it/s v_num: 0.000      
                                                              rmse/val: 3980.467
                                                              rmse/train:       
                                                              4013.686          
[[36m2025-01-22 11:30:57,198[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:30:57,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/003[0m
[[36m2025-01-22 11:30:57,332[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:30:57,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-01-22 11:30:57,377[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:30:57,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.14015302623589543 prior_scale[0m
[[36m2025-01-22 11:30:57,406[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001546142648648774 q_scale[0m
[[36m2025-01-22 11:30:57,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:30:57,421[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-01-22 11:30:57,421[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:30:57,421[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:31:08,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:31:08,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:31:08,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:31:08,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:31:08,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:31:08,067[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:31:08,068[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:31:08,068[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:31:08,069[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:31:08,101[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:31:08,110[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 26.30it/s v_num: 0.000      
                                                              rmse/val: 4174.618
                                                              rmse/train:       
                                                              4203.119          
[[36m2025-01-22 11:31:24,780[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:31:24,781[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/004[0m
[[36m2025-01-22 11:31:24,901[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:31:24,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-01-22 11:31:24,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:31:24,958[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01026814371296241 prior_scale[0m
[[36m2025-01-22 11:31:24,971[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017174472922154307 q_scale[0m
[[36m2025-01-22 11:31:24,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:31:24,985[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-01-22 11:31:24,985[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:31:24,985[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:31:35,200[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:31:35,215[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:31:35,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:31:35,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:31:35,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:31:35,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:31:35,219[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:31:35,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:31:35,220[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:31:35,235[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:31:35,253[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 27.49it/s v_num: 0.000      
                                                              rmse/val: 4181.150
                                                              rmse/train:       
                                                              4217.566          
[[36m2025-01-22 11:31:51,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:31:51,623[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/005[0m
[[36m2025-01-22 11:31:51,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:31:51,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-01-22 11:31:51,777[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:31:51,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.021500386108909676 prior_scale[0m
[[36m2025-01-22 11:31:51,805[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005816140699158816 q_scale[0m
[[36m2025-01-22 11:31:51,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:31:51,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-01-22 11:31:51,820[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:31:51,820[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:32:02,103[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:32:02,109[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:32:02,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:32:02,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:32:02,112[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:32:02,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:32:02,114[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:32:02,114[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:32:02,115[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:32:02,130[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:32:02,140[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 27.87it/s v_num: 0.000      
                                                              rmse/val: 4160.410
                                                              rmse/train:       
                                                              4193.476          
[[36m2025-01-22 11:32:18,413[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:32:18,414[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/006[0m
[[36m2025-01-22 11:32:18,527[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:32:18,556[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-01-22 11:32:18,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:32:18,590[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015205659078436342 prior_scale[0m
[[36m2025-01-22 11:32:18,608[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002873671566774025 q_scale[0m
[[36m2025-01-22 11:32:18,625[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-01-22 11:32:18,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-01-22 11:32:18,626[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:32:18,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:32:28,853[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:32:28,861[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:32:28,861[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:32:28,864[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:32:28,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:32:28,865[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:32:28,866[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:32:28,866[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:32:28,867[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:32:28,900[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:32:28,910[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 30.78it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3453.877         
                                                               rmse/train:      
                                                               3499.906         
[[36m2025-01-22 11:33:21,110[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:33:21,111[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/007[0m
[[36m2025-01-22 11:33:21,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:33:21,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-01-22 11:33:21,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-01-22 11:33:21,288[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1156399334005538 prior_scale[0m
[[36m2025-01-22 11:33:21,305[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002582231235363856 q_scale[0m
[[36m2025-01-22 11:33:21,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:33:21,319[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-01-22 11:33:21,319[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:33:21,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:33:31,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:33:31,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:33:31,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:33:31,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:33:31,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:33:31,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:33:31,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:33:31,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:33:31,755[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:33:31,795[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:33:31,805[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 3/3 0:00:00 • 0:00:00 14.53it/s v_num: 0.000      
                                                              rmse/val: 4152.552
                                                              rmse/train:       
                                                              4189.101          
[[36m2025-01-22 11:33:52,976[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-01-22 11:33:52,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-01-22_11-28-57/008[0m
[[36m2025-01-22 11:33:53,102[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-01-22 11:33:53,132[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-01-22 11:33:53,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-01-22 11:33:53,162[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.41347469058863023 prior_scale[0m
[[36m2025-01-22 11:33:53,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009135206248796449 q_scale[0m
[[36m2025-01-22 11:33:53,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-01-22 11:33:53,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-01-22 11:33:53,194[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-01-22 11:33:53,194[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
Train indices: 391 [5757, 588, 2127, 6217, 1585]
Valid indices: 782 [2585, 6782, 3084, 2186, 6394]
Test indices: 6642 [6199, 1383, 459, 5666, 5446]
0.06565926932648217 6.6588702845000975
[[36m2025-01-22 11:34:03,797[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-01-22 11:34:03,804[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-01-22 11:34:03,804[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-01-22 11:34:03,806[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-01-22 11:34:03,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-01-22 11:34:03,807[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-01-22 11:34:03,808[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-01-22 11:34:03,809[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-01-22 11:34:03,810[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-01-22 11:34:03,826[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-01-22 11:34:03,838[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 0/19                    0/3 0:00:00 • -:--:-- 0.00it/s v_num: 0.000       
                                                             rmse/val: 4761.617 
[[36m2025-01-22 11:34:04,128[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/poutine/trace_messenger.py", line 191, in __call__
    ret = self.fn(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/nn/module.py", line 450, in __call__
    result = super().__call__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/models/guides/radial.py", line 137, in forward
    fn = RadialNormal(loc, scale).to_event(site["fn"].event_dim)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/distributions/distribution.py", line 26, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/distributions/normal.py", line 56, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/distributions/distribution.py", line 68, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Parameter of shape (15, 70)) of distribution RadialNormal(loc: torch.Size([15, 70]), scale: torch.Size([15, 70])) to satisfy the constraint Real(), but found invalid values:
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/module.py", line 1303, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 152, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 122, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py", line 409, in step
    return closure()
           ^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py", line 108, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 318, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/models/bnn.py", line 122, in training_step
    output = self.bnn.predict(x[0], x[1],num_predictions=self.hparams.mc_samples_train)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/bnn.py", line 222, in predict
    preds.append(self.guided_forward(*input_data, guide_tr=trace))
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/tyxe/bnn.py", line 75, in guided_forward
    guide_tr = poutine.trace(self.net_guide).get_trace(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/poutine/trace_messenger.py", line 216, in get_trace
    self(*args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/poutine/trace_messenger.py", line 198, in __call__
    raise exc from e
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/poutine/trace_messenger.py", line 191, in __call__
    ret = self.fn(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/nn/module.py", line 450, in __call__
    result = super().__call__(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/models/guides/radial.py", line 137, in forward
    fn = RadialNormal(loc, scale).to_event(site["fn"].event_dim)
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/pyro/distributions/distribution.py", line 26, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/distributions/normal.py", line 56, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/torch/distributions/distribution.py", line 68, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Parameter of shape (15, 70)) of distribution RadialNormal(loc: torch.Size([15, 70]), scale: torch.Size([15, 70])) to satisfy the constraint Real(), but found invalid values:
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)
                                       Trace Shapes:      
                                        Param Sites:      
  net_guide.net.networks.0.Linear_Layer_1.weight.loc 15 70
net_guide.net.networks.0.Linear_Layer_1.weight.scale 15 70
                                       Sample Sites:      
[[36m2025-01-22 11:34:04,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'min_epochs': 20000, 'max_epochs': 20, 'accelerator': 'cpu', 'devices': 1, 'check_val_every_n_epoch': 1, 'deterministic': False}
[[36m2025-02-19 18:17:27,733[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating study <optuna.create_study>[0m
[[36m2025-02-19 18:17:27,736[0m][[34m__main__[0m][[32mINFO[0m] - Results will be stored in sqlite:////home/g15farris/bin/bayesaenet/bnn_aenet/results/TiO/bnn_rad.db[0m
[[36m2025-02-19 18:17:33,389[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating objective <bnn_aenet.tasks.hpsearch.objective_bnn>[0m
[[36m2025-02-19 18:17:33,435[0m][[34m__main__[0m][[32mINFO[0m] - Starting hyperparameter search ...[0m
[[36m2025-02-19 18:17:33,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:17:33,545[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.4156772025296228e-05, lr[0m
[[36m2025-02-19 18:17:33,562[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:17:33,576[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22702608040701588 prior_scale[0m
[[36m2025-02-19 18:17:33,591[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.13179630432958683 q_scale[0m
[[36m2025-02-19 18:17:33,609[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-19 18:17:33,610[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 000 __________________[0m
[[36m2025-02-19 18:17:33,610[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:17:33,610[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:17:44,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:17:58,654[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:17:58,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:17:58,660[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:17:58,661[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:17:58,662[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:17:58,925[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:17:58,925[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:17:59,018[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:17:59,256[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:18:02,580[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 23.26it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4148.150         
                                                               rmse/train:      
                                                               4177.330         
[[36m2025-02-19 18:18:47,575[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:18:47,576[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/000[0m
[[36m2025-02-19 18:18:47,693[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:18:47,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.195586024325663e-05, lr[0m
[[36m2025-02-19 18:18:47,734[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:18:47,749[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1374377640063412 prior_scale[0m
[[36m2025-02-19 18:18:47,762[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0030269344709026166 q_scale[0m
[[36m2025-02-19 18:18:47,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-19 18:18:47,776[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 001 __________________[0m
[[36m2025-02-19 18:18:47,777[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:18:47,777[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:18:58,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:18:58,693[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:18:58,693[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:18:58,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:18:58,696[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:18:58,697[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:18:58,698[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:18:58,698[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:18:58,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:18:58,723[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:18:58,966[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.91it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3784.014         
                                                               rmse/train:      
                                                               3871.495         
[[36m2025-02-19 18:19:40,390[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:19:40,391[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/001[0m
[[36m2025-02-19 18:19:40,541[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:19:40,573[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.367498945698204e-05, lr[0m
[[36m2025-02-19 18:19:40,588[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:19:40,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.012778268753495938 prior_scale[0m
[[36m2025-02-19 18:19:40,626[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.540207249341968 q_scale[0m
[[36m2025-02-19 18:19:40,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:19:40,641[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 002 __________________[0m
[[36m2025-02-19 18:19:40,641[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:19:40,641[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:19:50,929[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:19:50,944[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:19:50,944[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:19:51,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:19:51,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:19:51,178[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:19:51,180[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:19:51,180[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:19:51,181[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:19:52,295[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:19:57,656[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.11it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3943.328         
                                                               rmse/train:      
                                                               3965.726         
[[36m2025-02-19 18:20:51,653[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:20:51,655[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/002[0m
[[36m2025-02-19 18:20:51,804[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:20:51,848[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005473369642905611, lr[0m
[[36m2025-02-19 18:20:51,867[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:20:51,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002699606552195955 prior_scale[0m
[[36m2025-02-19 18:20:51,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06562115716452717 q_scale[0m
[[36m2025-02-19 18:20:51,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:20:51,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 003 __________________[0m
[[36m2025-02-19 18:20:51,931[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:20:51,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:21:03,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:21:03,520[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:21:03,520[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:21:03,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:21:03,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:21:03,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:21:03,525[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:21:03,526[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:21:03,527[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:21:03,577[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:21:04,017[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.82it/s v_num: 0.000     
                                                               rmse/val: 44.068 
                                                               rmse/train:      
                                                               107.845          
[[36m2025-02-19 18:22:45,052[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:22:45,054[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/003[0m
[[36m2025-02-19 18:22:45,163[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:22:45,191[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.3170990774640101e-05, lr[0m
[[36m2025-02-19 18:22:45,203[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:22:45,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.10583829396911469 prior_scale[0m
[[36m2025-02-19 18:22:45,228[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023905570899706415 q_scale[0m
[[36m2025-02-19 18:22:45,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:22:45,241[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 004 __________________[0m
[[36m2025-02-19 18:22:45,242[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:22:45,242[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:22:55,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:22:55,602[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:22:55,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:22:55,604[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:22:55,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:22:55,606[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:22:55,607[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:22:55,607[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:22:55,608[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:22:55,642[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:22:59,117[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 20.76it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4025.035         
                                                               rmse/train:      
                                                               4119.967         
[[36m2025-02-19 18:24:02,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:24:02,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/004[0m
[[36m2025-02-19 18:24:03,036[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:24:03,076[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1.674127903856e-05, lr[0m
[[36m2025-02-19 18:24:03,092[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:24:03,110[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001047833275436284 prior_scale[0m
[[36m2025-02-19 18:24:03,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02949625201538112 q_scale[0m
[[36m2025-02-19 18:24:03,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:24:03,144[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 005 __________________[0m
[[36m2025-02-19 18:24:03,145[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:24:03,145[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:24:13,392[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:24:13,621[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:24:13,622[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:24:13,885[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:24:13,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:24:13,887[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:24:13,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:24:13,889[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:24:13,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:24:14,048[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:24:14,882[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 14/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 28.22it/s v_num: 0.000     
                                                               rmse/val:        
                                                               4082.659         
                                                               rmse/train:      
                                                               4184.395         
[[36m2025-02-19 18:24:57,545[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 14.
[[36m2025-02-19 18:24:57,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:24:57,652[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:24:57,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.71964865643354e-05, lr[0m
[[36m2025-02-19 18:24:57,691[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:24:57,705[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0038638969563953266 prior_scale[0m
[[36m2025-02-19 18:24:57,721[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033827492632411567 q_scale[0m
[[36m2025-02-19 18:24:57,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:24:57,735[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 006 __________________[0m
[[36m2025-02-19 18:24:57,736[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:24:57,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:25:07,617[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:25:07,624[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:25:07,624[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:25:07,626[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:25:07,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:25:07,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:25:07,629[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:25:07,629[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:25:07,630[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:25:07,644[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:25:08,143[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 27.26it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3724.583         
                                                               rmse/train:      
                                                               3827.244         
[[36m2025-02-19 18:25:58,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:25:58,324[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/006[0m
[[36m2025-02-19 18:25:58,429[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:25:58,458[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00029994809793642315, lr[0m
[[36m2025-02-19 18:25:58,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:25:58,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0020959477484878194 prior_scale[0m
[[36m2025-02-19 18:25:58,498[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008257988273685458 q_scale[0m
[[36m2025-02-19 18:25:58,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:25:58,511[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 007 __________________[0m
[[36m2025-02-19 18:25:58,511[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:25:58,511[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:26:08,423[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:26:08,430[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:26:08,431[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:26:08,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:26:08,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:26:08,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:26:08,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:26:08,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:26:08,437[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:26:08,473[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:26:08,690[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:07 •       25.90it/s v_num: 0.000     
                                     0:00:00                   rmse/val:        
                                                               1843.579         
                                                               rmse/train:      
                                                               1894.637         
[[36m2025-02-19 18:29:15,894[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:29:15,897[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/007[0m
[[36m2025-02-19 18:29:16,125[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:29:16,165[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 7.478015213333154e-05, lr[0m
[[36m2025-02-19 18:29:16,186[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:29:16,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.07537199486913888 prior_scale[0m
[[36m2025-02-19 18:29:16,221[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0666791815288874 q_scale[0m
[[36m2025-02-19 18:29:16,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:29:16,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 008 __________________[0m
[[36m2025-02-19 18:29:16,250[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:29:16,250[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:29:27,211[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:29:27,218[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:29:27,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:29:27,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:29:27,222[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:29:27,223[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:29:27,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:29:27,224[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:29:27,225[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:29:27,270[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:29:27,583[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:03 • 0:00:00 14.40it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1784.804         
                                                               rmse/train:      
                                                               1917.461         
[[36m2025-02-19 18:31:00,692[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:31:00,694[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/008[0m
[[36m2025-02-19 18:31:00,818[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:31:00,849[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2.01904291186572e-05, lr[0m
[[36m2025-02-19 18:31:00,863[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 18:31:00,879[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.714967484470097 prior_scale[0m
[[36m2025-02-19 18:31:00,894[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00834519932080496 q_scale[0m
[[36m2025-02-19 18:31:00,908[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 18:31:00,909[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 009 __________________[0m
[[36m2025-02-19 18:31:00,909[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:31:00,909[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:31:10,939[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:31:10,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:31:10,947[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:31:10,949[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:31:10,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:31:10,950[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:31:10,951[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:31:10,951[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:31:10,952[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:31:11,003[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:31:11,014[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 27.69it/s v_num: 0.000     
                                                               rmse/val:        
                                                               1609.985         
                                                               rmse/train:      
                                                               1657.312         
[[36m2025-02-19 18:32:02,194[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:32:02,195[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/009[0m
[[36m2025-02-19 18:32:02,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:32:02,347[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002686321798731397, lr[0m
[[36m2025-02-19 18:32:02,362[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:32:02,380[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01116798829495977 prior_scale[0m
[[36m2025-02-19 18:32:02,398[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013611901663306908 q_scale[0m
[[36m2025-02-19 18:32:02,413[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:32:02,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 010 __________________[0m
[[36m2025-02-19 18:32:02,414[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:32:02,414[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:32:12,088[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:32:12,094[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:32:12,094[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:32:12,096[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:32:12,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:32:12,097[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:32:12,098[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:32:12,098[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:32:12,099[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:32:12,131[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:32:12,149[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:14 •       13.79it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 36.441 
                                                               rmse/train:      
                                                               28.848           
[[36m2025-02-19 18:37:17,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:37:17,931[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/010[0m
[[36m2025-02-19 18:37:18,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:37:18,313[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002668116545003139, lr[0m
[[36m2025-02-19 18:37:18,335[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:37:18,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.015791568646716513 prior_scale[0m
[[36m2025-02-19 18:37:18,382[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00013400032806480455 q_scale[0m
[[36m2025-02-19 18:37:18,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:37:18,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 011 __________________[0m
[[36m2025-02-19 18:37:18,412[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:37:18,412[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:37:29,308[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:37:29,315[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:37:29,316[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:37:29,319[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:37:29,320[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:37:29,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:37:29,321[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:37:29,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:37:29,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:37:29,370[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:37:30,382[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:13 •       14.27it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 56.227 
                                                               rmse/train:      
                                                               47.223           
[[36m2025-02-19 18:43:08,878[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:43:08,881[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/011[0m
[[36m2025-02-19 18:43:09,072[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:43:09,124[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001741204381065012, lr[0m
[[36m2025-02-19 18:43:09,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:43:09,176[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01578701912640358 prior_scale[0m
[[36m2025-02-19 18:43:09,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010569299297450266 q_scale[0m
[[36m2025-02-19 18:43:09,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:43:09,226[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 012 __________________[0m
[[36m2025-02-19 18:43:09,227[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:43:09,227[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:43:20,201[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:43:20,213[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:43:20,214[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:43:20,217[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:43:20,218[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:43:20,219[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:43:20,221[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:43:20,221[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:43:20,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:43:20,265[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:43:20,281[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:14 •       13.14it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 51.129 
                                                               rmse/train:      
                                                               44.330           
[[36m2025-02-19 18:49:09,278[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:49:09,280[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/012[0m
[[36m2025-02-19 18:49:09,445[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:49:09,485[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00015991366116446953, lr[0m
[[36m2025-02-19 18:49:09,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:49:09,529[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.023551654708581973 prior_scale[0m
[[36m2025-02-19 18:49:09,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010194432109815798 q_scale[0m
[[36m2025-02-19 18:49:09,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-19 18:49:09,570[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 013 __________________[0m
[[36m2025-02-19 18:49:09,571[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:49:09,571[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:49:20,682[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:49:20,723[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:49:20,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:49:20,728[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:49:20,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:49:20,729[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:49:20,730[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:49:20,730[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:49:20,731[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:49:22,631[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:49:22,944[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.64it/s v_num: 0.000     
                                                               rmse/val: 60.782 
                                                               rmse/train:      
                                                               47.652           
[[36m2025-02-19 18:52:43,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:52:43,896[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/013[0m
[[36m2025-02-19 18:52:49,193[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:52:49,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009801615183585152, lr[0m
[[36m2025-02-19 18:52:49,361[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:52:49,386[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03777462213368495 prior_scale[0m
[[36m2025-02-19 18:52:49,411[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00042903850239015034 q_scale[0m
[[36m2025-02-19 18:52:49,432[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:52:49,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 014 __________________[0m
[[36m2025-02-19 18:52:49,433[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:52:49,434[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:52:59,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:52:59,995[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:52:59,995[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:53:00,032[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:53:00,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:53:00,034[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:53:00,035[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:53:00,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:53:00,036[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:53:03,856[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:53:04,260[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       15.55it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 40.086 
                                                               rmse/train:      
                                                               30.803           
[[36m2025-02-19 18:58:34,948[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 18:58:34,960[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/014[0m
[[36m2025-02-19 18:58:36,607[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 18:58:36,930[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009912618747798267, lr[0m
[[36m2025-02-19 18:58:37,713[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 18:58:38,027[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04295889441861082 prior_scale[0m
[[36m2025-02-19 18:58:38,514[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005831230834389495 q_scale[0m
[[36m2025-02-19 18:58:38,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 18:58:38,982[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 015 __________________[0m
[[36m2025-02-19 18:58:38,983[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 18:58:38,983[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 18:58:49,050[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 18:58:49,082[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 18:58:49,082[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 18:58:49,247[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 18:58:49,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 18:58:49,261[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 18:58:49,262[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 18:58:49,262[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 18:58:49,264[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 18:58:49,864[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 18:58:51,421[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       16.11it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 64.198 
                                                               rmse/train:      
                                                               36.133           
[[36m2025-02-19 19:03:55,564[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:03:55,566[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/015[0m
[[36m2025-02-19 19:03:56,180[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:03:56,487[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009243036929562794, lr[0m
[[36m2025-02-19 19:03:56,636[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:03:56,678[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0057475489968997415 prior_scale[0m
[[36m2025-02-19 19:03:56,704[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005478446090810961 q_scale[0m
[[36m2025-02-19 19:03:56,888[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:03:56,889[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 016 __________________[0m
[[36m2025-02-19 19:03:56,889[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:03:56,890[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:04:06,799[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:04:06,827[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:04:06,827[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:04:06,849[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:04:06,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:04:06,850[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:04:06,851[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:04:06,851[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:04:06,852[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:04:07,297[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:04:10,310[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       15.83it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 38.046 
                                                               rmse/train:      
                                                               28.685           
[[36m2025-02-19 19:09:19,122[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:09:19,215[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/016[0m
[[36m2025-02-19 19:09:20,305[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:09:20,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00014571280564622014, lr[0m
[[36m2025-02-19 19:09:20,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:09:20,397[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.03298570457662521 prior_scale[0m
[[36m2025-02-19 19:09:20,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003862680292386194 q_scale[0m
[[36m2025-02-19 19:09:20,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-19 19:09:20,467[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 017 __________________[0m
[[36m2025-02-19 19:09:20,468[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:09:20,468[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:09:30,614[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:09:30,684[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:09:30,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:09:30,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:09:30,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:09:30,687[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:09:30,688[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:09:30,688[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:09:30,689[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:09:31,503[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:09:33,898[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:02 • 0:00:00 11.89it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2072.619         
                                                               rmse/train:      
                                                               2214.988         
[[36m2025-02-19 19:10:42,260[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:10:42,262[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/017[0m
[[36m2025-02-19 19:10:43,472[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:10:43,525[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005091840068070752, lr[0m
[[36m2025-02-19 19:10:43,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:10:43,580[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.27634381419905757 prior_scale[0m
[[36m2025-02-19 19:10:43,604[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0021829084037059353 q_scale[0m
[[36m2025-02-19 19:10:43,621[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-19 19:10:43,622[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 018 __________________[0m
[[36m2025-02-19 19:10:43,622[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:10:43,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:10:54,361[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:10:54,368[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:10:54,368[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:10:54,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:10:54,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:10:54,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:10:54,435[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:10:54,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:10:54,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:10:54,525[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:10:56,706[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 8.31it/s v_num: 0.000     
                                                               rmse/val: 182.740
                                                               rmse/train:      
                                                               187.208          
[[36m2025-02-19 19:11:55,856[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:11:56,173[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/018[0m
[[36m2025-02-19 19:11:56,518[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:11:56,577[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00012380141318859208, lr[0m
[[36m2025-02-19 19:11:56,603[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:11:56,629[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007133078560557303 prior_scale[0m
[[36m2025-02-19 19:11:56,654[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002709777519789646 q_scale[0m
[[36m2025-02-19 19:11:56,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-19 19:11:56,672[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 019 __________________[0m
[[36m2025-02-19 19:11:56,673[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:11:56,673[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:12:06,657[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:12:06,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:12:06,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:12:06,711[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:12:06,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:12:06,713[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:12:06,715[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:12:06,716[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:12:06,718[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:12:06,763[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:12:10,998[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:06 • 0:00:00 15.34it/s v_num: 0.000     
                                                               rmse/val: 48.973 
                                                               rmse/train:      
                                                               42.168           
[[36m2025-02-19 19:15:19,456[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:15:19,481[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/019[0m
[[36m2025-02-19 19:15:19,644[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:15:19,699[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00048110769481380023, lr[0m
[[36m2025-02-19 19:15:19,719[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:15:19,745[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05537459988237193 prior_scale[0m
[[36m2025-02-19 19:15:19,772[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0013109684371485494 q_scale[0m
[[36m2025-02-19 19:15:19,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:15:19,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 020 __________________[0m
[[36m2025-02-19 19:15:19,792[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:15:19,792[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:15:29,626[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:15:29,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:15:29,633[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:15:29,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:15:29,635[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:15:29,636[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:15:29,636[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:15:29,637[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:15:29,637[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:15:29,686[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:15:31,793[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       15.87it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 46.314 
                                                               rmse/train:      
                                                               33.771           
[[36m2025-02-19 19:20:48,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:20:48,304[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/020[0m
[[36m2025-02-19 19:20:50,537[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:20:50,957[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002516816447185209, lr[0m
[[36m2025-02-19 19:20:51,647[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:20:51,737[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01993471218243757 prior_scale[0m
[[36m2025-02-19 19:20:51,773[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00021765260154807801 q_scale[0m
[[36m2025-02-19 19:20:51,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:20:51,792[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 021 __________________[0m
[[36m2025-02-19 19:20:51,792[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:20:51,793[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:21:02,021[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:21:02,192[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:21:02,192[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:21:02,433[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:21:02,434[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:21:02,435[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:21:02,436[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:21:02,436[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:21:02,438[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:21:02,508[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:21:04,062[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:13 •       14.98it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 54.626 
                                                               rmse/train:      
                                                               47.562           
[[36m2025-02-19 19:26:29,362[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:26:29,508[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/021[0m
[[36m2025-02-19 19:26:31,369[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:26:32,594[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00018543097468971017, lr[0m
[[36m2025-02-19 19:26:33,433[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:26:34,205[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02571488190300574 prior_scale[0m
[[36m2025-02-19 19:26:35,090[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024274155095662376 q_scale[0m
[[36m2025-02-19 19:26:35,113[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:26:35,114[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 022 __________________[0m
[[36m2025-02-19 19:26:35,114[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:26:35,114[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:26:45,251[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:26:45,259[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:26:45,259[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:26:45,262[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:26:45,262[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:26:45,263[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:26:45,263[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:26:45,264[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:26:45,265[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:26:49,207[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:26:54,254[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.56it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 55.279 
                                                               rmse/train:      
                                                               47.223           
[[36m2025-02-19 19:31:48,091[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:31:48,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/022[0m
[[36m2025-02-19 19:31:50,768[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:31:51,011[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 8.599088110514248e-05, lr[0m
[[36m2025-02-19 19:31:51,067[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:31:51,593[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.02703858630794211 prior_scale[0m
[[36m2025-02-19 19:31:51,875[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00026444495402769486 q_scale[0m
[[36m2025-02-19 19:31:51,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:31:51,897[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 023 __________________[0m
[[36m2025-02-19 19:31:51,898[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:31:51,898[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:32:01,713[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:32:01,721[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:32:01,721[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:32:01,724[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:32:01,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:32:01,725[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:32:01,726[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:32:01,726[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:32:01,727[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:32:01,902[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:32:02,912[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.41it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 58.551 
                                                               rmse/train:      
                                                               49.553           
[[36m2025-02-19 19:36:55,061[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:36:55,199[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/023[0m
[[36m2025-02-19 19:36:58,586[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:36:59,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00037227045560485247, lr[0m
[[36m2025-02-19 19:36:59,366[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:36:59,392[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06268117141804794 prior_scale[0m
[[36m2025-02-19 19:36:59,416[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0011970131495003097 q_scale[0m
[[36m2025-02-19 19:36:59,597[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:36:59,598[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 024 __________________[0m
[[36m2025-02-19 19:36:59,598[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:36:59,599[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:37:09,463[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:37:09,512[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:37:09,512[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:37:09,583[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:37:09,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:37:09,584[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:37:09,585[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:37:09,586[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:37:09,587[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:37:10,548[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:37:12,529[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.03it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 54.478 
                                                               rmse/train:      
                                                               38.977           
[[36m2025-02-19 19:42:13,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:42:13,503[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/024[0m
[[36m2025-02-19 19:42:15,414[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:42:15,457[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007467572073500967, lr[0m
[[36m2025-02-19 19:42:15,478[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:42:15,502[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0215507667389912 prior_scale[0m
[[36m2025-02-19 19:42:15,526[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.006455858899900074 q_scale[0m
[[36m2025-02-19 19:42:15,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:42:15,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 025 __________________[0m
[[36m2025-02-19 19:42:15,544[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:42:15,544[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:42:25,223[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:42:25,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:42:25,335[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:42:25,400[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:42:25,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:42:25,401[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:42:25,402[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:42:25,402[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:42:25,403[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:42:25,779[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:42:26,923[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.70it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 52.490 
                                                               rmse/train:      
                                                               40.348           
[[36m2025-02-19 19:47:23,750[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:47:23,883[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/025[0m
[[36m2025-02-19 19:47:35,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:47:37,503[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00019944557211756017, lr[0m
[[36m2025-02-19 19:47:38,501[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:47:40,075[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.04057309158943759 prior_scale[0m
[[36m2025-02-19 19:47:41,729[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00025281679433532435 q_scale[0m
[[36m2025-02-19 19:47:42,895[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:47:42,896[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 026 __________________[0m
[[36m2025-02-19 19:47:42,897[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:47:42,897[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:47:52,545[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:47:52,552[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:47:52,552[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:47:52,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:47:52,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:47:52,684[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:47:52,685[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:47:52,686[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:47:52,687[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:47:53,141[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:47:54,743[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       16.16it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 56.454 
                                                               rmse/train:      
                                                               45.026           
[[36m2025-02-19 19:53:07,050[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:53:07,051[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/026[0m
[[36m2025-02-19 19:53:07,173[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:53:07,208[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0002175257618344715, lr[0m
[[36m2025-02-19 19:53:07,222[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:53:07,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15443972296330513 prior_scale[0m
[[36m2025-02-19 19:53:07,258[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015694584588120133 q_scale[0m
[[36m2025-02-19 19:53:07,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-19 19:53:07,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 027 __________________[0m
[[36m2025-02-19 19:53:07,274[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:53:07,274[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:53:17,956[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:53:17,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:53:17,964[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:53:17,966[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:53:17,966[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:53:17,967[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:53:17,968[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:53:17,968[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:53:17,969[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:53:18,020[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:53:18,719[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 8.99it/s v_num: 0.000     
                                                               rmse/val:        
                                                               2685.265         
                                                               rmse/train:      
                                                               2777.188         
[[36m2025-02-19 19:53:55,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:53:55,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/027[0m
[[36m2025-02-19 19:53:55,757[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:53:55,797[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00010984057067772252, lr[0m
[[36m2025-02-19 19:53:55,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:53:55,838[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.007301934118258236 prior_scale[0m
[[36m2025-02-19 19:53:55,868[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006056070399915061 q_scale[0m
[[36m2025-02-19 19:53:55,887[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-19 19:53:55,887[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 028 __________________[0m
[[36m2025-02-19 19:53:55,887[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:53:55,888[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:54:05,622[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:54:05,628[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:54:05,628[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:54:05,630[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:54:05,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:54:05,631[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:54:05,632[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:54:05,632[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:54:05,633[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:54:05,647[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:54:08,252[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:05 • 0:00:00 17.48it/s v_num: 0.000     
                                                               rmse/val: 62.270 
                                                               rmse/train:      
                                                               51.350           
[[36m2025-02-19 19:56:26,249[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:56:26,251[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/028[0m
[[36m2025-02-19 19:56:26,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:56:26,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006507147135583015, lr[0m
[[36m2025-02-19 19:56:26,442[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:56:26,491[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.6670023417651386 prior_scale[0m
[[36m2025-02-19 19:56:26,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5371406001661326 q_scale[0m
[[36m2025-02-19 19:56:26,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-19 19:56:26,535[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 029 __________________[0m
[[36m2025-02-19 19:56:26,536[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:56:26,536[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:56:36,495[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:56:36,502[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:56:36,502[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:56:36,504[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:56:36,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:56:36,505[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:56:36,506[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:56:36,506[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:56:36,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:56:36,556[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:56:39,804[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 12/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 12.91it/s v_num: 0.000     
                                                               rmse/val: 890.946
                                                               rmse/train:      
                                                               1128.963         
[[36m2025-02-19 19:57:11,591[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 12.
[[36m2025-02-19 19:57:12,298[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:57:12,405[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:57:12,451[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00039858386729232296, lr[0m
[[36m2025-02-19 19:57:12,471[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:57:12,504[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.31730371192912665 prior_scale[0m
[[36m2025-02-19 19:57:12,532[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00022722237749769626 q_scale[0m
[[36m2025-02-19 19:57:12,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-19 19:57:12,552[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 030 __________________[0m
[[36m2025-02-19 19:57:12,553[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:57:12,553[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:57:22,818[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:57:22,825[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:57:22,825[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:57:22,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:57:22,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:57:22,828[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:57:22,829[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:57:22,829[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:57:22,830[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:57:22,845[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:57:24,270[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 13.16it/s v_num: 0.000     
                                                               rmse/val: 166.927
                                                               rmse/train:      
                                                               149.541          
[[36m2025-02-19 19:58:14,166[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 19:58:14,167[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/030[0m
[[36m2025-02-19 19:58:14,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 19:58:14,309[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00020761114198439623, lr[0m
[[36m2025-02-19 19:58:14,324[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 19:58:14,342[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.043143625003094155 prior_scale[0m
[[36m2025-02-19 19:58:14,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0001947512734353313 q_scale[0m
[[36m2025-02-19 19:58:14,374[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 19:58:14,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 031 __________________[0m
[[36m2025-02-19 19:58:14,375[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 19:58:14,375[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 19:58:24,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 19:58:24,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 19:58:24,158[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 19:58:24,160[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 19:58:24,161[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 19:58:24,161[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 19:58:24,162[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 19:58:24,162[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 19:58:24,163[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 19:58:24,195[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 19:58:25,502[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.61it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 53.065 
                                                               rmse/train:      
                                                               44.082           
[[36m2025-02-19 20:02:57,128[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:02:57,130[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/031[0m
[[36m2025-02-19 20:02:57,259[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:02:57,318[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00033712577504425254, lr[0m
[[36m2025-02-19 20:02:57,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 20:02:57,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.09003849481600758 prior_scale[0m
[[36m2025-02-19 20:02:57,400[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003499864068608863 q_scale[0m
[[36m2025-02-19 20:02:57,422[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:02:57,423[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 032 __________________[0m
[[36m2025-02-19 20:02:57,424[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:02:57,424[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:03:07,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:03:07,518[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:03:07,518[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:03:07,522[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:03:07,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:03:07,523[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:03:07,524[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:03:07,524[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:03:07,526[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:03:07,576[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:03:09,989[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:10 •       17.76it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 54.205 
                                                               rmse/train:      
                                                               42.045           
[[36m2025-02-19 20:07:42,144[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:07:42,146[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/032[0m
[[36m2025-02-19 20:07:42,266[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:07:42,333[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035629709725730995, lr[0m
[[36m2025-02-19 20:07:42,352[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 20:07:42,375[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.12191596999050804 prior_scale[0m
[[36m2025-02-19 20:07:42,393[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004038267211935987 q_scale[0m
[[36m2025-02-19 20:07:42,409[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:07:42,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 033 __________________[0m
[[36m2025-02-19 20:07:42,410[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:07:42,410[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:07:52,026[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:07:52,033[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:07:52,033[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:07:52,035[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:07:52,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:07:52,036[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:07:52,037[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:07:52,037[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:07:52,038[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:07:52,085[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:07:52,847[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.12it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 53.733 
                                                               rmse/train:      
                                                               44.202           
[[36m2025-02-19 20:12:25,113[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:12:25,115[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/033[0m
[[36m2025-02-19 20:12:25,240[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:12:25,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032367871312388637, lr[0m
[[36m2025-02-19 20:12:25,291[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 20:12:25,310[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1155845475783687 prior_scale[0m
[[36m2025-02-19 20:12:25,329[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0033708456833970056 q_scale[0m
[[36m2025-02-19 20:12:25,348[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:12:25,349[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 034 __________________[0m
[[36m2025-02-19 20:12:25,349[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:12:25,349[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:12:35,141[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:12:35,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:12:35,148[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:12:35,150[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:12:35,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:12:35,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:12:35,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:12:35,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:12:35,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:12:35,199[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:12:36,948[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:12 •       15.98it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.457 
                                                               rmse/train:      
                                                               38.268           
[[36m2025-02-19 20:17:39,077[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:17:39,079[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/034[0m
[[36m2025-02-19 20:17:39,211[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:17:39,262[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00035487057048681704, lr[0m
[[36m2025-02-19 20:17:39,284[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 20:17:39,311[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.18382657867549812 prior_scale[0m
[[36m2025-02-19 20:17:39,339[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.004288795376663385 q_scale[0m
[[36m2025-02-19 20:17:39,359[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-19 20:17:39,360[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 035 __________________[0m
[[36m2025-02-19 20:17:39,360[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:17:39,360[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:17:49,725[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:17:49,732[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:17:49,732[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:17:49,733[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:17:49,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:17:49,734[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:17:49,735[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:17:49,735[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:17:49,736[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:17:49,787[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:17:51,956[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━━ 12/12 0:00:01 • 0:00:00 7.91it/s v_num: 0.000     
                                                               rmse/val: 662.504
                                                               rmse/train:      
                                                               766.011          
[[36m2025-02-19 20:18:34,022[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:18:34,023[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/035[0m
[[36m2025-02-19 20:18:34,159[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:18:34,199[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00043808074312795856, lr[0m
[[36m2025-02-19 20:18:34,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:18:34,238[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.08603023076259066 prior_scale[0m
[[36m2025-02-19 20:18:34,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0224280841777176 q_scale[0m
[[36m2025-02-19 20:18:34,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:18:34,278[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 036 __________________[0m
[[36m2025-02-19 20:18:34,279[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:18:34,279[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:18:44,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:18:44,339[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:18:44,339[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:18:44,342[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:18:44,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:18:44,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:18:44,345[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:18:44,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:18:44,346[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:18:44,364[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:18:47,511[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:06 •       29.16it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 79.965 
                                                               rmse/train:      
                                                               71.644           
[[36m2025-02-19 20:21:47,344[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:21:47,345[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/036[0m
[[36m2025-02-19 20:21:47,447[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:21:47,490[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0003177674612956481, lr[0m
[[36m2025-02-19 20:21:47,507[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 2 mc_samples_train[0m
[[36m2025-02-19 20:21:47,531[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4032752763787085 prior_scale[0m
[[36m2025-02-19 20:21:47,554[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.011023890267181178 q_scale[0m
[[36m2025-02-19 20:21:47,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:21:47,571[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 037 __________________[0m
[[36m2025-02-19 20:21:47,572[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:21:47,572[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:21:57,584[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:21:57,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:21:57,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:21:57,595[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:21:57,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:21:57,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:21:57,597[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:21:57,597[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:21:57,598[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:21:57,645[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:22:03,604[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:11 •       17.53it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 57.144 
                                                               rmse/train:      
                                                               63.648           
[[36m2025-02-19 20:26:59,256[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:26:59,258[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/037[0m
[[36m2025-02-19 20:26:59,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:26:59,466[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005574031557594498, lr[0m
[[36m2025-02-19 20:26:59,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:26:59,517[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.15263359978432264 prior_scale[0m
[[36m2025-02-19 20:26:59,547[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0026564843700889514 q_scale[0m
[[36m2025-02-19 20:26:59,567[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:26:59,568[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 038 __________________[0m
[[36m2025-02-19 20:26:59,568[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:26:59,569[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:27:09,745[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:27:09,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:27:09,754[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:27:09,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:27:09,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:27:09,757[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:27:09,758[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:27:09,758[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:27:09,759[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:27:09,813[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:27:11,674[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.48it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 47.979 
                                                               rmse/train:      
                                                               44.081           
[[36m2025-02-19 20:30:12,226[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:30:12,228[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/038[0m
[[36m2025-02-19 20:30:12,412[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:30:12,465[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006363986638647187, lr[0m
[[36m2025-02-19 20:30:12,486[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:30:12,515[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11391461605311784 prior_scale[0m
[[36m2025-02-19 20:30:12,543[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.01566549918672798 q_scale[0m
[[36m2025-02-19 20:30:12,564[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 64 batch_size[0m
[[36m2025-02-19 20:30:12,565[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 039 __________________[0m
[[36m2025-02-19 20:30:12,565[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:30:12,565[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:30:22,692[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:30:22,699[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:30:22,699[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:30:22,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:30:22,704[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:30:22,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:30:22,706[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:30:22,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:30:22,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:30:22,754[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:30:23,678[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 98/98 0:00:03 • 0:00:00 28.35it/s v_num: 0.000     
                                                               rmse/val: 65.887 
                                                               rmse/train:      
                                                               78.782           
[[36m2025-02-19 20:31:54,996[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:31:55,000[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/039[0m
[[36m2025-02-19 20:31:55,147[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:31:55,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 5.2706572166984026e-05, lr[0m
[[36m2025-02-19 20:31:55,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:31:55,249[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.1991502962542714 prior_scale[0m
[[36m2025-02-19 20:31:55,275[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0037555001751692226 q_scale[0m
[[36m2025-02-19 20:31:55,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 256 batch_size[0m
[[36m2025-02-19 20:31:55,297[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 040 __________________[0m
[[36m2025-02-19 20:31:55,298[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:31:55,298[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:32:05,695[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:32:05,702[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:32:05,703[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:32:05,705[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:32:05,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:32:05,706[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:32:05,707[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:32:05,707[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:32:05,708[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:32:05,754[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:32:10,244[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 24/24 0:00:00 • 0:00:00 25.31it/s v_num: 0.000     
                                                               rmse/val:        
                                                               3991.947         
                                                               rmse/train:      
                                                               4095.037         
[[36m2025-02-19 20:32:44,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:32:44,078[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/040[0m
[[36m2025-02-19 20:32:44,184[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:32:44,216[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00024850942979689865, lr[0m
[[36m2025-02-19 20:32:44,229[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:32:44,245[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.11896775837864178 prior_scale[0m
[[36m2025-02-19 20:32:44,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.002360282049637177 q_scale[0m
[[36m2025-02-19 20:32:44,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:32:44,274[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 041 __________________[0m
[[36m2025-02-19 20:32:44,275[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:32:44,275[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:32:54,140[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:32:54,148[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:32:54,149[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:32:54,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:32:54,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:32:54,152[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:32:54,152[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:32:54,153[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:32:54,153[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:32:54,171[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:32:54,995[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.12it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 53.042 
                                                               rmse/train:      
                                                               37.978           
[[36m2025-02-19 20:35:49,479[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:35:49,482[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/041[0m
[[36m2025-02-19 20:35:49,614[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:35:49,663[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005502170050939229, lr[0m
[[36m2025-02-19 20:35:49,684[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:35:49,712[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.06975253071444983 prior_scale[0m
[[36m2025-02-19 20:35:49,742[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0056089651797559086 q_scale[0m
[[36m2025-02-19 20:35:49,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:35:49,763[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 042 __________________[0m
[[36m2025-02-19 20:35:49,764[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:35:49,764[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:35:59,741[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:35:59,748[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:35:59,749[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:35:59,751[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:35:59,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:35:59,752[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:35:59,753[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:35:59,753[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:35:59,754[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:35:59,802[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:36:00,846[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:06 •       28.47it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 61.427 
                                                               rmse/train:      
                                                               44.133           
[[36m2025-02-19 20:38:57,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:38:57,977[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/042[0m
[[36m2025-02-19 20:38:58,128[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:38:58,177[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00032042960346764636, lr[0m
[[36m2025-02-19 20:38:58,195[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:38:58,220[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.4824680742396971 prior_scale[0m
[[36m2025-02-19 20:38:58,250[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009858436134119238 q_scale[0m
[[36m2025-02-19 20:38:58,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:38:58,272[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 043 __________________[0m
[[36m2025-02-19 20:38:58,272[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:38:58,272[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:39:08,319[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:39:08,325[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:39:08,326[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:39:08,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:39:08,329[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:39:08,330[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:39:08,331[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:39:08,331[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:39:08,334[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:39:08,380[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:39:10,104[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:06 •       28.78it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.694 
                                                               rmse/train:      
                                                               42.557           
[[36m2025-02-19 20:42:07,145[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:42:07,147[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/043[0m
[[36m2025-02-19 20:42:07,283[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:42:07,326[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 3.837549521677119e-05, lr[0m
[[36m2025-02-19 20:42:07,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:42:07,370[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.5569605135264493 prior_scale[0m
[[36m2025-02-19 20:42:07,395[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009253151256826019 q_scale[0m
[[36m2025-02-19 20:42:07,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:42:07,415[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 044 __________________[0m
[[36m2025-02-19 20:42:07,416[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:42:07,416[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:42:17,550[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:42:17,557[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:42:17,557[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:42:17,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:42:17,560[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:42:17,561[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:42:17,561[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:42:17,562[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:42:17,562[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:42:17,616[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:42:19,995[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.35it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 100.655
                                                               rmse/train:      
                                                               99.303           
[[36m2025-02-19 20:45:26,756[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:45:26,759[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/044[0m
[[36m2025-02-19 20:45:26,882[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:45:26,915[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00031964861448183874, lr[0m
[[36m2025-02-19 20:45:26,931[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:45:26,950[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.9696095345028837 prior_scale[0m
[[36m2025-02-19 20:45:26,968[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0024177987723031677 q_scale[0m
[[36m2025-02-19 20:45:26,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:45:26,986[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 045 __________________[0m
[[36m2025-02-19 20:45:26,987[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:45:26,987[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:45:36,862[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:45:36,868[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:45:36,869[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:45:36,871[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:45:36,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:45:36,872[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:45:36,873[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:45:36,873[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:45:36,874[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:45:36,916[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:45:37,846[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 28.35it/s v_num: 0.000     
                                                               rmse/val: 203.127
                                                               rmse/train:      
                                                               180.359          
[[36m2025-02-19 20:46:26,617[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:46:26,618[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/045[0m
[[36m2025-02-19 20:46:26,738[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:46:26,769[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007730227575218416, lr[0m
[[36m2025-02-19 20:46:26,782[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:46:26,800[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2881760395327305 prior_scale[0m
[[36m2025-02-19 20:46:26,819[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0015820277236672344 q_scale[0m
[[36m2025-02-19 20:46:26,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:46:26,834[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 046 __________________[0m
[[36m2025-02-19 20:46:26,834[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:46:26,834[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:46:36,460[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:46:36,467[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:46:36,467[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:46:36,469[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:46:36,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:46:36,471[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:46:36,472[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:46:36,472[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:46:36,473[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:46:36,486[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:46:38,409[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.58it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 23.547 
                                                               rmse/train:      
                                                               24.488           
[[36m2025-02-19 20:49:25,085[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:49:25,086[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/046[0m
[[36m2025-02-19 20:49:25,254[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:49:25,302[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007775621394184789, lr[0m
[[36m2025-02-19 20:49:25,327[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:49:25,353[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.42536336673129177 prior_scale[0m
[[36m2025-02-19 20:49:25,379[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001651252734115642 q_scale[0m
[[36m2025-02-19 20:49:25,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:49:25,399[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 047 __________________[0m
[[36m2025-02-19 20:49:25,400[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:49:25,400[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:49:35,055[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:49:35,062[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:49:35,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:49:35,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:49:35,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:49:35,065[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:49:35,066[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:49:35,066[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:49:35,067[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:49:35,115[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:49:37,316[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.43it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 44.432 
                                                               rmse/train:      
                                                               41.747           
[[36m2025-02-19 20:52:22,175[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:52:22,177[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/047[0m
[[36m2025-02-19 20:52:22,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:52:22,344[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007741150987621087, lr[0m
[[36m2025-02-19 20:52:22,365[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:52:22,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.44290072308456185 prior_scale[0m
[[36m2025-02-19 20:52:22,410[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.001680034895198947 q_scale[0m
[[36m2025-02-19 20:52:22,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 32 batch_size[0m
[[36m2025-02-19 20:52:22,425[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 048 __________________[0m
[[36m2025-02-19 20:52:22,426[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:52:22,426[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:52:32,054[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:52:32,060[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:52:32,060[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:52:32,062[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:52:32,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:52:32,063[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:52:32,064[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:52:32,064[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:52:32,065[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:52:32,108[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:52:33,321[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 195/195 0:00:05 •       33.23it/s v_num: 0.000     
                                     0:00:00                   rmse/val: 48.311 
                                                               rmse/train:      
                                                               45.081           
[[36m2025-02-19 20:55:12,019[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:55:12,021[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/048[0m
[[36m2025-02-19 20:55:12,136[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:55:12,169[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007964901622266018, lr[0m
[[36m2025-02-19 20:55:12,185[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:55:12,206[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.45881680257106094 prior_scale[0m
[[36m2025-02-19 20:55:12,232[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0010694705232140477 q_scale[0m
[[36m2025-02-19 20:55:12,251[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 512 batch_size[0m
[[36m2025-02-19 20:55:12,252[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 049 __________________[0m
[[36m2025-02-19 20:55:12,252[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:55:12,253[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:55:22,916[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:55:22,924[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:55:22,924[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:55:22,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:55:22,926[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:55:22,927[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:55:22,930[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:55:22,930[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:55:22,931[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:55:22,982[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:55:26,112[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 12/12 0:00:00 • 0:00:00 16.56it/s v_num: 0.000     
                                                               rmse/val: 145.120
                                                               rmse/train:      
                                                               129.280          
[[36m2025-02-19 20:55:50,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:55:50,668[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/049[0m
[[36m2025-02-19 20:55:50,780[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:55:50,816[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006388735487204058, lr[0m
[[36m2025-02-19 20:55:50,832[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:55:50,850[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.26718110464474126 prior_scale[0m
[[36m2025-02-19 20:55:50,869[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018216379683021913 q_scale[0m
[[36m2025-02-19 20:55:50,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:55:50,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 050 __________________[0m
[[36m2025-02-19 20:55:50,884[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:55:50,884[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:56:00,583[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:56:00,590[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:56:00,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:56:00,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:56:00,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:56:00,593[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:56:00,594[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:56:00,594[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:56:00,595[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:56:00,610[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:56:02,535[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 29.74it/s v_num: 0.000     
                                                               rmse/val: 66.006 
                                                               rmse/train:      
                                                               48.287           
[[36m2025-02-19 20:56:49,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:56:49,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/050[0m
[[36m2025-02-19 20:56:49,726[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:56:49,775[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007666653625843438, lr[0m
[[36m2025-02-19 20:56:49,791[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:56:49,811[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2640433041614966 prior_scale[0m
[[36m2025-02-19 20:56:49,829[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0017307795540234005 q_scale[0m
[[36m2025-02-19 20:56:49,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:56:49,847[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 051 __________________[0m
[[36m2025-02-19 20:56:49,847[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:56:49,848[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:56:59,581[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:56:59,588[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:56:59,588[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:56:59,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:56:59,590[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:56:59,591[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:56:59,592[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:56:59,592[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:56:59,593[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:56:59,637[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:57:00,993[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 29.26it/s v_num: 0.000     
                                                               rmse/val: 63.410 
                                                               rmse/train:      
                                                               53.755           
[[36m2025-02-19 20:57:50,681[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:57:50,682[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/051[0m
[[36m2025-02-19 20:57:50,798[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:57:50,842[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007885390614698347, lr[0m
[[36m2025-02-19 20:57:50,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:57:50,884[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.32453734165709613 prior_scale[0m
[[36m2025-02-19 20:57:50,902[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0018086780309550935 q_scale[0m
[[36m2025-02-19 20:57:50,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:57:50,935[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 052 __________________[0m
[[36m2025-02-19 20:57:50,936[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:57:50,936[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:58:00,761[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:58:00,768[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:58:00,768[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:58:00,770[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:58:00,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:58:00,771[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:58:00,772[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:58:00,772[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:58:00,773[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:58:00,805[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:58:02,865[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 29.10it/s v_num: 0.000     
                                                               rmse/val: 90.085 
                                                               rmse/train:      
                                                               70.432           
[[36m2025-02-19 20:58:52,234[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:58:52,235[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/052[0m
[[36m2025-02-19 20:58:52,371[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:58:52,420[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.000788290003227383, lr[0m
[[36m2025-02-19 20:58:52,438[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:58:52,463[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2612324342708461 prior_scale[0m
[[36m2025-02-19 20:58:52,488[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0016515960546614067 q_scale[0m
[[36m2025-02-19 20:58:52,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:58:52,506[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 053 __________________[0m
[[36m2025-02-19 20:58:52,507[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:58:52,507[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 20:59:02,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 20:59:02,272[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 20:59:02,273[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 20:59:02,274[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 20:59:02,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 20:59:02,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 20:59:02,276[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 20:59:02,276[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 20:59:02,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 20:59:02,308[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 20:59:02,433[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:02 • 0:00:00 24.31it/s v_num: 0.000     
                                                               rmse/val: 65.597 
                                                               rmse/train:      
                                                               55.855           
[[36m2025-02-19 20:59:59,075[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 20:59:59,076[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/053[0m
[[36m2025-02-19 20:59:59,215[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 20:59:59,271[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006505220137515962, lr[0m
[[36m2025-02-19 20:59:59,294[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 20:59:59,317[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.29346304968791825 prior_scale[0m
[[36m2025-02-19 20:59:59,338[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007041063773569427 q_scale[0m
[[36m2025-02-19 20:59:59,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 20:59:59,358[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 054 __________________[0m
[[36m2025-02-19 20:59:59,358[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 20:59:59,359[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:00:09,260[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:00:09,266[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:00:09,266[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:00:09,269[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:00:09,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:00:09,270[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:00:09,271[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:00:09,271[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:00:09,272[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:00:09,304[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:00:10,204[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 26.39it/s v_num: 0.000     
                                                               rmse/val: 73.600 
                                                               rmse/train:      
                                                               56.234           
[[36m2025-02-19 21:01:04,025[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:01:04,027[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/054[0m
[[36m2025-02-19 21:01:04,157[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 21:01:04,196[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006677374103199373, lr[0m
[[36m2025-02-19 21:01:04,213[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 21:01:04,233[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2824837110080889 prior_scale[0m
[[36m2025-02-19 21:01:04,257[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0005418380682789308 q_scale[0m
[[36m2025-02-19 21:01:04,276[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 21:01:04,277[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 055 __________________[0m
[[36m2025-02-19 21:01:04,277[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 21:01:04,277[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:01:13,963[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:01:13,970[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:01:13,970[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:01:13,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:01:13,973[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:01:13,974[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:01:13,975[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:01:13,975[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:01:13,976[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:01:14,018[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:01:14,562[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 25.17it/s v_num: 0.000     
                                                               rmse/val: 44.946 
                                                               rmse/train:      
                                                               33.179           
[[36m2025-02-19 21:02:07,999[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:02:08,001[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/055[0m
[[36m2025-02-19 21:02:08,140[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 21:02:08,181[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0008652817533150435, lr[0m
[[36m2025-02-19 21:02:08,200[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 21:02:08,221[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.22600926568020038 prior_scale[0m
[[36m2025-02-19 21:02:08,242[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007852870011666664 q_scale[0m
[[36m2025-02-19 21:02:08,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 21:02:08,261[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 056 __________________[0m
[[36m2025-02-19 21:02:08,261[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 21:02:08,261[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:02:18,589[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:02:18,596[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:02:18,596[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:02:18,599[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:02:18,600[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:02:18,601[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:02:18,601[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:02:18,602[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:02:18,603[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:02:18,639[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:02:18,841[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 24.97it/s v_num: 0.000     
                                                               rmse/val: 51.515 
                                                               rmse/train:      
                                                               44.482           
[[36m2025-02-19 21:03:13,015[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:03:13,016[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/056[0m
[[36m2025-02-19 21:03:13,174[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 21:03:13,217[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0009001325566888042, lr[0m
[[36m2025-02-19 21:03:13,234[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 21:03:13,260[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.2468952372867076 prior_scale[0m
[[36m2025-02-19 21:03:13,282[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.05320235517324705 q_scale[0m
[[36m2025-02-19 21:03:13,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 21:03:13,300[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 057 __________________[0m
[[36m2025-02-19 21:03:13,300[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 21:03:13,301[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:03:23,311[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:03:23,318[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:03:23,318[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:03:23,321[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:03:23,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:03:23,322[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:03:23,323[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:03:23,323[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:03:23,324[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:03:23,358[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:03:27,954[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 33.97it/s v_num: 0.000     
                                                               rmse/val: 75.270 
                                                               rmse/train:      
                                                               133.732          
[[36m2025-02-19 21:04:20,973[0m][[34mutils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/utils/utils.py", line 39, in wrap
    metric_dict, object_dict = task_func(cfg=cfg, trial=trial)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/bin/bayesaenet/bnn_aenet/tasks/train.py", line 92, in train
    trainer.fit(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 141, in run
    self.on_advance_end(data_fetcher)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 295, in on_advance_end
    self.val_loop.run()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 268, in on_run_end
    self._on_evaluation_end()
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 313, in _on_evaluation_end
    call._call_callback_hooks(trainer, hook_name, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 208, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/g15farris/.conda/envs/bnn/lib/python3.12/site-packages/optuna_integration/pytorch_lightning.py", line 117, in on_validation_end
    raise optuna.TrialPruned(f"Trial was pruned at epoch {epoch}.")
optuna.exceptions.TrialPruned: Trial was pruned at epoch 19.
[[36m2025-02-19 21:04:21,275[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:04:21,387[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 21:04:21,440[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00044979907655165187, lr[0m
[[36m2025-02-19 21:04:21,462[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 21:04:21,489[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.34593615690974117 prior_scale[0m
[[36m2025-02-19 21:04:21,518[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0007952162302181156 q_scale[0m
[[36m2025-02-19 21:04:21,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 21:04:21,539[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 058 __________________[0m
[[36m2025-02-19 21:04:21,540[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 21:04:21,540[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:04:31,399[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:04:31,405[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:04:31,406[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:04:31,409[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:04:31,410[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:04:31,411[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:04:31,411[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:04:31,412[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:04:31,413[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:04:31,448[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:04:35,036[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 24.69it/s v_num: 0.000     
                                                               rmse/val: 70.114 
                                                               rmse/train:      
                                                               55.291           
[[36m2025-02-19 21:05:28,667[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:05:28,669[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/058[0m
[[36m2025-02-19 21:05:28,821[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0 pretrain_epochs[0m
[[36m2025-02-19 21:05:28,862[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.00046583531412183445, lr[0m
[[36m2025-02-19 21:05:28,880[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 1 mc_samples_train[0m
[[36m2025-02-19 21:05:28,904[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.8691154400447709 prior_scale[0m
[[36m2025-02-19 21:05:28,926[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 0.0006513758012240511 q_scale[0m
[[36m2025-02-19 21:05:28,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - 128 batch_size[0m
[[36m2025-02-19 21:05:28,945[0m][[34mbnn_aenet.tasks.hpsearch[0m][[32mINFO[0m] - _________________ Starting trial 059 __________________[0m
[[36m2025-02-19 21:05:28,946[0m][[34mutils.utils[0m][[33mWARNING[0m] - Extras config not found! <cfg.extras=null>[0m
[[36m2025-02-19 21:05:28,946[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating datamodule <bnn_aenet.datamodule.aenet_datamodule.AenetDataModule>[0m
0.1
(0.06565926932648217, 6.6588702845000975)
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
Train indices: 6253 [5757, 588, 2127, 6217, 1585]
Valid indices: 781 [5719, 2261, 1413, 2713, 5799]
Test indices: 781 [2496, 6248, 7331, 3091, 4123]
0.06565926932648217 6.6588702845000975
[[36m2025-02-19 21:05:39,144[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating model <bnn_aenet.models.bnn.BNN>[0m
[[36m2025-02-19 21:05:39,151[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-02-19 21:05:39,151[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-02-19 21:05:39,154[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-02-19 21:05:39,156[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-02-19 21:05:39,157[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating callback <optuna.integration.PyTorchLightningPruningCallback>[0m
[[36m2025-02-19 21:05:39,158[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-02-19 21:05:39,159[0m][[34mutils.utils[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-02-19 21:05:39,161[0m][[34mtrain[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-02-19 21:05:39,212[0m][[34mtrain[0m][[32mINFO[0m] - Logging hyperparameters![0m
[[36m2025-02-19 21:05:43,808[0m][[34mtrain[0m][[32mINFO[0m] - Starting training![0m
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                              ┃ Type       ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                               │ NetAtom    │  2.7 K │
│ 1  │ net.networks                      │ ModuleList │  2.7 K │
│ 2  │ net.networks.0                    │ Sequential │  1.3 K │
│ 3  │ net.networks.0.Linear_Layer_1     │ Linear     │  1.1 K │
│ 4  │ net.networks.0.Activation_Layer_1 │ Tanh       │      0 │
│ 5  │ net.networks.0.Linear_Layer_2     │ Linear     │    240 │
│ 6  │ net.networks.0.Output_Layer       │ Linear     │     32 │
│ 7  │ net.networks.1                    │ Sequential │  1.3 K │
│ 8  │ net.networks.1.Linear_Layer_1     │ Linear     │  1.1 K │
│ 9  │ net.networks.1.Linear_Layer_2     │ Linear     │    240 │
│ 10 │ net.networks.1.Output_Layer       │ Linear     │     32 │
└────┴───────────────────────────────────┴────────────┴────────┘
Trainable params: 2.7 K                                                         
Non-trainable params: 0                                                         
Total params: 2.7 K                                                             
Total estimated model params size (MB): 0                                       
Epoch 19/19 ━━━━━━━━━━━━━━━━ 49/49 0:00:01 • 0:00:00 27.47it/s v_num: 0.000     
                                                               rmse/val: 135.842
                                                               rmse/train:      
                                                               102.764          
[[36m2025-02-19 21:06:35,776[0m][[34mutils.utils[0m][[32mINFO[0m] - Closing loggers...[0m
[[36m2025-02-19 21:06:35,778[0m][[34mutils.utils[0m][[32mINFO[0m] - Output dir: /home/g15farris/bin/bayesaenet/bnn_aenet/logs/TiO_hps_rad/runs/2025-02-19_18-17-24/059[0m
[[36m2025-02-19 21:06:35,901[0m][[34m__main__[0m][[32mINFO[0m] - Number of finished trials: 60[0m
