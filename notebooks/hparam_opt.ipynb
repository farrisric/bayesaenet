{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/anaconda3/envs/bayesian/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from ase.db import connect\n",
    "import pyro\n",
    "from models.bnn import BNN\n",
    "from models.nets.network import NetAtom\n",
    "import torch\n",
    "import pytorch_lightning as L\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from optuna import Study\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "from datamodule.aenet_datamodule import AenetDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodele = AenetDataModule('/home/riccardo/bin/repos/aenet-bayesian/examples/liquid_water/train.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NetAtom(\n",
    "    datamodele.input_size, \n",
    "    datamodele.hidden_size, \n",
    "    datamodele.species, \n",
    "    datamodele.active_names, \n",
    "    datamodele.alpha,\n",
    "    'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'net': net,\n",
    "        'lr': 0.00055,\n",
    "        'pretrain_epochs': 0,\n",
    "        'mc_samples_train': 1,\n",
    "        'mc_samples_eval': 20, \n",
    "        'dataset_size': datamodele.train_size, \n",
    "        'fit_context': 'lrt', \n",
    "        'prior_loc': 1, \n",
    "        'prior_scale': 1, \n",
    "        'guide': 'normal', \n",
    "        'q_scale': 1.,\n",
    "        'obs_scale' : 10.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyro.optim.optim.PyroOptim at 0x797d7b6fe000>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "ClippedAdam({'lr': 0.0001, 'betas': [0.95, 0.999], 'clip_norm': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='elbo/val', min_delta = 0., # minimum change in the monitored quantity to qualify as an improvement\n",
    "  patience= 3, # number of checks with no improvement after which training will be stopped\n",
    "  verbose= False, # verbosity mode\n",
    "  mode= \"min\", # \"max\" means higher metric value is better, can be also \"min\"\n",
    "  strict= True, # whether to crash the training if monitor is not found in the validation metrics\n",
    "  check_finite= True,) # when set True, stops training when the monitor becomes NaN or infinite\n",
    "#   'stopping_threshold'= null, # stop training immediately once the monitored quantity reaches this threshold\n",
    "#   'divergence_threshold'= null, # stop training as soon as the monitored quantity becomes worse than this threshold\n",
    "#   'check_on_train_epoch_end'= null,)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='elbo/val',\n",
    "    patience=100,\n",
    "    mode='min' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_root_dir = '../examples/liquid_water/'\n",
    "\n",
    "def objective(trial: Trial, model_kwargs : dict, output_dir: str):\n",
    "    # model_kwargs['pretrain_epochs'] = trial.suggest_categorical(\n",
    "    #         \"pretrain_epochs\", [0, 5]\n",
    "    #     )\n",
    "    model_kwargs['lr'] = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "    #model_kwargs['prior_loc'] = trial.suggest_float(\"prior_loc\", 0., 1., log=True)\n",
    "    model_kwargs['prior_scale'] = trial.suggest_float(\"prior_scale\", 0.1, 5, log=True)\n",
    "    model_kwargs['q_scale'] = trial.suggest_float(\"q_scale\", 1e-4, 5, log=True)\n",
    "    model_kwargs['obs_scale'] = trial.suggest_float(\"obs_scale\", 0.1, 5, log=True)\n",
    "\n",
    "    model = BNN(**model_kwargs)\n",
    "    trainer = L.Trainer(min_epochs = 1, max_epochs = 20, default_root_dir=default_root_dir, callbacks=early_stopping)\n",
    "    trainer.fit(model=model, datamodule=datamodele)\n",
    "\n",
    "    return trainer.callback_metrics['elbo/val'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite://///home/riccardo/bin/repos/aenet-bnn/src/results/bnn_lrt.db\", pool_pre_ping=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbnn_hyperparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqlite:///../../bnn_lrt.db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminimize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna_log\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      9\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m     10\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m         catch\u001b[38;5;241m=\u001b[39m(\u001b[38;5;167;01mRuntimeError\u001b[39;00m,),\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/bayesian/lib/python3.12/site-packages/optuna/study/study.py:1136\u001b[0m, in \u001b[0;36mcreate_study\u001b[0;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to direction. You can also set the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding `StudyDirection` member.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1130\u001b[0m     )\n\u001b[1;32m   1132\u001b[0m direction_objects \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1133\u001b[0m     d \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d, StudyDirection) \u001b[38;5;28;01melse\u001b[39;00m StudyDirection[d\u001b[38;5;241m.\u001b[39mupper()] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m directions\n\u001b[1;32m   1134\u001b[0m ]\n\u001b[0;32m-> 1136\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[43mstorages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1138\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mcreate_new_study(study_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/bayesian/lib/python3.12/site-packages/optuna/storages/__init__.py:31\u001b[0m, in \u001b[0;36mget_storage\u001b[0;34m(storage)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RedisStorage(storage)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(\u001b[43mRDBStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(storage, RDBStorage):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(storage)\n",
      "File \u001b[0;32m~/anaconda3/envs/bayesian/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py:187\u001b[0m, in \u001b[0;36mRDBStorage.__init__\u001b[0;34m(self, url, engine_kwargs, skip_compatibility_check, heartbeat_interval, grace_period, failed_trial_callback)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version_manager \u001b[38;5;241m=\u001b[39m _VersionManager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_compatibility_check:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_table_schema_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bayesian/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py:1310\u001b[0m, in \u001b[0;36m_VersionManager.check_table_schema_compatibility\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1306\u001b[0m version_info \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mVersionInfoModel\u001b[38;5;241m.\u001b[39mfind(session)\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m version_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1310\u001b[0m current_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m head_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_version()\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_version \u001b[38;5;241m==\u001b[39m head_version:\n",
      "File \u001b[0;32m~/anaconda3/envs/bayesian/lib/python3.12/site-packages/optuna/storages/_rdb/storage.py:1337\u001b[0m, in \u001b[0;36m_VersionManager.get_current_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1335\u001b[0m context \u001b[38;5;241m=\u001b[39m alembic\u001b[38;5;241m.\u001b[39mmigration\u001b[38;5;241m.\u001b[39mMigrationContext\u001b[38;5;241m.\u001b[39mconfigure(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mconnect())\n\u001b[1;32m   1336\u001b[0m version \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mget_current_revision()\n\u001b[0;32m-> 1337\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m version\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name='bnn_hyperparams',\n",
    "    storage=\"sqlite:///../../bnn_lrt.db\",\n",
    "    directions=[\"minimize\"]\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "        lambda trial: objective(trial, model_kwargs=model_kwargs, output_dir='optuna_log'),\n",
    "        n_trials=60,\n",
    "        timeout=None,\n",
    "        catch=(RuntimeError,),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
